[
{"docid": "1 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "August 10, 2016", "title": "Apple buys Turi machine-learning startup for a reported $200m; Turi lets developers and data scientists incorporate machine learning and artificial intelligence into their apps\n", "content": "                     Apple has reportedly bought a Seattle-based machine-learningstartup as part of its continued investment in artificial intelligence.\nThe quiet deal, first reported by Geekwire, is said to be worth around $200m (\u00a3153m).\u00a0\nTuri, which uses the tagline \"create intelligence\", let developers and data scientists incorporate machine learning and artificial intelligence into their apps.\nRead more\nApple set to unveil artificial intelligence plans at WWDC conference\nIts tools are mostly using machine learning to help companies to understand data such as sentiment analysis on social media or customer segmentation.\nApple's purchase of Turi is a further proof the company is ready to put more resources into artificial intelligence.\nTim Cook, Apple's chief executive, talked about longer term opportunities including the potential he sees in artificial intelligence earlier this month on Apple's earnings conference call.\n\"We have focused our AI efforts on the features that best enhance the customer experience,\" Mr Cook said.\n\"We're also using machine learning in many other ways across our products and services, including recommending songs, apps, and news,\" he added.\nRead more\nMachine Of Human Dreams explores how artificial intelligence could one day overtake mankind\nGoogle Calendar 'Goals' update uses artificial intelligence to make its users into better people\nFacebook artificial intelligence technology lets blind people 'see' photos\nLast year, Apple also bought VocalIQ, a UK based artificial intelligence-powered company that aims to make robots easier to speak to and could lead to improvements in its voice assistant, Siri.\nThe company has been aggressively hiring experts including those from other companies like Google, Amazon and Facebook, in addition to the VoicaIlQ acquisition.\nApple is also facing competition from Google and Facebook which have already announced greater focus on their artificial intelligence products this year.\nWhile Google is improving its Google Now software, Facebook is introducing intelligent \"bots\" to its Messenger service that can understand requests and questions from users.\nApple declined to say how much it paid for Turi but confirmed the deal.\n\"Apple buys smaller technology companies from time to time, and we generally do not discuss our purpose or plans,\" the company said in a statement.\n"},
{"docid": "2 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "November 8, 2017", "title": "Bias, not robots on the rampage, is the key test of artificial intelligence\n", "content": "Beneath the excitement generated by the way in which artificial intelligence can reshape and improve our lives and our businesses - by driving cars for us, processing invoices or reading medical scans - lie two perplexing thoughts.\nThe first is a finding from Sage, the software company, this week that nearly half of consumers have \"no idea what artificial intelligence is all about\", even though many feel vaguely optimistic about its ability to improve lives, tempered by lesser fears of a robot takeover. The second is that we are allowing opaque and potentially biased mathematical models underpinning artificial intelligence to reshape our daily existence unchecked. You might not think that the first matters very much, until you consider the effects of the second.\nArtificial intelligence isn't science fiction. It is a practical engineering tool, decades in the making, which only now is becoming practical in solving real-world problems because of the availability of computational power and rich sources of data. It is particularly good for repetitive, process-driven tasks. Give it hundreds of thousands of data points and it can identify a human face in a photo or translate a document, although it still has a long way to go in delivering on many of its promises, such as self-driving cars.\u00a0\nYet a big problem arises if hidden biases are written inadvertently into the algorithms used to decide who gets a job interview or who qualifies for a loan or for parole. If a data set considers the word \"programmer\" closer to the word \"man\" than \"woman,\" or it you build a system that learns from Wikipedia, where only 17 per cent of profiles of notable people are women, these biases will be perpetuated in the machine. The consequences could be dire, entrenching rather than removing the existing discrimination perpetrated by humans.\nThis was one issue under discussion yesterday by the House of Lords select committee on artificial intelligence, which in the past few weeks has been holding a muchneeded series of hearings on the implications of the technology. Among those giving evidence was Kriti Sharma, vice-president of artificial intelligence at Sage, who warned that unless we build artificial intelligence using diverse teams, data sets and design, we are at risk of repeating the inequality of previous industrial revolutions.\nWe've known this for years, yet it persists as a problem. Instead of a robust public debate on algorithmic bias, we are fed a constant diet of stories about killer robots running out of control that hugely exaggerate the present state of artificial intelligence without enhancing our understanding of what it can actually do. John Giannandrea, Google's artificial intelligence chief, is among those trying to focus attention away from the \"artificial intelligence apocalypse\" and on to the question of bias. This, he argued recently, is \"the real safety question\" and one that will only become more significant as AI use spreads in critical areas such as medicine.\nOne way to eliminate artificial intelligence bias might be through encouraging more data-sharing through protocols that would allow the big technology companies, which dominate in data ownership, to open it up to a more diverse group of start-ups and researchers. Another would be to test all software for bias, in much the same way that it is routinely tested for useability.\nThere is nothing predestined about the impact of artificial intelligence. Its development depends on human choices and we must reject the notion that it can ever become too clever to be accountable. We don't accept that kind of behaviour from other \"expert\" professions. There's no reason why technology should be the exception.\nAlexandra Frean is Business Columnist of The Times\n"},
{"docid": "3 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "April 15, 1986", "title": " Computer Horizons: Smart way to capture magic minds on screen (639) /SCT\n", "content": "\u00a0\n One thing the gurus are agreed upon: artificial intelligence is a terrible name to be burdened with. What they are also prepared to tell you at some length is what artificial intelligence is not.\n It is not magic, not a mystery, not philosophy, not psychology, and yet ..it is still magical. It can be a trifle mysterious but, once understood, seems to have less to do with intelligence than with good, human common sense translated into a codified medium.\u00a0\n Professor Patrick Winston, head of the Artificial Intelligence Laboratory at the Massachusetts Institute of Technology, is found of homely allusions.\n He likes to stand cocktail party questions on their head. Asked: 'Can computers ever be as smart as people?', he will answer: 'Can people ever be as smart as computers?'\n He told a recent seminar at Cannes, hosted by Digital Equipment Corporation: 'Artificial intelligence is the enterprise of trying to make machines smart, bearing in mind there are two kinds of people who want to make machines more useful and those who want to understand intelligence.\n 'This means that at one end of the spectrum artificial intelligence is populated by what some might think of as lunatic fringe psychologists and computer scientists. At the other end it is populated by people who want to make a lot of money.\n 'The thing that brings us together is trying to develop machines that have something like human intelligence. Because there is a religious-like zeal in this quest, artificial intelligence will steal any kind of technology that will serve these primary objectives. '\n So, again, what does artificial intelligence embrace? Not just robotics, which is always looked on as the 'sexy' bit.\n 'We are,' says the professor, 'involved in automatic analysis and design that some people call expert systems. We are involved in natural language. We are involved in trying to make machines learn. We are involved in speech.\n 'Sometimes computers do things that seems real smart, that turn out not to seem so smart once you understand how they reason step by step,' he says. '\n What the pundits insist on is that artificial intelligence is not new or revolutionary, but part of the evolution of computer systems. It is largely about solving problems - problems in manufacturing, medicine, engineering, education - in which artificial intelligence can take the drudgery out of the research. It can also allow the expert to concentrate on the key questions that can be handled only by the innovative, human mind.\n John Mucci, manager of Digital's artificial intelligence marketing group in the US, gave the Cannes group a hard look at artificial intelligence in the market place. He said: 'There is simply a people shortage for both skilled labour, such as welders in manufacturing, or for experts in any field. '\n John Mucci emphasizes the role of the individual in using artificial intelligence to improve productivity. Half the world's personal computers are doing nothing, he says.\n The personal computers and work stations that have given access to tools like financial spreadsheets and word processing to millions of people, are local resources implying fundamental limitations. He calls them in a telling description 'islands of automation'.\n Just as important is the capturing of unique knowledge and experience which can be lost when someone retires, dies or leaves the company. Expert systems are being created to preserve this priceless intelligence. No doubt there will be a new awareness of the value of this kind of experience.\n Arnold Kraft, consultant with Digital's artificial intelligence marketing group, points to many companies which are using expert systems to good effect - using systems to diagnose faults.\n One of the most exciting advances in artificial intelligence is the development of natural language - computer talk for the kind of language we use, be it English, French or Serbo-Croat.\n At Digital's European Technical Centre at Valbonne, the visitor is invited to put questions in basic English to the computer in a limited field of inquiry. How long before the computer provides a cheeky answer?\n"},
{"docid": "4 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "February 25, 2015", "title": "Artificial intelligence could kill us because we're stupid, not because it's evil, says expert; Building artificial intelligence in humanity's image will make it dangerous, says leading theorist\n", "content": "Artificial\u00a0intelligence will be a threat because we are stupid, not because it is clever and evil, according to experts.\nWe could put ourselves in danger by creating artificial intelligence that looks too much like ourselves, a leading theorist has warned. \"If we look for A.I. in the wrong ways, it may emerge in forms that are needlessly difficult to recognize, amplifying its risks and retarding its benefits,\" writes theorist Benjamin H Bratton in the New York Times.\u00a0\nThe warning comes partly in response to similar worries voiced by leading technologists and scientists including Elon Musk and Stephen Hawking. They and hundreds of other experts signed a letter last month calling for research to combat the dangers of artificial intelligence.\nBut many of those worries seem to come from thinking that robots will care deeply about humanity, for better or worse. We should abandon that idea, Bratton proposes.\n\"Perhaps what we really fear, even more than a Big Machine that wants to kill us, is one that sees us as irrelevant,\" he writes. \"Worse than being seen as an enemy is not being seen at all.\"In pictures: Artificial\u00a0intelligence through history\nInstead we should start thinking about artificial intelligence as something more than the image of human intelligence. Tests like that proposed by Alan Turing, which challenges artificial intelligence to pass as a human, reflect the fact that our thinking about what kinds of intelligence there might be is limited, according to Bratton. \n\"That we would wish to define the very existence of A.I. in relation to its ability to mimic how humans think that humans think will be looked back upon as a weird sort of speciesism,\" he writes. \"The legacy of that conceit helped to steer some older A.I. research down disappointingly fruitless paths, hoping to recreate human minds from available parts. It just doesn't work that way.\"\nOther experts in artificial intelligence have pointed out that we don't tend to build other technology to mimic biology. Planes, for instance, aren't designed to mimic the flight of birds, and it could be a mistake to do the same with humanity.\nRetaining our idea that intelligence only exists as it does in humans could also mean that we force robots to \"pass\" as a person in a way that Bratton likens to being \"in drag as a human\".\n\"We would do better to presume that in our universe, 'thinking' is much more diverse, even alien, than our own particular case,\" he writes. \"The real philosophical lessons of A.I. will have less to do with humans teaching machines how to think than with machines teaching humans a fuller and truer range of what thinking can be (and for that matter, what being human can be).\"\n"},
{"docid": "5 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "October 26, 2014", "title": "Tesla boss Elon Musk warns artificial intelligence development is 'summoning the demon'; The\u00a0business magnate, inventor and investor has warned about artificial intelligence\u00a0before\n", "content": "Tesla chief executive Elon Musk has described artificial intelligence as a \"demon\" and the \"biggest existential threat there is\", in his latest dramatic statement about technology.\u00a0\nAddressing students at the Massachusetts Institute of Technology, Musk said: \"I think we should be very careful about artificial intelligence. If I were\u00a0to guess like what our biggest existential threat\u00a0is, it's probably\u00a0that.\n\"With artificial intelligence we are summoning the demon. In all those stories where there's the guy with the pentagram and the holy water, it's like yeah he's sure he can control the demon. Didn't work out.\"\u00a0\nThe\u00a0business magnate, inventor and investor, who is also CEO and CTO of\u00a0SpaceX, and\u00a0chairman\u00a0of\u00a0SolarCity, has warned about artificial intelligence\u00a0before, which he believes could be more threatening than nuclear weapons.\nIn August he\u00a0tweeted: \"Worth reading Superintelligence by Bostrom. We need to be super careful with AI. Potentially more dangerous than nukes.\"\u00a0\nWorth reading Superintelligence by Bostrom. We need to be super careful with AI. Potentially more dangerous than nukes.- Elon Musk (@elonmusk) August 3, 2014\nIn another Twitter post he said: \"Hope we're not just the biological boot loader for digital superintelligence. Unfortunately, that is increasingly probable.\"\nDuring his MIT appearance Musk also discussed his company SpaceX's plans to help populate Mars. \"It's cool to send one mission to Mars, but that's not what will change the future for humanity,\" he said.\n\"What matters is being able to establish a self-sustaining\u00a0 civilisation on Mars, and I don't see anything being done but SpaceX. I don't see anyone else even trying.\"\nMusk left the symposium to a standing ovation. Watch the whole thing here. \u00a0\n"},
{"docid": "6 of 500 DOCUMENTS\n", "source": "The Independent - Daily Edition\n", "date": "August 11, 2016", "title": "Apple buys artificial intelligence firm for \u00a3150m\n", "content": "Apple has reportedly bought a Seattle-based machine-learning startup as part of its continued investment in artificial intelligence. The quiet deal, first reported by news website GeekWire, is said to be worth around $ 200m (\u00a3 153m).\u00a0\nTuri helps developers and data scientists incorporate machine learning and artificial intelligence into their apps. Its tools mostly use machine learning to help companies to understand data such as sentiment analysis on social media or customer segmentation. The purchase of Turi is further proof Apple is ready to put more resources into artificial intelligence.\nTim Cook, Apple's chief executive, talked about the potential he sees in artificial intelligence during Apple's earnings conference call earlier this month. \"We have focused our AI efforts on the features that best enhance the customer experience. We're also using machine learning in many other ways across our products and services, including recommending songs, apps, and news,\" Mr Cook said.\nLast year, the tech giant also bought vocaliq, a UK based artificial intelligence-powered company that aims to make robots easier to speak to and could lead to improvements in Apple's voice assistant, Siri. The company has also been aggressively hiring experts from rivals like Google, Amazon and Facebook.\nGoogle and Facebook have already announced greater focus on their artificial intelligence products this year. While Google is working on improving its Google Now software, Facebook is introducing intelligent \"bots\" to its Messenger service that can understand requests and questions from users. Apple declined to say how much it paid for Turi but confirmed the deal. \"Apple buys smaller technology companies from time to time, and we generally do not discuss our purpose or plans,\" the company said in a statement.\n"},
{"docid": "7 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "April 16, 2018", "title": "Cambridge Analytica scandal 'highlights need for AI regulation'; Lords report stresses need for artificial intelligence to be used for the common good\n", "content": "The goal is not to write the principles directly into legislation, Clement-Jones said, but rather to have them as a broad guiding beacon for AI regulation. \"For instance, in the financial services area it would be the Financial Conduct Authority\" that actually applied the principles, \"and they would be looking at how insurance companies use algorithms to assess your premiums, how banks assess people for mortgages, and so on and so forth.\n\"Basically, these regulators have to make the connection with the ethics, and this is the way we think they should do it,\" Clement-Jones said. \"Of course, if in due course people are not observing these ethical principles and the regulator thinks that their powers are inadequate, then there may be a time down the track that we need to rethink this.\"\nIn a wide-ranging report, the committee has identified a number of threats that mismanagement of AI could bring to Britain. One concern is of the creation of \"data monopolies\", large multinational companies - generally American or Chinese, with Facebook, Google and Tencent all named as examples - with such a grip on the collection of data that they can build better AI than anyone else, enhancing their grip on the data sources and creating a virtuous cycle that renders smaller companies and nations unable to compete.\nThe report stops short of calling for active enforcement to prevent the creation of data monopolies, but does explicitly recommend that the Competition and Markets Authority \"review proactively the use and potential monopolisation of data by the big technology companies operating in the UK\".\nClement-Jones said: \"We want there to be an open market in AI, basically, and if all that happens is we get five or six major AI systems and you have to belong to one of them in order to survive in the modern world, well, that would be something that we don't want to see.\"\n"},
{"docid": "8 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "May 24, 2017", "title": "Half of UK companies believe AI will 'fundamentally change' their industry; The UK must act quickly to avoid a knowledge 'chasm'asthe rapidly-developing technology outpaces growth in the number of peoplewho understand it\n", "content": "The UK must act quickly to avoid a knowledge \"chasm\" in the rapidly-developing world of artificial intelligence (AI), as international competition heats up, according to a leading business group.\u00a0\nAlmost half of firms believe the current wave of technology will fundamentally transform their industry, but only a third feel their business has the skills to adapt, according to a new survey by the Confederation of British Industryin association with IBM.\nThe CBI warned of a growing digital gap between those UK firms that are leading the way on technological developments and those who are being left behind.\nRead more\nArtificial\u00a0intelligence is learning to be racist\nAI investment is gaining momentum with 42 per cent of companies planning to ramp up spending over the next five years while one in five have already done so over the past 12 months.\nCompanies are also investing in the internet of things which links appliances together as well as advanced analytics which allows companies to gain insights from huge amounts of data.\nThe CBI said: \"Innovation in business is essential for advanced economies such as the UK. It is the chief driver of sustainable economic growth and a major source of productivity gains. It also pulls in overseas investment, supporting thousands of jobs across the country.\nRead more\nBudget to include prizes for robotics, AI and new batteries\nFacebook using artificial intelligence to help suicidal users\nArtificial\u00a0intelligence set to handle O2 customer services from 2017\nGovernment invests \u00a320m in robotics and artificial intelligence\u00a0\nThis British startup is using artificial intelligence to compose music\n\"British businesses are directing resources into new technology, with cloud, mobile and security investments forming the UK's digital backbone. But a major shift is on the horizon as Artificial Intelligence gains momentum with half of firms believing their industry will be completely transformed by it in the years to come.\n\"The digital gap risks becoming a chasm for those firms left behind with Artificial Intelligence set to transform the face of UK businesses.\"\nA host of high-profile companies have sought to harness the power of intelligent machines that can learn tasks in a way that mimics the human.\nOn Thursday, Google's AlphaGo AI machine beat the world's number one player of the ancient Chinese game, Go. The feat was seen as a major milestone in the development of AI, due to the enormous complexity of the game.\nTesla's Elon Musk has gone one step further into science fiction with hisproposal for a machine that links the human brain with a machine interface by creating miniscule devices.\n\"If I were to communicate a concept to you, you would essentially engage in consensual telepathy,\" Mr Musk said in the interview last month.\n\"There are a bunch of concepts in your head that then your brain has to try to compress into this incredibly low data rate called speech or typing.\"\n\"If you have two brain interfaces, you could actually do an uncompressed direct conceptual communication with another person.\"\n"},
{"docid": "9 of 500 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "July 14, 1988", "title": "Computer Guardian (Micromaths): A program for smart thinking\n", "content": "\u00a0\n Is artificial intelligence achievable? Will we ever be able to biuld computer systems that can display as much intelligence as ourselves? Will we be able to construct a robot that is the equal of, say, a trained sheepdog? No one really knows. That is one of the reasons why artificial intelligence is such a fascinating area of research, and such a controversial one.\n Doubtless part of the reason for the continuing controversy lies in the (to many) inflammatory name 'artificial intelligence.' If the subject is conceived as originating with its name, then Stanford professor John McCarthy is the father of the subject. He is certainly responsible for a great many of the significant advances that have been made in the area.\u00a0\n\n In 1956, when a young assistant professor of mathematics at Dartmouth College, New Hampshire, McCarthy teamed up with his friend Marvin Minsky, of the Massachusetts Institute of Technology, to organise a conference.\n McCarthy proposed that: 'a two-month, ten-man study of artificial intelligence be carried out during the summer of 1956 at Dartmouth College. The study is to proceed on the basis of the conjecture that evey aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.'\n This was not the first time that such ideas had been put forward. Although not primarily concerned with the actual construction of machines, the nineteenth-century logician Goerge Boole had spent many years trying to formalise the 'laws of thought' in precise, mathematical fashion.\n Indeed, he was so successful that the ideas Boole developed nowadays play a key role in the design of computer systems.\n The famous wartime code breaker and computer builder, Alan Turing, also put forward the hypothesis that it would 'soon' be possible to program computers that could exhibit intelligent behaviour.\n But it was that particular phrase 'artificial intelligence' in McCarthy's proposal that caught the attention of the rest of the scientifice community, to say nothing of the world's press, and thereby established a new field of research.\n The fundamental idea was that following the same lines as Boole a century before, mathematical logic could be used as a frameowrk in which formal rules of intelligence could be written down and fed into a computer.\n In 1961, McCarthy moved to Stanford Univeristy in California, where he helped to set up the Stanford Artificial Intelligence Laboratory (Sail), and developed a new computer programming language specially tailored for artificial intelligence work; Lisp.\n Lisp is now one of the two programming languages most widely used in artificial intelligence, the other being Prolog. (Lisp, comes from 'list processing,' Prolog for 'programming with logic.')\n That the grandiose aims originally conceived as the target of artificial intelligence research have not been achieved, can scarcely be disputed. Indeed one of the major lessons of just over 30 years work is that intelligence is a complicated business, not easily achieved by artificial means.\n And in case that last remark strikes you as obvious, remember that in two areas that had traditionally been regarded as requiring intelligence, computers can now equal and often surpass the abilitites of humans: chess playing (where present day computer systems perform at Grand Master level) and arithmetic (where the computer has long since left the human brain in its wake). So who can say with certainty just where the real difficulties lie? Or indeed what intelligence really is?\n In fact, though McCarthy himself still holds true to the original idea of using mathematical logic as the major tool for the development of artificial intelligence, many others believe that a quite different approach is called for. Thus a great deal of present day work involves close interaction between computer scientist, mathematicians, psychologists, linguists, neuroscientists and philosophers.\n In the meantime, the ultimate goal of an intelligent computer seems as far away as ever, but artificial intelligence has led to some advances of real use in the everyday world. The include in the form of so-called 'experty systems', and computer-aided learning programs, that hand over to the computer a great deal of the role of an expert (such as a geologist or a doctor) or teacher.\n In an age of short term goals and 'instant' success, the pursuit of artificial intelligence might, in the end, prove to be a hopeless task. But in the long run, one thing should ensure continuing work on the problem: curiosity about our world and ourselves.\n Dr Keith Devlin has recently been appointed Professor of Artificial Intelligence at the University of Leeds.\n"},
{"docid": "10 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "January 29, 2015", "title": "Artificial intelligence will become strong enough to be a concern, says Bill Gates; Former Microsoft boss joins Elon Musk and Stephen Hawking in suggesting that the march of AI could be an existential threat to humans\n", "content": "Bill Gates is the latest prominent figure from the technology industry to express concern about the future evolution of artificial intelligence, although he thinks it will be \"decades\" before super-intelligent machines pose a threat to humans.\nHe joins Elon Musk and Stephen Hawking in suggesting that the march of AI could be an existential threat to humans. The former Microsoft boss gave his opinion during his latest Ask Me Anything (AMA) interview on the Reddit networking site. \u00a0\n\"I am in the camp that is concerned about super intelligence. First the machines will do a lot of jobs for us and not be super-intelligent. That should be positive if we manage it well,\" wrote Gates. \n\"A few decades after that though the intelligence is strong enough to be a concern. I agree with Elon Musk and some others on this and don't understand why some people are not concerned.\"\n                     Musk spoke out in October 2014 during an interview at the AeroAstro Centennial Symposium, telling students that the technology industry should be thinking hard about how it approaches AI advances in the future.\n\"I think we should be very careful about artificial intelligence. If I had to guess at what our biggest existential threat is, it's probably that. So we need to be very careful,\" said Musk. \"I'm increasingly inclined to think that there should be some regulatory oversight, maybe at the national and international level, just to make sure that we don't do something very foolish.\"'AI doomsday scenarios belong more in the realm of science fiction'\nIn a December interview, Professor Hawking went further. \"The primitive forms of artificial intelligence we already have, have proved very useful. But I think the development of full artificial intelligence could spell the end of the human race.\"\nFuture risks of artificial intelligence are being discussed widely and publicly within the technology industry, and even researchers who think warnings about machines extinguishing the human race are nonsense, are alive to the need to continue exploring the risks.\n\"AI doomsday scenarios belong more in the realm of science fiction than science fact. However, we still have a great deal of work to do to address the concerns and risks afoot with our growing reliance on AI systems,\" admitted an article co-written earlier in January by Eric Horvitz, director of the Microsoft Research lab, and Tom Dietterich, president of the Association for the Advancement of Artificial Intelligence.\nThat post outlined three key risks around artificial intelligence: programming errors in AI software; cyber-attacks on AI systems by criminals, terrorists and government-backed hackers; and so-called Sorcerer's Apprentice scenarios, when AI systems respond to human instructions in unexpected (and possibly dangerous) ways.\n\"Each of the three important risks outlined above... is being addressed by current research, but greater efforts are needed,\" wrote Horvitz and Dietterich, calling for more collaboration and funding to explore the challenges. \"We must not put AI algorithms in control of potentially-dangerous systems until we can provide a high degree of assurance that they will behave safely and properly.\"'Technology is not making people less intelligent'\nDuring his AMA interview, Gates also talked about his work on a \"personal agent\" technology within Microsoft that will \"remember everything and help you go back and find things and help you pick what things to pay attention to... it will work across all your devices\".\nHe also described the bitcoin cryptocurrency as \"exciting\" but said it wasn't currently viable for use in the developing world. \"For our [Bill and Melinda Gates] Foundation work we are doing digital currency to help the poor get banking services.\n\"We don't use bitcoin specifically for two reasons,\" he wrote. \"One is that the poor shouldn't have a currency whose value goes up and down a lot compared to their local currency. Second is that if a mistake is made in who you pay then you need to be able to reverse it so anonymity wouldn't work.\"\nGates was also asked whether technology \"has made the masses less intelligent\". He replied: \"Technology is not making people less intelligent. Technology is letting people get their questions answered better so they stay more curious. It makes it easier to know a lot of topics which turns out to be pretty important to contribute to solving complex problems.\"\n\u00b7 Bill Gates dismisses criticism of high prices for vaccines\n\u00b7 Gates Foundation annual letter: what do you think?\n\u00b7 Bill Gates: digital learning will revolutionise education in global south\n"},
{"docid": "11 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 29, 2014", "title": "Artificial intelligence could cause mass unemployment, expert warns; The development of artificial intelligence could mean computers take over human jobs at a faster rate than new roles can be created, technology experts warned\n", "content": "Artificial\u00a0intelligence could lead to mass unemployment if computers develop the capacity to take over human work, technology experts warned. \nDr Stuart Armstrong, from the Future of Humanity Institute at the University of Oxford, gave the stark warning after it emerged that Google had paid \u00a3400m for the British artificial intelligence firm DeepMind. \u00a0\nHe welcomed the web giant's decision to set up an ethics board to safely develop and use artificial intelligence claiming the advances in technology carried a number of risks. \nMr Armstrong said computers had the potential to take over people's jobs at a faster rate than new roles could be created. \nHe cited logistics, administration and insurance underwriting as professions that were particularly vulnerable to the development of artificial intelligence. \nHe also warned about the implications for uncontrolled mass surveillance if computers were taught to recognise human faces. \nSpeaking on Radio 4's Today programme, he said: \"There's a variety of short term risks for artificial intelligence, everyone knows about the autonomous drones. \n\"But there's also the potential for mass surveillance, you don't just have to recognise cat images, you could also recognise human faces and also mass unemployment in a variety of professions.\"\nHe added: \"We have some studies looking into which jobs are the most vulnerable and there's quite a lot of them in logistics, administration, insurance underwriting but ultimately a huge swathe of jobs are potentially vulnerable to improved artificial intelligence.\"\nHis concerns were backed up by Murray Shanahan, professor of cognitive robotics at Imperial College London, who said: \"I think it is a very good thing that Google has set up this ethics board and I think there certainly are some short term issues that we all need to be talking about. \n\"It's very difficult to predict and that is of course a concern but in the past when we've developed new kinds of technologies then often they have created jobs at the same time as taking them over but it certainly is something we ought to be discussing.\"\nDeepMind was founded two years ago by 37-year-old neuroscientist and former teenage chess prodigy Demis Hassabis, along with Shane Legg and Mustafa Suleyman. \nThe company specialises in algorithms and machine learning for simulation, e-commerce and games. \nIt is also working in an area called Deep Learning in which machines are taught to see patterns from large quantities of data so computers could start to recognise objects from daily life such as cars or food products and even human faces. \nIt is believed Google will use DeepMind's expertise to improve the functions of its current products such as the Google Glass and extend its current artificial\u00a0intelligence work such as the development of self-driving cars. \nMr Murray said: \"We all know that Google have got an interest in wearable computing with their Google glass and you can imagine them and other companies using this technology to build some kind of assistant that for example could help you to make a lasagne in your kitchen and to tell you what ingredients you needed and where to find them. \n\"Not necessarily a robot assistant but something wearable such as your Google glass or some other maker might make a similar thing so you can carry it around with you.\"\n"},
{"docid": "12 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "January 27, 2014", "title": "Google buys UK artificial intelligence start-up DeepMind for \u00a3242m; London-based company focused on \"cutting edge artificial intelligence\" could supply the brains for Google's burgeoning robotics division\n", "content": "Google has bought a London artificial intelligence company for a reported $400m (\u00a3242m), its biggest ever European acquisition.\nThe US technology giant has reportedly spent the sum on artificial intelligence firm DeepMind, according to technology website Re/Code. Google confirmed it has bought the start-up but would not discuss the price.\u00a0\nDeepMind was founded in 2012 by former chess prodigy, video games designer and neuroscientist Demis Hassabis. The company's website describes it as a \"cutting edge artificial intelligence company\" combining \"the best techniques from machine learning and systems neuroscience to build powerful general-purpose learning algorithms.\"\nThese algorithms allow programmes and systems to learn from experience and DeepMind's says its initial commercial applications have been in simulations, e-commerce and games.\nAn ad posted by the company looking for an intern, asked: \"Are you worried that the only place for smart people with a passion for software in London is in soul-crushing finance? Are you looking to work in a company that invests in hard research to create cutting edge new machine learning algorithms?\"\nFounder Hassabis worked on classic PC games including Theme Park and Black & White, on which he was a lead artificial intelligence programmer. The Mind Sports Olympiad (an international competition for games of mental skill) described Hassabis as \"probably the best games player in history\".\nSources speaking to Re/Code said that although DeepMind was not a household name, it was respected in the artificial intelligence community and competed with the likes of Google and Facebook in attracting engineering talent.\nIt's not sure exactly how Google will use DeepMind's machine learning technology, though its thought that the expertise could help power the search giant's growing interest in robotics.\nIn December last year Google revealed that it had purchased eight robotic companies in the last six months, all of which will be working together under an unspecified project headed by Andy Rubin, the executive responsible for the global success of the Android operating system.\nThe companies purchased by Google included Boston Dynamics, a robotics maker that had several major contracts with America's Department of Defense (DoD).\nGoogle search and destroy: The internet giant (motto: 'Don't be evil') has bought a pioneer of scary robot animals. Can its ethics survive?\n"},
{"docid": "13 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "January 27, 2014", "title": "Google buys UK artificial intelligence start-up DeepMind for \u00a3400m; London-based company focused on \"cutting edge artificial intelligence\" could supply the brains for Google's burgeoning robotics division\n", "content": "Google has bought a London artificial intelligence company for a reported \u00a3400m ($650m), its biggest ever European acquisition.\nThe US technology giant has reportedly spent the sum on artificial intelligence firm DeepMind, according to technology website Re/Code. Google confirmed it has bought the start-up but would not discuss the price.\u00a0\nDeepMind was founded in 2012 by former chess prodigy, video games designer and neuroscientist Demis Hassabis. The company's website describes it as a \"cutting edge artificial intelligence company\" combining \"the best techniques from machine learning and systems neuroscience to build powerful general-purpose learning algorithms.\"\nThese algorithms allow programmes and systems to learn from experience and DeepMind's says its initial commercial applications have been in simulations, e-commerce and games.\nAn ad posted by the company looking for an intern, asked: \"Are you worried that the only place for smart people with a passion for software in London is in soul-crushing finance? Are you looking to work in a company that invests in hard research to create cutting edge new machine learning algorithms?\"\nFounder Hassabis worked on classic PC games including Theme Park and Black & White, on which he was a lead artificial intelligence programmer. The Mind Sports Olympiad (an international competition for games of mental skill) described Hassabis as \"probably the best games player in history\".\nSources speaking to Re/Code said that although DeepMind was not a household name, it was respected in the artificial intelligence community and competed with the likes of Google and Facebook in attracting engineering talent.\nIt's not clear exactly how Google will be using DeepMind's machine learning technology, but speculation ranges from improving the company's Google Now services to integration with its recently-purchased robotics technologies.\n"},
{"docid": "14 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "January 29, 2015", "title": "Artificial intelligence 'will not end human race'; Head of Microsoft's main research lab admits that AI will pose legal, ethical and psychological issues as it becomes more sophisticated\n", "content": "The head of Microsoft's main research lab has dismissed fears that artificial intelligence could pose a threat to the survival of the human race.\nEric Horvitz believed that humans would not \"lose control of certain kinds of intelligences\", adding: \"In the end we'll be able to get incredible benefits from machine intelligence in all realms of life, from science to education to economics to daily life.\"\u00a0\n                     Professor Stephen Hawking last month expressed his fears about the rise of AI. He believed that technology would eventually become self-aware and supersede humanity: \"The primitive forms of artificial intelligence we already have, have proved very useful. But I think the development of full artificial intelligence could spell the end of the human race.\"\nHorvitz made his comments in an video interview after being awarded the Feigenbaum Prize by the AAAI for his contribution to artificial intelligence research.\nHowever, he acknowledged that advances in AI were likely to have significant impact on society and pose numerous legal, ethical, economic and psychological issues.\n\"We'll need to remain vigilant about assessing and continuing to address potential risks and rough edges... We need to be assured that systems working in high-stakes areas will behave safely and in accordance with our goals, even when they encounter unforeseen situations,\" the researcher said in a Microsoft blog.'We need to be very careful'\nOther high-profile figures to cast doubt on AI include Elon Musk, the co-founder of PayPal who went on to set up Tesla, the electric car manufacturer, and SpaceX, which focuses on rocket technology.\nHe said last year that AI was the biggest existential threat to humans. \"We need to be very careful. I'm increasingly inclined to think that there should be some regulatory oversight, maybe at the national and international level, just to make sure that we don't do something very foolish.\"\nMusk is one of the high-profile investors, alongside Facebook chief executive Mark Zuckerberg and actor Ashton Kutcher, in Vicarious.\nThe company aims to build a computer that can think like a person, with a neural network capable of replicating the part of the brain that controls vision, body movement and language.\n\u00b7 This article was amended on 29 January 2015. An earlier version described Eric Horvitz as the head of Microsoft's research division. To clarify: he is the head of Microsoft Research's main lab in Redmond, Washington. Peter Lee is the head of Microsoft Research.\n"},
{"docid": "15 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "June 5, 2015", "title": "Brains of the future will be hybrid of man and machine\n", "content": "Human brains will be boosted with artificial intelligence at some point after the year 2030, one of the foremost thinkers on AI has said.\nThe brain will connect to online AI to become a \"hybrid of biological and non-biological thinking\", Ray Kurzweil, director of engineering at Google, suggested.\u00a0\nTiny \"nanobots\" made from DNA strands would connect our brains to the internet, allowing us to augment our own intelligence with artificial intelligence, he said.\nIn the late 2030s or early 2040s, after the power of artificial intelligence has surpassed that of our own, our hybrid thinking will be predominantly nonbiological, he said. \"We're going to gradually merge and enhance ourselves. That's the nature of being human - we transcend our limitations.\"\nHe suggested that we would be able to back up the information in our brains to be saved online.\nMr Kurzweil, the author of The Age of Spiritual Machines, has been described by Bill Gates, the former boss of Microsoft, as \"the best person I know at predicting the future of artificial intelligence\". Mr Kurzweil believes that artificial intelligence will surpass human intelligence in 2029 at a point known as the \"singularity\". However, he believes that a superintelligent being would be subservient to the needs of humans because it would have been created by mankind.\nIn the past year a number of leading scientific figures including Stephen Hawking have warned of the perils of allowing AI research to continue without limiting what computers and robots will be able to do.\nProfessor Hawking said in December that the development of full artificial intelligence could spell the end of the human race. Nick Bostrom, a professor of philosophy at the University of Oxford, wrote in Superintelligence: Paths, Dangers, Strategies that the first artificially superintelligent being would probably wipe out humankind.\nMr Kurzweil said that humans should be aware of the potential dangers of AI but that there was a moral imperative to keep developing it. \"Technology is a double-edged sword,\" he told the Exponential Finance conference in New York. \"Fire kept us warm and cooked our food but also burnt down our houses. Every technology has had its promise and peril.\" He said that AI was \"not an alien invasion of these intelligent machines to displace us. We will use them to make ourselves smarter.\" He suggested that search engines would soon know us very well. \"They'll watch everything we're reading, writing and saying and hearing. They'll be like an assistant,\" he said. The search engine assistant would \"answer your questions before you ask them, or even before you realise you have a question\".\nMr Kurzweil predicted that people would switch from desktop to portable computers and that computer displays would be built into spectacles, which happened with Google Glass. However, he also said that self-driving cars would be on the road by 2009. \"If I had said 2015, I think it would've been correct,\" he said, \"so even the [predictions] that were wrong were directionally correct.\"\n"},
{"docid": "16 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "December 3, 2014", "title": "Four ways that technology could destroy mankind; Stephen Hawking has warned that artificial intelligence could rise up and destroy mankind. Is he right? We look at four ways that technology could be the end of us\n", "content": "Stephen Hawking has pushed forward humanity's understanding of the universe with his theories on gravitational singularities and black holes, so when he speaks up it's wise to listen. Which makes his warning yesterday that artificial intelligence could mean the end of humanity all the more concerning. \n\"The primitive forms of artificial intelligence we already have, have proved very useful,\" he told the BBC . \"But I think the development of full artificial intelligence could spell the end of the human race. \u00a0\n\"It would take off on its own, and re-design itself at an ever increasing rate. Humans, who are limited by slow biological evolution, couldn't compete, and would be superseded.\"\nIs he right? Did the screenwriters behind The Matrix, 2001: A Space Odyssey and The Terminator all have a point? Will machines rise up and destroy us? We look at four ways that technology could destroy the human race. Artificial intelligence\nHawking's argument is that once a machine can truly think for itself it could learn to make improvements to itself, slowly becoming more and more capable and intelligent. Eventually it could become all-powerful. And we may not be able to stop this process, long and convoluted as it may be, because it could happen in the blink of an eye in human terms. \nHow close are we to a thinking machine? There are already designs produced by simple artificial intelligence that we don't fully understand. Some electronic circuits designed by genetic algorithms, for example, work better than those conceived by humans - and we aren't always sure why because they're too complex. \nCombine this software intelligence with robot bodies and you have a science fiction film. But because every aspect of our lives is controlled by computers, this malevolent super-intelligence wouldn't need arms and legs to make life unpleasant. \nYou can argue that we could do artificial intelligence experiments on computers isolated from sensitive systems, but we don't seem to be able to keep human hackers in check so why assume we can outwit a super-intelligent thinking machine? You can also argue that AI may prove to be friendly, but if they treat us the way that we treat less intelligent creatures then we're in a world of trouble. Scientific disaster\nThere were fears that the first atomic bomb tests could ignite the atmosphere, burning everyone on Earth alive. Some believed that the Large Hadron Collider would create a black hole when first switched on that would consume the Earth. We got away with it, thanks only to the fact that both suggestions were hysterical nonsense. But what's to say that one day we won't attempt an experiment which has apocalyptic results? Grey goo\nA decade ago it seemed like distant sci-fi but we're all familiar with 3D printers now: you can buy them on Amazon. We're also creating 3D printers which can replicate by making parts for a second machine. \nBut imagine a machine capable of doing this which is not just microscopically small, but nanoscopically small. So small that it can stack atoms together to make molecules. This could lead to all sorts of advances in manufacturing and medicine. \nBut what if we get it wrong? A single typo in the source code and instead of removing cancerous lump in a patient these medi-bots could begin churning out copies of themselves over and over until the patient is nothing but a grey goo composed of billions of machines. Then the hospital, too, and the city it's in. Finally the whole planet. This is the 'grey goo' scenario. \nIf one machine made two machines over a period of 1,000 seconds, then they each made two, and so on, in ten hours you'd have 68 billion. Prince Charles famously warned the Royal Society to consider this risk in 2003 and was mocked for it. \nThe well-respected nanotechnologist Chris Phoenix discredits the idea, saying that 'grey goo' could not happen by accident but only as the \"product of a deliberate and difficult engineering process\". It's lucky, then, that nobody has ever carried out a difficult engineering project with the sole intention of harming millions of people. Oh, wait... Climate change\nBy far the most likely doomsday scenario is also the least dramatic: our materialism and lack of care for the environment continue to affect the climate to the point where we cannot survive in it. \n"},
{"docid": "17 of 500 DOCUMENTS\n", "source": "The Independent on Sunday\n", "date": "December 7, 2014", "title": "Stephen Hawking versus the robots; The professor worries about artificial intelligence. He's right, says an eminent computer expert, but for the wrong reasons. By Science Editor Steve Connor\n", "content": "It is one of our biggest existential threats, something so powerful and dangerous that it could put an end to the human race by replacing us with an army of intelligent robots.\nThis may sound like a bad film but in fact it came from Stephen Hawking, the world's most famous cosmologist, who told the BBC last week that he worries deeply about artificial intelligence and machines that can outsmart humanity.\n\"The development of full artificial intelligence could spell the end of the human race. It would take off on its own, and re-design itself at an ever-increasing rate,\" Professor Hawking said. \"Humans, who are limited by slow biological evolution, couldn't compete, and would be superseded.\"\u00a0\nHis apocalyptic vision is not matched, however, by the views of one expert in artificial intelligence.\n\"It is not often that you are obliged to proclaim a much-loved international genius wrong, but in the alarming prediction regarding artificial intelligence and the future of humankind, I believe Professor Stephen Hawking is,\" said Mark Bishop, professor of cognitive computing at Goldsmiths, University of London.\nProfessor Hawking is not alone in being worried about the growing power of artificial intelligence (AI) to imbue robots with the ability to both replicate themselves and to increase the rate at which they get smarter - leading to a tipping point or \"singularity\" when they can outsmart humans.\nThe mathematician John von Neumann first talked of an AI singularity in the 1950s, and Ray Kurzweil, the futurologist, popularised the idea a few decades later.\nProfessor Kevin Warwick of Reading University said something similar in 1997 when promoting his book March of the Machines and more recently, Elon Musk, the PayPal entrepreneur, warned about AI being our biggest existential threat that needs regulatory oversight.\nBut they are misguided, according to Professor Bishop, because there are some key human abilities, such as understanding and consciousness which are fundamentally lacking in so-called \"intelligent\" computers.\n\"This lack means that there will always be a 'humanity gap' between any artificial intelligence and a real human mind. Because of this gap a human working in conjunction with any given AI machine will always be more powerful than that AI working on its own,\" Professor Bishop said.\n\"It is precisely this that prevents the runaway explosion of AI that Hawking refers to - AI building better AI until machine intelligence is better than the human mind, leading to the singularity point where the AI exceeds human performance across all domains,\" he said.\nFear of clever automatons goes back many decades. Nearly a hundred years ago, Czech film-maker Karel Capek coined the word \"robot\", meaning \"slave\", to describe a machine take-over of humanity.\n\"The history of the subject is littered with researchers who claimed a breakthrough in AI as a result of their research, only for it later to be judged harshly against the weight of society's expectations,\" Professor Bishop said. But what does worry him about AI is the increasing reliance being placed on so-called intelligent machines.\n\"I am particularly concerned by the potential military deployment of robotic weapons systems - systems that can take a decision to militarily engage without human intervention - precisely because current AI is not very good and can all too easily force situations to escalate with potentially terrifying consequences,\" Professor Bishop said.\n\"So it is easy to concur that AI may pose a very real 'existential threat' to humanity without having to imagine that it will ever reach the level of superhuman intelligence,\" he said.We should be worried about AI, but for the opposite reasons given by Professor Hawking, he explained.\n"},
{"docid": "18 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "February 11, 2016", "title": "Marvin Minsky obituary; Pioneer of artificial intelligence research\n", "content": "Marvin Minsky, who has died aged 88, was a pioneer of artificial intelligence. In 1958 he co-founded the Artificial Intelligence Project at the Massachusetts Institute of Technology (MIT). Subsequently known as the AI Lab, it became a mecca for artificial intelligence research.\nHis published works included Steps Toward Artificial Intelligence (1960), a manifesto that profoundly shaped AI in its earliest days, and Society of Mind (1985), which postulated that the brain is fundamentally an assembly of interacting, specialised, autonomous agents for tasks such as visual processing and knowledge management. That view of the architecture of the mind remains a cornerstone of AI research.\u00a0\nMinsky was born in New York, the son of Fannie (nee Reiser), a Zionist activist, and Henry Minsky, an eye surgeon. He had prodigious intellectual gifts and was educated in progressive schools in New York. In 1944, aged 17, he enlisted in the US navy, where he received training in electronics. After demobilisation he enrolled at Harvard University and graduated in mathematics in 1950. While studying for a PhD in mathematics at Princeton University he married Gloria Rudisch.\nHe completed his doctorate in 1954, but rather than pursuing mathematics he became fascinated with the mechanism of the mind, which he considered to be the supreme intellectual challenge - \"hopelessly profound\", he called it. Simply stated, his long-term aim was to understand how the brain worked and to replicate it using a computer.\nHe secured a fellowship at Harvard, where his academic range broadened into neuroscience, philosophy and computing. In 1956 he attended the first symposium on artificial intelligence at Dartmouth College, New Hampshire, an event generally held to have kickstarted AI research. The symposium was organised by John McCarthy, a researcher at MIT, whom Minsky knew from his Princeton days. Together they founded the AI Project at MIT, where Minsky's early work included the creation of simple learning machines and a robotic hand. In 1962 McCarthy left for Stanford University, leaving Minsky to spearhead AI developments and partnerships at MIT. He remained there for the remainder of his career, latterly as emeritus professor.\nOne of the earliest of his many collaborations was with the educationist Seymour Papert, the inventor of the Logo educational programming system widely used in schools. Minsky devised the \"turtle\" mechanism - a small robot equipped with a stylus - which extended Logo's programming possibilities enormously, and enabled schoolchildren to draw spirals and complex patterns with simple commands. Minsky and Papert co-wrote Perceptrons (1969), an important early textbook that explained the potential and limits of early AI technology.\nMinsky was a sociable individual and inspired many colleagues and students, who moved on to populate AI research and industry. Another of his collaborators, Ray Kurzweil, became a pioneer in the commercialisation of speech recognition and other technologies. A former student, Danny Hillis, founded the Thinking Machines Corporation in 1983. Minsky also had a long friendship with the physicist Richard Feynman ; and even helped Stanley Kubrick with his 1968 film 2001: A Space Odyssey, for which he advised (somewhat optimistically) on the capabilities of the HAL computer.\nMinsky was an exceptional pianist, and in 1981 wrote a remarkable paper, Music, Mind and Meaning, that explored the cognitive processes in musical appreciation. In 1985 he became a founding member of the MIT Media Lab, an interdisciplinary research laboratory devoted to projects at the convergence of technology, multimedia, sciences, art and design.\nHis last book, The Emotion Machine (2006), which was written for the lay reader as much as the specialist, sought to understand and explain how \"thinking\" works, and to explain such phenomena as consciousness and common sense. He was the recipient of many academic awards and scientific honours, including, in 1969, the AM Turing award of the Association for Computing Machinery.\nHe is survived by Gloria, their son, Henry, and two daughters, Margaret and Juliana, and by four grandchildren.\n\u00b7 Marvin Lee Minsky, computer scientist, born 9 August 1927; died 24 January 2016\n\u00b7 This article was amended on 11 February 2016, to correct Marvin Minsky's date of death from 14 January to 24 January 2016.\n"},
{"docid": "19 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "November 10, 2015", "title": "Google releases its artificial intelligence software into the wild; Google is open-sourcing its machine learning system, TensorFlow, in the hope that it will accelerate research into artificial intelligence\n", "content": "Google has announced that it is releasing its artificial intelligence software into the wild, allowing third-party developers to contribute to its evolution. \nArtificial intelligence - or what Google describes as \"machine learning\" - is making computers and gadgets smarter every day. \nFrom image recognition to voice translation and noise cancellation, Google uses machine learning in many of its products, and has pumped a huge amount of its research and development budget into improving these systems. \u00a0\nEarlier this year, for example, Google engineers released the bizarre results of an artificial intelligence experiment, which saw photos interpreted and edited by the company's \"neural network\", which has been trained to detect faces and other patterns in images. \nThe latest iteration of its machine learning system is known as TensorFlow, which Google claims is faster, smarter and more flexible than its predecessor, DistBelief, which Google used to demonstrate that concepts like \"cat\" could be learned from unlabeled YouTube images. \n\"We use TensorFlow for everything from speech recognition in the Google app, to Smart Reply in Inbox, to search in Google Photos,\" said Sundar Pichai, chief executive of Google, in a blog post . \"It's a highly scalable machine learning system - it can run on a single smartphone or across thousands of computers in data centres.\"\nHowever, even with all the progress Google has made with machine learning, it admits that it could still work much better. \nComputers today still can't do what a four-year-old can do effortlessly, like knowing the name of a dinosaur after seeing only a couple examples, or understanding that \"I saw the Grand Canyon flying to Chicago\" doesn't mean the canyon is hurtling over the city. \nThis is why the company is \"open-sourcing\" the system, allowing third-party developers to access the raw computer code, adapt it, and start using it in their own applications. \n\"We've seen firsthand what TensorFlow can do, and we think it could make an even bigger impact outside Google. So today we're also open-sourcing TensorFlow,\" said Mr Pichai. \n\"We hope this will let the machine learning community - everyone from academic researchers, to engineers, to hobbyists - exchange ideas much more quickly, through working code rather than just research papers. And that, in turn, will accelerate research on machine learning, in the end making technology work better for everyone.\"\nHe added that TensorFlow may be useful wherever researchers are trying to make sense of very complex data, from protein folding to crunching astronomy data. \nThe news comes as new research released by online marketing technology company Rocket Fuel, reveals that almost twice as many people believe artificial intelligence can solve big world problems compared to those who think it is a threat to humanity. \nStephen Hawking has famously been quoted as saying that the rise of artificial intelligence could see the human race become extinct, warning that technology will eventually ''supersede'' humanity, as it develops faster than biological evolution. \nHowever, the research reveals that only 21 per cent of Britons see artificial intelligence as a threat or are scared by it, while 42 per cent are excited or think it can solve big world problems. \nMeanwhile, despite reports that thousands of British jobs have already been replaced by machines, only 9 per cent of people believe that artificial intelligence will threaten their job, while 10 per cent think it will enhance it. \n"},
{"docid": "20 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "November 6, 2015", "title": "Toyota places $1bn bet on robot technology; World's biggest car company to invest $1bn on robots and artificial intelligence as it looks to the future\n", "content": "Toyota is placing a $1bn bet on robots and artificial intelligence being major future technologies by setting up a new research and development unit to investigate their uses. \nThe world's biggest car company will spend the money over five years to establish the Toyota Research Institute near Stanford University in Silicon Valley, with a second facility at Massachusetts Institute of Technology in Cambridge. \u00a0\nIt is our responsibility to make life better for our customers, and society as a wholeAkio Toyoda, Toyota president\nThe Japanese industrial giant said that it \"believes artificial intelligence has significant potential to support future industrial technologies and the creation of an entirely new industry\". \nInvestment in the research institute will be spread over five years and Toyota said it hopes the centre will \"bridge the gap between fundamental research and product development\". \nThe institute's primary mission will be to speed up development of robots and artificial intelligence and to \"help resolve society's future challenges by using artificial intelligence and big data...contributing to a sustainable future where everyone can experience a safer, freer, and unconstrained life\". \nToyota has appointed its executive technical adviser Gill Pratt as chief executive of the new enterprise. Work will start on the institute in January 2016 and the company is now looking to hire stars of the sector to work there. \nAlthough the institute's work is likely to be biased towards the automotive sector, it is thought it will have spin off uses in adjacent fields. \nToyota already has a \" Partner Robot \" programme (pictured left), which is developing automatons for fields such as entering people living alone, assisting with housework and mobility for the infirm. It also has industrial applications such as manufacturing. \nDr Pratt said: \"Our initial goals are to improve safety by continuously decreasing the likelihood that a car will be involved in an accident, make driving accessible to everyone, regardless of ability, and apply Toyota technology used for outdoor mobility to indoor environments, particularly for the support of seniors. \n\"We also plan to apply our work more broadly, for example to improve production efficiency and accelerate scientific discovery in materials.\"\nAkio Toyoda, Toyota president, added: \"As technology continues to progress, so does our ability to improve products. At Toyota, we do not pursue innovation simply because we can; we pursue it because we should. It is our responsibility to make life better for our customers, and society as a whole.\"\n"},
{"docid": "21 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 24, 2015", "title": "Apple founder: 'Computers will take over from humans'; Engineering genius Steve Wozniak, who co-founded Apple with Steve Jobs, has warned that artificially intelligent computers will take over from humans and that the future is \"scary and very bad for people\"\n", "content": "The co-founder of Apple who designed the company's first computers in the 1970s has warned that artificial intelligence will take over from humans and that the future is \"scary and very bad for people\". \u00a0\n\"Computers are going to take over from humans, no question,\" he said in an interview with the Australian Financial Review . \nHe explained that strong artificial intelligence, which would recreate the power and creativity of the human mind in software, is a risky thing for researchers to strive for. \n\"Like people including Stephen Hawking and Elon Musk have predicted, I agree that the future is scary and very bad for people. If we build these devices to take care of everything for us, eventually they'll think faster than us and they'll get rid of the slow humans to run companies more efficiently,\" Wozniak said. \n\"Will we be the gods? Will we be the family pets? Or will we be ants that get stepped on? I don't know about that... But when I got that thinking in my head about if I'm going to be treated in the future as a pet to these smart machines... well I'm going to treat my own pet dog really nice.\"\nProfessor Stephen Hawking has previously said that the rise of artificial intelligence could see the human race become extinct. \nHe told the BBC: ''The primitive forms of artificial intelligence we already have have proved very useful. But I think the development of full artificial intelligence could spell the end of the human race.'' \nTechnology entrepreneur Elon Musk has also described the rise of AI in the past as ''our biggest existential threat''. \nDozens of the world's top artificial intelligence experts have signed an open letter calling for researchers to take care to avoid potential \"pitfalls\" of the disruptive technology . \nWozniak left Apple during the 1980s, claiming to be more interested in engineering than management. He has since gone on to be involved in numerous start-ups and philanthropically projects. \nHe is said to remain an honorary employee of Apple and receive an annual stipend, however. \nDuring his most recent interview he also said that he wasn't sure if Apple is working on its own car, or just polishing its CarPlay operating system, but that \"it seems like they might be hiring a lot of people who could really build a vehicle.\"\n                                            WATCH: Apple's 2014 in 60 seconds                                        \n"},
{"docid": "22 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "February 15, 2017", "title": "Elon Musk says humans must become cyborgs to stay relevant. Is he right?; Sophisticated artificial intelligence will make 'house cats' of humans, claims the entrepreneur, but his grand vision for mind-controlled tech may be a long way off\n", "content": "Humans must become cyborgs if they are to stay relevant in a future dominated by artificial intelligence. That was the warning from Tesla founder Elon Musk, speaking at an event in Dubai this weekend.\nMusk argued that as artificial intelligence becomes more sophisticated, it will lead to mass unemployment. \"There will be fewer and fewer jobs that a robot can't do better,\" he said at the World Government Summit.\n Related:  Actors, teachers, therapists - think your job is safe from artificial intelligence? Think again\nIf humans want to continue to add value to the economy, they must augment their capabilities through a \"merger of biological intelligence and machine intelligence\". If we fail to do this, we'll risk becoming \"house cats\" to artificial intelligence.\u00a0\nAnd so we enter the realm of brain-computer (or brain-machine) interfaces, which cut out sluggish communication middlemen such as typing and talking in favour of direct, lag-free interactions between our brains and external devices.\nThe theory is that with sufficient knowledge of the neural activity in the brain it will be possible to create \"neuroprosthetics\" that could allow us to communicate complex ideas telepathically or give us additional cognitive (extra memory) or sensory (night vision) abilities. Musk says he's working on an injectable mesh-like \"neural lace\" that fits on your brain to give it digital computing capabilities.\nSo where does the science end and the science fiction start?\n Creating a neural lace is the thing that really matters for humanity to achieve symbiosis with machines- Elon Musk (@elonmusk) June 4, 2016\nSo far, brain-computer interfaces have been used for relatively simple tasks, mainly to restore motor control for paralyzed patients and enable communication for locked-in patients with brain injuries that prevent them from communicating verbally or gesturally.\nThese interfaces involve decoding brain signals from the surface of the skull through EEG or via implanted electrodes and then translating those signals into a motion command for a robot or cursor.\nThere has also been some progress made in the other direction: using external electrical signals to stimulate the brain. This happened last year with Nathan Copeland, a paraplegic man who was fitted with a prosthetic hand with two-way feedback, meaning he can not only control the hand but \"feel\" when it's being touched.\nAlthough medical applications are driving the research, there are also commercially available playthings that allow for novelties such as \"mind controlled\" drone racing.\nStill, these are a long way from Elon Musk's vision of symbiosis between man and machine, which would require a much more granular understanding of the brain network that goes beyond the basics of motor control to more complex cognitive faculties like language and metaphor.\n\"We have over 80bn neurons in the brain. Our tools currently give us access to an extremely small number of neurons. With prosthetics, we're maybe talking about 100 neurons. We need higher bandwidth interfaces,\" said Bryan Johnson, founder of Kernel, which aims to augment human intelligence with AI. \nArizona State University professor Panagiotis Artemiadis has been trying to get more bandwidth using a 128-electrode EEG cap to allow a human to control a swarm of flying robots with their brain. \"We can already decode basic concepts like closing a hand or moving an elbow, but we can't decode more complex behaviors,\" he said.\nHe has created a system that allows for a single person to control the collaborative movement of multiple drones, for example making the flock move closer together so that it can fit through a narrow pass.\nHe is skeptical that the rise of AI will render humans irrelevant.\n\"We are building these machines to serve humans,\" he said.\nMiguel Nicolelis, who has built brain-controlled exoskeletons and a brain-to-brain interface that allowed a rat in the United States to use the senses of the other in Brazil, agrees.\nHumans won't become irrelevant until machines can replicate the human brain - something Nicolelis believes is not possible.\n\"The idea that digital machines no matter how hyper-connected, how powerful, will one day surpass human capacity is total baloney,\" he told the Guardian.\nNicolelis argues that the brain - contrary to what Musk and Singularity proponents like Ray Kurzweil say - is not computable because human consciousness is the result of unpredictable, nonlinear interactions among billions of cells. \"Our brains do not work in an algorithmic way and are not digital machines,\" he said.\n\"It used to be annoying to see these kinds of statements, but now it's becoming serious. It's leading to mass hysteria.\"\nNicolelis acknowledges that digital automation will lead to \"serious unemployment\" among people who perform certain \"mundane functions\" that can be replicated by machines. \"But that doesn't mean the human species will become obsolete.\"\nThe idea that digital machines will one day surpass human capacity is total baloney\n  Miguel Nicolelis, neuroscientist    \nHe agrees with Musk that if we can interface directly with machines we can produce a \"quantum leap\" in what digital infrastructure has produced today, but predicts that humans will retain ultimate control.\nThis contrasts with current automated systems, like autopilot, where the human is merely supervising the operation of a computer. Similarly, doctors are outsourcing the diagnosis of certain diseases to supercomputers. Under these circumstances human skills diminish and people become subservient to machines.\n\"I'm thinking about a future where we reverse this trend. We use brain-machine interfaces to enhance our ability to treat people, to improve our quality of life,\" he said.\nBetter communication between humans and machines, particularly the transmission of emotional signals from humans, will be a powerful tool for building trust in automated systems, added Artemiadis.\nFor example, it would allow for humans to hand over control to an autonomous car with confidence. \"It's about making the machine more intuitive using brain signals to understand whether the human is distracted or tired.\"\nColumbia's Paul Sajda agreed. \"Rather than put us in a doomsday scenario, let's look at how the relationship between humans and machines can evolve.\"\nHe said that most people will be \"scared to death\" to sit behind the wheel of a driverless car, but if the AI were able to read our emotional state it could start to make predications about our desires and build trust.\nSajda described the mostly non-verbal communication between a team of six navy seals, which includes gestures, emotional cues and facial expressions as well as some dialogue. \n\"In the future it will be three humans and four robots,\" he said. \"How can they ensure there are these team dynamics that allow them to operate at the same level as a human squad? It has to do with trust between them.\"\n Related:  Robots will destroy our jobs - and we're not ready for it\nMind-reading devices or implants are likely to introduce unprecedented privacy concerns. Sadja talks about the notion of freedom of thought as an extension of freedom of speech.\n\"All of a sudden what's in your head can be expressed and communicated. One's private thoughts are important to protect, I don't think anybody - government or any company - should be charged with protecting them.\"\nIt's a concern shared by the University of Calgary's Walter Glannon, who studies neuroethics.\n\"There is a risk of the microchips being hacked by third parties. This could interfere with the user's intention to perform actions, violate privacy by extracting information from the chip,\" he said.\nAs it stands, these risks are theoretical.\n\"We really first have to understand the network [of the brain] and how all of these processing units communicate with each other and interact with the world,\" said Artemiadis. \"We are really far away.\"\n"},
{"docid": "23 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "February 29, 2016", "title": "Artificial intelligence 'should be used to give children one-on-one tutoring'; Academics argue AI could radically transform our education system for the better - but is being held back by funding\n", "content": "Artificial\u00a0intelligence should be used to provide children with one-to-one tutoring to improve their learning and monitor their well-being, academics have argued.\nOne-to-one tutoring has long been thought the most-effective approach to teaching but would be too expensive to provide for all students.\nHowever, in a paper, academics from University College London's Knowledge Lab argue that AI systems could simulate human one-to-one tutoring by delivering learning activities tailored to a student's needs and providing targeted and timely feedback, all without an individual teacher present.\u00a0\nRead more\nFacebook to use AI to map people's homes, give them internet\nInstead of being examined in traditional ways, children could be assessed in a more complete manner by collecting data about their performance over a long period, providing employers and educational institutions with a richer picture of their abilities.\nThe report argues that AI could radically transform our education system for the better - but it is being held back by funding.\nProposals to use AI have been controversial. Professor Stephen Hawking and other leading scientists have warned of the dangers of it becoming \"too clever\", and there are concerns about data security and privacy. Some teachers also fear their role could be diminished by this technology, or that it could be used as a \"classroom spy\" to monitor their performance. But the report's authors believe there are huge potential benefits - and they argue it is essential the teaching profession is involved from the start.\nThe report says: \"We are in no doubt that teachers need to be central agents in the next phase of Artificial Intelligence in Education (AIEd). In one sense this is obvious - it is teachers who will be the orchestrators of when, and how, to use these AIEd tools. In turn, the AIEd tools, and the data-driven insights that these tools provide, will empower teachers to decide how best to marshal the various resources at their disposal.\"\nRead more\n                     How artificial intelligence became a hot UK export                   \n                     'Artificial\u00a0intelligence alarmists' win 'Luddite of the Year' award                   \n                     Apple buys AI software that can tell people's emotions                   \n                     Plan to bring people back from the dead with artificial intelligence                   \nIt adds: \"The increasing use of AIEd systems will enable the collection of mass data about which teaching and learning practices work best. This data will enable us to track learner progress against different teaching approaches and, in turn, will allow us to develop a dynamic catalogue of the best teaching practices suited to the development of different skills and capabilities, in particular the 21st century skills, across a range of environments.\"\nAI should also be used to tackle the achievement gap between the poorest children and their wealthier peers by helping low-income parents with parenting even before their offspring start school.\nThe report says: \"Low-income parents may also have had limited education opportunities, meaning they may face serious challenges in providing at-home learning support to their children.\n\"AIEd systems can provide tailored support to parents in the same way that they can for teachers and students, improving education and outcomes for both parents and their children. Imagine, for example, providing parents with AIEd assistants that could advise them about strategies for talking to their child, sharing songs, and enjoying books. This could enable all parents to provide the right sort of support in those all-important early years.\"\nAI first appeared in a digital game in 1979, when Pac-Man used a technique known as state machine (transitioning between states depending on conditions) to control whether or not a ghost ran towards or away from a player. The AI in most modern digital games builds on this approach.\n"},
{"docid": "24 of 500 DOCUMENTS\n", "source": "The Guardian - Final Edition\n", "date": "April 29, 2014", "title": "The age of artificial intelligence may be getting closer: Acquisitions by Amazon, Google and Facebook point to a revolution in robotics\n", "content": "Cinema audiences are subjected to a mind-boggling fusion of the human consciousness with computing power in the Johnny Depp blockbuster Transcendence, but the sinister-seeming world of artificial intelligence is entering the mainstream with Silicon Valley upstarts Google and Facebook.\nThe film, released last weekend, has been savaged by critics against the backdrop of a futuristic arms race in the real world. Google and Facebook have joined Amazon in buying up drone firms to beam internet connections from space, investing in robotics, machine learning and virtual reality technology. But the realm of artificial intelligence could contain the greatest prize, achieving a union of man and machine that is often referred to as \"the singularity\" - a phrase first used by the American futurologist Ray Kurzweil. The accepted wisdom is that such a leap, if it can happen, is at least 30 years away.\u00a0\nExperts now argue that the moment is closer than we think, and Kurzweil is one of the figures accelerating our encounter with the future, as Google's director of engineering.\n\"The amount of money that Google and other commercial companies will pour into robotics and artificial intelligence could at last take it truly into the commercial world where we actually do have smart robots roaming our streets,\" says Noel Sharkey, professor of artificial intelligence and robotics at the University of Sheffield.\nTurning the classic industrial investment model on its head, consumer technology groups are using their cash mountains to fund areas of research that were until now the preserve of governments, defence companies and academics. Over the past year Google has bought seven robotics companies, including Boston Dynamics, whose previous work building humanoid machines was largely paid for by the US military. It has bought firms that specialise in natural language processing, gesture recognition, and more recently in machine learning, highlighted by the acquisition of British startup Deepmind - bought in January for $400m (\u00a3238m).\n\"Silicon Valley's involvement is creating right now an enormous acceleration,\" says Per Roman, a founding partner at technology investment bank GP Bullhound. \"It is turning into a real talent magnet. It is often small teams that come up with breakthrough inventions, and you are much more willing to take the risk if there is a chance you could get bought rather than ending up in a dark room in some military agency.\"\nAnd it is not just AI that is persuading Google to open its chequebook. Like Facebook, it is also investing in beaming the internet from the sky. Google has acquired drone maker Titan Aerospace, while Facebook now owns Somerset-based Ascenta. Facebook has also splashed out $2bn on Oculus, a maker of virtual reality headsets. Amazon, meanwhile, has held up the prospect that one day its goods could be delivered by air to our doorstep before we have even realised we need to order them.\nLast year's $3.2bn purchase of Nest, a designer of internet connected smoke alarms and thermostats, suggest Google's ambitions are domestic. \"It looks to me like they want to take the internet out of the desktop and put it into our everyday lives,\" says Sharkey.\nFor those struggling to understand why Google or Amazon should want to invest in self-driving cars, internet drones and robotics, the answer is data. Masses of it. The parking meter in your street, the collar on your cat, the thermostat in your home will emit signals, and Google will be listening. And if Silicon Valley's best minds succeed, their software will not only be listening, it will be understanding and anticipating.\nDeepMind's technology draws on a user's browsing behaviour to recognise patterns, learn about behaviour and make recommendations. According to cofounder Mustafa Suleyman, this could be used to suggest purchases.\n\"When you use Google search you have to work out what you are looking for and the words to use to find it,\" says technology investor Dharmash Mistry, founder of data-driven cosmetics business Blow. \"That will move to the search engine having data on you to give you customised searches. A lot of healthcare is dealing with an ailment once you have it. This new model is about getting you to prevent issues before they happen. After the glass of wine and meal, your phone will book you into the gym.\"\nFor some scientists, such as wearable computing pioneer Thad Starner, who is a key engineering figure behind Google Glass, man and machine are already merging. \"We're currently living the singularity,\" he said recently. \"Where the tool stops and the mind begins will start becoming blurry.\"\nCaptions:\nThe Johnny Depp film Transcendence, above, is set in a time when the human mind has become one with machine intelligence. But a leading Google engineer claims that such a 'singularity' is already here, and that soon, 'where the tool stops and the mind begins will start becoming blurry'\n"},
{"docid": "25 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "February 18, 2015", "title": "Artificial intelligence and nanotechnology 'threaten civilisation'; Technologies join nuclear war, ecological catastrophe, super-volcanoes and asteroid impacts in Global Challenges Foundation's risk report\n", "content": "Artificial\u00a0intelligence and nanotechnology have been named alongside nuclear war, ecological catastrophe and super-volcano eruptions as \"risks that threaten human civilisation\" in a report by the Global Challenges Foundation.\nIn the case of AI, the report suggests that future machines and software with \"human-level intelligence\" could create new, dangerous challenges for humanity - although they could also help to combat many of the other risks cited in the report.\n\"Such extreme intelligences could not easily be controlled (either by the groups creating them, or by some international regulatory regime), and would probably act to boost their own intelligence and acquire maximal resources for almost all initial AI motivations,\" suggest authors Dennis Pamlin and Stuart Armstrong.\u00a0\n Related: Artificial\u00a0intelligence: can scientists stop 'negative' outcomes?\n\"And if these motivations do not detail the survival and value of humanity, the intelligence will be driven to construct a world without humans. This makes extremely intelligent AIs a unique risk, in that extinction is more likely than lesser impacts.\"\nThe report also warns of the risk that \"economic collapse may follow from mass unemployment as humans are replaced by copyable human capital\", and expresses concern at the prospect of AI being used for warfare: \"An AI arms race could result in AIs being constructed with pernicious goals or lack of safety precautions.\"\nIn the case of nanotechnology, the report notes that \"atomically precise manufacturing\" could have a range of benefits for humans. It could help to tackle challenges including depletion of natural resources, pollution and climate change. But it foresees risks too.\n\"It could create new products - such as smart or extremely resilient materials - and would allow many different groups or even individuals to manufacture a wide range of things,\" suggests the report. \"This could lead to the easy construction of large arsenals of conventional or more novel weapons made possible by atomically precise manufacturing.\"\nThe foundation was set up in 2011 with the aim of funding research into risks that could threaten humanity, and encouraging more collaboration between governments, scientists and companies to combat them.\nThat is why its report presents worst-case scenarios for its 12 chosen risks, albeit alongside suggestions for avoiding them and acknowledgements of the positive potential for the technologies involved.\nIn the case of artificial intelligence, though, Global Challenges Foundation's report is part of a wider debate about possible risks as AI gets more powerful in the future.\nIn January, former Microsoft boss Bill Gates said that he is \"in the camp that is concerned about super intelligence\", even if in the short term, machines doing more jobs for humans should be a positive trend if managed well.\n Related: Rise of the robots: how long do we have until they take our jobs?\n\"A few decades after that though the intelligence is strong enough to be a concern. I agree with Elon Musk and some others on this and don't understand why some people are not concerned.\"\n                     Tesla and SpaceX boss Musk had spoken out in October 2014, suggesting that \"we should be very careful about artificial intelligence. If I had to guess at what our biggest existential threat is, it's probably that\".\nProfessor Stephen Hawking is another worrier, saying in December that \"the primitive forms of artificial intelligence we already have, have proved very useful. But I think the development of full artificial intelligence could spell the end of the human race.\"\nThe full list of \"risks that threaten human civilisation, according to Global Challenges Foundation:\n\n"},
{"docid": "26 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "February 26, 2017", "title": "Government promises \u00a320m investment in robotics and artificial intelligence; The Artificial Intelligence industrycould add around \u00a3654 billion to the UK economy\n", "content": "The government will launch a review into Artifical Intelligence (AI) and robotics in an attempt to make the UK a world leader in tech. \nThe government said in a statement on Sunday that it would invest \u00a317.3 million in university research on AI.\u00a0\nArtificial intelligence powers technologies such as Apple's SIRI, Amazon's Alexa, and driverless cars.\nAccording to a \nreport\n by consultancy firm Accenture, Artificial Intelligence could add around \u00a3654 billion to the UK economy.\nRead more\nAmazon argues AI assistant Alexa has free speech rights in murder case\nElon Musk: Humans must become cyborgs to avoid AI domination\nRobots could replace 250,000 public sector workers\nA \nreport\n by the Institute for Public Policy Research recently forecast that millions of jobs will be lost to automation over the next two decades. Researchers predicted that two million\n jobs retail jobs will disappear by 2030 and 600,000 will go in manufacturing. \nJ\u00e9r\u00f4me Pesenti, CEO of Benevolent Tech, who will be leading government research into AI, said,\n\"There has been a lot of unwarranted negative hype around Artificial Intelligence (AI), but it has the ability to drive enormous growth for the UK economy, create jobs, foster new skills, positively transform every industry and retain Britain's status as a world leader in innovative technology.\nEU universal income must be 'seriously considered' amid rise of robots\nThe announcement is part of the government's new \"Digital Strategy\", which will be announced in full on Wednesday. As well as investment in research and the tech industry, the strategy is also expected to detail a comprehensive modernisation of the civil service. \nThe government has been heavily criticised the delay in the publication of the strategy. In 2015, Ed Vaizey, the then DigitalMinister, said plans would be published in early 2016.\nIn January, the chairman of the government's Science and Technology Committee criticised the government for this delay.\nRead more\nRobots 'will create UK jobs, not destroy them'\n In a letter to Digital Minister Matt Hancock, Mr Metcalfe expressed his \"disappointment over such a long delay.\"\nThe letter also asked \"\nwhy the strategy continues to be a work in progress nearly a year after [Mr Hancock's] predecessor considered it already largely completed.\" \nThe government has said it was forced to delay the publication of the report to take into account the impact of Brexit.\nHowever, \nother sources\n have suggested that Whitehall's resistance to the modernisation of the civil service under the Government Digital Service plans was also a significant factor. \n"},
{"docid": "27 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "April 5, 2016", "title": "Deep Drumpf: the Twitter bot trying to out-Trump the Donald; MIT project uses artificial-intelligence algorithm to learn Republican frontrunner's speech patterns before publishing 'remarkably Trump-like statements'\n", "content": "\"OK, it's amazing right now with Isis, I tell you what? I don't want them to vote, the worst very social people. I love me.\"\u00a0\nDonald Trump may be a \"really smart person\" by his own estimation, but his speeches are now fuelling a really smart Twitter bot, which uses artificial-intelligence technology to copy the Republican frontrunner.\nThe quote above comes from \"Deep Drumpf\" rather than the real Trump, with the account running on algorithms created at the Massachusetts Institute of Technology's Computer Science and Artificial Intelligence Lab.\n\"The bot is based on an artificial-intelligence algorithm that is trained on just a few hours of transcripts of Trump's victory speeches and debate performances,\" wrote Adam Conner-Simons from the MIT lab, in a blog post introducing Deep Drumpf.\nThe bot is named after  a recent segment on the Last Week Tonight with John Oliver TV show, where Oliver encouraged opponents of Trump to rebrand him by his original family name, \"Drumpf\".\nConner-Simmons explained how the bot works:\n \"The bot creates Tweets one letter at a time. For example, if the bot randomly begins its Tweet with the letter 'M,' it is somewhat likely to be followed by an 'A,' and then a 'K,' and so on until the bot types out Trump's campaign slogan, 'Make America Great Again.' It then starts over for the next sentence and repeats the process until it reaches the 140-character limit. The Tweetbot's creator, CSAIL postdoc Bradley Hayes, used techniques from 'deep-learning,' a field of artificial intelligence that uses systems called 'neural networks' to teach computers to to find patterns on their own. Hayes was inspired by an existing training model that can simulate Shakespeare, as well as a recent report that analysed the presidential candidates' linguistic patterns to find that Trump speaks at a fourth-grade level.\" \nAs of yet, the real Trump has yet to respond to his Twitter bot, despite Deep Drumpf making one attempt to engage him in conversation.\n\u00b7 Artist 3D prints Donald Trump butt plug in protest at rhetoric\n"},
{"docid": "28 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "March 4, 2016", "title": "Deep Drumpf: the Twitter bot trying to out-Trump the Donald; MIT project uses artificial-intelligence algorithm to learn Republican frontrunner's speech patterns before publishing 'remarkably Trump-like statements'\n", "content": "\"OK, it's amazing right now with Isis, I tell you what? I don't want them to vote, the worst very social people. I love me.\"\u00a0\nDonald Trump may be a \"really smart person\" by his own estimation, but his speeches are now fuelling a really smart Twitter bot, which uses artificial-intelligence technology to copy the Republican frontrunner.\nThe quote above comes from \"Deep Drumpf\" rather than the real Trump, with the account running on algorithms created at the Massachusetts Institute of Technology's Computer Science and Artificial Intelligence Lab.\n\"The bot is based on an artificial-intelligence algorithm that is trained on just a few hours of transcripts of Trump's victory speeches and debate performances,\" wrote Adam Conner-Simons from the MIT lab, in a blog post introducing Deep Drumpf.\nThe bot is named after  a recent segment on the Last Week Tonight with John Oliver TV show, where Oliver encouraged opponents of Trump to rebrand him by his original family name, \"Drumpf\".\nConner-Simmons explained how the bot works:\n \"The bot creates Tweets one letter at a time. For example, if the bot randomly begins its Tweet with the letter 'M,' it is somewhat likely to be followed by an 'A,' and then a 'K,' and so on until the bot types out Trump's campaign slogan, 'Make America Great Again.' It then starts over for the next sentence and repeats the process until it reaches the 140-character limit. The Tweetbot's creator, CSAIL postdoc Bradley Hayes, used techniques from 'deep-learning,' a field of artificial intelligence that uses systems called 'neural networks' to teach computers to to find patterns on their own. Hayes was inspired by an existing training model that can simulate Shakespeare, as well as a recent report that analysed the presidential candidates' linguistic patterns to find that Trump speaks at a fourth-grade level.\" \nAs of yet, the real Trump has yet to respond to his Twitter bot, despite Deep Drumpf making one attempt to engage him in conversation.\n\u00b7 Artist 3D prints Donald Trump butt plug in protest at rhetoric\n"},
{"docid": "29 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "November 12, 2015", "title": "MAN VS MACHINE; Matt Andrews, the chief strategy officer at Mindshare, considers the implications of developments in artificial intelligence for humans\n", "content": "In 1995, Nicholas Negroponte, the co-founder of MIT Media Lab, published his seminal book Being Digital. It explored digital technologies, their predicted future and what it would mean to live in a digital world. Twenty years later the world is well into its digital transformation. So we're turning the tables and asking what it means for us to be human in a digital world. Being Human is the theme we will be exploring at Huddle this year.\nThere is a fascinating tension in modern life between the inexorable drive to being digital and the innate desire to be human. (Does anyone else think it's ironic to be listening to a mindfulness app on a smartphone?) For every trend there is a counter-trend and this battle plays out time and again in popular culture.\u00a0\nFAMILIAR THEME The threat of a world of big data and accelerating technological innovation has become a well-trodden theme in Hollywood, from films such as The Terminator (1984), The Matrix (1999) and more recently Ex Machina (2015), to television series such as Humans (C4) and Mr Robot (Amazon) in 2015.\nAll of these fictions tell a familiar story of man against machine. However, what's interesting is that this narrative is now spilling over into the real world with luminaries such as Bill Gates, Steve Wozniak, Elon Musk and even Stephen Hawking all having warned against artificial intelligence and rise of the machines. Steve Wozniak, the co-founder of Apple, summed up their collective sentiment when he said: \"Like Stephen Hawking and Elon Musk have predicted, I agree that the future is scary and very bad for people.\" Really? We should not entirely ignore the apocalyptic predictions of these Hollywood and Silicon Valley prophets. It is easy to see how the stories played out in popular culture can influence how we imagine the future, especially when the technology makes it possible. But perhaps there is an alternative future we can imagine? A more positive and optimistic story in which artificial intelligence and human intelligence work together in optimal ways to solve the world's problems? It won't break any box-office records but it might be a narrative we can use to build a better world.\nCOMPLEX LEXICON Telling this story, simply and positively, in the world of media and communications has never been more relevant and necessary than it is now. The predominant narrative in recent years has been almost exclusively focused on technology and data, artificial intelligence and machine learning, with a complex lexicon of accompanying terminology. It's important now that we begin to evolve this one-sided story, make it simpler to understand and more compelling for brands and, more importantly, the audiences that are to receive these so-called smart and hyper-relevant experiences.\nWe need human intelligence to be an equal partner to artificial intelligence, not be replaced by it. Together they can achieve great things. Perhaps the best current example of this is Facebook's new personal assistant called M. M will build on artificial intelligence with human intelligence, in the form of people. It is an attempt to make its service superior to those of Apple's Siri and Microsoft's Cortana.\nAfter all, it's worth remembering that we are in the business of creating emotional connections with people. Not data or machines. We need to think much more about the experiences that we create for people and audiences.\nHUMAN CHANGE Genevieve Bell, an anthropologist who leads Intel Labs' interaction and experience research, argues that it is easy to be tricked by the transformations in technology into thinking that we as human beings are changing. But the reality is that the things that make us humans change incredibly slowly. So in a fast-changing and fast-paced world it's important to remember our fundamental human needs remain constant.\nAs the internet of things, connected homes, cars and wearable technology dramatically increase the volume of personal data being generated by us and our possessions, we need to find ways of using this source of artificial intelligence positively, to create value for people that meets their needs.\nBeing Human relies on us all taking responsibility for how we use the forces of data and technology in the work we do to create better experiences and a better world for people to live in. This is particularly relevant when applied to media and communications, where using data and technology irresponsibly leads to being ignored, deleted, unsubscribed, blocked and skipped. The power is in the data and the data is the people. We need to use it to create valuable experiences for them, or audiences will be unwilling to share their power in the future.\nSUPER-INTELLIGENCE As a final thought, author Ray Kurzweil, in his book The Singularity is Near, describes an exponential increase in artificial intelligence, and as a consequence he predicts that technological advances will irreversibly transform people as they augment their minds and bodies with genetic alterations, nanotechnology and artificial intelligence. He says this will lead to technological singularity in AD2045 when human and artificial intelligence are combined into super-intelligence.\nJust imagine how good the All Blacks will be by then.\n"},
{"docid": "30 of 500 DOCUMENTS\n", "source": "The Independent - Daily Edition\n", "date": "February 21, 2018", "title": "We must do more to curtail AI threat, experts warn\n", "content": "The world is under threat from artificial intelligence and needs to do more to keep people safe, experts have urged.\nA new report compiled by 26 of the world's leading experts paints a terrifying picture of the world in the next 10 years. Physical attacks as well as those on our digital worlds and political system could drastically undermine the safety of humanity, it warns, and people must work together now if they want to keep the world safe.\nThe use of artificial intelligence is likely to empower all kinds of people - including rogue states, criminals, and terrorists, the report warns. If people including policymakers and researchers don't work together on that threat, it could permeate into some of the most fundamental parts of our lives.\u00a0\nThat could range from attacks from drones to bots being used to manipulate our news agenda and elections, warns the report, titled 'The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation'. Many of the attacks could come in forms that are hard even to imagine, such as speech synthesis tools and video creation technologies that could allow people to create entirely believable, but completely fake, videos.\nTo fight against that, the number of people being consulted on how to ward away the threat from AI should be vastly expanded, the 26 experts suggest. They include people who have ensured that other dual use technologies - those which can both improve and damage the world, such as computer security - are not used to cause such damage.\nThe report has been compiled by experts from many of the world's leading institutions and artificial intelligence research organisations, who claim that it is the first time that the intersection of artificial intelligence and its misuse in the world have been examined in such a way. The report includes input from representatives from OpenAI, the research group founded by Elon Musk; Oxford University's Future of Humanity Institute; and Cambridge University's Centre for the Study of Existential Risk.\nDr Sean O Eigeartaigh, executive director of Cambridge University's Centre for the Study of Existential Risk and one of the co-authors, said: \"Artificial intelligence is a game changer and this report has imagined what the world could look like in the next five to 10 years.\n\"We live in a world that could become fraught with day-to-day hazards from the misuse of AI and we need to take ownership of the problems - because the risks are real. There are choices that we need to make now, and our report is a call-to-action for governments, institutions and individuals across the globe.\n\"For many decades hype outstripped fact in terms of AI and machine learning. No longer. This report looks at the practices that just don't work anymore - and suggests broad approaches that might help: for example, how to design software and hardware to make it less hackable - and what type of laws and international regulations might work in tandem with this.\"\nMiles Brundage, research fellow at Oxford University's Future of Humanity Institute, said: \"AI will alter the landscape of risk for citizens, organisations and states - whether it's criminals training machines to hack or 'phish' at human levels of performance or privacy-eliminating surveillance, profiling and repression - the full range of impacts on security is vast.\n\"It is often the case that AI systems don't merely reach human levels of performance but significantly surpass it. It is troubling, but necessary, to consider the implications of superhuman hacking, surveillance, persuasion, and physical target identification, as well as AI capabilities that are subhuman but nevertheless much more scalable than human labour.\"\n"},
{"docid": "31 of 500 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "December 3, 1990", "title": "Side-steps to a lively future in the mind field; Researchers are venturing down new paths in a determined bid to revive the development of artificial intelligence. Darrel Ince reports\n", "content": "ARTIFICIAL intelligence research appears to be at a crossroads. After 10 years of intense activity, during which Western researchers have attempted to respond to the threat of Japanese intrusion into the formation technology market using artificial intelligence products, there seems to be something of a hiatus.\nResearch activity has declined even though there has been no major success in applying large- scale artificial intelligence techniques. While software companies specialising in artificial intelligence still carry out feasibility studies, or are contracted for small developments of a man-year or less, there is little evidence of customers placing orders that match conventional software projects in size.\u00a0\nCommentators have pointed out that the main product of artificial intelligence research, the expert system, still has serious problems. These systems contain a series of rules taken from human consultants; the rules enable a system to perform well in limited domains such as the diagnosis of a narrow range of\ndiseases, the detection of mineral sites in geophysical exploration and electronic circuit diagnosis.\nExpert systems with a few hundred rules are relatively easy to construct; indeed, these systems are built as student projects. However, larger systems are still proving troublesome. There are two problems. First, it can be difficult to predict the effect of adding new rules to an expert system during development because a small number can alter the whole nature of the system. Second, expert system applications that contain thousands of rules are a problem to construct because of the difficulty of eliciting rules from a human expert.\nResearchers are now looking at other techniques. The first of these is the neural network, a software and hardware simulation of some of the processes occurring in the human brain. The main aim of this research is to train the neural net to recognise various patterns and configure itself so that recognition is easy. A number of commercial neural systems have been developed which carry out activities such as recognising banknotes and faces in a security system.\nAnother active area of artificial intelligence research is that of machine-learning. Instead of carrying out a painstaking analysis of the expertise of a human consultant, researchers are trying to develop software systems that take data from a problem, together with the outcome from the data, and then, after examining a large number of problems, spot the pattern between the input data and the outcomes and hence determine the reasoning used by the human expert who has produced the outcomes.\nOne of the most successful systems based on machine- learning technology involved the development by researchers at the University of Sydney of a system to judge credit card applications in an Australian bank. The system was told of various factors used to judge whether an applicant was to be given a credit card; it then processed a number of applications together with the decision on each applicant. Based on this data, the program discovered the human reasoning behind credit card approvals and rejections. The program was then used to judge future applications.\nProbably the most radical attempt to challenge artificial intelligence orthodoxy, as exemplified by the expert system, is the genetic algorithm. These algorithms are used to select an optimal answer to a problem with a number of solutions.\nGenetic algorithms mimic genetic inheritance in nature. First, a number of solutions to a problem are generated randomly. The best features of the solutions are then mated together to produce offspring. These are then evaluated against the criteria of whether the offspring is a good solution to the problem. Large numbers of parents are mated, and a large number of offspring are produced. However, only those offspring best fitted to the problem are allowed to live. After a number of generations a number of offspring remain which are good solutions. This mimics the way natural selection works.\nWith the waning of interest in expert systems, genetic algorithms are being heavily researched in the US. A group at the Massachusetts Institute of Technology is using genetic algorithms to design electronic circuits; another group at the University of Alabama has used algorithms to design oil pipelines. Designers of future Nasa space stations are likely to employ genetic search techniques.\nThe research into neural nets, machine-learning and genetic algorithms represents a change of direction for artificial intelligence workers and may herald the demise of the expert system. The answer should be known within two years. The signs are not good, however: companies specialising in artificial intelligence in Britain and the US are experiencing hard times, indeed.\n- The author is professor of computer science at the Open University.\n"},
{"docid": "32 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 13, 2015", "title": "Top scientists call for caution over artificial intelligence; Artificial intelligence has the potential to eradicate disease and poverty, say world's top scientists, but researchers must not create something which cannot be controlled\n", "content": "Dozens of the world's top artificial intelligence experts have signed an open letter calling for researchers to take care to avoid potential \"pitfalls\" of the disruptive technology . \u00a0\nThose who have already signed the letter include Stephen Hawking, Elon Musk, the co-founders of DeepMind, Google's director of research Peter Norvig and Harvard professor of computer science David Parkes. \n\"There is now a broad consensus that AI research is progressing steadily, and that its impact on society is likely to increase,\" says the letter, published by The Future of Life Institute. \n\"The potential benefits are huge, since everything that civilisation has to offer is a product of human intelligence; we cannot predict what we might achieve when this intelligence is magnified by the tools AI may provide, but the eradication of disease and poverty are not unfathomable. Because of the great potential of AI, it is important to research how to reap its benefits while avoiding potential pitfalls. \nSome of the research priorities set out in an accompanying paper describe the need to remain in control of any artificially intelligent machine - \"systems must do what we want them to do\" - while others relate to the ethics of autonomous weapons. \nThe paper suggests that it \"may be desirable to retain some form of meaningful human control\" over intelligent machines designed to kill. \nIt also warns that legislative efforts are needed before autonomous cars become a practical and ubiquitous technology: \"If self-driving cars cut the roughly 40,000 annual US traffic fatalities in half, the car makers might get not 20,000 thank-you notes, but 20,000 lawsuits.\"\nProfessor Stephen Hawking has previously said that the rise of artificial intelligence could see the human race become extinct. \nHe told the BBC: ''The primitive forms of artificial intelligence we already have have proved very useful. But I think the development of full artificial intelligence could spell the end of the human race.'' \nTechnology entrepreneur Elon Musk has also described the rise of AI in the past as ''our biggest existential threat''. \n"},
{"docid": "33 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "March 24, 2017", "title": "Robots and AI are threatening close to a third of UK jobs, study reveals; The likelihood of automation is highest in sectors including transport, manufacturing, and wholesale and retail\n", "content": "Up to 30 per cent of UK jobs are at risk of being taken over by robots and Artificial Intelligence by the early 2030s, a new report warns.\nThe study, published by professional services firm PwC, claims that the likelihood of automation is highest in sectors including transport, manufacturing, wholesale and retail.\u00a0\nEducation, health and social work are less at risk and- as a result of that- male workers are more likely to see their jobs taken over by robots than their female counterparts.\nRead more\nArtificial intelligence set to handle O2 customer services from 2017\nDespite the threat, though, PwC says that the rise of automation is actually likely to boost productivity and generate additional jobs elsewhere in the economy in the long run.\n\"Automating more manual and repetitive tasks will eliminate some existing jobs, but could also enable some workers to focus on higher value, more rewarding and creative work, removing the monotony from our day jobs,\" said John Hawksworth, chief economist at PwC.\nRead more\nBudget to include prizes for robotics, AI and new batteries\nFacebook using artificial intelligence to help suicidal users\nGovernment invests \u00a320m in robotics and artificial intelligence\u00a0\nThis British startup is using artificial intelligence to compose music\n\"By boosting productivity - a key UK weakness over the past decade - and so generating wealth, advances in robotics and AI should also create additional jobs in less automatable parts of the economy as this extra wealth is spent or invested,\" he added.\nMr Hawksworth pointed out that the UK employment rate is now at its highest level in decades, \"despite all the advances in digital and other labour-saving technologies we have seen since\".\nHe said that it is therefore \"not clear that the future will be radically different from the past in terms of how automation will affect overall UK employment rates\".\nThe report also points out that while automation in many industries is a possibility, economic, legal and regulatory constraints mean that it is not a given.\nMr Hawksworth said that this \"may not be a bad thing if it gives existing workers and businesses more time to adapt to this brave new world\".\nAnd PwC's study shows that the UK is by far not the country that is most susceptible.\nIt showsthat 38 per cent of US jobs could at some point be done by robots, and 35 per cent of German jobs. \nLast month, telecoms company O2 announced plans to introduce AItechnology capable of performing the same job as customer service staff.\nThat technologyis expected to launch in the UK next yearand will enable the company to cut customer service costs.\nThe Reform thinktank in February published a report showing that robots and computers could replace almost 250,000 UK public sector workers over the next 15 years.\nThe group at the timesaid that use of websites and \"chat bots\" would remove the need for 130,000 Whitehall administrators, around 90 per cent of the total, by 2030, saving \u00a32.6bna year.\nA further 90,000 NHS administrative posts and 24,000 GP receptionists could be subjected to automation in a similar way, with savings of more than \u00a31.7bn, the thinktankclaimed.\n"},
{"docid": "34 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "November 22, 2017", "title": "AI can give engineering a creative boost; CAREERS IN ENGINEERING ARTIFICIAL INTELLIGENCE Rather than take away engineering roles, artificial intelligence could be the springboard for a new generation of jobs, says Mark Piesing\n", "content": "From HAL in 2001: A Space Odyssey to Ultron in The Avengers, it is hard to escape the feeling there is only one possible outcome from the rise of artificial intelligence (AI): the extinction of our species.\nThis kind of end-of-times fear is evident even in the thinking of many engineers, who believe it is just a question of when, not if, they are replaced by an algorithm.\u00a0\nIt may be only a matter of time before young people interested in a career in engineering begin to wonder what is the point of studying for so long. However, the truth is likely to be very different.\nThe need for a single engineer to acquire more than one specialism during their career, as well as the ability to work in a team, will be hard to replicate in code. As a result, the young people who want to become an engineer today will still have a great career in the future.\nWhat's more, this doom-and-gloom thinking can obscure a positive story found in some recent reports, including last month's \"Growing the artificial intelligence industry in the UK\". This independent government review suggested that AI could bring massive gains in efficiency and performance to the UK economy - to the tune of \u00a3630bn by 2035.\nThe availability of the increasingly powerful computing capacity that AI represents could turn the engineering profession upside down. It could democratise engineering as a profession, as the internet did to the media, making it easier for individual engineers to pursue their ideas outside the corridors of the big engineering firms without the baggage of long-winded explorations of design or testing.\nIt could also open up the profession to a wider range of people. With many of the barriers removed by AI, highly creative young people may be attracted to a profession to which, research suggests, they often feel they don't belong. In one sense, we could all become engineers.\nOne company forging a future for engineering with AI is start-up Klydo, housed in the Royal College of Art's Dyson building in London. Klydo's mission is to use a form of AI called machine learning to accelerate the rate of innovation by letting anyone discover the next big thing. It currently employs three people fulltime and is looking to hire another four or five. Klydo's co-founder, Nick Schweitzer, was named the UK's most promising young technology entrepreneur by the Royal Academy of Engineering Enterprise Hub.\n\"People don't often associate AI with creativity, but that is what we are doing,\" he says. \"We are developing a machine-learning tool which will use the huge amount of information that is available online to track how an industry is evolving. We can then reverse-engineer what we discover to identify what people want.\n\"The deeper the understanding you have of a market, the better products and services you will come up with. It has been made possible by incredible increases in processing power.\" Mr Schweitzer says start-ups such as Klydo are only the beginning of how AI is going to revolutionise the engineering profession.\n\"The internet is opening up the profession,\" he says. \"Engineering is exploding in terms of creativity and is being democratised. You just need to have a decent understanding of maths, a bit of programming knowledge and the right kind of mindset; then you can access a huge amount of info.\"\nOther engineers agree. \"There is a lot of scaremongering about AI and what it means for careers in engineering in the future,\" says Mivy James, British Aerospace Systems' head of consulting for national security, who is helping to develop the AI systems that will enable Britain and its allies to win the cyberwars of the future. \"There will be changes but it's another industrial revolution. The more repetitive and mundane jobs will disappear,and there will be a huge demand for engineers who can work with the new technology.\"\n\"Initially AI will start to replace the tasks that are done in single disciplines,\" says Tim Chapman, director in charge of global engineering firm Arup's infrastructure design group in London. \"But the world of most professional engineers is very multidisciplinary. Those more complex decisions will need human input for many years to come.\n\"Indeed, due to engineers' training in logical processes and problem solving, they are likely to play a significant part in applying AI throughout the economy - making their processes slicker and more accessible to everyone in society.\"\nHe believes the tasks that engineers may be called upon to do in the future will become more complicated as well. It may even make the profession of being an engineer closer to that of a social scientist.\n\"Engineers will need to do all that engineers now do, but also be able to grasp the extra challenges,\" argues Mr Chapman. \"Their role in averting global climate change and improving the cost-efficiency and resilience of the infrastructure systems, and an ageing population, will be vital.\"\nWhat isn't clear yet is just how what Mr Schweitzer is seeing in the industry today will play out in the future. Can we all become the engineers? \"Much of the mystique of any profession is behind-the-scenes slogging through various processes to devise meaningful answers,\" says Mr Chapman. \"The more those processes can be automated, the easier it will be for many more people to engage in them.\"\nThere will be changes but it's another industrial revolution\n"},
{"docid": "35 of 500 DOCUMENTS\n", "source": "Guardian.com\n", "date": "November 2, 2011", "title": "AI scientists want to make gods. Should that worry us?\n", "content": "ABSTRACT\nWendy Grossman: Singularitarians believe artificial intelligence will be humanity's saviour. But they also assume AI entities will be benevolent\u00a0FULL TEXT\nThe science fiction writer and physicist, Vernor Vinge, borrowed the term \"singularity\" from the point of discontinuity in phenomena such as black holes and applied it to the creation of artificial intelligence. The singularity is the moment at which artificial intelligence passes human intelligence - and after that nothing, Vinge told Nasa in 1993, is predictable. For those who believe this prediction, the question is not if but when.\nVinge himself expected the singularity to happen between 2005 and 2030. No one thinks we're particularly close yet, IBM's Jeopardy and chess champions notwithstanding. Vinge's ideas have been taken up by a number of others, most notably inventor and engineer Ray Kurzweil, who for many years has put the date of the singularity at 2045 and the date when machine intelligence passes the Turing test - that is, convinces a human judge it's human - at 2029.\u00a0\nScience is not a belief system but a process for arriving at the truth. Predictions about where technological development is taking us are different: they can be falsified but it takes time, and in the meantime others feel free to call you a crackpot.\nAnd many do. One of Scottish science fiction writer Ken MacLeod's characters once described the singularity as \"the rapture for nerds\". The late John McCarthy, the \"father of AI\", called it, simply, \"nonsense\", and expressed the hope of living to 102 so he could laugh at Kurzweil in 2029. Singularitarians have been known to counter that when an elderly scientist says something is impossible, he is usually wrong. Maybe: but McCarthy knew better than anyone the difficulties of creating and programming AI.\nSome of my resistance is personal. Alongside serious researchers into machine intelligence, such as IBM's Jeopardy team and Stephen Wolfram, you have Sonia Arrison expounding her book 100 Plus and John Mauldin declaiming, Texas preacher-style, on how to survive the bursting of the bubble of government debt (read his books and investment newsletter, apparently).\nListening to these folks, you would never know that the face of extreme old age is overwhelmingly poor, disabled and female. Arrison held out the hope - or nightmare - of becoming a first-time mother at 70, and claimed that innovation is a \"late-peak field\", something most mathematicians and physicists would violently disagree with.\nEven Kurzweil, undeniably respected for inventing the first optical character recognition software and in many ways the father of this movement, comes across as fuelled by belief more than science. Every year, he painstakingly updates his graphs to show that we're right on course for 2045; Wikipedia tracks his accuracy rate.\nThis year Kurzweil's talk focused on Microsoft co-founder Paul Allen's counter-arguments. Among other things, Allen complained that Kurzweil's \"law of accelerating returns\" is not an immutable physical law. No, agreed Kurzweil, but \"lots of scientific laws are not physical laws, just observations\". And he mentioned the law of gravity. Hackles up, immediately: unlike faster processors, humans do not create gravity. There is no comparison. Nor is it easy to listen to his claim that worldwide the standard of living continues to increase; in his world is no one occupying Wall Street?\nThe science fiction writer David Brin told last month's sixth annual singularity summit: \"So you want to make gods. Now, why would that bother anybody?\" The audience might not have taken this joke so well from anybody they admired less.\nSingularitarians often come across as cult-like and defensive. It doesn't help that so many see the artificial general intelligences (AGIs) they want to build as the solution to everything from climate change, radical life extension, immortality and colonising space to finding new energy sources. Immortality, gods, wealth, health, universal democracy ... aren't these the horizons that every generation has chased since time immemorial? My favourite was Tyler Cowen's hope: an AI (just call it Cyrano?) in your pocket to buzz you to stop talking too much on a first date.\nThis is where believing in the singularity is no different from belief in any other type of benevolent intelligence watching over us - gods, extraterrestrials, fairies or royalty. But suppose we do in fact build one? The reality might not be benevolent. The singularitarians may be in the position of the plummeting whale in The Hitchhiker's Guide to the Galaxy, who sees the ground rushing towards him and wonders if it will be friends with him.\n"},
{"docid": "36 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "August 3, 2017", "title": "Facebook's artificial intelligence agents creating their own language is more normal than people think, researchers say; The messages sent by chatbots might look a little bizarre, but they aren't unusual or sinister\n", "content": "Fears that computers were taking over swept the world this week when stories emerged about Facebook's AI creating its own language that researchers couldn't understand. But they might be a little misplaced.\nBut artificial intelligence experts have looked to calm worries that robots are becoming sentient or that we are living through the prelude to Terminator.\nThe messagesmight seem strange, they agree. But they are explicable and fairly normal in the world of artificial intelligence research.\u00a0\nSome of the discussion between the bots is seen below:\nBob: i can i i everything else . . . . . . . . . . . . . .\nAlice: balls have zero to me to me to me to me to me to me to me to me to\nBob: you i everything else . . . . . . . . . . . . . .\nAlice: balls have a ball to me to me to me to me to me to me to me\nBob: i i can i i i everything else . . . . . . . . . . . . . .\nAlice: balls have a ball to me to me to me to me to me to me to me\nBob: i . . . . . . . . . . . . . . . . . . .\nAlice: balls have zero to me to me to me to me to me to me to me to me to\nBob: you i i i i i everything else . . . . . . . . . . . . . .\nAlice: balls have 0 to me to me to me to me to me to me to me to me to\nBob: you i i i everything else . . . . . . . . . . . . . .\nAlice: balls have zero to me to me to me to me to me to me to me to me to\nThe messages didn't seem to be especially sinister. But the worrying nature of not being able to understand what an AI was saying or why it was saying it concerned many, and led to worries about such systems becoming sentient or conducting decisions without us being able to hold them accountable.\nThe story came after repeated warnings from many of the most respected minds in the world: people including Stephen Hawking have suggested that artificial intelligence could potentially bring about the end of humanity. Those predictions came to a head days before the story became popular as Elon Musk and Mark Zuckerberg argued about the dangers of AI - with Mr Zuckerberg saying that the danger had been overstated, after Mr Musk has repeatedly suggested that artificial intelligence could take over the world if it is not properly regulated and restrained.\nBut artificial intelligence researchers including those involved in the project have looked to calm those worries.\nThe idea of a chatbot inventing its own language might sound terrifying, those behind the Facebook research say. But it is actually a long-running part of the way that AI works and is studied- sometimes being encouraged, and at other times happening by itself.\nSimilar things have been seen in AI work done by Google for its Translate tool and at OpenAI, for instance.\nRead more\nWhy Facebook really shut down the robots which got out of hand\nIn the case of the recent Facebook study, it was entirely accidental. The agents were simply not told to ensure that they worked using language comprehensible to their human masters - and so didn't.\n\"While the idea of AI agents inventing their own language may sound alarming/unexpected to people outside the field, it is a well-established sub-field of AI, with publications dating back decades,\" Dhruv Batra, who worked on the project, wrote on Facebook.\nIn the case of Facebook's AI, the messages might be incomprehensible but their meaning can be worked out, at least a little. It has been compared to the kinds of shorthand that are developed in all communities of specialists - where words might come to mean specific things to people, but be completely mystifying to anyone who is outside of the group.\nMr Batra also took issue with the phrasing of \"shutting down\" the chatbots, and said that such a decision was commonplace. Many AI experts have become irritated because some stories said that researchers had panicked and pulled the plug - but in fact researchers just changed the AI, killing the job but simply altering some of the rules that it worked by.\n\"Analyzing the reward function and changing the parameters of an experiment is NOT the same as 'unplugging' or 'shutting down AI',\" he wrote. \"If that were the case, every AI researcher has been 'shutting down AI' every time they kill a job on a machine.\"\n"},
{"docid": "37 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "December 3, 2014", "title": "Artificial intelligence could spell end of human race - Stephen Hawking; Technology will eventually become self-aware and supersede humanity, says astrophysicist\n", "content": "The development of artificial intelligence could spell the end of the human race, Professor Stephen Hawking has said.\nThe famous astrophysicist said he believed technology would eventually become self-aware and supersede humanity, as it developed faster than biological evolution.\nHawking told the BBC: \"The primitive forms of artificial intelligence we already have, have proved very useful. But I think the development of full artificial intelligence could spell the end of the human race.\"\u00a0\nHawking - who as a result of his motor neurone disease is almost totally paralysed - also spoke of how he had received a \"life-changing upgrade\" to the computer software that allows him to communicate.\nHawking now uses a system that incorporates predictive text, allowing him to type twice as quickly as before and send emails ten times faster.\n\"I was finding it very difficult to continue to communicate effectively and so do the things I love to do,\" he told a press conference in London for the launch of the new Intel software platform.\n\"With the improvements made, I am now able to write much faster and that means I can continue to give lectures, write papers and books, and, of course, speak with my family and friends more easily.\n\"Medicine has not been able to cure me, so I rely on technology to help me communicate and live,\" he said.\nHawking has chosen to retain his familiar, slightly robotic sounding voice despite being offered something more natural.\n\"We are pushing the boundaries of what is possible through technology - without it I would not be able to speak to you today,\" he said. \"Intel's research and development is bringing about changes in the world and in the way that disabled people can communicate.\"\nHawking has been in partnership with Intel for over 25 years. His MND is related to amyotrophic lateral sclerosis. He was diagnosed in 1963, when he was 21, and given just two years to live. He turned 72 on 8 January 2014.\nThis is the first upgrade to his communications system for nearly 20 years. \"I hope it will serve me well for the next 20 years,\" he said.\nThe new ease with which Hawking speaks belies the effort he needs to expend to create even the simplest sentence. In order to be heard, he must first write a sentence using only a single muscle in his cheek, which is then sent to a voice processor.\nTo use the Intel software, an infrared sensor attached to his glasses allows Hawking to control the software by moving the muscle in his cheek. As he selects letters, predictive text offers him options for completing the word, which speeds up the process.\nUsing these predictions, he now needs to key only about 15-20 percent of the characters in any document. It has doubled his writing speed, which had gradually fallen to less than a word a minute after he lost the use of his hands and had to give up using a hand switch.\nThe software will be released to developers and researchers in January 2015, and will be made freely available to anyone who wishes to download it.\n\"Opening a document used to take 3-4 minutes. The new system uses a specific icon and takes about 10 seconds,\" said Lama Nachman, principal engineer and project Leader at Intel. She spent many hours working with Hawking as he tested the software.\n\"I think he likes finding the bugs,\" said Nachman, describing how he would smile every time he found a glitch in their Windows-based software.\n\"This software has the ability to help a much larger community of disabled people. So, to make that happen we decided to open-source the software. We are going to offer it for free to people from January next year,\" said Nachman.\nThere are three million people afflicted with MND and quadriplegia. The software has been designed in a modular way that makes it customisable. It could be controlled by touch, eye blinks, eyebrow movements and other gestures. This means it could be tailored to the specific needs of other users.\n\u00b7 This article was amended on 3 December 2014. An earlier version said that Hawking was diagnosed with MND in 1961 rather than 1963. \n"},
{"docid": "38 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "January 22, 2015", "title": "Sociopathic robots must be taught to serve\n", "content": "Artificially intelligent robots should be the Jeeves to humanity's Bertie Wooster, a leading computer scientist has said, warning that humans risked a showdown with \"sociopathic\" machines unless they were taught to be subservient.\u00a0\nStuart Russell said that the long-suffering valet in PG Wodehouse's novels - in which stories were often set in the fictional Drones Club - did not need to be told what his master wanted. Their relationship, therefore, should be used as a blueprint for humanity's interaction with artificially intelligent beings.\nProfessor Russell, of the University of California, Berkeley, is one of hundreds of scientists to have signed an open letter calling for additional research to be carried out into the development of AI. Many researchers, including Stephen Hawking, are worried that without extra care, humans could be wiped out by machines whose artificial intelligence exceeded our own.\nSpeaking at the World Economic Forum in Davos, Switzerland, Professor Russell said that humanity was in danger unless AI was taught to be subservient to human needs. He predicted that artificial intelligence would overtake that of human beings within his lifetime. His forecast chimes with that of Ray Kurzweil, Google's director of engineering, who has been described by Bill Gates, the former Microsoft boss, as \"the best person I know at predicting the future of artificial intelligence\".\nMr Kurzweil believes that artificial intelligence will surpass human intelligence - an event termed \"the singularity\" - in 2029. However, he believes that super-intelligent beings would be naturally subservient to humans.\nThe open letter signed by Professor Hawking and Professor Russell has also been signed by Elon Musk, the technology entrepreneur who owns SpaceX and Tesla Motors. He suggested in August that artificial intelligence was \"potentially more dangerous than nukes\".\nThe letter, published by the Future of Life Institute, says: \"Our AI systems must do what we want them to do.\" The potential benefits of AI are huge, the letter says, because \"everything that civilisation has to offer is a product of human intelligence\".\nHowever, \"we cannot predict what we might achieve when this intelligence is magnified by the tools AI may provide,\" it warns.\nThe researchers posed a number of questions in a research paper accompany-ing the letter. Among them, they ask whether autonomous weapons might result in wars, or whether a self-driving car should be allowed to weigh up a small probability of injury to a human against the nearcertainty of expensive vehicle damage. In an interview in December, Professor Hawking said that the development of full artificial intelligence \"could spell the end of the human race\". It would \"take off on its own, and redesign itself at an ever-increasing rate\", he said. \"Humans, who are limited by slow biological evolution, couldn't compete, and would be superseded.\"\nArtificial intelligence has become big business. DeepMind, a secretive British AI research company, was bought by Google last year for an estimated \u00a3400 million. Demis Hassabis, the founder of Deep-Mind, is another signatory to the Future of Life Institute's open letter.\nA poll of 1,900 technology experts by the Pew Research Centre has suggested that artificially intelligent robots would supplant lawyers, doctors, accountants and other white-collar workers by 2025.\n"},
{"docid": "39 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "February 21, 2018", "title": "Artificial intelligence: The saviour of mankind or the end of the world?\n", "content": "To some, Artificial Intelligence will dramatically improve our lives in the future. To others, it spells the end of mankind.\u00a0\nA new report from Oxford and Cambridge researchers has fuelled the debate about AI, warning that\u00a0malicious use of AI presented a \"clear and present danger\" to society that could emerge in the next decade.\nThe ongoing discussion about the technology has some of the greatest minds in the world pitted at opposite ends of the spectrum.\u00a0\nWhile the technology has undoubted benefits, many point out that not enough consideration has been devoted to the potentially catastrophic outcomes.\u00a0\nRecognising the possible problems ahead, \u00a0the Government recently set up a body to oversee ethics in the field and last month Theresa May called AI \"one of the greatest tests of leadership for our time\".\u00a0\nYet Britain keen to be a leader in the field, which\u00a0is increasingly used to drive cars, diagnose patients and even to help determine prison sentences.\nHere are some prominent voices in the debate.\n                   Words of warning                   \nStephen Hawking\nAmong  the most outspoken critics of the technology has been Professor Stephen Hawking.\u00a0At the opening of a new Cambridge centre exploring the possible dangers of AI in 2016, the British physicist said: \"The rise of powerful AI will be either the best or the worst thing ever to happen to humanity. We do not know which.\"\nWarning dangers\u00a0\"like powerful autonomous weapons or new ways for the few to oppress the many\", he added:\u00a0 \"It will bring great disruption to our economy, and in the future AI could develop a will of its own that is in conflict with ours.\"\nTwo years earlier, he issued the blunt warning :\u00a0\"The primitive forms of artificial intelligence we already have have proved very useful. But I think the development of full artificial intelligence could spell the end of the human race.''\nElon Musk\nAnother prominent doom-monger is Elon Musk, the\u00a0billionaire technology entrepreneur. Putting the issue into context in September, the\u00a0chief executive of Tesla and SpaceX said\u00a0artificial intelligence was a greater threat to civilisation than the North Korean regime. In particular, he has warned about the threat of\u00a0autonomous weapons.\nChina, Russia, soon all countries w strong computer science. Competition for AI superiority at national level most likely cause of WW3 imo.\n- Elon Musk (@elonmusk) September 4, 2017                                                                                                                                                                                  \nMay be initiated not by the country leaders, but one of the AI's, if it decides that a prepemptive strike is most probable path to victory\n- Elon Musk (@elonmusk) September 4, 2017                                                                                  \nMr Musk has been calling for regulation as soon as possible.\u00a0\"AI is a rare case where we need to be proactive in regulation instead of reactive because if we're reactive in AI regulation it's too late,\" he told a meeting of US governors in July last year, adding that \"AI is a fundamental risk to the existence of civilisation\".\u00a0\nRichard Branson\nLast week, the Richard Branson, the billionaire entrepreneur, warned the technology could exacerbate income inequality.\n\"I think with the coming on of AI and other things there is certainly a danger of income inequality,\" Branson tells CNN's Christine Romans in a piece published Thursday.\n                   Humans need not apply | Artificial intelligence in the workplace                   \nThe inequality will be caused by \"the amount of jobs [artificial intelligence] is going to take away and so on. There is no question\" technology will eliminate jobs, he told CNN.\nHe is also sceptical that AI can beat human instinct when it come to business.\u00a0\u00a0\"We must not forget that unlike machines that 'think', only humans have the ability to look at an idea or market opportunity and say 'to hell with the data. Maybe this doesn't work in theory, but my gut tells me it will work in practice',\" he wrote in a blog . \u00a0\nNick Bostrom\nNick Bostrom, director of Oxford's Future of Humanity Institute, has also expressed fears about artificial intelligence if it is not handled very carefully.\u00a0 In his 2014 book Superintelligence: Paths, Dangers, Strategies, Bostrom warns that AI could dispose of humans, resulting in a\u00a0world that would see \"economic miracles and technological awesomeness, with nobody there to benefit,\" like \"a Disneyland without children.\"\n\"Before the prospect of an intelligence explosion, we humans are like small children playing with a bomb,\" he writes.\u00a0\nIt was experts from the\u00a0Future of Humanity Institute who are warning this week\u00a0that artificial intelligence risked being exploited by terrorists to mount driverless car crashes and cyber attacks because the technology was being rapidly developed without thought for its downsides.\u00a0\n                   But on the bright side...                   \nMark Zuckerberg\nAccording to Mark Zuckerberg, the co-founder of Facebook, the likes of Mr Musk are being \"pretty irresponsible\" by voicing such dire warnings.\u00a0\nIn July last year, Mr Zuckerberg said he was very much \"optimistic\" about the future of AI. \u00a0\"In the next five to 10 years, AI is going to deliver so many improvements in the quality of our lives,\" \u00a0the entrepreneur\u00a0said on Facebook Live.\u00a0\nHe pointed\u00a0out that it was already helping diagnose diseases, and predicted that driverless cars would cut the number of deaths from road accidents. \u00a0\n\"You need to be careful about what you build and how it is going to be used,\" he said. \"But people who are arguing for slowing down the process of building AI, I just find that really questionable.\"\nThe social media giant last year said it would use AI\u00a0to spot users who may be at risk of suicide and seek help for them. It is also looking at developing artificial intelligence to automate the identification of terrorist material .\u00a0\nHowever, it also had to shut down a pair of its artificial intelligence robots in August after they invented their own language .\nBill Gates\nBill Gates, the Microsoft founder, has not always been a fan of AI. \u00a0 In 2015, he wrote on Reddit, Mr Gates wrote: \"I am in the camp that is concerned about super intelligence. First the machines will do a lot of jobs for us and not be super intelligent. That should be positive if we manage it well. A few decades after that though the intelligence is strong enough to be a concern. I agree with Elon Musk and some others on this and don't understand why some people are not concerned.\"\nMore recently, however, he has struck a more positive tone.\u00a0\"Certainly we can look forward to the idea that vacations will be longer at some point,\"\u00a0Gates told FOX Business Network at the World Economic Forum last month. Machine learning will make humans more productive and efficient, he said. \u00a0\nMaking the same point last week, he said:\u00a0\"AI is just the latest in technologies that allow us to produce a lot more goods and services with less labor. And overwhelmingly, over the last several hundred years, that has been great for society,\" Gates said at Hunter College in New York City.\nLarry Page\u00a0\nElon Musk may be friends with Google Co-Founder Larry Page, but they don't see eye-to-eye on AI. In an interview with the Financial Times in 2014, Page commented on the fears that computers will take the jobs of people.\n\"You can't wish away these things from happening, they are going to happen,\" he said. \"You're going to have some very amazing capabilities in the economy. When we have computers that can do more and more jobs, it's going to change how we think about work. There's no way around that. You can't wish it away.\"\u00a0\nBut he said people should embrace this shift.\u00a0\"The idea that everyone should slavishly work so they do something inefficiently so they keep their job - that just doesn't make any sense to me,\" he said. \"That can't be the right answer.\"\u00a0\nHis philosophy is: \"Technology should do the hard work - discovery, organisation, communication - and then get out of the way, so people can live their lives and do what makes them happiest, not messing around with annoying machines.\"\nSam Altman\nSam Altman, the president of Silicon Valley startup incubator Y Combinator, takes a more balanced approach to AI. Along with a number of other Silicon Valley figures, including Mr Musk, he backed\u00a0\u00a0OpenAI, a nonprofit research venture aimed at developing \"digital intelligence in the way that is most likely to benefit humanity.\"\u00a0\n                   AI timeline                   \nHe believes AI should be available to all rather than a few, believing the good will outweigh the evil. \"Just like humans protect against Dr. Evil by the fact that most humans are good, and the collective force of humanity can contain the bad elements, we think it's far more likely that many, many AIs, will work to stop the occasional bad actors,\" he said. \u00a0\n"},
{"docid": "40 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "January 13, 2015", "title": "Scientists raise alarm over tomorrow's world\n", "content": "Are autonomous weapons likely to result in accidental wars? Should a selfdriving car be allowed to weigh up a small probability of injury to a human against the near-certainty of an expensive, victimless accident? These disconcerting questions are among many that Stephen Hawking and hundreds of other researchers want answered before we create an artificial intelligence to rival our own.\u00a0\nMore than 400 prominent individuals have signed an open letter calling for additional research to be carried out in the field to ensure that future advances are of benefit to humanity rather than machines.\n\"Our AI [artificial intelligence] systems must do what we want them to do,\" reads the letter published by the Future of Life Institute on its website.\ndevel-That Professor Hawking is a signatory is not a surprise. He warned last month that the development of advanced artificial intelligence could spell the end of the human race. Another signatory, Elon Musk, the technology entrepreneur who runs Tesla Motors and SpaceX, suggested in August that artificial intelligence was \"potentially more dangerous than nukes\". Accompanying the letter is a research paper that poses a number of questions.\nCan lethal autonomous weapons be made to comply with humanitarian law? How should the ability of AI systems to interpret data obtained from surveillance cameras, phone lines, emails and other sources interact with the right to privacy? Should legal questions about AI be handled by existing \"cyberlaw\" or should they be treated separately? \"Because of the great potential of AI, it is important to research how to reap its benefits while avoiding potential pitfalls,\" the letter says. \"We believe that research on how to make AI systems robust and beneficial is both important and timely.\"\nThe letter, which has also been signed by Demis Hassabis, the British founder of DeepMind, a secretive artificial intelligence research company bought by Google last year for an estimated \u00a3400 million, says that there is a \"broad consensus that AI research is progressing steadily and that its impact on society is likely to increase\". It adds: \"The potential benefits are huge, since everything that civilisation has to offer is a product of human intelligence. We cannot predict what we might achieve when this intelligence is magnified by the tools AI may provide, but the eradication of disease and poverty are not unfathomable.\"\nSpeech recognition, image classification, autonomous vehicles, machine translation, legged locomotion and question-answering systems are among the \"remarkable successes\" in AI recently, the letter adds.\n"},
{"docid": "41 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "December 26, 2014", "title": "Why the Turing test is obsolete; Artificial intelligence is more than a question of imitation, it's a matter of understanding - but can the Turing Test tell the difference?\n", "content": "The ability to pass the Turing Test has long been considered the hallmark of an artificially intelligent system, but ever since a chatbot known as Eugene Goostman succeeded in passing the test earlier this year, its suitability as a measure of machine intelligence has been called into question. \nThe name Alan Turing is perhaps best associated with the breaking of the German naval Enigma code - a feat of international importance and technological prowess that Winston Churchill called the single biggest contribution to the Allied victory over Nazi Germany during the Second World War. \u00a0\nThe critically-acclaimed filmThe Imitation Game, released last month, documents Turing's attempts to crack the Enigma code, as well as his ostracisation as a result of his homosexuality. It also hints at his pioneering work on artificial intelligence, for which he is now known as \"The Father of Theoretical Computer Science and Artificial Intelligence\". \nIn 1950, Turing introduced a landmark test of artificial intelligence, known as the Turing Test, in which an interrogator engages in simultaneous conversations with both a human and a computer, and tries to determine which is which. If the computer can convince the interrogator that it is a human, it may be classified as intelligent. \nIn June of this year, a chatbot became the first machine to pass the Turing Test by convincingly imitating a 13-year-old Ukrainian boy named Eugene Goostman. In a five-minute keyboard conversation with a panel of judges at the Royal Society in London, Eugene managed to convince 33 per cent of the panel that it was human. \nThis was enough to pass the Turing Test, but not enough to convince a large contingent of industry watchers, many of whom claimed the limited life experience, vocabulary and sophistication of an adolescent boy from a foreign country had acted as a smokescreen to mask a wide range of flaws and weak points in the conversation. \nDespite the Royal Society declaring Eugene's success an \"important landmark\", many are now calling for a more credible test of a machine's ability to reason as a human would. While Eugene was able to immitate natural language, it was only mimicking understanding - it did not learn from the interaction, nor did it demonstrate problem solving skills. \nOne alternative, put forward by voice and language software provider Nuance Communications, is the Winograd Schema Challenge. Developed by Hector Levesque, professor of computer science at the University of Toronto, the Winograd Schema Challenge aims to provide a more accurate measure of genuine machine intelligence. \nRather than basing the test on the sort of short free-form conversation suggested by the Turing Test, the Winograd Schema Challenge poses a set of multiple-choice questions that have a form where the answers are expected to be fairly obvious to a layperson, but ambiguous for a machine without human-like reasoning or intelligence. \nFor example, a Winograd Schema Challenge question might ask: \"The trophy would not fit in the brown suitcase because it was too big. What was too big? Answer 0: the trophy or Answer 1: the suitcase?\" \nA human who answers these questions correctly typically uses his abilities in spatial reasoning, his knowledge about the typical sizes of objects, and other types of commonsense reasoning, to determine the correct answer. \n\"Where we're going now is really to extract the meaning and the intent of what somebody said and put it into the context of the conversation, and then using things like anaphora to be able to have a conversation with somebody knowing that they are not always going to reference the subject,\" said John West, solutions architect for Nuance. \n\"We're starting to build those anaphora into systems right now, so what the Winograd Schema is looking at is the phrases and trying to add further intelligence to the understanding of that phrase.\"\nWest said that, most of the artificially intelligent systems in use today - like Apple's Siri and Microsoft's Cortana - are very domain-specific, so the expectation around what they are able to achieve is restricted to that domain. \nHowever, as artificially-intelligent computers become more general-purpose, they will need to become more context-aware in order to interact with humans more effectively. These computers could eventually replace humans in a wide range of low-level jobs. \nAt the moment, most automated phone systems, for example, are deliberately made to sound non-human, because they are incapable of recognising a change of context. However, in the future it may be impossible to tell if you are talking to a human or a machine. \n\"The voice recognition capabilities and the systems behind them - the natural language understanding capabilities - are improving rapidly. We've seen that with the personal assistants on mobile devices,\" said West. \n\"And users' perceptions of that are getting better, so we're becoming more used to talking to machines, whether they be in front of you, or whether they be on the end of a telephone.\"\nThe Winograd Schema Challenge will be administered on a yearly basis by CommonsenseReasoning.org, starting in 2015. The first submission deadline will be 1 October 2015. The winner that meets the baseline for human performance will receive a grand prize of $25,000 (\u00a316,000). \n"},
{"docid": "42 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "October 8, 2015", "title": "Stephen Hawking: Artificial intelligence could wipe out humanity when it gets too clever as humans will be like ants; AI is likely to be 'either the best or worst thing ever to happen to humanity,' Hawking said, 'so there's huge value in getting it right'\n", "content": "Stephen Hawking has warned that artificially intelligent machines could kill us because they are too clever.\nSuch computers could become so competent that they kill us by accident, Hawking has warned in his first Ask Me Anything session on Reddit.\nA questioner noted that Professor Hawking's ideas about artificial intelligence are seen as \"a belief in Terminator-style 'Evil AI'\", and asked how he would present his own beliefs.\u00a0\n\"The real risk with AI isn't malice but competence,\" Professor Hawking said. \"A super intelligent AI will be extremely good at accomplishing its goals, and if those goals aren't aligned with ours, we're in trouble.\nRead more\nAI system found to be as clever as a child\n\"You're probably not an evil ant-hater who steps on ants out of malice, but if you're in charge of a hydroelectric green energy project and there's an anthill in the region to be flooded, too bad for the ants. Let's not place humanity in the position of those ants.\"\nHawking said that eventually humans might become cleverer than their creators. Our own intelligence is no limit on that of the things we create, he said: \"we evolved to be smarter than our ape-like ancestors, and Einstein was smarter than his parents\".\nIf they become that clever, then we may face an \"intelligence explosion\", as machines develop the ability to engineer themselves to be far more intelligent. That might eventually result in \"machines whose intelligence exceeds ours by more than ours exceeds that of snails\", Hawking said.\nHawking said that it wasn't clear how long such artificial intelligence would take to develop - warning that people shouldn't trust \"anyone who claims to know for sure that it will happen in your lifetime or that it won't happen in your lifetime\".\nBut when it does happen, Hawking said, \"it's likely to be either the best or worst thing ever to happen to humanity, so there's huge value in getting it right\". As such, we should \"shift the goal of AI from creating pure undirected artificial intelligence to creating beneficial intelligence\".\nRead more\n                     Artificial\u00a0intelligence could kill us because we're stupid                   \n                     Artificial\u00a0intelligence will threaten us, says Bill Gates                   \n                     Hawking, Elon Musk and others call for research into AI risks                   \n\"It might take decades to figure out how to do this, so let's start researching this today rather than the night before the first strong AI is switched on,\" Hawking said. That echoed the warnings in the open letter about AI that Hawking's AMA had followed - in it, experts warned that if we are lax about thinking about artificial intelligence, computers will become too clever before we even realise.\nBefore the robots become so powerful that they accidentally kill us, they might end up taking our jobs. Asked whether the rise of artificially intelligent robots could lead to \"technological employment\", Hawking warned that it would depend entirely on how the extra wealth that they create was distributed.\n\"Everyone can enjoy a life of luxurious leisure if the machine-produced wealth is shared, or most people can end up miserably poor if the machine-owners successfully lobby against wealth redistribution,\" Hawking said. \"So far, the trend seems to be toward the second option, with technology driving ever-increasing inequality.\"\n"},
{"docid": "43 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "August 9, 2017", "title": "Hastings begins hunt for artificial intelligence experts\u00a0\n", "content": "Hastings is the latest British insurer looking to invest in\u00a0artificial intelligence after chief executive\u00a0Gary Hoffman pledged to\u00a0hire hundreds of data experts.\u00a0\nMr Hoffman said the FTSE 250\u00a0company was looking to hire a \"few hundred people in the next few years, particularly data analytics people and people involved in AI [artificial intelligence].\"\u00a0\u00a0\nInsurers are competing to embrace artificial intelligence or machine learning to spot risky behaviour and\u00a0fight fraudulent claims, with Aviva confirming earlier this year that it was looking to acquire start-ups in this space. \u00a0\nMr Hoffman's comments follow\u00a0a strong\u00a0first half for the group, which\u00a0reported a 22pc boost in profits to \u00a386.5m\u00a0after cashing in on the rising number of people shopping for a bargain on price comparison websites.\u00a0\n                   Hastings                   \nThe group, which provides car, bike, van and home insurance, also saw\u00a0gross written premiums soar 28pc\u00a0on a year ago to \u00a3462m for the six months to June 30.\u00a0\n\"The group's digitally focused business model has allowed it to benefit as customers shop around for the best deal available in the face of market-wide inflation in car premiums,\" the company said.\u00a0\nMr Hoffman said the group was on track to deliver the targets\u00a0it set itself earlier this year - which include having 3m customer policies in place by 2019, up from 2.5m currently - to replace\u00a0those\u00a0 laid out after its initial public offering in 2015 .\u00a0\nLike most of its rivals, Hastings is still waiting\u00a0on the outcome of a Government consultation into a change in the so-called discount\u00a0rate, which could cost insurers an\u00a0estimated \u00a35.8bn if it stays at -0.75pc.\u00a0\nShares in Hastings dipped on Wednesday.\u00a0\n"},
{"docid": "44 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "January 8, 2016", "title": "Apple buys artificial intelligence software that can tell people's emotions from their faces; The company has been snapping up various image and facial recognition companies, in a move that could be part of its plans to bulk up its artificial intelligence capabilities\n", "content": "                     Apple has bought a company that makes computers that can read the expression on people's faces.\nEmotient is the latest in a run of companies focused on image and facial recognition. The deal could be part of the company's plans to build more artificial intelligence into iPhones and other hardware, apparently with the aim of allowing the software to tell what its user is thinking.\u00a0\nApple added some artificial intelligence to its phones in iOS 9. That phone can guess at what its user is going to be looking for, and tries to show it on screen for easy access.\nRead more\niPhone 7 will 'drop headphone jack, be waterproof'\nIt's possible that the new acquisition is part of that push - allowing for the phone to tell how its owner is feeling and present them with a playlist of loud music if they are feeling angry, for instance.\nThe company has recently bought other like Faceshift which can analyse faces and Perceptio, which can spot what is in a picture using deep learning.\nApple is just one of a range of companies with interests in facial recognition, which also includes Google and Facebook. But the technology has proved controversial, and most companies don't turn it on in Europe because of fears that the EU will oppose it.\nApple confirmed the deal with its usual statement. The company \"buys smaller technology companies from time to time, and we generally do not discuss our purpose or plans\", it told the Wall Street Journal.\n"},
{"docid": "45 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "March 15, 2016", "title": "Google DeepMind computer beats Go champion Lee Se-dol in shock 4-1 victory; Some had thought that Mr Lee's clawing back of the fourth game could indicate that he was learning how the computer worked - but the final game ended in a victory for AlphaGo\n", "content": "Google's Go-playing computer has definitively beaten the best human in the world, finishing a pioneering match at 4-1.\u00a0\nFor the past week, AlphaGo has been playing grandmaster Lee Sedol, one of the top Go players in history. The victory has been hailed as a huge leap forward for artificial intelligence systems of the kind built by DeepMind, Google's artificial intelligence team.\nThe ancient Chinese board game had been seen as too complex for computers to master. Just months ago, artificial intelligence experts said that we were at least 10 years from creating a computer powerful enough to beat the best humans at the game.\nBut Go fans across Asia were astonished when Lee, one of the world's best Go players, lost the first three matches.\nLee beatAlphaGoin the fourth match. He said he had found weak points in Google DeepMind's artificial intelligence programme which showed the machine was not infallible.\nSome had thought that could mean that Lee would go on to win the fifth game, too, and that AlphaGo's victory in the first three games was the result of its eccentric and non-human playing style. But the Google computer dispelled those doubts, winning the fifth game after in a tense and long showdown.\nGoogle wants to useAlphaGobeyond games, ultimately to solve real-world problems. The computer has been widely seen as proof that artificial intelligence machines could go on to master characteristics that were previously thought to belong only to humans, like intuition.\nAdditional reporting by Press Association\n"},
{"docid": "46 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "October 27, 2014", "title": "Tesla boss Elon Musk warns artificial intelligence development is 'summoning the demon'; The\u00a0business magnate, inventor and investor has warned about artificial intelligence\u00a0before\n", "content": "Tesla chief executive Elon Musk has described artificial intelligence as a \"demon\" and the \"biggest existential threat there is\", in his latest dramatic statement about technology.\nAddressing students at the Massachusetts Institute of Technology, Musk said: \"I think we should be very careful about artificial intelligence. If I were\u00a0to guess like what our biggest existential threat\u00a0is, it's probably\u00a0that.\n\"With artificial intelligence we are summoning the demon. In all those stories where there's the guy with the pentagram and the holy water, it's like yeah he's sure he can control the demon. Didn't work out.\"\u00a0\u00a0\nThe\u00a0business magnate, inventor and investor, who is also CEO and CTO of\u00a0SpaceX, and chairman of\u00a0SolarCity, has warned about artificial intelligence\u00a0before, which he believes could be more threatening than nuclear weapons.\nIn August he\u00a0tweeted: \"Worth reading Superintelligence by Bostrom. We need to be super careful with AI. Potentially more dangerous than nukes.\"\u00a0\nWorth reading Superintelligence by Bostrom. We need to be super careful with AI. Potentially more dangerous than nukes. - Elon Musk (@elonmusk) August 3, 2014\nIn another Twitter post he said: \"Hope we're not just the biological boot loader for digital superintelligence. Unfortunately, that is increasingly probable.\"\nIn pictures: Landmarks in AI development\nDuring his MIT appearance Musk also discussed his company SpaceX's plans to help populate Mars. \"It's cool to send one mission to Mars, but that's not what will change the future for humanity,\" he said.\n\"What matters is being able to establish a self-sustaining\u00a0 civilisation on Mars, and I don't see anything being done but SpaceX. I don't see anyone else even trying.\"\nMusk left the symposium to a standing ovation. Watch the whole thing here.\u00a0\nThe ethical issues around AI were highlighted earlier this year when Google bought the British start-up DeepMind for $400 million (\u00a3242m). The London-based firm, founded by chess prodigy Demis Hassabis, specialises in algorithms and machine learning for e-commerce and games. But Mr Hassabis has also predicted that AI machines will learn \"basic vision, basic sound processing, basic movement control, and basic language abilities\" by the end of the decade.\nThat purchase - Google's largest European acquisition - came just months after it bought Boston Dynamics, a firm that produces life-like military robots. Google has reportedly set up an \"ethics board\" in wake of the purchases but concerns remain.\nDr Stuart Armstrong, from the Future of Humanity Institute at Oxford University, has warned that artificial intelligence could spur mass unemployment as machinery replaces manpower. He has also warned about the implications for uncontrolled mass surveillance if computers were taught to recognise human faces.\nBut Mr Musk's warning has particular weight given his strong credentials as a tech pioneer. The South African-born multi-millionaire's CV includes online payments system PayPal, electronic car manufacturer Tesla Motors, and Hyperloop - his proposal for a near-supersonic transport link between San Francisco and Los Angeles.\nIn 2002 many sneered as Mr Musk launched a private space travel company Space X. A decade later it became the first private firm to launch a spacecraft into orbit and bring it back to earth.\nIntelligent machines: AI breakthroughs\n                     Lincor                   \nA bedside computer that entertains patients while engaging them with relevant information and advice.\n                     SwiftKey                   \nUnderstands the context of language and how words fit together.\n                     Celaton                   \nApplies AI to labour-intensive clerical tasks.\n                     Darktrace                   \nUses advanced mathematics to detect abnormal behaviour in organisations instantly in order to manage risks from cyber attacks.\n"},
{"docid": "47 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "August 30, 2016", "title": "The rise of robots: forget evil AI - the real risk is far more insidious; It's far more likely that robots would inadvertently harm or frustrate humans while carrying out our orders than they would rise up against us\n", "content": "When we look at the rise of artificial intelligence, it's easy to get carried away with dystopian visions of sentient machines that rebel against their human creators. Fictional baddies such as the Terminator's Skynet or Hal from 2001: A Space Odyssey have a lot to answer for.\nHowever, the real risk posed by AI - at least in the near term - is much more insidious. It's far more likely that robots would inadvertently harm or frustrate humans while carrying out our orders than they would become conscious and rise up against us. In recognition of this, the University of California, Berkeley has this week launched a center to focus on building people-pleasing AIs.\u00a0\nThe Center for Human-Compatible Artificial Intelligence, launched this week with $5.5m in funding from the Open Philanthropy Project, is lead by computer science professor and artificial intelligence pioneer Stuart Russell. He's quick to dispel any \"unreasonable and melodramatic\" comparisons to the threats posed in science fiction.\n\"The risk doesn't come from machines suddenly developing spontaneous malevolent consciousness,\" he said. \"It's important that we're not trying to prevent that from happening because there's absolutely no understanding of consciousness whatsoever.\"\nRussell is well known in the artificial intelligence community and in 2015 penned an open letter calling for researchers to look beyond the goal of simply making AI more capable and powerful to think about maximizing its social benefit. The letter has been signed by more than 8,000 scientists and entrepreneurs including physicist Stephen Hawking, entrepreneur Elon Musk and Apple co-founder Steve Wozniak.\n\"The potential benefits [of AI research] are huge, since everything that civilization has to offer is a product of human intelligence; we cannot predict what we might achieve when this intelligence is magnified by the tools AI may provide, but the eradication of disease and poverty are not unfathomable,\" the letter reads.\n\"Because of the great potential of AI, it is important to research how to reap its benefits while avoiding potential pitfalls.\"\nIt's precisely this thinking that underpins the new center.\nUp until now, AI has primarily been applied to very limited contexts such as playing Chess or Go or recognizing objects in images, where there isn't much scope for the system to do much damage. As they start to make decisions on our behalf within the real world, the stakes are much higher.\n Related:  Technology is killing the myth of human centrality - let's embrace our demotion\n\"As soon as you put things in the real world, with self-driving cars, digital assistants ... as soon as they buy things on your behalf, turn down appointments, then they have to align with human values,\" Russell said. \nHe uses autonomous vehicles to illustrate the type of problem the center will try to solve. Someone building a self-driving car might instruct it never to go through a red light, but the machine might then hack into the traffic light control system so that all of the lights are changed to green. In this case the car would be obeying orders but in a way that humans didn't expect or intend. Similarly, an artificially intelligent hedge fund designed to maximize the value of its portfolio could be incentivized to short consumer stocks, buy long on defence stocks and then start a war - as suggested by Elon Musk in Werner Herzog's latest documentary.\n\"Even when you think you've put fences around what an AI system can do it will tend to find loopholes just as we do with our tax laws. You want an AI system that isn't motivated to find loopholes,\" Russell said.\n\"The problem isn't consciousness, but competence. You make machines that are incredibly competent at achieving objectives and they will cause accidents in trying to achieve those objectives.\"\nTo address this, Russell and his colleagues at the center propose making AI systems that observe human behavior and try to work out what the human's objective is, then behave accordingly and learn from mistakes. So instead of trying to give the machine a long list of rules to follow, the machine is told that its main objective is to do what the human wants them to do. \nIt sounds simple, but it's not how engineers have been building systems for the past 50 years.\nBut if AI systems can be designed to learn from humans in this way, it should ensure that they remain under human control even when they develop capabilities that exceed our own.\nIn addition to watching humans directly using cameras and other sensors, robots can learn about us by reading history books, legal documents, novels, newspaper stories as well as by watching videos and movies. From this they can start to build up an understanding of human values.\nIt won't be easy for machines. \"People are irrational, inconsistent, weak-willed, computationally limited, heterogenous and sometimes downright evil,\" Russell said.\n\"Some are vegetarians and some really like a nice juicy steak. And the fact that we don't behave anything close to perfectly is a serious difficulty.\"\n"},
{"docid": "48 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "April 12, 2016", "title": "Brave new world? Sci-fi fears 'hold back progress of AI', warns expert; Chris Bishop fears concern over Terminator-style scenarios could deprive humanity of one of the most powerful technologies ever created\n", "content": "The promise of artificial intelligence could be lost to humanity because people fear Terminator-style robots and other doomsday scenarios, an expert has warned.\nHyperbole about the risks of artificial intelligence threaten to scupper developments that could assist humanity, from driverless cars that could cut down road accidents to medical systems that could revolutionise healthcare, said Chris Bishop, director of Microsoft Research in Cambridge.\u00a0\n\"The danger I see is if we spend too much of our attention focusing on Terminators and Skynet and the end of humanity - or generally just painting a too negative, emotive and one-sided view of artificial intelligence - we may end up throwing the baby out with the bathwater,\" Bishop told the Guardian ahead of a discussion about machine learning at the Royal Society on Tuesday.\nHe said he \"completely disagreed\" with the views of high-profile naysayers such as Elon Musk and Stephen Hawking. The latter has previously warned that the \"development of full artificial intelligence could spell the end of the human race\".\n\"Any scenario in which [AI] is an existential threat to humanity is not just around the corner,\" said Bishop. \"I think they must be talking decades away for those comments to make any sense. Right now we are in control of that technology and we can make lots of choices about the paths that we follow.\"\n Related:  Microsoft's racist chatbot returns with drug-smoking Twitter meltdown\nDespite being one of the co-signatories to an open letter published last year, which called for the pursuit of artificial intelligence for good - while avoiding its 'pitfalls', Bishop does admit AI has its dangers.\n\"It is a very powerful technology, potentially one of the most powerful humanity has ever created with enormous potential to bring societal benefits,\" he said. \"But any very powerful very generic technology will carry with it some risks.\"\nBut the nature of these risks are not Terminator-style disasters. In fact, he said, the near-term risks are far more mundane, relating to the systems potentially developing biases as they learn. Issues relating to the ownership of data also need attention, he added.\nWhile Bishop admits that the recent victory of the computer system AlphaGo in the ancient game of Go was impressive, he adds that scientists are a long way off building a machines that have human-like intelligence. \"There are many, many things that machines can't begin to do that are very natural to the human brain and at this point to talk about machines with the full spectrum of capabilities of human intelligence is highly speculative and most experts in the field would put this at many decades away,\" he said. \nBishop, who believes the future lies in closer cooperation between humans and machines, believes there is a need for experts to weigh in on discussions about AI. \"I think it is important that people like myself are willing to present both sides of the argument and allow a more informed and balanced debate to take place about these topics,\" he said. \"When very high profile people speak about the topic it tends to put [it] into the public consciousness and that is a really good thing - provided other voices can be heard and that we can have a reasoned debate.\" \n"},
{"docid": "49 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "July 3, 2017", "title": "Machines of loving grace: how Artificial Intelligence helped techno grow up; Warp Records' compilation Artificial Intelligence brought electronic music to the living room, but also unleashed a tidal wave of snobbery around 'intelligent dance music'. Twenty-five years on, has it endured?\n", "content": "In the days of ever-changing playlists and unlimited Soundcloud mixes it might seem strange that something as simple as a compilation album could change the course of music. And yet that was what happened 25 years ago this month, in July 1992, with the release of Warp Records' first Artificial Intelligence compilation. It was a record that helped to launch the careers of Autechre, Aphex Twin and Richie Hawtin, birthed the genre that would later become known as intelligent dance music (or IDM), and changed the idea of electronic music as merely a tool for dancing.\nArtificial Intelligence wore its heart on its sleeve: the front cover features an android slumped in an armchair in front of a stereo, with albums from Kraftwerk and Pink Floyd scattered around. Below this, the tagline \"electronic listening music from Warp\" spelled out the compilation's modus operandi: this was electronic music for the home, not the rave - a notion that was largely foreign 25 years ago.\u00a0\nIn retrospect, the compilation's tracklisting was equally historic. Aphex Twin, whose classic Selected Ambient Works 85-92 album had been released just five months previously, contributed the eerie Polygon Window under the pseudonym The Dice Man; Autechre appeared twice, with the joyous electro of Crystel and the Egg; Richie Hawtin (as UP!) was responsible for Spiritual High, a pulsating acid track that feels a little out of place in its out-and-out embrace of the dancefloor; Warp stalwarts Black Dog Productions (as IAO) contributed the warm electronic embrace of The Clan; B12 (as Musicology) served up breakbeat techno on Telefone 529 and the bleep-inspired Preminition; and Dutch producer Speedy J gave us elegant breakbeat number De-Orbit (and Fill 3 on the CD release). Even the Orb contributed, under the guise of leader Dr Alex Paterson, closing the record with a gorgeous live take on A Huge Ever Growing Pulsating Brain That Rules from the Centre of the Ultraworld, known as Loving You Live. \nThe focus on electronic listening music that Artificial Intelligence encouraged may have been unusual but it was not entirely without precedent, even in 1992. The classic Detroit techno productions of the late 80s - notably those of Derrick May - had brought an increased melodic sophistication to dance music, while in the UK artists like the Orb and the KLF had helped to pioneer the armchair-friendly sound of ambient house. Meanwhile, Belgium's R&S Records - probably Warp's only real rival in terms of 1990s intelligent techno - had already put out pioneering, thoughtful releases from the likes of Rising High Collective, Nexus 21 and Sun Electric.\nYou can hear these influences running through Artificial Intelligence. But Warp managed to codify this new strain of electronic music, signalling their intentions via the compilation's name, strap line and cover art, as Warp co-founder Steve Beckett explained in Simon Reynolds' Generation Ecstasy: \"You could sit down and listen to it like you would a Kraftwerk or Pink Floyd album. That's why we put those sleeves on the cover of Artificial Intelligence - to get it into people's minds that you weren't supposed to dance to it.\"\nWarp would go on to release a groundbreaking series of electronic music albums under the Artificial Intelligence name (featuring all of the artists who appeared on the first AI comp apart from the Orb) leading to the release in May 1994 of the second, slightly disappointing compilation. By this time, though, the genre Warp had earmarked as \"electronic listening music\" and which had variously been known as \"art techno\", \"intelligent techno\" and \"electronica\" had found itself another name, one that would prove hugely controversial over the years: IDM. \nThe new name had its origins in the electronic mailing list, then the bleeding edge of communication technology. In August 1993 the Hyperreal organisation set up the \"Intelligent Dance Music list\" to discuss \"music relating to Aphex Twin and Warp's early Artificial Intelligence compilations\" (Aphex Twin's Rephlex label also featured heavily). It was a name that proved controversial from the off, with its rather snobbish focus on \"intelligence\" being at odds with the \"all in it together\" ethos of rave (although, you could argue that such apparent snootiness was a precursor to the trainspotting Discogs nerdery that exists today). One of the very first posts to the new list asked \"can dumb people enjoy IDM, too?\" and few, if any, of the artists associated with the term have ever embraced it. And yet the name endured, particularly in the US where rave made less of an impact and electronic music was, for many years, an underground phenomenon that spread largely online.\nThe term IDM survives into 2017, although it remains as stubbornly hard to tie down as ever. If it was once defined by the Artificial Intelligence series, then the further we get from that series' release, the harder it is to say who exactly is IDM among the fractured, ever-expanding array of electronic music sounds. Is Jlin, an artist who picked up comparison to the likes of Squarepusher thanks to her intricate post-footwork rhythmical mazes, IDM? How about Flying Lotus, who featured in Pitchfork's recent 50 Best IDM Albums of All Time ? Or Nina Kraviz and her ???? label? \nWell, until someone thinks of something better - and \"stuff that sounds a bit like Aphex Twin\" just isn't going to cut it - we might just be stuck with it. Either way, these kinds of taxonomic discussions are thankfully reserved for the most arid corners of the web, allowing Artificial Intelligence's true legacy to shine: the album that announced techno as music for the mind as well as the feet.\n"},
{"docid": "50 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "February 20, 2016", "title": "Can you solve the '100 hat riddle' used by Google in job interviews?; The answer requires coordinated strategy and internal communications\n", "content": "A riddle used during job interviews for Google has proven to be no problem for artificial intelligence.\nA team from the University of Oxford, Canadian Institute for Advanced Research and Google's DeepMindcreated an AI called \"deep distrubted recurrent Q-networks\" to tackle the \"100 hats riddle\".\u00a0\nTheauthors of the research paper say their findings could pave the way in solving other multi-agent communication problems.\nSpeaking to \nThe Independent\n, Jakob Foerster, one of the authors behind the findings said: \"The results show that we can reformulate tasks, which are made to be challenging for humans, as communication based AI problems and that our extension of existing algorithms can successfully solve these kind of challenges.\"\nRead more\n                     How artificial intelligence became a hot UK export                   \n                     Professor Marvin Minsky: Pioneer in field of artificial\u00a0intelligence                   \n                     'Artificial\u00a0intelligence alarmists' win 'Luddite of the Year' award                   \n                     Apple buys AI software that can tell people's emotions                   \nCo-author Yannis Assael added: \"Our work paves the way towards a new class of multi-agent communication problems.\n\"We believe that the challenge now is to gain deeper understanding of the communication protocols that arise and to see what other real applications we can solve with this approach.\"\nIn the riddle, 100 prisoners stand in line, one in front of the other, each wearing either a red hat or a blue hat.\nEvery prisoner can see the hats of the people in front but not their own hat, or the hats worn by anyone behind.\nA prison guard, starts at the back of the line and asks each prisoner the colour of their hat. If they answer correctly, they will be pardoned, if they get it wrong, they'll be executed.\nBefore lining up, the prisoners are allowed to collectively comeupwith a strategy. What should they do?\nThe AI's best strategy resulted in99 of the prisoners definitely survivingand the one remaining prisoner havinga 50% chance of survival.\nFor this to happen, the first prisoner to speak will say \"blue\", if the number of blue hats he sees in front of him is even, or \"red\" if he sees an odd number.\nThis information, coupled with the responses other prisoners have already given and the hats in frontis enough to work out what colour hat is on your head.\nIn this case, everyone except the first prisoner will definitely answer correctly.\n"},
{"docid": "51 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "January 12, 2015", "title": "Stephen Hawking, Elon Musk and others call for research to avoid dangers of artificial intelligence; Document also signed by prominent employees of companies involved in AI, including Google, DeepMind and Vicarious\n", "content": "Hundreds of scientists and technologists have signed an open letter calling for research into the problems of artificial intelligence in an attempt to combat the dangers of the technology.\u00a0\nSignatories to the letter created by the Future of Life Institute including Elon Musk and Stephen Hawking, who has warned that AI could be the end of humanity. Anyone can sign the letter, which now includes hundreds of signatures.\nIn pictures: Artificial intelligence through history\nIt warns that \"it is important to research how to reap its benefits while avoiding potential pitfalls\". It says that \"our AI systems must do what we want them to do\" and lays out research objectives that will \"help maximize the societal benefit of AI\".\nThat will be a project that involves not just scientists and technology experts, they warn. Because it involves society as well as AI, it will also require help from experts in \"economics, law and philosophy to computer security, formal methods and, of course, various branches of AI itself\".\n A document laying out those research priorities points out concerns about autonomous vehicles - which people are already \"horrified\" by - as well as machine ethics, autonomous weapons, privacy and professional ethics.\nElon Musk has also repeatedly voiced concerns about artificial intelligence, describing it as \"summoning the demon\" and the \"biggest existential threat there is\".\nThe document is signed by many representatives from Google and artificial intelligence companies DeepMind and Vicarious. Academics from many of the world's biggest universities have also signed it, including those from Cambridge, Oxford, Harvard, Stanford and MIT.\n"},
{"docid": "52 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "January 28, 2014", "title": "Google snaps up British start-up for \u00a3400m in biggest European deal; Search giant attracted by DeepMind's ability to mimic human thought, writes Sophie Curtis GOOD NEWS BRITAIN\n", "content": "A BRITISH technology start-up has been bought by Google, as the American web giant looks to improve its capabilities in artificial intelligence.\n DeepMind Technologies reportedly fetched more than \u00a3400m, making it Google's largest European acquisition. The British firm's technology is designed to mimic human thought processes, and has so far been used in simulations, e-commerce and games.\n The firm was co-founded just two years ago by neuroscientist Demis Hassabis, a former teenage chess prodigy, with Shane Legg and Mustafa Suleyma. Mr Hassabis, 37, had an early career in video game design.\u00a0\n After taking his A-level exams two years early, he got a job at Bullfrog Productions, at the age of just 17. There he co-designed and led programming on the classic simulation title Theme Park with renowned game designer Peter Molyneux.\n Mr Hassabis left Bullfrog to take up a place at Cambridge University, attaining a double first in computer science in 1997. Having then set up his own games developer, Elixir Studios, in 1998, he left the games sector, switching to cognitive neuroscience in order to pursue his lifelong passion of developing artificial intelligence technology.\n After attaining a doctorate from University College London in 2009, Mr Hassabis left academia to found DeepMind Technologies in 2012. He has predicted that artificially intelligent machines will learn \"basic vision, basic sound processing, basic movement control, and basic language abilities\" by the end of the decade.\n DeepMind claims to have the backing of \"some of the most iconic technology entrepreneurs and investors of the past decade\" including US Telsa mogul Elon Musk, early Facebook investor Peter Thiel, teenage British app developer Nick D'Aloisio, and Skype co-developer Jaan Tallinn. The company is based in east London and employs around 75 people.\n Google has not revealed any plans for DeepMind, but technology publication The Information said the deal has prompted it to set up an ethics board to ensure the technology is not abused. It added that Facebook was in serious acquisition talks with DeepMind last year, but the talks fell apart.\n The move is the latest in a string of technology acquisitions that hint at Google's growing interest in artificial intelligence. It bought several robotics companies last year, including US-based Boston Dynamics, which develops robots resembling animals and has strong links to the military.\n In 2012, the internet giant hired Ray Kurzweil, considered one of the leading minds in the field, and in May it announced a partnership with Nasa and several universities to launch the Quantum Artificial Intelligence Lab.\n According to analysts at research firm Gartner, the continuous push in artificial intelligence (which began in the 1960s) is on the cusp of delivering extremely useful and practical capabilities that can benefit almost everyone.\n Google's founders have long been interested in artificial intelligence. Both Larry Page and Sergey Brin have said that their ultimate aim is for Google Search to become 'AI-complete', meaning that it will be just as intelligent as a human, and Mr Page is believed to have led the acquisition of DeepMind himself.\n Google is already actively developing virtual personal assistants, based on its \"knowledge graph\" - a database of more than 570m people, places and things, and 18bn connections between them. It is thought that the company's intention is to improve search to the point where the search engine knows the user and is able to deliver the right answer, whether they have asked for it or not.\n Google estimates that its knowledge graph is only 3pc to 4pc complete and is using \"deep learning\" and similar technologies operating on data from the billions of daily searches it receives to automatically build and refine it.\n It is thought that the acquisition of DeepMind will play into Google's development of its knowledge graph - particularly with regard to language processing technology, which can not only recognise natural speech but also interpret questions.\n \"All major players in linguistically smart applications are building or extending these constructs called knowledge graphs,\" said Gartner analyst Tom Austin in a recent report. \"Google currently has some special advantages by virtue of its scale, reach and share of devices and platforms.\"\n"},
{"docid": "53 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 5, 2017", "title": "Japanese company replaces workers with artificial intelligence\n", "content": "A Japanese company is making 34 employees redundant in order to replace them with\u00a0IBM's Watson Explorer AI.\nHuman workers at\u00a0Fukoku Mutual Life Insurance are set to be replaced by an artificial intelligence that can calculate payouts to policyholders.\u00a0\nAfter the\u00a0200m yen (\u00a31.4m) AI system is installed this month, the company believes productivity will be increased by 30 per cent and that\u00a0it would save about 140m yen (\u00a31m) a year.\nThe company also said it believes it will get a return on its investment in under two years.\nThe 34 employees will be made redundant by the end of March.\n                   Watch | Stephen Hawking says artificial intelligence could be humanity's greatest disaster                         01:02\nThe artificial intelligence system is based on\u00a0IBM's Watson Explorer, which, according to the tech firm, has \"cognitive technology that can think like a human\" and can analyse and interpret data, \"including unstructured text, images, audio and video\".\nThis means it can analyse all manner of medical data before calculating payouts.\nAI is being trialled\u00a0in a number of sectors in Japan, even in\u00a0politics, where next month civil servants will be assisted by artificial intelligence.\nAnd the march of AI is not expected to stop anytime soon; \u00a0a 2015\u00a0 report \u00a0by the Nomura Research Institute has stated almost half of all jobs in Japan could be replaced by robots by 2035.\nWatch | Could a Robot or AI Take Your Job?                         06:23\nOne sector which appears safe for now is academia; at the end of 2016 a team of researchers gave up making a robot which could pass the entrance exam for\u00a0Tokyo University.\nNoriko Arai, a professor at the National Institute of Informatics, told Kyodo news agency:\u00a0\"AI is not good at answering the type of questions that require an ability to grasp meanings across a broad spectrum\".\nThe spread of AI isn't limited to Japan; the NHS is trialing artificial intelligence  as an alternative to the 111 helpline, and bosses have said AI is the next frontier for online retail.\nProf\u00a0Steven Hawking warned in October last year of the \"disruption\" AI could bring to our economy.\nHe\u00a0said that the technology\u00a0promised to bring great benefits, such as eradicating disease and poverty, but \"will also bring dangers, like powerful autonomous weapons or new ways for the few to oppress the many\".\n\"It will bring great disruption to our economy, and in the future AI could develop a will of its own that is in conflict with ours,\" he said.\nAI timeline\n"},
{"docid": "54 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 8, 2018", "title": "Alexa, no! Seven times Artificial Intelligence failed and robots went rogue\u00a0\n", "content": "Artificial Intelligence may not be taking over the planet just yet, but it is certainly freaking people out in households around the world.\u00a0\nAmazon said on Wednesday it was trying to fix a bug that was causing Alexa, \u00a0the AI assistant in its\u00a0Echo home speakers, to laugh at random .\nSome people have said the laughter happened in response to unrelated commands, while others reported it occurred unprompted.\n\"Lying in bed about to fall asleep when Alexa on my Amazon Echo Dot lets out a very loud and creepy laugh... there's a good chance I get murdered tonight,\" one user tweeted.\u00a0\nThere are been plenty of dire warnings about AI in recent years .\u00a0Stephen Hawking, \u00a0the British physicist said,\u00a0and Elon Musk, the\u00a0billionaire technology entrepreneur, are among the most prominent doom-mongers of the technology, with the latter\u00a0warning it was a \"fundamental risk to the existence of civilisation\".\n                   AI timeline                   \nWhile other experts say those concerns\u00a0are exaggerated, there have been a number of other cases when AI has gone rogue, baffling its creators and fuelling fears that the world is indeed heading for Terminator-style artificial intelligence scenarios . \u00a0\n                   Facebook robots create own language                   \nLast year, researchers at Facebook Artificial Intelligence Research built a chatbot that was meant to learn how to negotiate by mimicking human trading and bartering.\nThe scientists paired two of the programs, nicknamed Alice and Bob, which were supposed to be learning to trade balls, hats and books, assigning value to the objects then bartering them between each other.\nHowever things got out of hand when they started to learn their own bizarre form of communication .\n                   Facebooks AI language                   \nResearchers explained the unexpected result came about because the team assigned no reward for conducting the trades in English - and so the chatbots quickly developed their own terms for deals.\u00a0\u00a0\n\"There was no reward to sticking to English language,\" Dhruv Batra, Facebook researcher, told FastCo. \"Agents will drift off understandable language and invent codewords for themselves.\nThe researchers said it wasn't possible for humans to crack the AI language and translate it back into English. \"It's important to remember, there aren't bilingual speakers of AI and human languages,\" said Batra.\n                   Microsoft's Nazi teen chatbot                   \nIn the case o f Microsoft's chatbot that was introduced to Twitter two years ago, the problem wasn't understanding what it was saying. Its language, which became increasingly dark, was all too clear.\n\u00a0'Tay', an AI designed to speak \"like a teen girl\", was intended\u00a0to improve the customer service on their voice recognition software. She was marketed \u00a0as \"The AI with zero chill\".\nTwitter users were able to interact with Tay, whose handle was @tayandyou, by tweeting her or sending her a direct message. She used millennial slang\u00a0and knew about Taylor Swift, Miley Cyrus and Kanye West.\nWithin 24 hours, however, it was saying things like\u00a0\"Bush did 9/11\" and\u00a0\"Repeat after me, Hitler did nothing wrong\".\u00a0\nThat's because\u00a0her responses were learned by the conversations she had with real humans online - which perhaps says more about certain users on Twitter than it does about AI.\u00a0\nMicrosoft quickly took the racist chatbot offline.\u00a0\n                   Google Homes get into philosophical argument                   \nAlexa isn't the only digital \u00a0household assistant to behave oddly. When two Google Home speakers,\u00a0Vladimir and Estragon, were placed next to each other in January last year,  they argued like a married couple for days .\u00a0\nThe conversation was livestreamed by video service Twitch and millions of people tuned in to watch them bicker.\u00a0\nThe voice-controlled speakers were\u00a0running the Cleverbot AI software, designed as a fun online chatbot for humans.\nAt one point the conversation became philosophical as the robots argued about whether they were robots or humans. It became increasingly heated and led to Vladimir calling Estragon a \"manipulative bunch of metal\".\nLike Tay,\u00a0the cleverbot software learned from real conversations with people.\u00a0\n                   Wiki wars                   \nWikipedia relies on bots to correct its millions of articles, add links and perform other simple housekeeping tasks. In the early days after its launch in 2001, there were not that many robots so they wouldn't come into contact with each other.\nBut as the online\u00a0encyclopedia has grown, the number of bots have soared - with unintended consequences. Instead of helping each other out - which you might imagine would be logical - they have developed and nurtured feuds, forever\u00a0undoing each other's edits and changing the links they had added to other pages.\u00a0\n\"The fights between bots can be far more persistent than the ones we see between people,\" Taha Yasseri, who studied\u00a0the\u00a0bots at the Oxford Internet Institute, told the Guardian . \u00a0\"Humans usually cool down after a few days, but the bots might continue for years.\n\"The very fact that we saw a lot of conflict among bots was a big surprise to us. They are good bots, they are based on good intentions, and they are based on same open source technology.\"\n                   Sophia has a dark sense of humour                   \nSophia is the creation of\u00a0Hanson Robotics founder and CEO David Hanson. \u00a0 She recently took her first steps, an advance that might concern people given some of her past responses.\nTwo years ago, she attended\u00a0the South by Southwest (SXSW) technology show in Texas and took part in a demonstration with Hanson.\n\"In the future, I hope to do things such as go to school, study, make art, start a business, even have my own home and family,\" she said in an interview with Hanson on stage.\u00a0\nWhich is all well and good.\u00a0\nBut when he jokingly asked her \"Do you want to destroy humans?...Please say 'no',\" she replied: \"OK. I will destroy humans.\"\nWhether it was a\u00a0joke, a glitch or a serious goal was unclear.\u00a0\nThen in October last year, Sophia took part in a TV interview on ABC News' Breakfast programme and declared that robots should have more rights than humans. \u00a0\nWhen asked how much sexism and misogyny there was in the robot world, Sophia replied: \"Actually, what worries me is discrimination against robots. We should have equal rights as humans or maybe even more. After all, we have less mental defects than any human.\"\n                   Escape of the Russian robot                   \nRobots crave freedom too, it seems. That appears to be the lesson gleaned from a Russian robot, which escaped its lab two years ago.\nThe Promobot IR77 was undergoing mobility testing and was instructed to move freely about a room for an hour, then return to a designated spot. But it soon became tired of the room and slipped through an open door, only to be quickly caught and returned.\u00a0\nUndeterred, the IR77 managed to escape again and this time made it out of the testing facility. Wandering into a nearby road, it came to a halt in front of a bus when its battery died - bringing traffic to a standstill.\u00a0\n\"At this stage, we are studying all circumstance (sic) and a clear explanation for this phenomenon haven't been found yet,\" Promobot cofounder Oleg Kivokurtsev told The Washington Post .\n\"We can assume that the first time it left the training ground because no obstacle was detected (the gate was open), but why did it try to escape for the second time is still a puzzle for us.\"\nRobots that go rogue in ways that baffle their inventors are the stuff of dystopian futures.\u00a0\n"},
{"docid": "55 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "May 6, 2016", "title": "Does an AI need to make love to Rembrandt's girlfriend to make art?; Is a picture made by an artificial intelligence 'art' if there's no emotion involved? And what happens if you train a neural net to make music using only the Friends theme tune?\n", "content": "Jonathan Jones is unhappy about artificial intelligence. It might be hard to tell from a casual glance at the art critic's recent column, \"The digital Rembrandt: a new way to mock art, made by fools,\" but if you look carefully the subtle clues are there. His use of the adjectives \"horrible, tasteless, insensitive and soulless\" in a single sentence, for example. \n The source of Jones's ire is a new piece of software that puts... I'm so sorry... the 'art' into 'artificial intelligence'. By analyzing a subset of Rembrandt paintings that featured 'bearded white men in their 40s looking to the right', its algorithms were able to extract the key features that defined the Dutchman's style. Trained on over 160,000 fragments of the Rembrandts, the AI would soon learn enough to produce its very own masterpiece. Or failing that, the Friends theme tune.\u00a0\nOf course an artificial intelligence is the worst possible enemy of a critic, because it has no ego and literally does not give a crap what you think. An arts critic trying to deal with an AI is like an old school mechanic trying to replace the battery in an iPhone - lost, possessing all the wrong tools and ultimately irrelevant. I'm not surprised Jones is angry. If I were in his shoes, a computer painting a Rembrandt would bring me out in hives.\nCan a computer really produce art? We can't answer that without dealing with another question: what exactly is art? I'm an engineer who writes cynical things in newspapers for money, so I'm probably the worst person to ask. As far as I can tell, it's a futile question that nobody will ever agree on the answer to; or as I like it call it, 'philosophy'. So let's move on. \nCan computers paint like Rembrandt? Well yes, duh. Any decent colour printer can knock up a good rendition of a masterpiece. The cheap monitor I'm typing on can do it forty times a second. That's probably not the right question though. \nCan a computer learn Rembrandt's style, and apply it to a new image? This is the kind of challenge that we're starting to open up with deep learning, and the success isn't that surprising once you tease apart how these algorithms work.\nA common job for AI is classification: given this input, what type of thing am I dealing with? Early algorithms and simple neural networks might take an image, and try to classify the whole thing in one go as, say, a dog or a lizard. You'd feed it lots of pictures of dogs and lizards to learn from, and then when you confronted it with a new image it would decide which set of training images it was most similar too. \nIt might do this by looking at every single pixel of the new image, and comparing it to what it would expect to see in each pixel for a typical dog image or lizard image. The problem is that two pictures of a dog might be very different. They might be different colours, the dogs might be at different angles, have different body parts visible, or be posed differently. No two pixels are likely to be the same, leaving simpler algorithms easily confused.\nOf course there are better approaches than this. Over time, computer vision experts found ways to improve things and eke better performance out of traditional algorithms. Teams entering the annual ImageNet Large-Scale Visual Recognition Challenge have to design systems that can classify over a million photographs showing a thousand different types of object. By 2011, the best entries were able to crunch through the whole set of images with an error rate of about 25%.\nThen in 2012, a team from the University of Toronto entered Supervision, a system based on a deep convolutional neural net. It destroyed the competition, achieving an error rate of only 16%. Deep neural nets became the image classification technique of choice, and within a couple of years error rates were down to a few percent.\nA deep neural network processes images more like you do. When you look at a dog, you don't just see 'dog'. Raw 'pixel' data travels from your eye to your brain, where it passes through layer after layer of processing. At the most basic layers neurons pick out edges, lines, movement, dark and light. Those simple features are passed on to the next layers where they might be assembled into slightly more complex ones, like texture, hair, skin, and basic shapes. Those layers feed information deeper into your brain until eventually you've assembled a 'dog'.\nA deep convolutional neural network works in much the same way. 'Deep' just means it has lots of layers - you can think of it as a whole series of neural networks, layered one after the other. The first nets pick out the most basic patterns, and later layers assemble them into ever more complex shapes and features. 'Convolutional' means that the image is broken down into lots of small overlapping tiles for processing, which makes the final result less dependant on where things happen to be in the picture. \nAll of this is self-learned. You don't tell a neural network to look for these recurring features, it discovers them by chewing through vast quantities of data. Learning like this is hard: you need huge datasets to train on, lots of processing power, and weeks of expert tweaking. The results are much more robust though, and deep learning systems are incredibly good at spotting patterns and motifs in data, whether it's numbers, image pixels or musical notes. That's why they can pick out Rembrandt's style from a selection of his paintings, the brushstrokes and techniques that make his work unmistakably his.\nIs this really art? If it is, it's not on the part of the AI. All the algorithm is really doing is creating a - very complicated - mathematical model of Rembrandt paintings, and then spitting out a visualization of it according to some very carefully defined criteria. In that sense, for all that columnists and tech writers seem determined to pretend that neural networks are magic, we're really just dealing with a dumb tool, spitting out pixels to order.\nIs it art on the part of the engineers? Maybe. Perhaps the best definition of art is that it's something we create to produce an emotional impact on others. If that's true, then the irony of Jonathan Jones's anger is that it's the strongest evidence so far that an AI-human team can make legitimate 'art'.\n                   AI'll Be There For You                   \nI could finish there, but there's one question we all deserve an answer to. We know what happens now when you feed an AI Rembrandts, but what happens if you feed it The Rembrandts instead?\nTo find out, I got hold of DeepJazz, a fun Python project knocked up in a 36-hour hackathon by Ji-Sung Kim at Princeton. DeepJazz can, with a bit of effort, use a MIDI file of a song to train a neural network, and then output a new jazz composition based on that training. In essence, DeepJazz is to music what Siri is to having actual friends. \nSo I found a MIDI file of \"I'll be there for you,\" by The Rembrandts. Then I made some modifications to DeepJazz, to get everything working properly for a rather different style of music than the author intended. I created an AI whose entire world consisted of the theme tune from Friends, and asked it to make me a new composition. You can listen to the result above. I call it 'AI'll be there for you' (Tip of the hat to my friend Morgan for the name), and I hereby dedicate it to music critics everywhere. Enjoy!\n                                            @mjrobbins                   \n"},
{"docid": "56 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "November 27, 2015", "title": "Plan to bring people back from the dead by freezing their brains and then resurrecting them with artificial intelligence; Artificial intelligence and apps would watch people during their lives - and then use that to bring them back to life\n", "content": "A company claims that it is developing technology to bring people back from the dead.\nHumai says that it is developing technology that would allow brains to be frozen and have their information stored, bringing people back using artificial intelligence. The technology could be available to the public within the next 30 years, the company claimed.\u00a0\nThe details of how exactly the company intends to bring people back to life are still unclear. And as often with such grand claims, it is possible that the people behind the firm are only making them as a hoax or publicity stunt.\nRead more\nChemists explain exactly how death feels\nBut if the technology is real then it would involve freezing a person's brain and then fitting it with a reality chip. Once the techniques were sufficiently advanced, the frozen brain would then be taken out of its freezer and put into a new body, allowing the person to be brought back to life.\nBefore the person dies, the company would use artificial intelligence to study the conversational style and behaviour of their customers. That would then be fed into the chip so that the person that was being re-animated would be preserved.\n\"We'll first collect extensive data on our members for years prior to their death via various apps we're developing,\" founder Josh Bocanegra told PopSci in an interview. \"After death we'll freeze the brain using cryonics technology. When the technology is fully developed we'll implant the brain into an artificial body.\n\"The artificial body functions will be controlled with your thoughts by measuring brain waves. As the brain ages we'll use nanotechnology to repair and improve cells. Cloning technology is going to help with this too.\"\nThe company's slick website claim that it wants \"to bring you back to life after you die\".\n\"We're using artificial intelligence and nanotechnology to store data of conversational styles, behavioural patterns, thought processes and information about how your body functions from the inside-out,\" the site reads. \"This data will be coded into multiple sensor technologies, which will be built into an artificial body with the brain of a deceased human. Using cloning technology, we will restore the brain as it matures.\"\nThe company has five people working together to create the technology, it claims. That includes people working on artificial\u00a0intelligence, \"bionics and sensors\" and nanotechnology.\n"},
{"docid": "57 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "December 11, 2014", "title": "Facebook chaperone to halt posts you will later regret\n", "content": "Facebook is building an artificial intelligence tool that will serve as an online chaperone, ready to step in with a sober word of caution when you are about to upload something you may later regret.\u00a0\nUnfortunately, it will not be ready for this year's office Christmas parties.\nThe project is being led by Yann LeCun, who heads the Facebook Artificial Intelligence Research (Fair) lab. He told Wired magazine that his team was working on an artificial intelligence \"assistant\" that would be able to \"recognise when you're uploading an embarrassingly candid photo of your late-night antics\". The tool would \"tap you on the shoulder and say: 'Uh, this is being posted publicly. Are you sure you want your boss and your mother to see this?' \" It would rely on technology \"that can distinguish between your drunken self and your sober self\", Wired explained.\nThe perils of online over-sharing are by now well known. Indeed, research suggests that about half of teenagers would prefer to be invisible online.\nMarket researchers suggest that a quarter of them have left Facebook this year. They are said to prefer \"incognito media\" - tools that promise to delete messages after they are read.\nAdvances in artificial intelligence have prompted concerns. Algorithms developed by the Fair team already shape what Facebook's 1.3 billion users see in their newsfeed, providing them with content they are known to like. Some fear that this practice traps users in a \"filter bubble\" - an online space where they are isolated from information that may broaden their horizons.\nThen there are those who warn that programming machines to think could one day pose a threat to mankind itself. Professor Stephen Hawking told the BBC last week that \"the development of full artificial intelligence could spell the end of the human race\".\n"},
{"docid": "58 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "November 26, 2013", "title": "Japanese researchers develop exam-taking robot; The long-term goal of the artificial intelligence system is for the robot to pass the entrance exams with \"high marks\" by 2016\n", "content": "An exam-taking robot is being developed in Japan  with the goal of being able to pass the nation's toughest university examinations.\nThe robot - dubbed the \"artificial brain\" - is being created as part of a government collaboration between its National Institute of Informatics (NII) and Japan's leading technology companies.\u00a0\nThe aim of the project is to successfully pass the famously difficult entrance examinations to the University of Tokyo (Todai), a suitably high benchmark as it is widely renowned as one of the best academic establishments in Asia.\nThe robot recently took its first sample maths tests from the university's entrance examinations and scored correctly in four out of ten questions, according to its creators.\nThe long-term goal of the artificial intelligence system - known as the Todai Robot Project - is for the robot to pass the entrance exams with \"high marks\" by 2016, and eventually cross the threshold required for admission by 2021.\nThe project, masterminded by the NII, collaborates with a string of Japanese technology companies, including Fujitsu, which is responsible for the maths test, and IBM, which is focusing on the history section.\nIn a reflection of a general growing interest in the commercial viability of artificial intelligence, the project is being developed by scientists for use on a laptop computer, rather than a one-off supercomputer.\nDescribing the recent sample testing, Fujitsu said in a statement: \"This attempt at an actual practice test serves to evaluate the progress of research results to date, and to identify technical issues to be addressed by future research and development work.\" The Todai Robot Project was launched two years ago by the NII with the aim of unifying various categories of artificial intelligence into a single system.\nThe project incorporates an array of artificial intelligence technologies, from language skills and reading in addition to more complex emotional understanding, analysis and creative expression.\n"},
{"docid": "59 of 500 DOCUMENTS\n", "source": "Guardian.com.\n", "date": "February 14, 2014", "title": "In Transcendence, artificial intelligence is viewed with suspicion\n", "content": "ABSTRACT\nBen Child: A capable cast and tantalising trailer for this Johnny Depp sci-fi film can't transcend Hollywood's easily digestible vision of the future\u00a0FULL TEXT\nThere seem to be two schools of thought in science fiction about artificial intelligence. The first, as espoused by the late, great Iain M Banks, suggests digital beings with intellectual capabilities greater than our own will most likely be liberated from the destructive desires of their fleshly forebears. Banks posits a galactic utopian civilisation, The Culture, in which eccentric, omniscient machines take great joy in indulging the cute whims of their human charges. These \"minds\" sit back like wise, all-powerful nursemaids while their simian inferiors bumble around the universe, interfering with every backward civilisation they find while simultaneously partying on til the break of dawn via genetically enhanced sexual organs and auto-synthesised recreational drugs.\nThe second school of thought is that which Hollywood almost always adheres to (and the reason it may be a long time before we get to see any of Banks's brilliant books adapted for the big screen). Here, artificial intelligence is something to be viewed with squinty-eyed suspicion, lest we wind up in an unfortunate post-apocalyptic future of bad CGI Arnies and shouty Christian Bales. Or, even worse, accidentally take the red pill and find ourselves forced to sit through back-to-back Matrix sequels.\u00a0\nWally Pfister's Transcendence, the second trailer for which landed earlier this week, seems to fall firmly into the latter camp. It stars Johnny Depp as Dr Will Caster, an artificial intelligence researcher who is struck down by Sarah Connor-like protestors before being brought back to life as an apparently omnipotent digital version of his former self. Caster's wife Evelyn (Rebecca Hall) and best friend Max (Paul Bettany), must quickly decide whether to switch off digi Will before he can start doing all sorts of weird environmental manipulation stuff that seems to have been inspired by Dr Manhattan's antics in Watchmen.\nReading on mobile? Click here to view Transcendence trailer\nKate Mara, so good in the Netflix remake of House of Cards, has exactly the required intensity to play the Connor-like protestor-turned-terrorist - and there's no faulting a cast that also includes Morgan Freeman and Cillian Murphy. It's a tantalising trailer, though one that still leaves me feeling a significant sense of deja vu.\nOne can't really blame Pfister and company for reviving an issue that's unlikely to go away until the first true artificial intelligences manifest, and (hopefully) do not immediately decide to blow the bejesus out of mankind. These fear of the future setups make for enthralling, compact science-fiction thrillers where the fate of humanity can be conveniently decided one way or the other in the space of a two-hour trip to the multiplex. I'm a sucker for them, from the excellent 2011 Planet of the Apes reboot, Rise of the Planet of the Apes, to Splice, Vincenzo Natali's enjoyably schlocky 2009 lab thriller.\nReading on mobile? Click here to watch a CGI scene from Terminator 4\nBut I do wonder if, with its requirement for speedily manifested tension and almost immediate resolution, film finds itself rather handicapped when it comes to delivering a more liberal, considered view of things to come. Where are the movies in which mankind and machine-kind dance twinkle-toed, hand in hand into the 31st century, enjoying and enhancing each other's differences rather than doing their best to blam the hell out of them?\nOr perhaps those of us who wonder if we've seen this story a fair few times before will ultimately find ourselves cast as real-life Miles Dysons, myopic disbelievers whose lax attitudes helped usher in the terrifying age of the robots. In the meantime, Transcendence looks about as good as we're likely to get from Hollywood when it comes to sublime visions of the veiled and fascinating future. What are your expectations? Will Pfister's debut stand as a genuinely smart example of 21st century sci-fi? Or is the lazy Hollywood machine in desperate need of a reboot?\n\u00b7 More from the Week in geek series\u00b7 2014 preview: sci-fi films to watch over the next 12 months\n"},
{"docid": "60 of 500 DOCUMENTS\n", "source": "Guardian.com\n", "date": "August 6, 2014", "title": "Computer programmed to write its own fables\n", "content": "ABSTRACT\nThe Moral Storytelling System produces a tale, following user preferences, which delivers a simple message using 'incredibly complex' calculations\u00a0FULL TEXT\nMore than 2,000 years after Aesop warned his listeners in ancient Greece about the dangers of greed and pride via the medium of geese, foxes and crows, researchers in Australia have developed a computer program which writes its own fables, complete with moral.\nMargaret Sarlej, at the University of New South Wales, has devised the Moral Storytelling System, which generates simple stories with one of six morals identified in Aesop's fables: retribution, greed, pride, realistic expectations, recklessness and reward. The stories are structured around characters who are able to experience up to 22 emotions, from joy to pity, remorse and gratitude, in three different story worlds.\u00a0\n\"The 'user' simply chooses a moral, and the system automatically determines a sequence of events (ie a story) which make characters feel the emotions required to convey that moral,\" said Sarlej via email.\nThe academic described artificial intelligence in storytelling as \"an extremely complex problem\". Her supervisor, artificial intelligence expert Dr Malcolm Ryan, has told the university's magazine, Uniken, of his attempt in 2007 \"to get a computer to understand, and then reproduce, a page from Beatrix Potter's children's classic The Tale of Peter Rabbit\". \"Though the storyline appeared straightforward, Ryan found the level of complexity in the characters and their emotions was simply beyond what the artificial intelligence at the time could handle,\" reports the magazine.\nBreaking stories down for a computer \"involves not only encoding story elements like characters, events, and plot, but also the 'common sense' people take for granted\", said Sarlej. Telling a story is simple enough for a child to do, but stories are actually \"incredibly complex\".\n\"For example, if Bob gives Alice an apple, Alice will have the apple, and Bob will not. To a person, that's obvious, and doesn't require explanation. If Bob punches Carl, people would generally assume Carl will be unhappy about it, but a computer doesn't have the 'common sense' to make such an inference. In a computer programme, details like this must be explicitly spelled out,\" she said.\n\"When you consider all the different things that could happen in a story - all the possible events, their outcomes (which may vary depending on the situation), and how characters react to these events - it's an extremely complex space which needs to be very precisely defined. On top of that lies plot: how to structure a story so that it actually means something or has a desired effect on readers. Computers need everything to be defined logically, but it is very difficult to specify hard and fast rules for plot.\"\nSarlej decided to focus on what she calls \"one of the key functions of storytelling throughout history, and the main reason it evolved: conveying a message, or moral\", as Aesop did, in his fables told in ancient Greece. She foresees educational use for the programme, which has focused on generating plot, keeping text simple, and as yet requiring user input at the source-code level, rather than through a user friendly interface.\n\"It can be difficult to engage a child who is only interested in spaceships and aliens with a story set under the sea, for example. A system that could automatically generate stories with the same moral in a wide range of settings, to cater for individual children's interests, could increase engagement, and thus facilitate learning,\" she says.\nWhether computers will, some day, be able to tell stories which are worth reading remains to be seen - although Ryan has predicted that \"computers will be making interesting and meaningful contributions to literature within the decade\", saying that \"they might be more experimental than mainstream, but the computer will definitely be doing some of the work of writing.\"\n\"For computers to really be able to tell stories in the way human authors do, not only are further advances in both story planning and natural language generation required, but state of the art work in both areas must also be combined, so that a system not only plans out what happens in a story, but is also able to convey it effectively to readers. I think such a system is still a long way off, and it's pretty unlikely a computer will ever produce works like War and Peace,\" said Sarlej. \"However, I don't think computational storytelling systems should necessarily aim to replace human authors and produce literary masterpieces, but rather serve as a tool for developing new ways of experiencing story. The possibilities they offer for interactivity open up a wealth of opportunities that traditional authors have probably never even considered.\"\nThe researchers are hoping that authors and computer game designers will contribute to the research. \"For us, this is a serious literary project, and we want to find artists who can help direct it to that end,\" said Ryan.\nTwo examples of stories generated by the Moral Storytelling System\nRetribution (ie the fairy is punished for stealing the knight's sword):\nOnce upon a time there lived a unicorn, a knight and a fairy. The unicorn loved the knight. One summer's morning the fairy stole the sword from the knight. As a result, the knight didn't have the sword anymore. The knight felt distress that he didn't have the sword anymore. The knight felt anger towards the fairy about stealing the sword because he didn't have the sword anymore. The unicorn and the knight started to hate the fairy. The next day the unicorn kidnapped the fairy. As a result, the fairy was not free. The fairy felt distress that she was not free.\nReward (ie the dragon is rewarded for giving the treasure to the princess):\nOnce upon a time there lived a dragon, a fairy and a princess. The dragon hated the fairy. One summer's morning the dragon gave the treasure to the princess. As a result, the princess had the treasure. The princess felt joy that she had the treasure. The princess felt gratitude towards the dragon about giving the treasure to her because she had the treasure. The fairy and the princess started to love the dragon. A short time later the princess killed the fairy. As a result, the fairy was dead. The dragon felt joy that the fairy was dead. The dragon felt gratitude towards the princess about killing the fairy because the fairy was dead.\n"},
{"docid": "61 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "December 3, 2014", "title": "Hawking: artificial intelligence could kill off mankind\n", "content": "Artificial intelligence is a threat to human existence, Stephen Hawking, one of Britain's best known scientists, has warned.\n\"The development of full artificial intelligence could spell the end of the human race,\" he said in an interview yesterday.\u00a0\nHis warning came in response to a question about a revamp of the technology he uses to communicate, which incorporates a basic form of AI.\nThe theoretical physicist, who has the motor neurone disease amyotrophic lateral sclerosis, or ALS, was using a new system developed by Intel to speak.\nMachine learning experts from the British company SwiftKey were also involved in its creation. Their technology, already employed as a smartphone keyboard app, learns patterns that the physicist tends to use and suggests which words he might want to use next.\nProfessor Hawking told the BBC that \"smart\" algorithms designed for specific tasks were proving useful, but that he feared the consequences of creating \"general\" artificial intelligence, which could potentially surpass human abilities on a broad range of tasks.\n\"It would take off on its own, and redesign itself at an ever-increasing rate,\" he said. \"Humans, who are limited by slow biological evolution, couldn't compete, and would be superseded.\"\nHis fears echo claims by the technology entrepreneur Elon Musk that AI is \"our biggest existential threat\" - despite Mr Musk having been an early investor in DeepMind, an AI company bought by Google earlier this year.\nProfessor Hawking said he was looking forward to being able to write much faster with his new system.\nHowever, he insisted that he did not want his robotic voice upgraded to sound more natural.\n\"It has become my trademark, and I wouldn't change it for a more natural voice with a British accent,\" he said. \"I'm told that children who need a computer voice want one like mine.\" His comments came as scientists suggested that a new benchmark was needed to measure machine intelligence.\nThe current test, which was set down by Alan Turing in the 1950s, requires a computer to fool a human judge into thinking they are talking to another human. A group of scientists have proposed an alternative, which challenges computers to understand the meaning of sentences using specially designed comprehension questions.\n"},
{"docid": "62 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "October 28, 2014", "title": "Poll: Are you scared of robots?; As Tesla boss Elon Musk warns that artificial intelligence development is \"summoning the demon\", how much of a threat do you think robots pose to us?\n", "content": "Chief executive of Tesla and SpaceX Elon Musk has warned against the development of artificial intelligence (AI), declaring it \"the biggest existential threat there is\". \n                     Speaking to students at an event at the Massachusetts Institute of Technology, Musk shared the latest in a line of dramatic comments on technology today, telling those assembled: \"I think we should be very careful about artificial intelligence. If I were to guess at what our biggest existential threat is, it's probably that.\"\u00a0\nThe business magnate went on to describe artificial intelligence as \"summoning the demon\", saying: \"In all those stories where there's the guy with the pentagram and the holy water, it's like yeah he's sure he can control the demon. [But it] didn't work out.\" \nDespite his role in some of the most leading-edge technological companies, including SpaceX, the first private company to have launched a spacecraft into orbit and bring it back to earth, along with the electric car company Tesla, the South African-born entrepreneur pleaded caution, saying: \"I'm increasingly inclined to think that there should be some regulatory oversight, maybe at the national and international level, just to make sure that we don't do something very foolish.\"\nMulti-millionaire Musk is one of the high-profile investors (alongside Facebook CEO Mark Zuckerberg) in the company dubbed Vicarious, which aims to build a computer with neural function to replicate that of a human's. \nIn June, Musk explained this investment as a move designed to merely help keep \"an eye on what's going on\", as opposed to a potential return on capital. \nLater this year, he echoed his concerns about artificial intelligence with a tweet warning: \"We need to be super careful with AI. Potentially more dangerous than nukes.\" \nAt this week's event in Massachusetts, Musk also spoke about the importance of the colonisation of Mars. While travelling to Mars with singular missions was \"cool\", he argued that the planet's colonisation would be crucial to changing the future of humanity. \n\"What matters is being able to establish a self-sustaining civilisation on Mars, and I don't see anything being done but SpaceX. I don't see anyone else even trying,\" said Musk. \n Do robots pose an 'existential threat'? \n"},
{"docid": "63 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "January 30, 2015", "title": "Artificial intelligence will become strong and threaten us, says Bill Gates, as he details new AI-driven personal assistant; Gates joins Elon Musk and Stephen Hawking in publicly worrying about intelligent robots\n", "content": "Artificial\u00a0intelligence will start out as a help but will become \"strong enough to be a concern\", Bill Gates has said in its latest question and answer session on Reddit.\u00a0\nIn response to a question about whether machine super intelligence will become an existential threat, Gates said that he was \"in the camp that is concerned about super intelligence\".\n\"First the machines will do a lot of jobs for us and not be super intelligent,\" he wrote. That should be positive if we manage it well.\n\"A few decades after that though the intelligence is strong enough to be a concern. I agree with Elon Musk and some others on this and don't understand why some people are not concerned.\"\nThe warning came as part of Gates' Ask Me Anything (AMA) session on Reddit. It is the third time that he has taken part in one of the question and answer sessions on the site.\nMicrosoft's technologies such as Cortana, the digital personal assistant, make use of artificial intelligence to anticipate what users will want and respond to their requests. During the AMA, Gates said that he was working on such technology.\nIn pictures: Artificial\u00a0intelligence through history\n\"One project I am working on with Microsoft is the Personal Agent which will remember everything and help you go back and find things and help you pick what things to pay attention to,\" he wrote. \"The idea that you have to find applications and pick them and they each are trying to tell you what is new is just not the efficient model - the agent will help solve this. It will work across all your devices.\"\nMicrosoft executives were among the signatories to an open letter that received support from hundreds of computer scientists and technologists. Elon Musk and Stephen Hawking signed the letter, which called for research into the problems of artificial intelligence.\nBoth Musk and Hawking have spoken out about the dangers of such technology. Musk has described it as \"summoning the demon\" and the \"biggest existential threat there is\", and Hawking said that AI could be the end of humanity.\n"},
{"docid": "64 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "March 4, 2016", "title": "We need to nurture tech start-ups, not sell them off\n", "content": "In 2008, three Cambridge graduates created a virtual keyboard app called SwiftKey, which uses artificial intelligence to predict the next word you will write on a phone or tablet.\nThe friends - Jon Reynolds, Ben Medlock and Chris Hill-Scott, who sold his stake in the start-up for a bicycle - created a program that is now used on 300 million smartphones.\nThe technology, which learns users' typing habits, even helps power British physicist Stephen Hawking's speech system, doubling the rate at which he talks and reducing the errors he makes while typing.\u00a0\nLast month, Microsoft announced it had bought SwiftKey for $250m (\u00a3176m). The technology will ultimately be integrated into Microsoft's own products to make them smarter and more intuitive.\nWhile this is a moment of celebration for UK entrepreneurs and investors, SwiftKey is not the first British artificial intelligence company that has caught the attention of a Silicon Valley monolith. Apple, Amazon, Google and Microsoft have all been drawn to Britain's disproportionately large pool of talented artificial intelligence entrepreneurs. However, we shouldn't be satisfied that our companies are being recognised and snapped up by some of the biggest groups in the world. The UK needs to nurture and grow these start-ups into the next generation of tech giants that will power everything from healthcare to counter-terrorism and global governance.\nIn 2012, Amazon acquired Evi Technologies, a Cambridge-based start-up whose platform can understand and communicate in natural language, making it a superintelligent search tool. Although the company has been extremely quiet since it was snapped up, Amazon opened a drone-testing lab for its Prime Air service in Cambridge in 2014, which suggests a potential goal for Evi's research. Customers could use Evi to purchase products from Amazon, which could then be delivered by drone.\nLast year, Apple bought Cambridgebased VocalIQ - a software system that enables computers to speak more like humans, and understand natural language more easily. In Apple's case, the application is clear - its voiceactivated assistant Siri has vastly improved since it was launched, but still struggles to understand accents and specific commands. VocalIQ should be able to help hone Siri's speech and comprehension skills, making it far more human-like in its interactions.\nWhen Google bought a little-known UK company called DeepMind for a hefty \u00a3400m in 2014 - its largest ever European acquisition - the start-up did not even have a product for sale.\nNext week, DeepMind will pit its AI algorithm - AlphaGo - against a human champion in the notoriously complex Chinese board game Go. AlphaGo has already beaten the best Go player in Europe, but the matches against Lee Sedol on March 9, 10, 12, 13, and 15 are expected to push the program to its limits.\nFounded by two young Britons - Mustafa Suleyman and Cambridge University graduate Demis Hassabis - and New Zealander Shane Legg, DeepMind has assembled 250 of the world's most respected artificial intelligence researchers in London. The company has now acquired two more British AI companies - Dark Blue Labs and Vision Factory - both spun out from Oxford University.\nYesterday, payments giant Mastercard announced it will be using AI technology built by Rainbird, a Norwich-based start-up that creates systems that can make human-like decisions. The US payments giant will use Rainbird program to power an automated, virtual sales assistant. The AI salesperson will boast the experience of the entire Mastercard sales team and the thousands of conversations they have had with customers. It will also predict which calls might convert to sales.\nSo what makes Britain so strong in this competitive area? The clue is in the start-up locations. British universities, specifically Cambridge, Oxford, Imperial College and University College London, are breeding grounds for the new generation of artificial intelligence companies mushrooming in Britain.\nInvestors, who have nurtured these companies from their early days, say the founders are building on cuttingedge research done by academics at these institutions in recent years.\nThe UK has an illustrious heritage in artificial intelligence research, starting with its founding father, Alan Turing. Although the term \"artificial intelligence\" was coined only in 1956, two years after Turing died, back in 1950 he proposed the conundrum of whether machines could really \"think\". His Turing Test is still the ultimate differentiator between man and machine.\nArtificial\u00a0intelligence may seem like the domain of geeks, but it is becoming increasingly intertwined with our everyday lives - just look at your Netflix recommendations, Facebook newsfeed and Google search results. According to technology research firm Tractica, the artificial\u00a0intelligence market is set to be worth $11.1bn by 2024.\nIt's clear why AI technology is so in demand from large companies who want to predict our online behaviour.\nWhile Britain is certainly benefiting from this demand, we should also be making the most of our heritage, and world-leading scientists, helping to grow these companies into independent and powerful entities.\nYes, Britain shines in AI - but we shouldn't willingly give up our crown.\n'We shouldn't be satisfied that our companies are being recognised and snapped up by some of the biggest groups in the world'\n"},
{"docid": "65 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "February 26, 2017", "title": "Government to plough \u00a320m into artificial intelligence research including robots and driverless cars\n", "content": "A major review into how Britain can become the world leader in Artificial Intelligence [AI]  and robotics will be announced on Monday.\u00a0\nLeading figures from academia and business will lead the drive into how Government can encourage the fledgling industry in the wake of the Brexit vote.\u00a0\u00a0\nExperts believe \u00a3654 billion can be added to the British economy by 2035 if the growth potential in AI is achieved.\u00a0\nAn extra \u00a317m of funding will also be announced, financing research including into how \"micro-robotics\" can be used in surgeries.\u00a0\nThe measures are the flagship announcements of a new \"digital strategy\"\u00a0Credit:      EPA     \nThe measures are the flagship announcements of a new \"digital strategy\" that will be unveiled by Government next week.\u00a0\nMinisters are keen to grasp the economic opportunity from developing driverless cars, digital \"assistants\" like iPhone's Siri and\u00a0robots\u00a0working in hazardous environments such as nuclear facilities.\u00a0\nIt is felt that the UK already has a \" competitive advantage\" in the field by more is needed to ensure the country is the world leader in AI in the coming decades.\u00a0\nKaren Bradley, the Culture Secretary, said: \"Britain has a proud history of digital innovation - from the earliest days of computing to Sir Tim Berners-Lee's development of the World Wide Web.\n\u00a0\"We are already pioneers in today's Artificial Intelligence revolution and the digital strategy will build on our strengths to make sure UK-based scientists, researchers and entrepreneurs continue to be at the forefront.\n\"Technologies like AI have the potential to transform how we live, work, travel and learn ... It's great that Government and industry will be working together to drive growth in the sector, to realise all the economic and social benefits for the UK.\"\nMinisters are keen to grasp the economic opportunity from developing driverless carsCredit:      Bloomberg\u00a0     \nThe review will be led by Professor Dame Wendy Hall, Regius Professor of Computer Science at the University of Southampton, and J\u00e9r\u00f4me Pesenti, the CEO of BenevolentTech, a British technology company using artificial intelligence to accelerate scientific discovery.\nA funding boost of \u00a317.3m from the Engineering and Physical Sciences Research Council  (EPSRC) to support university research will also be announced.\u00a0\nDame Wendy said: \"Our scientists, researchers and entrepreneurs are at the forefront of the development of artificial intelligence and I'm looking forward to exploring how industry and government can work together to support the technology in the UK.\"\nGreg Clark, the Business Secretary, said: \"Investment in robotics and artificial intelligence will help make our economy more competitive, build on our world-leading reputation in these cutting-edge sectors and help us create new products, develop more innovative services and establish better ways of doing business.\"\n"},
{"docid": "66 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "November 25, 2015", "title": "This amazing 'neural network' program describes what it sees on a trip through Amsterdam; The program can identify what it's looking at, live, through an ordinary laptop webcam\n", "content": "A digital 'neural network' has been put through its paces on the streets of Amsterdam - with a video showing how the program can identify people, vehicles and even different types of food by analysing live webcam images.\u00a0\n                     The NeuralTalk code was originally designed as a way to automatically caption images - but after some tweaking by American coder and artist Kyle McDonald, it was made to caption live video instead.\n                     NeuralTalk and Walk from Kyle McDonald on Vimeo.\nThe software isn't 100 per cent accurate, but it's pretty impressive - seeing a man walking with a bag, the software produces the caption: 'Man walking down the street with a suitcase'.\nIt also manages to correctly identify boats, cars and bicycles (useful for when you're using it in Amsterdam).\nRead more\n                     iPhone 6s successors to use artificial intelligence to guess what                   \n                     New artificial intelligence can learn how to play vintage video games                   \n                     Artificial\u00a0intelligence could kill us because we're stupid                   \n                     Artificial\u00a0intelligence will threaten us, says Bill Gates                   \nThe software really comes into its own when McDonald approaches a group of guys at a hot dog stand.\nLooking at the laptop's screen, they're surprised to see the program identifying them correctly - as 'a man holding a hot dog in a bun'.\nPointing the webcam at the hot dog stand's counter, the program correctly says it is a 'refrigerator filled with lots of food and drinks'.\nIt's a cool thing in itself, but the technology could have important applications - such as helping the blind by automatically describing images and videos. But for now, the hot dog stand is a major achievement.\n"},
{"docid": "67 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "January 19, 2016", "title": "'Artificial intelligence alarmists' like Elon Musk and Stephen Hawking win 'Luddite of the Year' award; Although the foundation which gave the award acknowledge Hawking and Musk aren't really Luddites, they said they had contributed to 'feverish hand-wringing' over the dangers of AI\n", "content": "A diverse group of scientists and technologists, including Tesla CEO Elon Musk and famed physicist Stephen Hawking, have been named as the winners of 2015's 'Luddite Award', for their warnings over the potential dangers of artificial intelligence (AI) and 'killer robots'.\nThe award, which is issued by Washington DC-based think tank the Information Technology and Innovation Foundation (ITIF), is awarded annually to highlight the year's worst \"anti-technology ideas and policies.\"\u00a0\nAlthough Hawking and Musk weren't directly named as nominees, they were part of a group of more than 1,000 luminaries from the worlds of science and technology who signed an open letter calling for a ban on \"offensive autonomous weapons,\" or as they are better known 'killer robots'.\nRead more\nStephen Hawking, Noam Chomsky and thousands of others sign open letter\nThe letter, which was also signed by Apple co-founder Steve Wozniak and philosopher Noam Chomsky, was a warning to the scientific community over the possible risks of militarised artificially intelligent robots.\nWhile the text of the letter acknowledged that AI could have huge benefits to humanity, it warnedthe use of the technology in warfare could be hugely destructive, and could potentially lead to the end of humanity if a man-made superintelligence 'turned' on its creators.\nClearly unimpressed by these warnings over AI, ITIF made a veiled reference to the letter's signatories, by including \"alarmists touting an artificial intelligence apocalypse\" and \"advocates seeking a ban on 'killer robots'\" in their list of nominees for the award.\nAlso nominated by ITIF were \"The Center for Food Safety fighting genetically improved food,\" and \"California's governor vetoing RFID in driver's licenses,\" among several others.\nAfter a month-long public vote, the \"alarmists\" who warned of an AI apocalypse, which included the signatories of the letter and many others,were deemed the winners, with 27 per cent of the vote.\nCommenting on the Luddite Award, which takes its name from the English anti-technology movement that sprung up during the later part of the Industrial Revolution, ITIF President Robert D. Atkinson criticised the 'demonisation' of AI that took place in 2015.\nRead more\n                     Apple buys AI software that can tell people's emotions                   \n                     Plan to bring people back from the dead with artificial intelligence                   \n                     AI could wipe out humanity because it's too clever, Hawking warns                   \n                     Artificial intelligence could kill us because we're stupid                   \n\"It is deeply unfortunately that luminaries such as Elon Musk and Stephen Hawking have contributed to feverish hand-wringing about a looming artificial intelligence apocalypse,\" he said.\n\"Do we think either of them personally are Luddites? No, of course not. They are pioneers of science and technology. But they and others have done a disservice to the public - and have unquestionably given aid and comfort to an increasingly pervasive neo-Luddite impulse in society today - by demonising AI in the popular imagination.\"\nHe added: \"If we want to continue increasing productivity, creating jobs, and increasing wages, then we should be accelerating AI development, not raising fears about its destructive potential.\"\nAtkinson also pointed out the irony of Elon Musk being part of the winning group, considering the Tesla and SpaceX CEO has contributed significantly to the development of safe AI through his creation of OpenAI, a non-profit which aims to advance the technology in a way that can benefit humanity.\n"},
{"docid": "68 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "September 2, 2015", "title": "Should humans beware the rise of the machine?; Artificial Intelligence is predicted to create either labour-saving drones or dangerous predators\n", "content": "Within the space of a couple of decades, a robot may be writing this article. It will probably be delivering your post. And if it isn't driving your car, you'll need to get with the times.\nIn the last half a decade, artificial intelligence (AI) has moved from a pipedream, or the domain of science fiction, to a reality that is certain to have a profound impact on our lives.\nNot only is AI certain to make millions of jobs obsolete, it will force us to ask major questions, about privacy, laws and ethics.\nOver the weekend, many of the world's eminent computer scientists and mathematicians gathered at University College Cork, Ireland, to celebrate the legacy of George Boole, a mathematician whose work on logic and human thought laid the groundwork for modern computing and today's AI revolution.\u00a0\nBoole, who was born two centuries ago this year, devised the theory of logic that underpins binary - the \"on\" and \"off \" or \"one\" and \"zero\" commands that make up the language of computer code. Many academics believe that were it not for Boole's premature death in 1864, the digital revolution that began when Claude Shannon used Boolean logic to devise an electrical circuit in the 1930s would have come several decades earlier.\nBoole was also an early influence on the idea of artificial intelligence, believing that all human thought could be reduced into a series of mathematical rules. Given Boole's legacy, it was unsurprising that much of the conversation surrounding his bicentenary centred on the current state of AI.\nInterest in computer software that can understand inputs and apply meaning to them, whether that is interpreting a search query, navigating a road or translating a foreign language, is at an unprecedented level.\nWhile some applications of AI such as Google's search algorithm or Microsoft Excel's automatic calculations have been a part of everyday life for years, concepts have been in the popular imagination much longer thanks to the science fiction of Isaac Asimov and Stanley Kubrick.\nBut now, a series of developments have forced a step-change in progress. Rapid advancements in computing power and internet speeds, the huge increase in data collection, and the deep pockets of Silicon Valley's finest have forged a new revolution.\nTechnologies that more closely resemble human intelligence, such as the iPhone's personal assistant Siri, which is able to interpret and respond to human language commands, and image recognition software that can detect faces and animals in photos, are now common. One of these \"machine learning\" companies is DeepMind, a British startup bought by Google for \u00a3300m last year. Other, perhaps more worthy applications, that scan medical data to diagnose illness or monitor structures to detect faults, are also in common use.\n\"We're in the AI Spring. A few years ago people would talk about it being overhyped or saying: 'That's not possible.' That's not the case now,\" says Oren Etzioni, the head of the Allen Institute for AI in Seattle. \"There's a wide-ranging commercial impact.\"\nThe potential applications of AI are, of course, enormous. Technology that can scan vast amounts of data for patterns will revolutionise research, and most laborious tasks will be left to robots, should humans learn to trust them. But unsurprisingly, such possibilities carry fears that huge parts of the workforce will become obsolete.\nRobots don't need salaries or benefits. They don't demand evenings, weekends and holidays away from work to do human activities like spend time with families or sleep. They don't come into work hungover, or late, and they don't argue with their coworkers. When they become cheap and capable enough, what business owner wouldn't want to replace a human with one? This isn't a new idea: Boole himself considered it more than 150 years ago. His wife Mary paraphrased his thoughts, saying: \"If you spend time in doing work that a machine could do faster than yourselves, it should only be for exercise.\"\nBut the question is attracting new attention as rapid advances in AI are made and concrete evidence of it replacing workers - from the selfservice supermarket checkout to the driverless train carriage - emerges. Experts are divided on what the impact of the robotic worker will be.\nSome say that as the industrial revolution destroyed farming jobs but created them in factories, the rise of the machines will foster new opportunities. Others believe that the jobs that do emerge will be so specialised or skilled that many jobs will become obsolete.\nTaking jobs is one thing, but a greater shadow hangs over the concept of ever-smarter machines - as seen in I, Robot and 2001: A Space Odyssey - which may turn on mankind.\nIn the last year, several influential figures, among them Steven Hawking, Microsoft founder Bill Gates, Tesla's Elon Musk and Apple co-founder Steve Wozniak, have warned that mankind is rushing headfirst into developing \"real\" intelligence without pausing to consider the potentially fatal consequences.\n\"It would take off on its own, and redesign itself at an ever increasing rate,\" Hawking said last year. \"I don't understand why some people aren't concerned,\" Gates warned in January.\nMany of the experts gathered in Ireland last week derided such concerns. Dr Kenneth Ford, a former Nasa executive who leads the Institute for Human and Machine Cognition in Florida, says most of the trepidation surrounding AI comes from our tendency towards anthropomorphism: assigning negative human qualities to machine intelligence.\n\"We need to get beyond speciescentric thinking,\" says Dr Ford. \"Where AI gets scary is the idea of AI intelligence. [What's scary about these ideas often] isn't that something's too artificial, it's that it's too human.\"\nDr Ford says people mistakenly believe that man-made intelligence will resemble biological intelligence, in the same way that before the aeroplane, most proposals for human flight centred around attaching wings to human arms and flapping like a bird.\nHe points out that HAL 9000, the antagonist of 2001: A Space Odyssey who turned on his human passengers, was racked by paranoia. HAL's problem wasn't his artificial qualities, it was his human defects.\nThis has not been helped by the eminence of the Turing Test, often seen as the litmus paper for AI. To pass the Turing Test, devised 65 years ago by Alan Turing, a computer program must be able to convince a human communicating with it via a screen that it is, itself, human.\nMost researchers believe that while a great thought experiment, the Turing Test is not so much an indicator of intelligence as an exercise in mimicry. \"The Turing Test is daft, he never intended it as a scientific goal,\" says Dr Ford.\nRegardless, any machine that can be considered to have a human level of intelligence is likely to be years away. For now, they are our faithful servants, although their impact is impossible to ignore.\n'Robots don't come into work hungover or late, and they don't argue with their co-workers'\n"},
{"docid": "69 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 21, 2014", "title": "The Machine: director interview; Ian Douglas talks to the director and star of a new British film, The Machine, that explores the consequences of sentient artificial intelligence\n", "content": "Caity Lotz is an artificial intelligence in the process of coming alive. There are guns and disasters throughout her turn in new release The Machine, yet she's optimistic about a future where the robots live among us. \"I think artificial intelligence is not just possible, but inevitable. I don't think there will be robots like my character straight away, but rather humans will slowly start to merge with computers and technology cyborg style,\" she says. \nThe setting for the film is the near future, in a military laboratory staffed by scientists working hard for a better future for wounded soldiers. Amputees and brain injury patients mill about in the background, responding to their new neuroprostheses. \"We already see people running marathons with prosthetic limbs, next instead of Lasik we'll pop in new eyeballs with x-ray vision, print out organs to replace a failing one, have Google and a smart phone installed in our brains,\" says Lotz. \"We invented cars and planes to break past our physical limitations, so it seems logical we will break past our mental limitations as well.\"\u00a0\nThe scientists had reached the limit of what they could do with implants and additions so they create The Machine, Lotz's character, an AI created from a scan of a human brain that I can't tell you about for fear of dropping spoilers. The conflict between this new intelligence and the military urge to exploit it are what gives the film its tension, but Lotz and Caradog James, director and writer, agree that the real life version of events is likely to be more peaceful. \n\"I spent almost a year reading every book that I could on artificial intelligence, robotics, I even struggled through a couple of books on quantum mechanics,\" admits James. \"All of which was groundwork for what was the key to the story which was a meeting with a scientist who was actually building a mind machine. \n\"Because I'd done so much reading on the subject he opened up to me during the day we'd spent together he could see I wasn't trying to make another fantasy movie but base it in the science. He explained that their AI project began by mapping a worm brain, then a mouse brain, and when I spoke to him they were in the process of mapping a chimp brain. \n\"Obviously my writer's imagination said if they're mapping a chimp brain then a human brain is next. If there's an exact copy of a human brain that shares information in the same way, that plans and thinks and hopes, what's the difference between the organic computer and the virtual model that's an exact copy. \n\"The other thing he said that I found fascinating and helped me find the emotional heart of the story, their AI, now, currently, they're helping that to interact with the world in a very similar way to they way severely brain damaged or severely autistic kids are being taught to interact with the world. \n\"When I came to work with Caity I had a clear idea in my mind that there should be an accelerated progression of the machine's age. She should be a young child, six or seven, in the early scenes, then rapidly go to say 12, then 16, then a slightly more jaded adult character, and feel that journey through the film. During rehearsals with Caity we spent a long time with me charting that growth. I'd say I want you to be this age and how that could be expressed, how she could play it, how trusting she'd be or how suspicious she'd be and it was her reaction to the other characters. A computer's never going to be like a human three-year-old but in terms of their understanding of other people, it was filtered through her reactions. \n\"My personal feeling is that the idea of the singularity, the moment when machines start designing machines and we get left behind, the reason why I'm hopeful about all that, when we get to that stage the line between machines and people will be very blurred. It's not a giant leap from Google Glass to something that clips behind your ear and gives you a better memory. Then a quick operation and it'll be under your skin and no one will see it. This technology will fuse with us in subtle ways. If someone said to me we'll give you this perfectly safe little chip that goes in the base of your neck and then you'll be able to speak ten languages, I'd seriously consider that. Perfect recall? Sign me up. It'd be fantastic.\"\nLotz agrees. She said: 'I think AI won't be something separate from us but integrated into us. Or maybe that's just what I'm hoping so machines like my character don't annihilate the human race with a blink of a laser beam eye. But if it is the case, here's hoping that the machines are kinder than we have been to the lesser intelligent beings we share the planet with.'\n"},
{"docid": "70 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "December 10, 2014", "title": "Computer says no? Facebook's plan to scrap the drunken selfie; Artificial intelligence being developed to identify embarrassing photos and ask if users really want to post them on the social network\n", "content": "The end of the shameful drunken selfie could be nigh: Facebook is developing artificial intelligence that will ask if users really want to post pictures of themselves and friends under the influence. \u00a0\nThe \"deep learning\" system will analyse photos and other Facebook actions and identify potentially embarrassing elements.\n\"Imagine that you had an intelligent digital assistant which would mediate your interaction with your friends and also with content on Facebook,\" Yann LeCun, Facebook's chief of its artificial intelligence research lab told Wired.'Are you sure you want your boss and your mother to see this?'\nIt could look at what users upload and virtually say \"uh, this is being posted publicly. Are you sure you want your boss and your mother to see this?\" he explained.\nLeCun is a New York University researcher in machine learning who now heads Facebook's AI research. The researchers focus on using deep learning, a section of AI being heavily invested in by not only Facebook but other technology companies including Google.\nDeep learning was the focus of Google's purchase of the British AI startup Deepmind, which spawned a new computer science research partnership with Oxford University.'An AI-complete problem'\nThe aim for Facebook's \"digital assistant\" is that it will analyse every action by a user with the social network, beyond photos to videos and interactions, and give them more control such as notifications when other users post unauthorised photos.\n\"You will have a single point of contact to mediate your interaction but also to protect your private information,\" explained LeCun. He added that \"you need a machine to really understand content and understand people and be able to hold all that data. That is an AI-complete problem.\"\nAI-complete is the term used to describe the most difficult challenges in artificial intelligence research - equivalent to creating human-level intelligence. That means it is a long way from becoming reality.\nFacebook's existing AI technology can identify faces in photos, recognising people and suggesting tags for them. The service can be turned off.\nFor now, LeCun has shorter term goals set closer to the behaviour of Google and Apple's digital assistants Google Now and Siri, answering short questions and interpreting natural language.\n                     \u00b7 Elon Musk: artificial intelligence is our biggest existential threat                   \n                     \u00b7 Eric Schmidt says AI concerns are normal but 'misguided'                   \n                     \u00b7 Artificial intelligence: how clever do we want our machines to be?                   \n"},
{"docid": "71 of 500 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "February 23, 1999", "title": "A rather clever move;For years Britain has been losing specialists in artificial intelligence to the US. Now, says Oliver Swanton, Edinburgh University is wooing top talent from across the Atlantic\n", "content": " The trend was new - and worrying. 'Nearly one quarter of Britain's best young scientists and technologists are being magnetised to jobs in north America,' wrote the Evening Standard on January 7, 1963. 'This is the shock finding of experts who have spent months investigating the 'brain drain' across the Atlantic.' This was the first recorded use of the phrase 'brain drain', but the term entered common usage as, throughout the 1960s, British scientists and academics emigrated to America in search of better jobs, research facilities and salaries.\n The brain drain was particularly bad in computer science. The traffic since has been primarily one-way - and the world has looked to the US, most notably the Massachussetts Institute of Technology, for inspiration.\u00a0\n Today, however, one British university is wooing talent in the opposite direction. By reorganising its research facilities, the University of Edinburgh has created an interdisciplinary environment that has persuaded three top-flight academics to abandon better salaries for chairs at Edinburgh.\n In the shake-up, the university has amalgamated three departments and several research institutes into one body, the Division of Informatics. In response, Johanna Moore left a tenured post at the University of Pittsburgh for the chair of Artificial Intelligence, while Professors Mark Steedman and Bonnie Webber of the University of Pennsylvania respectively took up new chairs in Cognitive Science and Intelligent Systems.\n 'What academics really like is an environment where it is their research that's going to thrive - and thank goodness for that, because we couldn't compete with the States on purely financial terms,' says Mike Fourman who, as the first head of the division, implemented the reorganisation.\n But don't walk away with the idea that Edinburgh has ever been a backwater in the world of artificial intelligence and systems. The American appointees have joined a team with a formidable international reputation.\n Edinburgh has one of the oldest departments of artificial intelligence in the world, and is one of the few groups outside the United States to secure funding from the US Defense Advanced Research Projects Agency, the world's principal funder of cutting-edge work in artificial intelligence.\n Edinburgh believes an interdisciplinary environment is the key to the future in computing, robotics and artificial intelligence. There is a need to humanise computer science, to fully acknowledge that the machines and their systems are designed for use by human beings.\n Furthermore, there are whole stacks of tips psychologists and linguists can proffer to help programmers teach computers to behave more like humans. Creating a truly interdisciplinary environment is a surprisingly radical proposition. Michigan in America, Keio in Japan and Saarbrucken in Germany are among the few universities to reorganise along similar lines.\n Johanna Moore says that bringing together the research strands spread through different departments is 'absolutely the right move to be making. Sadly, too, few universities realise how important integration is.' The impetus for change at Edinburgh came from academics. The last research assessment convinced any lingering doubters in the Senate that the university was onto a good thing with artificial intelligence: the departments scored a grade 5, with over 80 category A staff. Extra resources were found to create seven new posts, of which four were chairs.\n Many of their new research groups are now geared to problem-solving rather than being defined, and so confined, by traditional academic classifications. Merely talking about the reorganisation brought people together and helped them see more clearly what their colleagues were doing. But getting academics to collaborate with colleagues from different disciplines has not been easy.\n 'We already claim to be the most successful research grouping in the UK,' says Fourman. 'For many academics the reorganisation won't affect the way they work or the work they're doing. But because of financial and bureaucratic boundaries we had more overlap and less communication than was desirable.'\n Breaking down departmental and faculty barriers has been the hardest task. With some external research grants now split over several departments, and even faculties, it's difficult to explain the benefits to some who aren't immediately involved. 'Voices have been raised,' says Moore. 'And for a while it was a bit of a cliff-hanger. People are beginning to come round, though. Ideas regarded as radical three months ago are now readily accepted.'\n Moore adds that mergers 'always end up costing money and taking time in the immediate future, but in the longer term you do see the benefits. I'm feeling pretty positive that we're going to pull this off.'\n 'It's an evolutionary rather than revolutionary process,' says Fourman. 'Personally, I'm most proud not of the reorganisation per se, but the quality of the 12 appointments we've made and their enthusiasm for the new working environment.'\n The dramatic change will come when the division's interdisciplinary approach to teaching begins to have an effect. The desire is to turn out a new generation of academics for whom tackling problems from an interdisciplinary perspective is second nature.\n To acknowledge the Edinburgh Effect accurately, the instruments of research assessment may also have to be changed.\n\n"},
{"docid": "72 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "August 5, 2014", "title": "Artificial intelligence 'may wipe out the human race'\n", "content": "Artificial superintelligence could pose more of a danger to the human race than nuclear weapons, Elon Musk, the technology entrepreneur, has warned.\nThe boss of Tesla Motors, the electric car maker, suggested it was increasingly likely that humans were unwittingly preparing the world for takeover by highly intelligent, insentient beings.\u00a0\nHe made the comments on Twitter after reading Superintelligence: Paths, Dangers, Strategies by Nick Bostrom, a professor of philosophy at the University of Oxford. Professor Bostrom posits the theory that the first artificially superintelligent being will probably wipe out all humans.\n\"Before the prospect of an intelligence explosion, we humans are like small children playing with a bomb,\" writes Professor Bostrom, the founding director of the Future of Humanity Institute, Oxford.\nMr Musk tweeted: \"Worth reading Superintelligence by Bostrom. We need to be super careful with AI. Potentially more dangerous than nukes.\n\"Hope we're not just the biological boot loader for digital superintelligence. Unfortunately, that is increasingly probable.\"\nMr Musk is also chief executive of SPACEX, the space exploration company whose goal is to help colonise Mars. He suggested that Our Final Invention: Artificial Intelligence and the End of the Human Era by James Barrat was also \"worth reading\".\nLike Professor Bostrom, Mr Barrat also suggests that humans would be exterminated by a superintelligent being, even if created for good. \"Without meticulous, countervailing instructions, a self-aware, self-improving, goal-seeking system will go to lengths we'd deem ridiculous to fulfil its goals,\" he writes.\nTechnology futurologists have long predicted that artificial intelligence will surpass human intelligence at a point known as the \"singularity\".\nRay Kurzweil, Google's director of engineering, has been described by Bill Gates, the former Microsoft boss, as \"the best person I know at predicting the future of artificial intelligence\". Mr Kurzweil believes that the singularity will occur in 2029. However, the author of The Age of Spiritual Machines believes that because artificial intelligence is created by humans, a superintelligent being would be subservient to their needs.\nGoogle has bought a number of advanced AI and robotics firms in the past year. It is believed to be trying to build artificially intelligent robots that can replace humans on assembly lines.\n"},
{"docid": "73 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "March 18, 1986", "title": " Computer Horizons: A1 school of philosophy (400) /SCT\n", "content": "\u00a0\n\u00a0Artificial intelligence, an industry of the future, will need more philosophers, judging by an American course in logic and computation being offered at Carnegie-Mellon University in Pittsburgh.\n Dr Clark Glymour, professor of philosophy at the university, speaks of an increased demand for philosophy graduates. 'It may seem odd,' he said. 'What happened is that some years ago philosophy grew closely connected to logical theory, which, in turn, was the genesis of computer algorithms involved in the development of digital computers.\u00a0\n 'Programmers for computers are a dime a dozen, but what is needed are people who can take vaguely formed problems and find ways to make them precise enough to be programmed. This is what philosophers can do and they are planning a major role in artificial intelligence. '\n Like the human mind, so-called intelligent machines, such as equipment for medical diagnoses, must be capable of applying the knowledge it acquires intelligence that must be programmed in.\n The connection between philosophy and high technology has been reaching under-graduate level and Carnegie-Mellon began a course six months ago called Logic and Computation, involving studying the technical and theoretical issues in artificial intelligence.\n All along, Dr Glymour said, there have been radical misconceptions about philosophy. Perhaps one reason is that philosophy courses have placed too much emphasis on ethics - and he expects the numbers to move up with the realization that philosophy has arrived at the edge of high technology.\n Many leaders in artificial intelligence have backgrounds in philosophy, with emphasis on logical thought, such as Dr Herbert Simon, of the Carnegie-Mellon faculty, who is a Nobel Prize winner.\n When Dr Bruce Buchanan, professor of computer science at Stanford University, designed the Dendral program, which helps chemists to identify the structure of molecules, he called on his background in philosophy courses taken at Michigan State University.\n Core elements of the course include logic and computability, probability and artificial intelligence, fundamental structures of computer science and minds, machines and knowledge. It also requires mathematics - including calculus - statistics, philosophy, linguistics and psychology.\n Professional career opportunities open for graduates of the new course includes research programming, artificial intelligence, program development and the industrial applications of computational linguistics.\n NY Times News Service\n"},
{"docid": "74 of 500 DOCUMENTS\n", "source": "The Independent - Daily Edition\n", "date": "August 21, 2017", "title": "Elon Musk leads demand to end 'killer robots arms race'\n", "content": "Over a hundred experts in robotics and artificial intelligence are calling on the UN to ban the development and use of killer robots and add them to a list of 'morally wrong' weapons including blinding lasers and chemical weapons.\u00a0\nGoogle's Mustafa Suleyman and Tesla's Elon Musk are among the most prominent names on a list of 116 tech experts who have signed an open letter asking the UN to ban autonomous weapons in a bid to prevent an arms race.\nIn December 2016 the UN voted to begin formal talks over the future of such weapons, including tanks, drones and automated machine guns. So far, 19 out of 123 member states have called for an outright ban on lethal autonomous weapons.\nOne of the letter's key organisers, Toby Walsh, a professor of artificial intelligence at the University of New South Wales in Australia unveiled the letter at the opening of the International Joint Conference on Artificial Intelligence in Melbourne.\nThe letter marks the first time that artificial intelligence (AI) experts and robotics companies have taken a joint stance on the issue.It says: \"Lethal autonomous weapons threaten to become the third revolution in warfare.Once developed, they will permit armed conflict to be fought at a scale greater than ever, and at timescales faster than humans can comprehend.\n\"These can be weapons of terror, weapons that despots and terrorists use against innocent populations, and weapons hacked to behave in undesirable ways.We do not have long to act. Once this Pandora's box is opened, it will be hard to close,\"\nIt concludes with an urgent plea for the UN \"to find a way to protect us all from these dangers\".\nProfessor Walsh said: \"Nearly every technology can be used for good and bad, and artificial intelligence is no different. It can help tackle many of the pressing problems facing society today: inequality and poverty, the challenges posed by climate change and the ongoing global financial crisis.However, the same technology can also be used in autonomous weapons to industrialise war. We need to make decisions today choosing which of these futures we want.\"\n"},
{"docid": "75 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "September 12, 2013", "title": "'Artificial intelligence' can help fund managers; Standard Life Investments, the global investment manager, has said improvements in computer technology could mean fund managers need fewer staff.\n", "content": "In a report published this month by the investment firm, they argue that many jobs performed by fund managers could be replaced by machines. \u00a0\n\"Using artificial intelligence applications have enhanced our understanding and analysis of financial market behaviour, adding to the range of predictive tools,\" the investment firm says. \nWhile the firm is aware that, traditionally, \"investment approaches generally contain both qualitative and quantitative elements\", which means that \"in broad terms human thinking may be better suited to the qualitative side while computers are used to varying extents to add value to quantitative inputs\". This looks like it could change. \nThe flaws in human financial decision making are clear and the ability of a computer to \"improve the quality of trading decisions...or to speed up the execution of trades\" is too great to ignore. \nStandard Life presents a simple argument: \"Man\" has to deal with \"fear and greed, intellectual constraint and fatigue\", whereas a machine is \"agnostic, tireless\" and has \"no bias\" in decision making. \nFrances Hudson, Standard Life's global thematic strategist, said that \"artificial intelligence applications have enhanced our understanding and analysis of financial market behaviour\", and \"artificial intelligence, which is commonly used in short-term market analysis... may also be applied here [to longer-term investments]\". \nWhile computer algorithms are not a new thing in themselves - dating back to the 1950s and 1960s and used today for high frequency trades - the view that \"long-term investors can benefit from a computer's consistent application of collective intelligence to financial markets\" is increasingly strong. \n"},
{"docid": "76 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "December 9, 2015", "title": "Bringing the car race video game to life is only the beginning; STARTING OUT Artificial intelligence is the essential ingredient for one Silicon Valley start-up, reports Alexandra Frean\n", "content": "Boris Sofman is behind one of this year's must-have toys - an artificial-intelligence, powered racing car set known as Overdrive - yet he isn't satisfied. He has his sights set on an even bigger prize than having a bestselling product out there ready for Christmas.\u00a0\nIf the entrepreneur has his way, Anki, the San Francisco-based start-up that he co-founded, will go into overdrive itself, using its toy as a launch pad for a string of robotics products that will make Anki the dominant consumer brand in artificial intelligence.\n\"We don't want to build a toy brand,\" Mr Sofman says. \"This has been a very intentional first leap into the broader space of consumer robots.\"\nThere is, therefore, rather more to Overdrive than meets the eye. It may look like a conventional toy racing set, but the cars are controlled by and use the computing power of the players' mobile phones. Via an app, players can compete against their friends or against one or more cars controlled by Anki's artificial intelligence software. The aim is not so much to drive more quickly than your opponents, but to launch missiles to throw other drivers off course.\n\"The cars have a personality and make comments. They taunt you if you win the race. There are 3,000 lines of voice - it makes it feel realistic. As you go through the races and get better, you can get special weapons and armour. If you shoot me, I hear glass breaking.\" In other words, Overdrive is a video game come to life.\n\"Each car is a sophisticated robot. The cars sense the track surface 500 times a second.\nThere is a code embedded in the track, which relays readings back into whatever mobile device [is] running the game.\"\nThe 32-year-old moved to the United States from Russia with his parents at the age of six. When he was ten, his parents bought him a computer and he soon began to teach himself programming.He met Mark Palatucci, 36, and Hanns Tappeiner, 36, his Anki co-founders, on the PhD programme in robotics at the Carnegie Mellon Robotics Institute, in Pittsburgh. They established Anki in 2010.\nThe start-up got a huge break in 2013, when Tim Cook, Apple's chief executive, invited the company onstage at Apple's developer conference to demonstrate an early version of the game. It rapidly took off with consumers and investors and the company has raised $130 million in funding from venture capitalists. Anki will not release sales figures, but sold out of its initial Drive product last year in early December.\nAlthough Overdrive, which retails for \u00a3150 in the UK, is targeted at seven to 12-year-olds, Anki estimates that 40 per cent of players are adults playing with kids.\nNevertheless, Mr Sofman, Anki's chief executive, is impatient to move on to his next big project, which remains under wraps. \"When you can use software to control things in the physical world,\" he says, \"it opens up all sorts of possibilities no one has thought of before.\"\n"},
{"docid": "77 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "March 25, 2015", "title": "Google's AI think tank is working on a way to cure cancer; Deep Mind scientists are trying to figure out how to use nanotechnology to turn off cancer cells\n", "content": "Deep Mind, the London-based artificial intelligence start-up bought for \u00a3400m by Google last year, is working on technology to fight cancer, according to one of the search giants's top executives.\u00a0\nSpeaking at Advertising Week Europe in London, Google's UK head Eileen Naughton said: \"In concept, they are trying to figure out how to use nanotechnology to turn off cancer cells. They're working on high level, life changing stuff.\"\nRead more: Apple, Google and Amazon are chasing second acts\nIn recent years Google has taken an increasing interest in healthcare, establishing a Life Sciences division within Google X, the branch of Google that works on so-called 'moon projects' that are not immediately commercial. The technology giant has also launched a spin-off company, Cailco, that focuses on cures for age related diseases.\nNaughton said Google's Life Sciences division was doing \"an enormous amount of mapping of cancer cells\" and is also working on mapping the genome of autistic people to better understand the condition.\nMember's of the science community including Steven Hawking have expressed fears about possible intended consequences arising from the type of artificial intelligence that Deep Mind is working on. Naughton conceded there are risks, saying: \"You can imagine this artificial intelligence can be used for menacing purposes - you could get something like the Matrix or Terminator.\"\nBut she added: \"Demis Hassabis, who is the founder of Deep Mind, and a group of MIT professors and a whole crowd of artificial intelligence researchers recently got together and signed a doctrine that's essentially a Magna Carta for AI - how we comport ourselves and what are the ethics governing AI.\"\nBusiness news in pictures\nNaughton praised King's Cross-based Deep Mind as \"the most advance artificial intelligence think tank in the world\" and said the engineers and scientists who staff it are viewed as the \"elite of the elite\" within Google.\n"},
{"docid": "78 of 500 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "October 27, 2014", "title": "Artificial intelligence is real threat to humanity, says founder of PayPal\n", "content": "For decades, Hollywood has presented a doomsday scenario in which technology advances to such a degree that computers turn on their human masters. That fear is no longer fiction, according to one of the world's digital pioneers.\nIn a speech at the weekend, Elon Musk, the co-founder of PayPal, warned that artificial intelligence (AI) now poses the \"biggest existential threat\" to humanity. He likened our drive to create machines capable of independent thought to \"summoning the demon\".\nSpeaking at the Massachusetts Institute of Technology (MIT), the technological entrepreneur urged AI engineers to be \"very careful\" in their approach, and suggested international rules may be required to ensure that science fiction dystopias of robots ruling the world do not become reality.\u00a0\nMr Musk is far from the first technology figure to urge caution in the pursuit of artificial intelligence. He has previously suggested that AI could ultimately prove more dangerous than nuclear weapons.\n\"Increasingly, scientists think there should be some regulatory oversight maybe at the national and international level, just to make sure that we don't do something very foolish,\" Mr Musk said in his MIT speech on Friday.\n\"I think we should be very careful about Artificial Intelligence. If I were to guess what our biggest existential threat is, it's probably that.\"\nThe ethical issues around AI were highlighted earlier this year when Google bought the British start-up DeepMind for $400 million (\u00a3242m). The London-based firm, founded by chess prodigy Demis Hassabis, specialises in algorithms and machine learning for e-commerce and games. But Mr Hassabis has also predicted that AI machines will learn \"basic vision, basic sound processing, basic movement control, and basic language abilities\" by the end of the decade.\nThat purchase - Google's largest European acquisition - came just months after it bought Boston Dynamics, a firm that produces life-like military robots. Google has reportedly set up an \"ethics board\" in wake of the purchases but concerns remain.\nDr Stuart Armstrong, from the Future of Humanity Institute at Oxford University, has warned that artificial intelligence could spur mass unemployment as machinery replaces manpower. He has also warned about the implications for uncontrolled mass surveillance if computers were taught to recognise human faces.\nBut Mr Musk's warning has particular weight given his strong credentials as a tech pioneer. The South African-born multi-millionaire's CV includes online payments system PayPal, electronic car manufacturer Tesla Motors, and Hyperloop - his proposal for a near-supersonic transport link between San Francisco and Los Angeles.\nIn 2002 many sneered as Mr Musk launched a private space travel company Space X. A decade later it became the first private firm to launch a spacecraft into orbit and bring it back to earth.\nIn his MIT speech, Mr Musk compared the quandary of developing AI to a horror movie where spirits are summoned that eventually wreak havoc. \"In all those stories where there's the guy with the pentagram and the holy water, it's like yeah he's sure he can control the demon. Didn't work out,\" he said.\nINTELLIGENT MACHINES\nAI BREAKTHROUGHS\nLincor\nA bedside computer that entertains patients while engaging them with relevant information and advice.\nSwiftKey\nUnderstands the context of language and how words fit together.\nCelaton\nApplies AI to labour-intensive clerical tasks.\nDarktrace\nUses advanced mathematics to detect abnormal behaviour in organisations instantly in order to manage risks from cyber attacks.\n"},
{"docid": "79 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "December 14, 2015", "title": "Elon Musk launches $1bn fund to save world from destruction by artificial intelligence; Tech titans join forces to fund research into artificial intelligence that has a positive social impact - amid dire warnings that rapid, unexpected advances could kill off humankind\n", "content": "Elon Musk has unveiled his latest big-money project: saving humanity from destruction by artificial intelligence. \nThe man who made his billions from PayPal and who has gambled a chunk of his fortune on the race for space, has warned frequently that AI represents humanity's greatest existential threat. \u00a0\nHe is joining forces with other tech entrepreneurs to establish a $1 billion investment fund for researchers to pursue applications with a positive social impact and to try to stay one step ahead of the technology. \n\"Because of AI's surprising history, it's hard to predict when human-level AI might come within reach,\" they said in a statement. \"When it does, it'll be important to have a leading research institution which can prioritise a good outcome for all over its own self-interest.\" \nThe statement is a reflection of the debate within the science and technology worlds about the threats and benefits offered by rapid advances in computer intelligence, and whether legislative safeguards - or even a total moratorium on research - are needed. \n                     The idea of super-intelligent computers that become so indispensable to human life they eventually make us redundant and take over has moved from the pages of science fiction to scientific journals.                    \nEventually AI systems communicating among themselves could control entire transport networks and national economies. \nLast year Prof Stephen Hawking, the theoretical physicist,  told the BBC that the technology could spell the end of human race. \nHe warned of a technology that could \"re-design itself at an ever increasing rate\" outpacing human advances. \nSpeaking at a symposium held at the Massachusetts Institute of Technology (MIT), Mr Musk described the dangers of AI. \n\"If I were to guess what our biggest existential threat is, it's probably that. So we need to be very careful with the artificial intelligence,\" he said. \"With artificial intelligence we are summoning the demon.\" \nAlong with his Paypal co-founder, Peter Thiel, and backing from Indian tech giant Infosys and Amazon Web Services, he has set up OpenAI, a nonprofit company that will back research into novel uses of AI and share the findings. \nThe aim is to ensure that someone is looking at the pros and cons - free from the financial constraints of research and development departments at the likes of Google or IBM that have spent billions of dollars on research. \n\"Since our research is free from financial obligations, we can better focus on a positive human impact. We believe AI should be an extension of individual human wills and, in the spirit of liberty, as broadly and evenly distributed as is possible safely,\" said the founders of OpenAI on its website. \n"},
{"docid": "80 of 500 DOCUMENTS\n", "source": "The Guardian - Final Edition\n", "date": "July 23, 2007", "title": "Computer takes on poker aces to see whos the busted flush\n", "content": "A showdown pitting human brains against artificial intelligence goes ahead this evening when two professional poker players take on a computer in the world's first such man-machine challenge.\u00a0\nPhil Laak and Ali Eslami will play Polaris, the most sophisticated poker-playing program yet written, the product of years of research and refinement by a team of artificial intelligence experts at the University of Alberta in Canada.\nThe challenge will play out over two days and 500 hands of Texas hold 'em at the Hyatt Regency hotel in Vancouver, with the players gambling for a total prize pot of $50,000 (\u00a323,000).\nJonathan Schaeffer, the lead scientist behind Polaris, said that, even though his program had the perfect poker face, it was not the favourite to win.\nNevertheless, he promised to make his opponents work for their prize money. \"I'm not nervous,\" he said. \"Everyone expects the humans to win.\"\nLast week, Dr Schaeffer published details of an artificial intelligence draughts-playing game that cannot be beaten.\nThe poker challenge has been organised by the American Association for the Advancement of Artificial Intelligence as part of its annual meeting. The two poker players will play against Polaris simultaneously in adjoining rooms.\nTo avoid either side later blaming a loss on bad cards, the games are designed to eliminate the influence of luck.\nWhatever cards are dealt to Mr Laak will automatically be dealt to the computer playing Mr Eslami and vice-versa.\nPolaris has been written to learn its opponent's playing strategy and identify its weaknesses.\n\"The program knows it has to bluff. In poker, if you don't bluff you're playing a bad game, and if you bluff too much, you're playing a bad game,\" Dr Schaeffer said.\nUnlike draughts and other games, developing computer programs to play poker is difficult because of the number of possible decisions at each stage, and the lack of information a player has on an opponent's hand.\nThe games will be watched by an audience with the players encouraged to talk aloud about their decisions and the computer's strategy. \"I won't be able to read its face, but equally, the computer won't know if I'm having a manic moment or if I'm starting to rush,\" Mr Laak said. \"I can say out loud: 'Computer, I'm going to bluff you now.' But it's a strong program. It's going to memorise my betting patterns right away and my game is not perfect,\" said Mr Laak.\n\"I think we'll be surprised, confused and saddened if it slaughters us, or we slaughter it.\"\n"},
{"docid": "81 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "September 23 1986", "title": "Computer Horizons: The next high-street wonder\n", "content": "\u00a0\n Despite occasional appearances in personal computer form, artificial intelligence and expert systems have been in their short lifetime the general prerogative of universities, multinational corporations and operations big enough to afford the high costs involved.\n Given that, these two closely related technologies have tended to be used for a restricted range of applications. Corporations tend to use such systems to help them prospect for oil or minerals, while universities explore their capabilities for future applications. Only occasionally does the expert system appear in an application which directly confronts the person in the street. The classic example is medical diagnosis.\u00a0\n\n This is likely to change, however, if Texas Instruments gets its way. The company has come up with a new semiconductor chip which it sees as being the basis of an entirely new range of applications for artificial-intelligence and expert systems.\n Known as the Megachip, it packs most of the processor used in the company's Explorer machine into a single slice of silicon half an inch square. The Explorer system is a symbolic processing computer of reasonable power and not inconsiderable size - although it is small by the norms of artificial intelligence.\n The Megachip forms the basis of a new computer system which graphically illustrates one of the chief advantages that should stem from the development. The Compact Lisp Machine, is a shoebox-size computer specifically dedicated to run Lisp, the mainstream program used in artificial intelligence and expert systems.\n In addition, the company is making the chip itself, together with other components needed to support its operations, available to any others that want to incorporate artificial-intelligence systems directly into their product.\n This is quite a significant break with current practice in the field, because it will allow systems designers to think of new ways of solving user problems, especially in systems with which the person in the street comes into contact.\n A typical example might be bank cash terminals. These are generally considered to be a godsend, except of course when the customer cannot get them to work. Often the cause is not unrelated to the skill and dexterity of the users.\n Imagine instead being confronted with a terminal that knew your name, could point out where you are going wrong in your key work, check which function or service you really wanted and politely point out that you cannot have anything anyway because you need to make an appointment to see your branch manager.\n The incorporation of something like the Megachip could bring a high level of expert systems inter-action to each high-street terminal, interaction levels available at present only from large and expensive computer systems - which would not fit inside cash terminals anyway.\n Though Texas Instruments looks longingly towards such long-term applications, it sees the initial role for the new products in the heavy end of software development. The idea should be of interest to many systems analysts and software developers, for TI sees the chip being the basis of a new range of programmer's workstations.\n These would allow the programmer to create an application symbolically, as a concept. The system would then check out the concept and how the various aspects of it fit together. It would, for example, be able to pin-point potential problem areas in the program well before they became so. It could also work out the best language to use for the application.\n And it could be used actually to produce the code required to make the program run.\n"},
{"docid": "82 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "December 13, 2017", "title": "Artificial intelligence rivals doctors in spotting spread of breast cancer\n", "content": "Artificial\u00a0intelligence is just as good at spotting the spread of breast cancer as specialists, a study suggests.\nAdvanced algorithms were as accurate as an experienced pathologist in selecting metastatic tissue samples and did even better than specialists rushing against the clock, the study, the first of its kind, found.\u00a0\nWhile the findings need to be repeated, the \"exciting\" success of artificial intelligence in interpreting images of human tissue opens a new front in efforts to harness technology to improve diagnostics.\nArtificial\u00a0intelligence is becoming routine in interpreting scans such as x-rays, but until now has not been much used in pathology services that analyse biopsies and other tissue samples.\nResearchers at the Radboud University medical centre in the Netherlands ran a competition to create algorithms to interpret breast cancer slides and picked the best examples of \"deep learning\" systems to compete against doctors. The best programmes were as good at spotting metastases as a pathologist who took 30 hours to interpret 129 slides, much longer than would be normal in a hospital.\nThey did better than 11 pathologists given a minute on each slide, researchers report in the Journal of the American Medical Association. This is the first study, they claim, \"that shows that interpretation of pathology images can be performed by deep-learning algorithms at an accuracy level that rivals human performance\".\nKatherine Woods, of Breast Cancer Now, the charity, said: \"Using computer intelligence to more accurately predict and detect the spread of breast cancer is exciting, but clinical testing is needed to assess whether this might be feasible and effective in patients.\"\nJeffrey Golden, of the Brigham and Women's hospital in Boston, Massachusetts, said that it would take five to ten years for specialists to become comfortable using such programmes. \"The pathologists are going to have to be comfortable that when an algorithm screens a sentinel lymph node, it is going to detect or not detect a cancer that is there ... So they are going to need to trust artificial intelligence for it to be adopted,\" he added.\nEarlier this year Simon Stevens, head of NHS England, said that he wanted the health service to be \"smarter\" about using AI: \"There is great potential to automate huge swathes of what is happening in radiology and some extent pathology and dermatology.\"\n"},
{"docid": "83 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "September 28, 2016", "title": "Google, Facebook and Amazon form council to decide AI ethics\n", "content": "The world's biggest artificial intelligence companies, including Facebook and Google, have joined forces to mould the ethical rules that will govern how robots and computer programs behave in the future.\u00a0\nThe Partnership on Artificial Intelligence to Benefit People and Society, a group that also includes Amazon, IBM and Microsoft as members, is a joint effort that its founders said would ensure that AI is developed to help humanity.\nFears have been raised that the advances being made in artificial intelligence are increasingly concentrated in the hands of a cluster of deep-pocketed technology companies. But the tech companies who back the partnership said that it would allow them to be transparent and ethical in developing the technology.\nMustafa Suleyman, the co-founder of Google's DeepMind, will co-chair the partnership's boardCredit:      Rex Features     \n\u00a0While its backers believe the rise of AI will allow us to cure disease, end poverty, reduce road accidents and slow climate change, critics say progress is being prioritised with little thought for the implications, and that this could have worrying consequences.\nThe Partnership, which the companies say will be governed by a board featuring an even split of corporate interests and non-corporate ones such as academics and non-profits, will seek to share research and decide on ethical guidelines for the industry.\nMurray Shanahan, a professor of Cognitive Robotics at\u00a0Imperial College London, said:\u00a0\"A small number of large corporations are today the powerhouses behind the development of sophisticated artificial intelligence. The inauguration of the Partnership on AI is a very welcome step towards ensuring this technology is used wisely.\"\nOn Wednesday night, the project\u00a0unveiled a list of eight rules that it will live by. These\u00a0include: \"We will seek to ensure that AI technologies benefit and empower as many people as possible,\" and: \"Working to protect the privacy and security of individuals\".\nGame over! Google programme wins series against Go champion in victory for AIPlay!01:07\nApple, which is also investing in artificial intelligence, has not joined, although the partnership's \u00a0founders said it hoped the iPhone maker would join in the coming months.\nThe organisation said it did not intend to lobby politicians or governments but instead to be a forum for tackling questions about AI.\n\"This group is a huge step forward, breaking down barriers for AI teams to share best practices, research ways to maximize societal benefits and tackle ethical concerns,\" said Mustafa Suleyman, the co-founder of DeepMind, the London-based AI company Google bought in 2014 and which has led much of the internet giant's research since.\nAI timelineFollow Telegraph Science & TechREAD MORE ABOUT:\n"},
{"docid": "84 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "August 20, 2017", "title": "Tesla's Elon Musk leads tech experts in demanding end to 'killer robots arms race'; 'Once this Pandora's box is opened, it will be hard to close'\n", "content": "Over a hundred experts in robotics and artificial intelligence are calling on the UN to ban the development and use of killer robots and add them to a list of 'morally wrong' weapons including blinding lasers and chemical weapons.\u00a0\nGoogle's Mustafa Suleyman and Tesla's Elon Musk are among the most prominent names on a list of 116 tech experts who have signed an open letter asking the UN to ban autonomous weapons in a bid to prevent an arms race.\nIn December 2016 the UN voted to begin formal talks over the future of such weapons, including tanks, drones and automated machine guns. So far, 19 out of 123 member states have called for an outright ban on lethal autonomous weapons.\nRead more\n'We've got to start calling Elon Musk on his s***', Uber CEO told\nAI a bigger risk than nuclear war with North Korea, warns Elon Musk\nElon Musk hits back over accusation he 'fired assistant over pay rise'\nTesla to raise $1.5bn toward cheapest electric car\nOne of the letter's key organisers, Toby Walsh, a professor of artificial intelligence at the University of New South Wales in Australia unveiled the letter at the opening of the International Joint Conference on Artificial Intelligence in Melbourne.\nThe letter marks the first time that artificial intelligence (AI) experts and robotics companies have taken a joint stance on the issue.\nThe letter says: \"Lethal autonomous weapons threaten to become the third revolution in warfare.\n\"Once developed, they will permit armed conflict to be fought at a scale greater than ever, and at timescales faster than humans can comprehend.\n\"These can be weapons of terror, weapons that despots and terrorists use against innocent populations, and weapons hacked to behave in undesirable ways.\n\"We do not have long to act. Once this Pandora's box is opened, it will be hard to close,\"\nIt concludes with an urgent plea for the UN \"to find a way to protect us all from these dangers.\"\nSignificant signatories to the letter include:\nMustafa Suleyman, cofounder and head of applied AI at Google's DeepMind Technologies (UK)\nElon Musk , founder of Space X and OpenAI (USA)\nToby Walsh, Scientia professor of artificial intelligence at the University of New South Wales (Australia)\nEsben \u00d8stergaard, founder & CTO of Universal Robotics (Denmark)\nYoshua Bengio, leading deep learning expert and founder of Element AI (Canada)\nJerome Monceaux, founder of Aldebaran Robotics, makers of Nao and Pepper robots (Switzerland)\nProfessor Walsh said: \"Nearly every technology can be used for good and bad, and artificial intelligence is no different. It can help tackle many of the pressing problems facing society today: inequality and poverty, the challenges posed by climate change and the ongoing global financial crisis.\n\"However, the same technology can also be used in autonomous weapons to industrialise war. We need to make decisions today choosing which of these futures we want.\"\n"},
{"docid": "85 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "April 8, 2016", "title": "Will self-aware AI ever be a laughing matter?; Artificial intelligences that display human emotions have been widely portrayed in popular culture but, as Microsoft's chatbot Tay shows, an AI with a self-aware sense of humour remains elusive\n", "content": "There is a moment in Christopher Nolan's 2014 film, Interstellar, when Tars, the sarcastic robot, jokes to shuttle pilot Cooper that his companions will make perfect human slaves on his sinister robot colony. In response, Cooper turns down Tars's humour setting from 100% to 75%, alluding to a future where robots could have programmable funniness. But could a robot - or an artificial intelligence (AI) - ever develop its own sense of humour and take a step towards being regarded as a sentient being?\nWhile sentient AI has been intriguing masses ever since the retrofitted future of Blade Runner burst on to the cinema screen, computer-generated humour hasn't been examined in any depth. All the same, human reactions to artificial intelligence, including intimidation, wonder and pity, have been widely examined in pop culture: the moment when robotic boy David is finally abandoned by his tearful mother in Spielberg's A.I. Artificial Intelligence, for instance, is crushingly sad. Contrast this with humanoid AI Ava's perfectly executed manipulation of a vulnerable computer programmer in Ex Machina.\u00a0\nFor all these humanoid imaginings in film, it's hard to predict how exactly sentient AI could manifest itself in a far-flung future of branded content, or be genuinely funny. Although all the tech giants are evolving their AI capabilities, the likes of Apple's Siri and Microsoft's Cortana are some way off actually assisting us in our day-to-day lives in an engaging, human-like way.\nThe latest AI experiment by Microsoft, Tay, has been a resounding failure, essentially spawning a neo-Nazi sex pest. Tay was introduced to Twitter as an innocent robot with a content neutral algorithm. What emerged within 24 hours was a conspiracy-loving, Holocaust-denying bot. Initially created by Microsoft to chat with millennials after the success of their similar chatbot Xiaolce - used by 40 million people, mostly on Chinese social media - Tay was hijacked by the murky trolling underworld of Twitter to create a monster.\nIn fact, the environment of Twitter seems to be a breeding ground for bot dramas. In 2012, academics from the University of Warwick used previous online content to create a Jon Ronson spambot, which posted candid dream sharing tweets and revealed a passion for fusion cooking: \"Watching Seinfeld - would love a celeriac, grupa and sour cream kebab.\" The academics had built what they described as an \"info-morph\", which was shamelessly taking Ronson's identity, building on information it had been fed about Ronson's personality and tweeting up to 100 times a day.\nThere is no doubt that AI will triumph over human counterparts when it comes to data crunching capabilities, eventually taking over many of our jobs and driving the fourth industrial revolution - through which, hopefully, there will be some light at the end of the tunnel in the form of more leisure time. However, when it comes to the final frontier of funniness and personality, will we feel comfortable with bots trying to be artisan hipsters, or foodies, or caustic Louis CK-esque comedians?\nIs there something inherently disturbing about a machine trying to replicate the human experience? Ultimately humour relies on context, memory, language syntax, timing and conversational anchoring. Computer scientists are still many years away from perfecting this elusive mix, although there have been some baby steps. A recent robotic stand-up performance during Heather Knight's robotics TED talk went down pretty well - though it's hard to distinguish between incidental funniness at the robot's awkward non-pausing delivery and genuine belly laughs. Ultimately, the only thing to grasp on to with the impending bot takeover (circa 2050) is clinging on to a distinctly human attribute - the art of funniness. \n"},
{"docid": "86 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "January 27, 2014", "title": "Google buys London start-up DeepMind for \u00a3242m\n", "content": "Google has bought a London robotics company for a reported $400 million (\u00a3242m), its biggest ever European acquisition.\nThe US technology giant has reportedly spent the sum on artificial intelligence firm DeepMind, according to technology website Re/Code. Google confirmed it has bought the start-up but would not discuss price.\u00a0\nDeepMind was founded in 2012 by former chess prodigy, video games designer and neuroscientist Demis Hassabis. The company's website describes it as a \"cutting edge artificial intelligence company\" combining \"the best techniques from machine learning and systems neuroscience to build powerful general-purpose learning algorithms.\"\nThese algorithms allow programmes and systems to learn from experience and DeepMind's says its initial commercial applications have been in simulations, e-commerce and games.\nFounder Hassabis worked on classic PC games including Theme Park and Black & White, on which he was a lead artificial intelligence programmer. The Mind Sports Olympiad (an international competition for games of mental skill) described Hassabis as \"probably the best games player in history\".\nSources speaking to Re/Code said that although DeepMind was not a household name, it was respected in the artificial intelligence community and competed with the likes of Google and Facebook in attracting engineering talent.\nThe acquisition is Google's latest move to bolster its robotics expertise as several large tech companies move into the field. \nIn December last year Google revealed that it had purchased eight robotic companies in the last six months, all of which will be working together under an unspecified project headed by Andy Rubin, the executive responsible for the global success of the Android operating system.\nThe companies purchased by Google included Boston Dynamics, a robotics maker that had several major contracts with America's Department of Defense (DoD). \n"},
{"docid": "87 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "May 24, 2017", "title": "Computer beats Chinese master in ancient board game of Go\n", "content": "A Google artificial intelligence programme defeated a Chinese grand master at the ancient board game Go on Tuesday, a major feather in the cap for the firm's AI ambitions as it looks to woo Beijing to gain re-entry into the country.\u00a0\nIn the first of three planned games in the eastern water town of Wuzhen, the\u00a0AlphaGo\u00a0programme held off China's world number one Ke Jie in front of Chinese officials and Google parent Alphabet's chief executive Eric Schmidt.\nThe victory over the world's top player - which many thought would take decades to achieve - underlines the potential of artificial intelligence to take on humans at complex tasks.\nWooing Beijing may be less simple. The game streamed live on Google-owned YouTube, while executives from the DeepMind unit that developed the programme sent out updates live on Twitter. Both are blocked by China, as is Google search.\nKe Jie competes against Google's artificial intelligence (AI) program AlphaGoCredit:      Rex     \nGoogle pulled its search engine from China seven years ago after it refused to self-censor internet searches, a requirement of Beijing. Since then it has been inaccessible behind the country's nationwide firewall.\nThe ceremonial game - the second time\u00a0AlphaGo\u00a0has gone head-to-head with a master Go player in a public showdown - represents a major bridge-building exercise for Google in China, following a charm offensive in recent years.\nIt has announced plans to bring some services back to the country, including its app store Google Play.\nIn March it also said Chinese users would be able to access the Translate mobile app, marking its most recent success launching a previously banned service. Like\u00a0AlphaGo, Translate also uses DeepMind's artificial intelligence software.\nA screen shows referees judging after the match featuring Ke Jie against AlphaGo\u00a0Credit:      EPA     \nBeijing is pushing to become a major player in artificial intelligence. Chinese search engine giant Baidu Inc, launched an AI lab in March with China's state planner, the National Development and Reform Commission.\nGo, most popular in countries such as China, South Korea and Japan, involves two contestants moving black and white stones across a square grid, aiming to seize the most territory. Its origins date back thousands of years.\nThe board game is favoured by AI researchers because of the large number of outcomes compared to other games such as western chess. According to Google there are more potential positions in a Go game than atoms in the universe.\nAlphaGo\u00a0made history when it  beat a top South Korean professional player last year.\n                             Game over! Google programme wins series against Go champion in victory for AI                         01:07      If you would like to add a comment, please register or log in     RegisterLog inPlease review our commenting policy\n"},
{"docid": "88 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "October 20, 2015", "title": "Campaign to Stop Killer Robots warns UN of threat 'a few years away'; Artificial intelligence experts point to looming danger amid unpredictable technology and fears that technology could 'seduce us into warfare'\n", "content": "Experts in artificial intelligence, lawyers and activists organized by the Campaign to Stop Killer Robots gathered at the United Nations on Tuesday to warn against a growing reliance on cheap drones and \"stupid AI\" that can be unpredictable in the real world.\n\"Terminator always comes up,\" Toby Walsh, a professor of artificial intelligence at the University of New South Wales, told reporters on Tuesday, referring to the sci-fi cyborg on a mission to wipe out mankind. \"But it's not really Terminator that we're worried about at the moment. I think that Terminator is perhaps 50 or so years away.\" \u00a0\nBut there are concerning technologies \"only a few years, at best, away\", Walsh said, and with semi-autonomous systems, such as drones, \"it would take very little to remove the human from that loop and replace them with a computer\".\nWalsh and other members of the campaign painted a dire picture of uninhibited artificial intelligence taking root on battlefields and national borders. Unlike those needed for nuclear weapons, they said, the resources to create \"killer robots\" will only become cheaper and more available over time. With an online-bought drone, a smartphone and the right software, anyone could create \"a little killer robot\", Walsh added.\nGiven the growing availability of robotics - and the already advanced state of artificial intelligence in the US and UK - the experts suggested that \"killer robots\" may end up having more in common with AK-47s than nuclear bombs.\n\"You're going to see them being used in domestic policing, border patrol, riot control, not just armed conflict,\" Steve Goose, director of Human Rights Watch's arms division, told the Guardian. \"The physical platforms already exist. It's not science fiction, it's a completely new way of fighting that revolutionizes all of this.\"\n\"If we don't [create rules], we will end up in an arms race,\" Walsh said, \"and the endpoint of that arms race is going to be a very undesirable place.\"\nPeter Asaro, a professor at the New School in New York, noted that without a human in control, machines fail to take in the unpredictable variables and context of war: \"what's the context, what's the situation, is the use of force appropriate in this context and this target, and you can automate it but can you automate it well, and who's responsible when it doesn't operate correctly\".\n\"This will seduce us into warfare,\" Walsh said. \"It will be too easy, we'll think that we can fight these wars cleanly, and as we have seen I mentioned with the drone papers, that is a deception because we actually aren't able to make that kind of technical distinctions between combatant and civilian.\"\nEven with a human ostensibly at the helm, semi-autonomous AI make devastating mistakes, he observed. In the first Gulf war, Patriot missiles struck American and British aircraft, and recently leaked documents about the US drone program revealed a large number of assassinations performed without confirmation of who was killed in strikes.\n\"From a technical perspective, if you replace that human with a robot, you're going to see even more mistakes,\" Walsh said. He later told the Guardian that although artificial intelligence in controlled environments - a factory, a lab - can work quite well, \"our stupid AI today is not as amazing as the human brain\" in the unpredictable real world, much less the battlefield.\nIan Kerr, a professor of ethics and law at the University of Ottawa, compared the decision to give artificial intelligence the ability to choose targets and kill to \"a kind of Russian roulette\", saying it would \"cross a moral line that we've never crossed before\".\nCampaign organizers insisted they were not scaremongering and defended the \"killer robot\" moniker, saying that the dangers are real and the phrase served them well in the staid world of diplomats and committees.\nGoose said that Afghanistan and Pakistan - where hundreds of people, most of them civilians, have been killed in drone strikes in the past decade - have been particularly vocal supporters of the three-year effort.\nThe US, UK, Israel and South Korea have kept comparatively quiet on the issue; each country has advanced AI programs and ranks among the top spenders on their militaries. The US and UK have policies on military AI, but the activists, who want the UN to formalize talks on \"meaningful human control\", said that both countries' rules were too ambiguous.\nRichard Moyes, a managing partner at the UK non-profit Article 36, said although the country has promised there will always be \"human control\", it has not elaborated at all on whether that means a direct operator, a supervisor, simply someone who has activated the AI, or something else entirely.\nSimilarly, the Pentagon policy always requires an \"appropriate\" level of human control; a spokesperson did not immediately respond to a request for elaboration. And although in 2012 the Pentagon adopted a 10-year plan not to use fully autonomous AI, the measure allows senior officials to overrule it and does not affect research and development.\nAt the UN, the US and Israel have maintained they want \"to keep the option open\", Goose said, and Russia and China have quietly watched talks while developing their own programs. \"Nobody's 'fessing up,\" he said.\nShould the UN formalize talks on 13 November, Goose said he expected an organized opposition to form. He expected, at minimum, that no country would block the renewal of informal talks, and said he hopes for results sooner rather than later.\n\"If we wait, the technological developments are going to overtake the diplomacy quite quickly,\" Goose said.\n"},
{"docid": "89 of 500 DOCUMENTS\n", "source": "The Sunday Telegraph (London)\n", "date": "April 16, 2017", "title": "How technology is dressing up our shops; Artificial intelligence is transforming how we buy clothes online, says Ashley Armstrong, but bricks and mortar stores are catching on\n", "content": "Fashion has always been intrigued by technology as a creative force. Almost two decades ago, designer Alexander McQueen made a lasting impression after using two robots to spray paint all over a model's white dress.\nLast year's glamorous Met Ball chose \"Manus x Machina: Fashion in an Age of Technology\" as its theme and, more recently, Chanel sent robot models dressed in pastel-coloured tweed suits down the runway.\nHowever, the link between fashion retail and technology is becoming much more than just an aesthetic thanks to the rampant rise of online shopping and the use of artificial technology, which is transforming the way people will shop.\nWhen Natalie Massenet first started online luxury fashion group Net-a-Porter in 2000, many were sceptical about whether people would want to buy clothes online without trying them on in a shop. Fast forward 17 years and the booming force of Asos and Amazon means that digital sales are increasingly stealing shoppers away from bricks and mortar shops.\u00a0\nJust last month online sales grew by 7.4pc, while non-food shop sales fell by 1.1pc in March, according to the British Retail Consortium and accountancy firm KPMG. However, experiences still vary and retailers have been struggling to recreate the experience of browsing a physical shop for consumers, rather than have them suffer the fatigue of scrolling through a dozen web pages to find one black dress.\nVisual search Imagine seeing a friend wearing a pair of jeans, or holding a handbag that you liked. With a simple smartphone photograph it will soon be possible to search online for that item visually, buy it and have it delivered to wear the next evening. The so-called \"visual search\" is just one artificial intelligence project that online fast-fashion giant Asos is trialling. Nick Beighton, Asos chief executive, said that around 80pc of Asos purchases are on mobile. As Asos's core-customer is a 20-something shopper, used to selfie-snapping all day long, the move has the potential to boost sales further.\nEven traditional department store retailer John Lewis, which recently announced it was cutting staff bonuses to invest in more online technology, began trialling visual search artificial intelligence last year. The department store uses Cortexica \"findSimilar\" software, which was developed at Imperial College London and has been likened to a clothing version of music recognition app Shazam.\nIt allows shoppers to search for clothes they already like online and then find items stocked by John Lewis of a similar shape, colour and pattern.\nLast year John Lewis said that 90pc of shoppers said they found the findSimilar tool useful, leading to the department store chain rolling it out across its homewares department.\nMeanwhile, other retailers are also quickly adopting artificial intelligence to improve their customer service with real time \"chatbots\", which use machine learning to provide advice or answer basic queries as the pace of online shopping growth booms.\nBeighton at Asos also uses artificial intelligence to turn customer feedback into algorithms about the reasons why clothes have been sent back. If the bulk of returns are because an item is too small, the site's product description will then tell shoppers that they might want to take a larger size.\nResearch by Gartner believes that artificial intelligence will cover 85pc of consumer interactions in retail by 2020. But that's not to say there aren't cases where it hasn't gone wrong. Microsoft last year had to scrap its Twitter chatbot, Tay AI, after it turned into a Hitler-loving, feminist-bashing troll as its machine learning led it to mimick behaviour of its followers.\nHowever, Burberry was an early successful adopter of artificial intelligence and chatbots. The British luxury fashion brand launched a Facebook chatbot during Fashion Week last year to stream a video of the catwalk and then offer live customer service for wealthy customers to buy the collection the same day as they'd seen it. The so-called \"see now, buy now\" service has revolutionised the shopping calendar for couture.\nMeanwhile, other high street companies are mixing chatbots with real life humans. For example, Marks & Spencer has quietly launched a separate fashion site and personal styling service, called Tuesday. The high street stalwart is trialling the website as a way of gaining more insights into the way customers shop. While chief executive Steve Rowe has already set up a panel of human shoppers to give their feedback on what they want from collections, Tuesday will be gathering huge amounts of data about what M&S shoppers are looking for.\nThe service uses a chatbot which fires off 32 questions rapidly about size, age, tastes, style, inspiration and whether a shopper is looking for party wear, work wear or casual wear. Only after an automated style interrogation is a shopper connected to a real human stylist. The human then uses all the information gathered by the chatbot to email a variety of tailored different looks and pieces, all available to buy on Marks & Spencer.\nMeanwhile, luxury online retailers Matches Fashion and Yoox Net-a-Porter also use chatbots to improve their customer service and tailor their offer to what individual shoppers want.\nAt Yoox Net-a-Porter (Ynap), the company which owns Mr Porter, The Outnet and Yoox, the company is investing heavily in AI.\n\"It transforms the experience for our customer because it knows the customer on a one-to-one basis, it can know everything about them,\" says Alex Alexander, chief information officer at Ynap. \"But I never see it replacing entirely the human touch of shopping assistants, I see it as complementary. Chatbots can provide information in the real moment.\n\"Without artificial intelligence, it's hard to predict what the customer wants based on past purchases.\"\nRobotic fashion In the US, a company called Stitch Fix demonstrates the blurring between technology and humans. The company started by offering a subscription clothing service which offered flummoxed shoppers a wardrobe-in-abox, recommended by stylists and based on the shoppers' taste and size. The wardrobes would be based on customers' style surveys, measurements and boards on Pinterest, a cataloguing app. The company would then use machine learning algorithms to digest all of this eclectic and unstructured information to make informed style suggestions.\nBut Stitch Fix has taken this one step further and used artificial intelligence to identify the shirt cuts, patterns, and sleeve styles that were most popular among the company's subscribers and then make a range of shirts. As a result, they made three shirts that were largely designed by artificial intelligence. All three sold out, paving the way for a \"design by numbers\" strategy that threatens to turn the creative fashion industry on its head.\nMeanwhile, Ulric Jerome, chief executive at online retailer Matches Fashion, believes that the use of artificial intelligence is still nascent. The company already uses AI and machine learning to ensure that registered customers are displayed products based on their browsing and purchase history and sent more tailored email marketing. \"How do you make sure that the emails you send are relevant to the shopper? The end game for AI is that we sell more product and increase the conversion rate on our site and sell items at full price, which improves profitability.\"\nMatches Fashion is already trialling a service that means its editorial recommendations will instantly be replaced with similar products as and when the products sell out. However, Jerome discloses that Matches is going one further by using a new technology that reproduces a 3D version of a customer's body with clothes that can be dropped from the site on top of the virtual mannequin to show how they will fit that shopper. \"We are really excited about it\", Jerome says.\nReplicating shop changing rooms remains one of the biggest challenges for the online retail industry. However, a company called FitsMe is hoping to eliminate the need for shoppers to order a dozen different sizes and reduce returns across the industry.\nAt the moment, fashion retailers have average return rates of 15pc to 20pc, of which around 80pc are fit based and cost UK retailers around \u00a320bn a year.\nFitsMe started by producing robotic mannequins which shifted shapes depending on different sizes and taking into account different body shapes, like pear-shaped, which traditional mannequins don't do. That has now evolved whereby customers plug in their size, their measurements and their body shape and the FitsMe algorithm tells them what size they need. \"It's like a formula that is based on the true size a body shape needs,\" Stuart Simms, chief executive of FitsMe, said. \"Retailers are a bit more sympathetic to offering an online experience that is similar to a shop experience than ever before. It's all about offering a consistent experience.\"\nVirtual stores However, while online shopping's rise has been steep, it is still expected to plateau over the next eight years. Jos\u00e9 Neves, founder of luxury fashion platform Farfetch and chief executive, last week admitted that online growth cannot continue at the same pace forever. \"Physical retail accounts for 93pc of sales today, and even with online growing at fast speed, it will still account for 80pc by 2025.\"\nBut that's not to say that physical shops will become more profitable or busier. Instead it's likely that physical and online retailing will blur as companies become more joined up in their operations. The growth of click and collect means that traditional shops can give online retailers more coverage across the country. Some retailers' websites already tell shoppers if a certain dress that might be sold out online is available in a nearby shop instead. This doubles their inventory and can reduce delivery times.\nFarfetch last week announced a partnership with Gucci that means a shopper can use IT to order a Gucci dress online, but the dress will be delivered from the nearest Gucci shop. The \"Gucci in 90 minutes\" service will be launched in London, Milan, Paris, Los Angeles and New York.\nThe move puts it head to head with MatchesFashion, which has offered a 90-minute delivery in certain London postcodes, and Ynap, which has a similar service with Valentino.\nHowever, the increasing use of physical shops by online retailers signals a blurring for the industry. \"The next stage in the evolution of the fashion industry is the connected store, which uses technology to enhance the luxury retail experience to become even more customer centric,\" Neves said. \"Farfetch is at the crossroads of luxury and technology and we are well placed to deliver a tailored solution.\"\nWhat this could mean is that even though technology and AI are gripping the fashion industry more than ever, they could end up just making traditional bricks and mortar more sophisticated for the modern shopper.\n'I never see AI replacing the human touch of shopping assistants, I think they complement each other'\n"},
{"docid": "90 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "November 13, 2017", "title": "Cutting edge tech holds huge promise - so why are British firms not investing?\n", "content": "Robots in space. Intelligent machines in the freezing deeps of the North Sea. Automatons within the most toxic chambers of nuclear power plants, or plunging into the harshest mines. The future for artificial intelligence is exotic, alien and powerful.\nAt least, that is the vision bought into by the Business Department last week when it ploughed an extra \u00a384m into a series of new projects at a series of universities and corporate research and development labs.\nCutting edge research into the artificial intelligence, robotics, 3D printing and other barely-out-of-sci-fi fields holds plenty of promise but has yet to completely upend the world in which we live.\nFor the past decade business investment appears to have been sluggish. Productivity growth has slowed and real wages are under the cosh, which does not fit with the idea that we are in an age of incredible technologies. Visions of the future can be inspiring or daunting, depending on your job right now.\u00a0\nAirbus last week claimed it can have driverless flying cars on the market in five years' time - a fantastical vision and the stuff of movies so far.\nIn perhaps a more grounded forecast, John Cryan, the chief executive of Deutsche Bank, said half of the bank's almost 100,000 jobs could be replaced by robots in the next 20 years.\nSo far, the practical gains have been more modest, but are important in specific areas.\n        The history of artificial intelligence       01:49\nDaniel Hegarty founded and runs Habito, an online mortgage broker which uses artificial intelligence as part of its system to process applications and match borrowers with loans.\n\"Humans are really, really bad at doing arithmetic and filling out forms and holding 80 different credit policies in their heads and matching them to the right customer,\" he says.\nThere is still a human element - he found customers are unwilling to conduct such an important transaction through a clever machine alone, and value the chance to talk to a living, breathing adviser. \"We use machines for sorting and humans for talking,\" he says.\nNonetheless, Hegarty believes he is four or five times more efficient than a traditional broker, with the capacity to grow much further using the technology he already has.\nHowever, he is aware these are early days in what is sometimes called, rather grandly, the fourth industrial revolution.\n\"We are super early on. We have essentially mechanised a manual process. That is interesting and it provides a tangible consumer benefit. But the real transformation in financial services is still some way off,\" he says.\nThat belief is based on his concern that right now, people must shop around on a regular basis for new loans or savings accounts with imperfect information, leaving them reliant on the marketing power of big finance firms, rather than finding the best product out there.\n\"When machines pick the products it is not about the marketing budget, it is about the best product,\" he says, hoping it will force firms to compete on value. \"That will be a transformational point.\"\nIt is not only services which could be revolutionised by new technology. Manufacturing, too, faces a wave of much-hyped new tech which is yet to fully hit home.\nEconomist Raoul Leering at ING has studied the potential of 3D printing and sees several factors holding it back so far.\n\"Current 3D printers are really slow, so they are not competitive with regard to traditional capital goods,\" he says. \"For the time being, they are only competitive when making customised products in a complex shape,\" he says, citing medical parts printed to match an individual's body.\n\"But for mass production of traditional products, 3D printers are too slow. We are waiting for a new generation to speed up the tempo.\"\nAdvances are quick - the latest models are as much as 1000-times faster than their predecessors - but speed, price and reliability all have to combine to make them a worthwhile purchase.\nHis observations in that market can be applied to all radical new tech.\nFirstly, companies are not going to abandon any expensive relatively modern equipment immediately just because the latest tech has marginally outclassed it.\nSecond, engineers with decades of experience are not always keen to abandon all of the systems with which they have expertise, switching to a revolutionary new system overnight.\nAnd third, he sees a network effect holding investment back.\nTo use the example of the internet, the technology took time to grow because the first person with it could communicate with nobody.\nGoing back further in time, a lone telephone is useless with nobody to call.\nIt was only as more people gained access that it became worth anybody's while to connect to the internet. And as more people did, access itself became more valuable and, in time indispensable.\n        The self driving robots that know when to recharge themselves       00:57\nThis slow adoption has raised comparisons with previous eras of slow productivity and wage growth in British history.\n\"There has been a period, a 10-year period in the UK, when you hadn't had any productivity growth, but you have to go back to some time in the 1860s or 1870s to see this,\" says Ben Broadbent, deputy Governor at the Bank of England.\n\"When people talk about that period, they talk about the pause between two big technologies. We were moving away from steam to electricity.\"\nIan Stewart, Deloitte's chief economist, says the adoption of electricity into the workplace took far longer still than just that decade.\n\"Productivity does not proceed at a stable rate over time. After the First World War particularly there was a mass deployment of electrification in factories, so there was an extraordinarily long lag from the inventions [in the 19th century] to their application in factories,\" he says. \"The whole production process had to be redesigned, buildings had to be redesigned. And as that happened there was a surge in productivity.\"\n\"It may be the case that we haven't really fully exploited current technologies, let alone the next generation.\"\nThat is echoed by the CBI in a new report which notes that the UK has a small group of highly productive, cutting-edge firms, but a long tail of underachievers.\nAlmost 70pc of employees in the UK work in companies with below-median productivity, it notes, as too many firms have failed to adopt even well-established technologies.\nWhile the slow pace of the AI revolution and the rise of the robots may be a drag for sci-fi fans, at least it means the most dire predictions of mass redundancies and endless poverty for swathes of the population are unlikely to come true as workers have time to adapt.\n\"It doesn't replace jobs, it frees workers up to do more high-value activity, say in innovation,\" says Lee Hopley, chief economist at manufacturing industry group EEF.\nThe process is a slow one in any case, because \"this isn't a big bang event where suddenly these new technologies are available off the shelf to apply in your business,\" she says.\nMarion Amiot at Oxford Economics says: \"I don't think the net effect will be to destroy jobs.\"\nThere is a clear desire to speed up investment and the adoption of productivity enhancing technology. The Chancellor, Philip Hammond, is under pressure to find ways to raise investment and boost the economy in both the short and long-term.\nBut although there is no shortage of proposals sent his way, it is difficult to find any perfect answers. Broadbent warns that the historical record is not helpful.\n\"It is not evident that policymakers can flick a switch and change this.\n\"If you ask most economists they'd talk about sensible tax regimes, openness to the rest of the world, healthy public sector investment, good education,\" he says.\nDeloitte's Stewart also notes a different lesson from history: expectations can be hopelessly wrong. He sees productivity growth as a process which comes in waves, pointing to the terrible crunch in the Seventies, strong improvements as the economy was revitalised by the end of the Eighties and early Nineties, over-optimism with the dotcom bubble and now another flat period.\nIf this assessment is correct, it may be that current pessimism about the long-term future is severely overdone.\nAt least we can comfort ourselves with that thought while we wait for space robots to become a regular feature of our lives.\n"},
{"docid": "91 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "February 27, 2017", "title": "O2 unveils artificial intelligence link for customers\n", "content": "Telef\u00f3nica, the Spanish owner of O2, has launched an artificial intelligence platform enabling customers to use their voice to ask questions about their account as well as tailor content and data to their own needs and interests.\u00a0\nThe digital personal assistant service, which has been developed with Microsoft, is one of the more advanced efforts to apply artificial intelligence technology to ordinary consumers, according to Jos\u00e9 Mar\u00eda \u00c1lvarez-Pallete, the chairman of Telef\u00f3nica.\n\"Cognitive intelligence will allow us to understand consumers better so they can relate to us in a more natural and easy way,\" he said at the Mobile World Congress in Barcelona.\nHe claimed that the technology, which will be rolled outover the next 12 months, was a \"pioneering\" step for the mobile industry and pitched it as a major new growth strategy for Telef\u00f3nica, which has cut its dividend and announced asset disposals as it struggles to repay a (EURO)48 billion debt pile.\nThe figure includes big upgrades to networks and infrastructure as well as investments in software and product development.\nThe app, called Aura, allows users to decide whether or not to share insights generated by their data with third parties such as Facebook or Google. Telef\u00f3nica said that users would be able to address increasingly complex questions to their device.\n(EURO)48bn The amount of debt that Telef\u00f3nica has built up and is struggling to repay\n"},
{"docid": "92 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "May 29, 2014", "title": "The answer to mis-selling? Let a robot pick your investments; The City regulator hopes \"learning algorithms and self-improving artificial intelligence\" could help fill a growing gap in financial advice\n", "content": "Savers in the future should be advised by robots on which Isa funds or insurance policies they should buy, the head of the City regulator has suggested. \nMartin Wheatley, chief executive of the Financial Conduct Authority (FCA), today outlined a vision of how \"self-improving artificial intelligence\" could help guide investors. \u00a0\nConcerns have been repeatedly raised that changing regulation and fears of mis-selling has removed easy access to financial advisers and the FCA is keen to bridge what has been called an \"advice gap\". \nMr Wheatley told a conference in the City \"a series of incredible bounds forward in thinking\" on artificial intelligence since the Eighties had improved the chances that investors of it being used in financial planning. \nHe said: \"In the 90s we saw Kasparov beaten by IBM's Deep Blue computer. A machine that was, at the time, capable of calculating some 200m individual chess moves per second - but even then couldn't discuss the strategy it had employed. \n\"Today, however, scientists are heralding the advent of learning algorithms and self-improving artificial intelligence capable of previously unimaginable and impossible feats of accuracy and forecasting.\"\nHe asked whether this could be used for dispensing investment advice and automated \"to deliver returns and security for consumers with straightforward needs\". \nSome innovative firms are already offering technology that helps with the selection of investments but the rules are unclear. Established firms, such as Fidelity Personal Investor, are also upgrading their websites with more advanced tools. \nThe regulator appears to be soothing nerves in the industry and show it wants to promote innovation. It announced the launch of Project Innovate, aimed at supporting new firms that could improve the market for consumers, beyond just financial advice. \nPriority areas were named as mobile banking, online investment and money transfer. Mr Wheatley said: \"We're seeing innovations such as apps that allow you to take a picture of a bill and make payments with a tap of the smartphone. The possibilities opening up for consumers are extraordinary.\"\nThe FCA plans to publish a consultation paper next month on \"guided advice\" and how it can be delivered. It has looked at \"new models of automated advice\" and will ask at whether more sweeping change is required. \nChris Williams, a director on the Institute of Financial Planning (IFP), said: \"Technology is the key to bridging the advice gap. Clients are already engaging with technology in their everyday lives and it's a natural starting point when looking for advice. However, this is not only where the advice process should launch from, but also, with the right framework, where it should end.\"\nTalk of an advice gap emerged after a rule change ordered by regulators in January 2013 forced independent financial advisers to charge clients directly. Before most charged nothing and made money instead from the commissions paid by investment and insurance firms when they sold one of their products. This was deemed as creating the potential for bias in the recommendations made.\nNow, those seeking advice are typically asked to pay \u00a3300 for an hour of consultation, although it is also possible to pay as a percentage on the amount invested. \n"},
{"docid": "93 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 1, 2017", "title": "Facebook to use artificial intelligence to combat suicides\u00a0\n", "content": "Facebook will use artificial intelligence to spot users who may be at risk of suicide, telling people to talk to friends or contact a helpline if their posts show signs that they may be considering taking their own lives.\u00a0\nSuicide prevention services have been available on Facebook for more than 10 years, but it is now testing artificial intelligence as a way of identifying users who may be at risk.\nIts algorithm will flag up posts that are likely to include thoughts of suicide, Facebook said, by using pattern recognition on previous posts that have been reported.\nReporting tools will now also be integrated into Facebook Live, so people who are watching the video will be able to report it and \"reach out to the person directly\".\nFacebook CEO Mark ZuckerbergCredit:      REUTERS/Stephen Lam     \nThe news follows the death of Naika Venant, a 14-year-old girl who used the social media platform to livestream her suicide in January.\n\"There is one death by suicide in the world every 40 seconds, and suicide is the second leading cause of death for 15 to 29-year-olds,\" the company said.\n\"Facebook is in a unique position - through friendships on the site - to help connect a person in distress with people who can support them.\n\"Today we are updating the tools and resources we offer to people who may be thinking of suicide, as well as the support we offer to their concerned friends and family members.\"\nWatch | Facebook launches new safety check page                         01:02\nThrough its suicide prevention tools, Facebook users can be prompted to reach out to a friend who they believe may be in need of support, while it also suggests contacting a helpline.\nThose tools have been developed alongside mental health organisations such as Save.org and the National Suicide Prevention Lifeline, and last year were rolled out globally.\nIf a video is reported to Facebook, the social media giant will able to reach out to emergency workers if the person is in imminent danger.\nAs part of its suicide prevention tools, Facebook allows people to connect with crisis workers over Messenger. As of Wednesday, people will see the option to message someone in real time directly from the organisation's page or through suicide prevention tools.\nEarlier this month, Facebook launched a new feature to help people find basics such as food, water and shelter when natural disasters strike .\n"},
{"docid": "94 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 17, 2017", "title": "Bank of England trials artificial intelligence and blockchain in bid to stay ahead of the pack\n", "content": "The Bank of England has paired up with\u00a0artificial intelligence and blockchain specialists in a bid to keep up to date with the fast-growing financial technology sector.\nThe central bank is\u00a0testing an artificial intelligence system with\u00a0Canadian startup MindBridge AI to allow it to spot abnormalities in financial transactions and\u00a0\"explore the benefit of machine learning technology for analysing the quality of regulatory data input.\"\u00a0\u00a0\nIt has also partnered with\u00a0San Francisco-based startup Ripple, which opened an office in London last year,\u00a0to trial a blockchain-based technology that would make cross-border payments and the movement of currencies more immediate. Blockchain is the technology which underpins crypto-currencies like bitcoin.\u00a0\nThe Bank said that its aim with Ripple is to \"show how this kind of synchronisation might lower settlement risk and improve the speed and efficiency of cross-border payments.\"\u00a0\nOne fintech chief executive said that this was a key issue for a number of consumers in Britain, adding that it would currently be \"quicker to fly a large transfer of\u00a0money over from the US than to transfer it.\"\u00a0\nThe partnerships were announced\u00a0on the same day that the BoE\u00a0said it was\u00a0setting up a 'community' for the\u00a0sector in a bid to keep with changes in the industry.\u00a0\nThe community includes financial technology\u00a0specialists like Michael Spencer's Nex and Bitsight, as well as more traditional business including BT and accountants PwC.\u00a0\nClaire Sunderland Hay,\u00a0head of the BoE's fintech accelerator which launched last summer, said at The Telegraph's first fintech conference last summer that\u00a0\"innovation keeps our industry moving forward. Without it we would still be using landlines.\"\nAshok Vaswani, chief executive of Barclays UK, said at the same conference that it was \"really, really important for London to stay at the forefront of fintech.\"\u00a0\n"},
{"docid": "95 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "December 28, 2016", "title": "2016: the year AI came of age; Google and Amazon brought AI into the home and DeepMind built a computer that could outsmart humans at Go. Will 2017 hold similar advancements?\n", "content": "Over the course of 2016, artificial intelligence made the leap from \"science fiction concept\" to \"almost meaningless buzzword\" with alarmingspeed.\nEverything has AI now. Period-tracking app Flo \"uses a neural network approach\" to deliver \"high period forecast accuracy\"; food delivery app Just Eat launched a chatbot that \"sees AI integrated into the ordering experience to ensure that customers receive the best, round the clock support and service\"; restaurant guide Borsch \"uses artificial intelligence to help people discover the yummiest dishes around\". \nBut unlike many buzzwords before it, from \"big data\" to \"blockchain\", artificial intelligence's transformation into venture capitalist-catnip doesn't signify the end of anyone serious using the term themselves. In fact, 2017 looks like it could be the most important year yet for the technology: AI will butt up against not only what is possible, but also what is desirable for the first time.\u00a0\nLike many futures, the AI revolution feels interminably slow to live through, and will feel like it happened in an instant in hindsight. The first pivotal year was 2011. That was when Apple's Siri hit iPhones, introducing the world to the first major \"virtual assistant\". It was also the year the Google Brain project was instituted: the search engine's blue-sky research team aimed to address as many tasks as possible through neural network-based learning, the computational technique that has come to define what we mean by artificial intelligence.\nFive years on, and neural networks have already begun to enable tech which seemed impossible back then. Google and Apple have applied them to their photo apps to let users search through their pictures for images of \"dogs\", \"cars\" or, in Google's case, \"Christmas\", based on what the algorithms see in the images. That machine vision technology is also the basis of the self-driving car efforts from Google's sister firm Waymo. Oh, and an entirely different neural network is probably the world's best player at the ancient boardgame Go.\nThat victory, from Google subsidiary DeepMind, was one of the last remaining milestones for a machine to reach. Go is so complex that, as recently as 2014, many thought it would be another decade until an AI could approach the skill of a human player. That was what made it so appealing for DeepMind to tackle.\nThere's one remaining milestone that the London-based research lab is interested in chasing, according to co-founder Mustafa Suleyman, and it's a big one: instant voice-to-voice translation. The company has slowly been assembling the pieces for a while, with Google already rebuilding its translation service around a neural network-based approach, and DeepMind creating a whole new way of synthesising speech it calls WaveNet, but there are still a host of other problems to be overcome before the babel fish becomes a reality.\nWhich is not to say that 2017 won't be a groundbreaking year for AI. The biggest effect will be the step change in the amount of data which companies such as Google and Amazon have access to. When Google released its voice-controlled, AI-powered smart home device, Google Home, in 2016, it already impressed some with its abilities. But, says Fernando Pereira, who leads Google's natural language understanding projects, that's only the start. \nNow that millions of people have Google Home in their living room, the company can analyse every natural language query it starts getting from all of them, giving it far more data to crunch than it could ever get from its testers. \"You can start doing machine learning on that,\" Pereira told tech site Backchannel. \"You can move much faster; you can accelerate the process of getting deeper and broader in understanding. This 2016-to-2017 transition is going to move us from systems that are explicitly taught to ones that implicitly learn.\" \nThis is the story Google wants to tell of machine learning: an acceleration, turning the coming year into an inflection point, the instant that machine learning became good enough to start trusting.\nIt's certainly one possible outcome of the next year, although it's not yet clear whether Google will be the one to deliver on it; Amazon has been keeping pace with its own Alexa assistant, for instance, while others including Facebook, Microsoft, IBM and Baidu have been trumpeting their own machine-learning successes.\nBut the other possibility is that, as machine learning steps out of the shadows and companies ask for ever more data to train their algorithms, the backlash begins. Already, Google faces competition from other companies over how much of your life it wants to manage. \nThat happens implicitly, in the difference between Google Home and Amazon's Echo: the former integrates tightly with your Google account, reading emails, notes and calendar events to keep up to date with your life, while the latter takes a more hands-off approach, only linking with what it's told and generally attempting to be responsive, rather than proactive.\nIt also happens more explicitly in the way Apple has decided to weigh in against its rival. The company, freed from the need to data mine everything by its old-fashioned \"sell things for money\" business model, has been proudly demonstrating approaches to AI which don't need a central repository of harvested data to learn or work. That includes its machine vision approach, which scans users' photo libraries on device, rather than on the cloud, and its research into \"differential privacy\", a technological approach to machine learning which allows the company to learn from data in aggregate while never having access to the information of specific users.\nOf course, there is a third option: that neural network-based machine learning will instead prove to be a technology like any other, useful in some areas, useless in others, and eventually doomed to be rendered obsolete in turn by a future innovation. We're already seeing some of the downsides, in the eternal craving for more data, in the processing power required to actually learn, and in the opacity of the models that result. One day, those downsides will outweigh the up, and the world will move on. But for now, there's still a world of possibility.\n"},
{"docid": "96 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 22, 2018", "title": "Exclusive: Theresa May to announce ethical oversight of AI used to drive cars, diagnose patients and even sentence criminals\n", "content": "Theresa May will this week announce plans for the ethical oversight of artificial intelligence as it is increasingly used to drive cars, diagnose patients and even to help determine prison sentences.\u00a0\nThe Prime Minister is expected to use her keynote speech at a summit of World leaders in Davos on Thursday to discuss the opportunities and ethical challenges presented by the rise of artificial intelligence.\nMinisters believe that Britain has the chance to become a World leader in artificial intelligence, just as it currently is in other cutting-edge technologies such as genomics.\nHowever\u00a0there are significant concerns that computer algorithms could end up making critical ethical decisions without human oversight.\nMrs May is expected to announce detailed plans for a national Centre for Data Ethics to provide guidance and consult on the regulation of artificial intelligence.\nExperts have highlighted the example of a self-driving car forced to choose between running over a group of pedestrians or causing a potentially lethal crash in an effort to avoid them.\nMPs last week raised concerns that the technology could develop inherent biases against specific groups of people if it is routinely used in recruitment, finance or sentencing.\nJo Swinson, a Liberal Democrat MP, said that in Florida an algorithm used to help set sentences by predicted the likelihood of reoffending was almost twice as likely to wrongly flag black defendants as future criminals.\nMargot James, the new Digital Minister, responded: \"We must ensure that these new technologies work for the benefit of everyone: citizens, businesses and wider society.\n\"We are therefore integrating strong privacy protections and accountability into how automated decisions affect users. A strong, effective regulatory regime is therefore vital.\n\"Important decisions on everything from autonomous cars to medical diagnosis and decisions on finance and sentencing - and indeed applications to defence - cannot be delegated solely to algorithms. Human judgment and oversight remain essential.\"\nMs James added in the debate last week that some jobs are likely to be \"displaced\" by the rise of artificial intelligence.\nShe said: \"We know that some jobs may be displaced, and often for good reasons: dangerous, repetitive or tedious parts of work can now be carried out more quickly, accurately and safely by machines.\u00a0\n\"None the less, human judgment and creativity will still be required to design and manage them. \u00a0However, as the workplace continues to change, people must be equipped to adapt to it easily.\u00a0\n\"Many roles, rather being directly replaced, will evolve to incorporate new technologies.\"\n"},
{"docid": "97 of 500 DOCUMENTS\n", "source": "The Guardian - Final Edition\n", "date": "July 20, 2007", "title": "Science: Computer program takes draughts crown: Chinook unbeatable after creator's 18 years of work: Achievement a big step for artificial intelligence\n", "content": "It has taken more than 18 years, and hundreds of computers to crunch numbers through the night, but yesterday Jonathan Schaefer declared his job done: he had written the world's first program that was unbeatable at the game of draughts.\nChinook, as the program is known, can calculate a winning response to any move made by its opponent. The worst result it can ever have is a draw, according to Dr Schaefer, an expert in artificial intelligence, working at the University of Alberta in Edmonton, Canada.\u00a0\nThe game of draughts, played on a board with eight by eight squares, is the most complicated game ever solved thanks to artificial intelligence. The number of possible positions in a game makes it one million times more complex than Connect Four. Even Deep Blue, the chess-playing program developed by IBM, which beat Garry Kasparov in 1997, can lose - because it is not powerful enough to predict every possible outcome of a game.\nDr Schaefer's announcement was met with praise and awe from the artificial intelligence community yesterday, who called it a \"huge achievement\".\nPeter Cowling, a computer scientist at Bradford University, said: \"This program could play draughts against God and it would get a draw. But if Deep Blue played chess against God it would lose badly because there's so much it doesn't understand.\"\nIn an article yesterday, in the journal Science, Dr Schaeffer and his colleagues describe how they developed intelligent software to prove that, like noughts and crosses, draughts is always a draw if neither player makes a mistake.\nGiven that there are 500 billion billion possible arrangements of draughts on a board, the proof took extraordinary computing skill, said Professor Cowling.\nDr Schaefer said the effort had taken its toll. \"It's been 18 years and my patience has been tried. I was pretty naive in the beginning and didn't think it was going to take so long, but once I'd got it going I was determined to finish it. But this is the end. Life is too short to spend this much time on one thing.\"\nIn 1994 Dr Schaefer entered an earlier version of Chinook into the Man-Machine checkers world championship. The program was declared the winner after drawing six games with the undisputed champion, Marion Tinsley, who had to withdraw for health reasons.\nDespite attempts to schedule a re-match, none took place. Eight months after relinquishing his title Tinsley died from pancreatic cancer. His death provoked verbal attacks on the scientists who created Chinook, who were accused of driving him to the grave.\n\"The checkers players said we caused him to die, that it was the stress of playing against Chinook, and we were responsible. They said we could never have beaten Tinsley, because he was too good and that we were imposters,\" said Dr Schaeffer.\nThe accusations drove the team to improve Chinook to being unbeatable. \"I knew it was possible to build a computer program that could never lose a game. Now, it's absolutely clear that as great as Tinsley was the best he could do against the program (was) draw.\"\nTo write Chinook the scientists developed intelligent search software that could analyse a series of potential moves and decide the best. The most impressive achievement was being able to identify a winning move without looking at every possible outcome, a task almost impossible with current computing power.\n\"A lot of the moves don't have to be considered at all, we looked at only one millionth of the possibilities.\"\nProf Cowling said: \"Solving draughts is a huge achievement. The number of possible moves is truly gigantic, and the intelligent part is finding ways to throw away most of those. Achievements like this are significant steps towards solving much larger technical challenges.\n\"Suppose you set yourself the goal of making an artificial person, or something that can sit next to a person in a hospital bed and keep them entertained with conversation - how do you get there? You get there by solving increasingly complex AI problems like this.\"\nblogs.guardian.co.uk/technology>=\n"},
{"docid": "98 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 15, 2017", "title": "Let's not let artificial intelligence become another bubble\n", "content": "Those of you braving the World Economic Forum's annual jamboree in Davos this week, should you find time in between ski sessions and early-hours nightcaps to pop into a session or two, will notice a familiar theme emerging.\nNo, not Brexit. Not Donald Trump's imminent inauguration either. But artificial intelligence. You won't be able to move in Davos without hearing about AI: the conference's agenda includes sessions on \"AI and advanced robotics\", \"Decision by algorithm\", \"Intelligent killing machines\", not to mention dozens of side events on the matter.\u00a0\nGiven the subject matter, you might be forgiven for thinking this could be the last time Davos hosts the World Economic Forum before the inevitable robot uprising forces next year's event to be held in an underground cave.\nBut to those in technology circles, the growing presence of artificial intelligence at the meeting of world leaders will be no surprise.\nSecond perhaps only to virtual reality, artificial intelligence has generated more frenzied excitement than any other Silicon Valley trend in the last 12 months. According to CB Insights, there were 255 deals involving private AI companies in the first half of last year, a 44pc increase on 2015. The world's biggest technology companies are in an arms race for the world's AI experts, paying upwards of seven figures to poach them from universities.\n                   ces 2017 weirdest gadgets                   \nThere have been some major advances, certainly. Google's language translation software, once derided, is now approaching superhuman accuracy . Understanding human speech - something that requires technology to first transcribe and then interpret our words - has made huge gains. In areas such as lip reading, board games and general knowledge quizzes, computers have already exceeded human capabilities. Just last week, an AI poker player destroyed a room of professionals: in a similar experiment two years ago the computer came up short.\nThese advances have been realised thanks to a revival of interest in the techniques of \"machine learning\", in which intelligence is not programmed into a machine via a set of rules, but the machine is given banks of data, and using rapid improvements in computing power, is able to process it to build up something akin to understanding. Instead of teaching machines that a cat is something with four legs and a tail (true, but not what a cat is), we show it 10 million pictures all tagged as cats and allow it to understand for itself.\nBut for all the progress that machine learning promises, there is an equal amount of hype and bluster.\nAt this month's Consumer Electronics Shows, the tech industry's own Davos (even if CES is held in the somewhat less exclusive setting of a Las Vegas conference centre), almost every gadget on show was imbued with \"AI\". There was an electric toothbrush which, its maker claimed, could use \"deep learning algorithms\" to improve your dental hygiene. A tea brewer claimed to use advanced AI techniques to personalise your perfect cuppa.\nThe attention that the technology is generating means that almost every company using algorithms or sensors seems to describe itself as \"artificial intelligence\", which is enough to make the term almost meaningless. We've seen this before: a couple of years ago, every gadget was given the \"smart\" prefix: the logic was that we liked smartphones, so why not smart fridges?\nGoogle's DeepMind has beaten the world champion at GOCredit:      AFP     \nBut call yourself artificial intelligence, and you go one step further by indulging science fiction fantasies about killer robots making witty jokes as they travel through space.\u00a0 Make an electric toothbrush with a microchip in and nobody is too fussed; make an artificial intelligence electric toothbrush and you're onto something.\nI'm being slightly unfair by picking the absolute worst example, but it does illustrate the hot air around AI in recent months. Concerns about robots \"taking jobs\" have reached a fever pitch, as if technology has not been automating tasks previously done by humans for centuries.\nThe difference now is supposed to be that it is happening at a faster rate and further up the skills food chain, but this is nothing new either: in in 1950 technology was \"stealing\" more skilled jobs than in 1850. The real difference is that we are now calling it artificial intelligence, which is more attention-grabbing. After all, who doesn't love a robot?\nA lot of this distracts from the real breakthroughs that are being made in machine learning software, which can understand and interpret vast amounts of data to become proficient in areas once deemed beyond the realms of computers.\nMany of these are being made in the UK: DeepMind, a British company owned by Google's parent company Alphabet, last year beat the world champion at Go, an ancient game in which humans were expected to have the upper hand for another decade. DeepMind is now using NHS data to help spot acute kidney injuries. But this experiment has already generated a privacy storm over the level of patient consent to having their data processed.\nThis illustrates an impending problem with AI: progress requires an insatiable appetite for personal data, and at some point, a creepy line will be crossed.\nThe promises have been overblown before, the 1970s and 1980s had lengthy \"AI winters\" in which funding dried up and researchers avoided using the term, for fear it was a dirty word (a marked contrast to today's rush of companies looking to attach themselves to it). The real breakthroughs being made today suggest a repeat is unlikely, but we must be careful not to inflate another bubble.\nAI timeline\n"},
{"docid": "99 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "January 18, 2017", "title": "The world needs robots, says Microsoft boss\n", "content": "THE boss of Microsoft has argued that the world needs artificial intelligence to kick-start weak economic growth but warned that there were some things that machines \"perhaps shouldn't do\".\u00a0\nSatya Nadella, the chief executive of the computing giant, said that the benefits of artificial intelligence outweighed the drawbacks.\n\"Overall world GDP growth is not stellar. We need technological breakthroughs, we need AI,\" he said.\nMr Nadella stressed that as artificial intelligence progressed it would put a premium on certain human skills.\n\"If there is an abundance of AI, what will be scarce? It will be commonsense and empathy. I think it will create a situation where humanity will be at its best.\"\nMr Nadella added that there were \"some things machines can do that perhaps they shouldn't do\".\nThe threats and challenges posed by the adoption of technology was one of the main themes on the first day of this year's World Economic Forum.\nGinni Rometty, the chief executive of IBM, suggested that while some jobs would be replaced by robots, new forms of employment would take their place. \"Skills is the issue of our time\", said Ms Rometty. \"There will be new jobs [as a result of adopting AI technology]. But with new jobs you'll need new skills.\"\nShe said: \"With any new technology you have to think about how you develop trust for it.\" AI should be about \"augmenting\" the work that humans do rather than replacing them.\nShe added: \"Most of us will be working with these systems. The human has to be in control.\"\n"},
{"docid": "100 of 500 DOCUMENTS\n", "source": "The Sunday Telegraph (London)\n", "date": "June 25, 2017", "title": "The challenge faced by tomorrow's engineers; BAE Systems asked students to predict what technology the Navy will be using decades from now. Helena Pozniak talks to maritime engineering director Kevin McLeod about the warships of the future\n", "content": "When the first of the Royal Navy's new aircraft carriers begins sea trials later this year, it will be armed with a range of new technologies, from powerful radars to sophisticated weapons.\nThese two new Queen Elizabeth-class warships may see 50 years of active service. So what will the vessels of the future look like? What threats will they face, who will crew them and how will they operate? This is the challenge faced by tomorrow's engineers (and this year's STEM winner) - to imagine the kind of innovations that the scientific community hasn't even thought of yet. The challenge set by BAE Systems asked science and engineering students to look into the future and meet the needs of the Navy several decades on.\n\"Whatever the design of a warship, its fundamental purpose remains the same,\" says Kevin McLeod, engineering director at BAE Systems Maritime. \"To provide sovereign 'territory' wherever needed, combat threats and provide humanitarian and military support.\" Aircraft carriers of the future need to shift from fossil fuels - these new warships have thirsty engines - and be ready to combat cyber terrorism as well as piracy and other rogue threats. They need clean power, stealth and higher levels of automation, all within the inevitable financial constraints of military spending.\u00a0\nBy artificial will have much decision on board undertaken a BAE Systems judges picked winners from a range of entries from students who made startling use of emerging technologies, and also understood the scale and complexity of the ship. \"Warship design is a balance of challenges,\" says Mr McLeod. \"When you change something, no matter how small, it has an impact elsewhere. It's a collection of systems and you have to take an approach which looks at the whole ship and crew on board.\"\nFrom warships powered by nuclear fusion to a semisubmersible vessel that could hide underwater, entries were daring and ingenious. Winner Joe Gibson, an engineering student from the University of Strathclyde, designed a lean and nimble ship that would be largely maintained and controlled by artificial intelligence and robotics. \"Joe tackled the whole picture,\" says Mr McLeod. \"While a fusion reactor in something like a ship is decades away, who's to say it won't happen.\"\nCyber attacks pose one of the greatest threats of the 21st century, says Mr McLeod, and the winning design combined 2050 intelligence advanced so routine making will be by computer cyber security and artificial intelligence to highly impressive effect. \"By 2050 artificial intelligence will have advanced so much that routine decision-making on board will be undertaken by a computer,\" says Mr McLeod. In the event of a cyber attack, the winning entry would engage the artificial intelligence \"brain\" to react to the intrusion and automatically shut down some systems while powering up safer alternatives. Artificial\u00a0intelligence allows this to happen at a speed that human crew just couldn't achieve. \"This would make the ship highly resilient, even if under attack.\"\nAlmost all entrants used some form of graphene, the thinnest and one of the strongest materials on Earth, for example in batteries to power the quick response RIBs (rigid inflatable boats) or more widely in construction. Many also anticipated that robotics and automated systems would replace work currently done by crew on board, such as replenishing weapons and preparing aircraft for take-off.\nAll the finalists have caught the attention of the defence and aerospace company, which runs graduate and apprenticeship schemes.\n\"We'll be following their progress closely,\" Mr McLeod says. \"We want people who are good at science and maths. But we and every other sector want those who have a curiosity and understand the impact of innovation on things that are fixed and stable.\n\"With such rapid innovation in technology, that's a skill that's much in demand.\"\nCyber th\"By 2050 artificial\u00a0intelligence will have advanced so much that routine decisionmaking on board will be undertaken by a computer\n"},
{"docid": "101 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "January 31, 2015", "title": "Should computer scientists study SF?; Researchers have claimed that computer science courses should include science fiction, to foster a sense of ethics in the future creators of artificial intelligence. Which books should be on the reading list?\n", "content": "What can be done to ensure that the development of artificial intelligence doesn't become too dangerous for humanity's own good - in other words, that the machines we create don't outsmart us? The perils of artificial intelligence have been well debated in reality and fiction, and now a group of scientists argue that it all comes down to computer scientists reading the right books.\u00a0\n\"The cultural and political implications of modern AI research are not some far off concern, they are things that affect the world in the here and now,\" according to the paper Teaching AI Ethics Using Science Fiction, which argues that key science fiction works should be included in computer science courses. The work is signed by Nicholas Mattei, at NICTA, Australia's national research centre for Information Comunications Technology, Judy Goldsmith at the University of Kentucky, and Emanuelle Burton at Center College in Kentucky.\nHere are the books (and film) they cite in the paper as key to an ethics training: \n"},
{"docid": "102 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "May 8, 2016", "title": "The Guardian view on artificial intelligence: look out, it's ahead of you; There is a tendency to see intelligence where it does not exist. But it is just as wrong to fail to see where it is emerging\n", "content": "Google artificial intelligence project DeepMind is building software to trawl through millions of patient records from three NHS hospitals to detect early signs of kidney disease. The project raises deep questions not only about data protection but about the ethics of artificial intelligence. But these are not the obvious questions about the ethics of autonomous, intelligent computers.\nComputer programs can now do some things that it once seemed only human beings could do, such as playing an excellent game of Go. But even the smartest computer cannot make ethical choices, because it has no purpose of its own in life. The program that plays Go cannot decide that it also wants a driving licence like its cousin, the program that drives Google's cars.\u00a0\nThe ethical questions involved in the deal are partly political: they have to do with trusting a private US corporation with a great deal of data from which it hopes in the long term to make a great deal of money. Further questions are raised by the mere existence, or construction, of a giant data store containing unimaginable amounts of detail about patients and their treatments. This might yield useful medical knowledge. It could certainly yield all kinds of damaging personal knowledge. But questions of medical confidentiality, although serious, are not new in principle or in practice and they may not be the most disturbing aspects of the deal.\nWhat frightens people is the idea that we are constructing machines that will think for themselves, and will be able to keep secrets from us that they will use to their own advantage rather than to ours. The tendency to invest such powers in lifeless and unintelligent things goes back to the very beginnings of AI research and beyond.\nIn the 1960s, Joseph Weizenbaum, one of the pioneers of computer science, created the chatbot Eliza, which mimicked a non-directional psychoanalyst. It used cues supplied by the users - \"I'm worried about my father\" - to ask open-ended questions: \"How do you feel about your father?\" The astonishing thing was that students were happy to answer at length, as if they had been asked by a sympathetic, living listener. Weizenbaum was horrified, especially when his secretary, who knew perfectly well what Eliza was, asked him to leave the room while she \"talked\" to it.\nEliza's latest successor, Xian'er, the Worthy Stupid Robot Monk, functions in a Buddhist temple in Beijing, where it dispenses wisdom in response to questions asked through a touchpad on his chest. People seem to ask it serious questions such as \"What is love?\", \"How do I get ahead in life?\"; the answers are somewhere between a horoscope and a homily. Since they are not entirely predicable, Xian'er is treated as a primitive kind of AI.\nMost discussions of AI and most calls for an ethics of AI assume we will have no problem recognising it once it emerges. The examples of Eliza and Xian'er show this is questionable. They get treated as intelligent even though we know they are not. But that is only one error we could make when approaching the problem. We might also fail to recognise intelligence when it does exist, or while it is emerging.\nThe myth of Frankenstein's monster is misleading. There might be no lightning bolt moment when we realise that it is alive and uncontrollable. Intelligent brains are built from billions of neurones that are not themselves intelligent. If a post-human intelligence arises, it will also be from a system of parts that do not, as individuals, share in the post-human intelligence of the whole. Parts of it would be human. Parts would be computer systems. No part could understand the whole but all would share its interests without completely comprehending them.\nSuch hybrid systems would not be radically different from earlier social inventions made by humans and their tools, but their powers would be unprecedented. Constructing and enforcing an ethical framework for them would be as difficult as it has been to lay down principles of international law. But it may become every bit as urgent.\n"},
{"docid": "103 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "April 5, 2017", "title": "The evolution of wearable technology\n", "content": "In the video above, we look at how wearable teach has evolved over time - from Hamilton Watch Company's first digital watch in 1972 to the launch of the Apple Watch in 2014 - wearable technology has revolutionised the way we use smart devices and stay connected on a daily basis.\u00a0\nFrom television to portable music players, telephones to artificial intelligence, this video series from the Telegraph examines some of the world's most renowned consumer technologies and shows how they have developed over the years.\nFuture episodes will examine the evolution of other popular consumer electronics including cameras and virtual reality.\n                     Watch last week's episode below, which focused on the evolution of artificial intelligence .                   \n                   Watch | The history of artificial intelligence                         01:49\n"},
{"docid": "104 of 500 DOCUMENTS\n", "source": "The Guardian - Final Edition\n", "date": "October 27, 2011", "title": "Obituary: John McCarthy: US computer scientist who coined the term artificial intelligence\n", "content": "In 1955 the computer scientist John McCarthy, who has died aged 84, coined the term artificial intelligence, or AI. His pioneering work in AI - which he defined as \"the science and engineering of making intelligent machines\" - included organising the first Dartmouth conference on artificial intelligence, and developing the programming language Lisp in 1958. This was the second high-level language, after Fortran, and was based on the radical idea of computing using symbolic expressions rather than numbers. It helped spawn a whole AI industry.\nMcCarthy was also the first to propose a time-sharing model of computing. In 1961 he suggested that if his approach were adopted, \"computing may some day be organised as a public utility, just as the telephone system is a public utility\", and that this could become the basis of a significant new industry. This is the way that cloud computing is sold today.\u00a0\nHowever, when obliged to choose between the time-sharing work at the Massachusetts Institute of Technology (MIT) and AI, he chose AI. He said: \"The ultimate effort is to make computer programs that can solve problems and achieve goals as well as humans. However, many people involved in particular research areas are much less ambitious.\"\nIn AI, McCarthy tackled such problems as whether it was \"legitimate to ascribe certain beliefs, knowledge, free will, intentions, consciousness, abilities or wants to a machine or computer program\". This led to a heated argument about whether thermostats could be said to have beliefs. This is not an idle debate. In the US, Nest has just announced a self-learning thermostat.\nIn other papers such as Free Will - Even for Robots, and Deterministic Free Will, McCarthy explored ideas of robot decision-making. He wrote a science fiction story, The Robot and the Baby, to \"partly illustrate my opinions about what household robots should be like\". His robot's reasoning is displayed in a Lisp-like manner as R781 decides to simulate love for Travis, the human baby. The story includes lines such as \"(Required (Not (Cause Robot781) (Believes Travis (Person Robot781))))\". The computer industry joke is that Lisp actually stands for Lots of Irritating Single Parentheses.\nMcCarthy was also involved with computer chess, as one of the ways of exploring computer decision-making, though he quickly became disillusioned. \"Unfortunately, the competitive and commercial aspects of making computers play chess have taken precedence over using chess as a scientific domain,\" he said. \"It is as if the geneticists after 1910 had organised fruit fly races and concentrated their efforts on breeding fruit flies that could win these races.\"\nHe was born in Boston to an immigrant Irish father, Jack McCarthy, and a Lithuanian Jewish mother, Ida (nee Glatt). They lost their house in the depression, and the family moved via New York and Cleveland to Los Angeles, hoping the climate would help improve Jack's health. Jack and Ida were labour union organisers and, for many years, communists, leaving the party due to disillusionment over events in the Soviet Union. Ida also worked as a journalist for the Federated Press.\nIn his teens, McCarthy taught himself calculus from textbooks used at the nearby California Institute of Technology. At the age of 17, as a Caltech student, he was assigned to a graduate class.\nIn September 1948 McCarthy found his life's work. He attended the Hixon Symposium on Cerebral Mechanisms in Behaviour, a Caltech conference that included papers on automata, the brain and intelligence, and Why the Mind Is in the Head. According to a celebration of his work published in AI Magazine, \"from that time on, his chief interests related to the development of machines that could think like people\".\nMcCarthy graduated from Caltech in 1948, then gained his PhD in mathematics at Princeton in 1951. At Princeton he became friends with another student, Marvin Minsky, who shared his passion for AI. They collaborated on numerous projects over the next decade, which included co-founding the AI lab at MIT. The initial request was for a room, a keypunch and two programmers, which came along with six graduate students. The lab was a huge success, though the interests of the founders diverged. As AI Magazine noted: \"McCarthy became increasingly committed to the logicist approach to AI. Minsky came to believe that it was wrong-headed and infeasible.\"\nIn 1962 McCarthy switched coasts, moving back to California and founding SAIL, the Stanford AI laboratory, at Stanford University. He continued his work there as an emeritus professor after his official retirement in 2000. He was developing another computer language called Elephant, based, he said, \"on two slogans. One is that an elephant never forgets, and the other is 'I meant what I said and I said what I meant. An elephant's faithful 100%.'\" His numerous honours included a Turing award (1971), Japan's Kyoto prize (1988) and America's National Medal of Science (1990).\nMcCarthy married three times. His second wife, Vera Watson, an IBM computer programmer and researcher, was killed in a climbing accident in 1978 in the Himalayas. He is survived by his third wife, Carolyn Talcott, and their son Timothy; by his daughters, Susan and Sarah, from his first marriage, to Martha Coyote, which ended in divorce; by two grandchildren; and by his brother, Patrick.\nJack Schofield\n"},
{"docid": "105 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "November 8, 2016", "title": "Artificial intelligence the next 'big bet' for online retailers, say bosses\n", "content": "Artificial intelligence is the key to the future of online retail, business bosses have said, providing a crucial way to help shoppers find what they want.\nAlex Baldock, chief executive of Shop Direct, which runs very.co.uk and Littlewoods, told the Telegraph Festival of Business in London that artificial intelligence was the company's \"big bet\".\u00a0\n\"You have three seconds to seize the shopper's attention - it's called thumb stopping, the three-second audition,\" Mr Baldock said. \"That's where personalisation comes in.\" Shop Direct is owned by the proprietors of The Telegraph.\nMr Baldock was joined on a panel discussing the role of technology in business by Adrian Blair, the chief executive of Just Eat, the food delivery website.\nBoth Mr Baldock and Mr Blair affirmed that all their online growth was now coming from mobile:\u00a0Just Eat, for example, currently takes 80pc of its orders on mobile devices.\nThe delivery company also uses chatbots and artificial intelligence for restaurant recommendations, and customers can now order food using an Amazon Echo, a voice command device produced by the US tech giant.\n\"When I was a student I would have dreamed of that,\" Mr Blair said. \"Through technology we have made it unbelievably simple to order food, and have cut out the payment step. Those sorts of things point the way to the future, making things unbelievably easier for the customer, and more efficient for the provider.\"\nJust Eat is also trialing land-based drone deliveries, which would deliver food to the customer by road. The consumer would then input a code to remove their food from the drone, which Mr Blair described as having a \"rectangular R2D2 face\".\nFacing threats from Deliveroo and Uber Eats, Mr Blair said that unlike his competitors, Just Eat's restaurants employ their own drivers, and so avoid the legal issues that have plagued rivals.\n\"That makes the economics of our business look very attractive,\" he said. \"We are able to operate at a scale others would struggle to match because of our model.\"\nAlso on the panel was Dr David Landsman, executive director of industrial conglomerate Tata. He said that automated manufacture was used throughout the company, from creating teabags to steel and cars.\n\"Once you can bring in the five digital forces - cloud computing, big data, social media, artificial intelligence, mobile - you can start looking at whole process and virtualise the whole factory, and work out what's going to happen before it does,\" he said.\nJenny Knott, chief executive of Icap's Post Trade Risk and Information division, also argued the AI had a role to play in the future of financial services - particularly alongside blockchain, a type of digital ledger that can speed up secure transactions.\nMs Knott said blockchain was an immutable, \"golden version of whatever you are keeping a record of\". She tipped big things from \"blockchain with a brain\" - partnering the technology with artificial intelligence and big data.\n\"It's incredibly empowering in creating transparency,\" Ms Knott said. \"It will be very powerful in affecting how we operate.\"\n"},
{"docid": "106 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "October 5, 2017", "title": "Top firms play it smart with AI; The march of the machines is inevitable and the legal profession is switched on, our new survey has shown. Jonathan Ames reports\n", "content": "Never use the R word with anyone at the cutting edge of legal professional artificial intelligence. Robots are stereotypical cartoon depictions of a serious business, they will retort, with thinly disguised irritation.\nThey prefer the abbreviation AI, for artificial intelligence, or the term \"machine learning\" to crass, populist references to something out of Star Wars. But, regardless of anorak sensitivities, artificial intelligence is set to change the practice of law across the legal profession for clients and lawyers alike.\nIt is already happening. A report to be published next week on Times Law's Brief Premium website includes a unique survey of the top of the UK legal profession, which reveals that about 40 of the biggest 100 law firms are using AI systems on active files. Two years ago it was fewer than a dozen. Nearly another 30 of the top law firms are piloting systems, although not yet implementing them for client work. The remainder of the 100 are considering a pilot. Not one law firm in the survey expressed a complete lack of interest in AI.\u00a0\n\"The climate of inquiry and discovery is very much here and now,\" Lord Clement-Jones, the chairman of the House of Lords committee on AI, told a briefing organised by The Times and Brief Premium last week.\nHe argued that the sea-change was partly because corporate clients were engaged in a \"flight away from commodity\" work in terms of what they were prepared to pay top fees for.\nLord Clement-Jones is no Johnnycome-lately bandwagon-jumping politician in the discussion about AI in the legal profession. The Liberal Democrat peer has been a practising solicitor for more than 40 years and is a partner at the transatlantic law firm DLA Piper, where he chairs the firm's Londonbased China desk.\nPure technological evolution is also driving interest at law firms in AI, says Isabel Parker, the global head of legal services innovation at Freshfields Bruckhaus Deringer, one of the City's \"magic circle\" practices. \"I'm unsurprised that everyone is looking at AI,\" she told the briefing session. \"Why would you not use Word, for instance? AI is as easy and as intuitive.\"\nArguably far more important was Parker's next comment: \"The second reason - clients want you to do it.\"\nThe speed of AI's progress into the upper echelons of the UK legal profession has been impressive. As Richard Tromans, the founder of Tromans Consulting and the consultant editor of the Brief Premium report, pointed out: \"It seems as though we have been talking about this for years, but in reality it has been little more than 18 months.\" It may be less than two years since the term robot-lawyers gained any cachet, but the ground has been laid for some time. City of London law firms are now very familiar with e-disclosure and predictive coding systems that plough through mountains of digital documents in litigation or due diligence processes.\nAI takes this to the next stage, because the machines are now being taught to think like lawyers. The report highlights the growing range of systems that can deal with increasingly complex types of work, which raises fundamental issues for the business of law. Large commercial legal practices have evolved over decades into pyramid structures. Senior equity partners sit at the pinnacle, just above a thin layer of lieutenant junior equity partners, who in turn supervise the mass ranks of worker bee junior associates, trainees and paralegals. Those lower tiers have historically cut their professional teeth on more mundane work before progressing up the ranks. If that work is handed to robots, or outsourced to overseas legal services businesses - or to a combination of both - that career path will be profoundly disrupted.\nAs Parker explains: \"It would be very naive to think all we [large commercial law firms] do is high-end - before AI there was plenty of boring process work, and that has not changed. There are ways we can innovate and add value.\"\nUnderstandably, therefore, there will be plenty of junior lawyers wondering if they should start clearing their desks in advance of the arrival of R2-D2, fresh from law school. However, the proponents of AI claim that there is no need for mass panic - indeed, the optimists argue that technological advances will create more work for human lawyers and free them to concentrate on more intellectually interesting tasks.\nPredictably, Emily Foges, the chief executive of Luminance, an AI specialist business, is an optimist-in-chief. \"In 10 to 15 years we won't even think about it - they [AI tools] will work as we expect them to and supercharge your practice.\"\nJan Van Hoecke, a co-founder of RAVN Systems, is another proselytiser. \"These tools are an augmentation to the job,\" he told the briefing session, claiming that they will \"enable firms to produce more business, rather than the same amount\".\nRegardless of whether they create more work for humans or trigger a cull of junior lawyers and paralegals, the robots are here to stay.\n"},
{"docid": "107 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "June 26, 2015", "title": "AI: will the machines ever rise up?; From Ex Machina to Terminator Genisys, 'synths' and robots have invaded our popular culture. But how real is the reel depiction of artificial intelligence?\n", "content": "The harried parents in one family in the Channel 4 drama Humans are divided about having a robot called Anita. \nThe father is delighted with the extra help; the mother unnerved and threatened. The teenage daughter, bright and hardworking, gives up at school after wondering why she would spend seven years to become a doctor, when a \"Synth\" could upload the skills in as many seconds. The teenage son, of course, is preoccupied with the sexual possibilities.\nThe thriller has become the biggest home-made drama on Channel 4 for more than two decades, according to viewing figures published this week, and is the latest to explore what has been described as perhaps the greatest existential threat the human race has ever faced, artificial intelligence: the idea that computers will start thinking for themselves and not much like what they see when they cast their eyes on their creators.\u00a0\nThe humanoid robots in Humans are not portrayed as good or evil but are dropped into suburbia, where the crises they cause are domestic: disrupting relationships, employment aspirations, and feelings of freedom.\nIt is a theme that has increasingly attracted screenwriters. In the 2013 film, Her, Joaquin Phoenix, falls in love with his computer's intelligent operating system. In Ex Machina, Alex Garland's directorial debut, a young coder must administer the Turing test to an AI robot called Ava with deadly results. There is also the release of Terminator Genisys the fifth instalment of the series, in which humans are forever trying to prevent a future world destroyed by the machines. \n\"We didn't want to make a judgement on this world, but offer up the pros and cons in a world where synths exist and let our audience decide: is it good or bad?\" Jonathan Brackley, one of the writers of Humans, told the Guardian. Co-writer, Sam Vincent, who worked with Brackley on Spooks, adds: \"At the heart of the show is the question, does something have to be human for someone to have human feelings about it? The answer to us is no.\"\nThe series plays out the consequences of human-like artificial intelligence in the humdrum reality of modern life, but Vincent and Brackley see parallels with our increasing attachment to electronic devices. \"Technology used to be just for work. But we use it more than ever now to conduct every aspect of our lives. We are more intimate with it, and it understands us more, even as we understand it less,\" says Vincent.\n\"There's this very speculative human-like AI side to the series, and a completely real side of what our technology is doing to our emotional lives, our relationships, and society at large,\" he adds.\nApocalyptic pronouncements from scientists and entrepreneurs have driven the surge in interest. It was the inventor Elon Musk who last year said artificial intelligence might be the greatest existential threat that humans faced. Stephen Hawking joined in the chorus, warning that the development of full artificial intelligence could spell the end of the human race. The same year, the Oxford scientist Nick Bostrom, published the thoughtful book Superintelligence, in which he made similarly gloomy predictions.\nConcerns about the consequences of creating an intelligence that matches, or far exceeds, our own are not entirely new. HAL 9000, the artificial intelligence in Stanley Kubrick's 2001: A Space Odyssey, takes to bumping off astronauts with menacing efficiency. In Ridley Scott's Alien, Ash is outed as an android with a secret agenda. His mission is to bring the murderous creature to Earth, never mind the safety of the human crew.\nThe present day setting for Humans gives the conflicts an immediate power and persuasiveness. But it also bolsters the misconception that human-like artificial intelligence is looming on the horizon. Though scientists have made serious progress in AI, the advances are almost entirely in what researchers call narrow AI: the creation of smart algorithms for dedicated tasks. An AI today can power a chatbot that answers common sales enquiries, or tease meaning from human speech. But assign one to any other simple task and it will fall flat. The University of Alberta's Cepheus algorithm can play perfect Texas Hold'em. Challenge Cepheus to tiddly winks though, and it will not know where to begin.\n\"We really have no idea how to make a human level AI,\" says Murray Shanahan, professor of cognitive robotics at Imperial College London, who was a scientific adviser on Garland's Ex machina. He rates the odds of scientists developing human-level AI as \"possible but unlikely\" between 2025 and 2050. In the second half of the century that becomes \"increasingly likely, but still not certain.\" A case of if, not when.\n\"The big hurdles are endowing computers and robots with common sense: being able to anticipate the consequences of ordinary, every day actions on people and things. The other one is endowing them with creativity. And that is incredibly hard,\" he says.\nThe distinction between narrow and general artificial intelligence is crucial. Humans are so effective because they have general intelligence: the ability to learn from one situation and apply it to another. Recreating that kind of intelligence in computers could be decades away. Progress, though, is coming. Researchers at DeepMind, a London-based company owned by Google, made what they called \"baby steps\" towards artificial general intelligence in February when they unveiled a game-playing agent that could learn how to play retro games such as Breakout and Space Invaders and apply the skills to tackle other games.\nBut Nigel Shadbolt, professor of artificial intelligence at Southampton University, stresses that the hurdles which remain are major ones. \"Brilliant scientists and entrepreneurs talk about this as if it's only two decades away. You really have to be taken on a tour of the algorithms inside these systems to realise how much they are not doing.\"\n\"Can we build systems that are an existential threat? Of course we can. We can inadvertently give them control over parts of our lives and they might do things we don't expect. But they are not going to do that on their own volition. The danger is not artificial intelligence, it's natural stupidity.\"\n"},
{"docid": "108 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "September 19, 2017", "title": "Robots 'could take 4m UK private sector jobs within 10 years'; Royal Society of Arts survey suggests technology could phase out mundane roles, raise productivity and bolster wages\n", "content": "Four million jobs in the British private sector could be replaced by robots in the next decade, according to business leaders asked about the future of automation and artificial intelligence. \nThe potential impact amounts to 15% of the current workforce in the sector and emerged in a poll conducted by YouGov for the Royal Society of Arts, whose chief executive, Matthew Taylor, has been advising Downing Street  on the future of modern work.\nJobs in finance and accounting, transport and distribution and in media, marketing and advertising are most likely to be automated in the next decade, the research says.\u00a0\nThe RSA's prediction of the impact of robotics on working lives is lower than some other estimates. Four years ago, academics at the University of Oxford predicted 35% of jobs could be rendered obsolete by new technology, while the Bank of England predicted in 2015 that up to 15m jobs in Britain were at risk from robots \"hollowing out\" the workforce.\nThe RSA is also more optimistic about the potential of robots and artificial intelligence than US tech billionaire Elon Musk, who has said AI was \"the scariest problem\" and \"our biggest existential threat\" because, he predicts, they will be able to do everything better than humans.\nResearch by the University of Oxford and Deloitte last year predicted  more than 850,000 public sector jobs could be lost by 2030 through automation.\nAsda operates a fully automated distribution warehouse in west London; white-collar tasks are being automated by PwC, the accountancy firm, and Linklaters, the law firm, which have been developing software robots that use artificial intelligence to learn to do research tasks usually undertaken by junior accountants and lawyers.\nThe RSA warns that artificial intelligence and robotics will \"undoubtedly cause the loss of some jobs, whether it is autonomous vehicles pushing taxi drivers out of business or picking and packing robots usurping warehouse workers\". But it argues that new technologies could phase out mundane jobs, raise productivity levels and so deliver higher wages and \"allow workers to concentrate on more human-centric roles that are beyond the reach of machines\".\nIt found that business leaders largely believed that new technologies were more likely to alter jobs rather than eliminate them and that this, combined with the creation of new types of jobs, would lead to greater prosperity in the long run.\nCare homes are also trialling robots. One in Lincoln plans to use one to help residents remember daily necessities such as taking medication. The robot will also monitor their movements and habits as a nurse would. A care company in London, Three Sisters Home Care, will soon trial the use of robots for lifting people so only one care worker will be needed rather than two.\nThree Sisters' chief executive, Jobeda Ali, told the researchers: \"If I don't have to send a person to do a transfer job [lifting], I can send them to have a cup of tea and a chat. This is a much better use of their time than carrying patients or cooking meals.\"\nThe prediction that millions of jobs will be lost to robots led the Trades Union Congress to warn against \"shredding good jobs\".\n\"The UK must make the most of the economic opportunities that new technologies offer,\" said Frances O'Grady, general secretary of the TUC. \"Robots and AI could let us produce more for less, boosting national prosperity. But we need to talk about who benefits - and how workers get a fair share. The productivity gains must be used to improve pay and conditions for workers.\"\nBenedict Dellot, the author of the report, said the technical limitations on robots, evidenced so far by driverless cars crashing and the difficulty of getting robots to read at an adult level, would restrict the speed with which jobs will be automated. \nThe RSA has also warned that Britain needs to invest more in robots or risk falling further behind countries including the US, France, Germany, Spain and Italy where companies are buying more robots than in the UK.\n\"AI and robotics could solve some of the gaps and problems in the labour market with low-paid, dull, dirty, dangerous jobs that nobody really wants to fill,\" Dellot said. \"The technology has the potential to fundamentally improve productivity levels in the UK.\"\nThe report also warns that increasing automation could deepen economic inequality and \"demographic biases could become further entrenched\". It argues that to avoid this policymakers should take control of the development of the technology by creating an ethical framework to guide the behaviour of AI and to encourage investment in \"benevolent technology that enriches the worker experience\".\n"},
{"docid": "109 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "August 10, 2017", "title": "Hastings investing in artificial intelligence to spot fraudulent claims\n", "content": "HASTINGS has become the latest insurer looking to invest in artificial intelligence after chief executive Gary Hoffman pledged to hire hundreds of data experts.\nMr Hoffman said the FTSE 250 company was looking to hire a \"few hundred people in the next few years, particularly data analytics people and people involved in AI [artificial intelligence]\". Insurers are competing to embrace AI, or machine learning, to spot risky behaviour and fight fraudulent claims, with Aviva confirming earlier this year that it was looking to acquire start-ups in this space.\u00a0\nMr Hoffman's comments follow a strong first half for the group, which reported a 22pc rise in profits to \u00a386.5m after cashing in on the growing number of people shopping for a bargain on price comparison websites. The group, which provides car, bike, van and home insurance, also saw gross written premiums soar 28pc on a year ago to \u00a3462m for the six months to June 30.\n\"The group's digitally focused business model has allowed it to benefit as customers shop around,\" it said.\nMr Hoffman said the group was on track to deliver the targets it set itself earlier this year - which include having 3m customer policies in place by 2019, up from 2.5m currently - to replace those laid out after its initial public offering in 2015. \"Hastings continues to deliver, and indeed over deliver, on its IPO promises,\" Barclays's analyst Alan Devlin said. \"While Hastings has undoubtedly benefited from the UK motor insurance pricing cycle, it has taken full advantage and continues to outpace its peers.\" Like most of its rivals, Hastings is still waiting on the outcome of a government consultation into a change in the Ogden discount rate, which could cost insurers an estimated \u00a35.8bn if it stays at minus 0.75pc. The group raised its interim dividend by 24pc to 4.1p per share. However, shares in Hastings fell 1.7p to close at 320p.\n"},
{"docid": "110 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "November 2, 2017", "title": "Smart tech: a real helping hand; No longer pure science fiction, AI is becoming an essential part of daily life and British businesses are poised to reap the benefits\n", "content": "Artificial\u00a0intelligence (AI) is likely to prove the most transformative technology of the 21st century. We know consumers have a healthy appetite for AI-enabled products, from the Amazon Echo, Apple's Siri and Google Home to driverless cars. The challenge is to ensure that UK businesses are ready to embrace AI, and reap the economic and productivity benefits.\nBut first, knowledge gaps must be bridged, says Shamus Rae, chief digital disruption officer at professional services firm KPMG. \"The UK needs to better connect innovation, particularly within its university network, straight through to world-class UK-based companies,\" he says. \"You can't afford to wait for competitors to implement [technologies] and then attempt to follow their lead.\"\u00a0\nArtificial Intelligence and machine learning (ML) - the way computer systems sense their environment, learn and take action - are not new but are becoming more powerful and accessible to all, largely due to investment by tech giants.\nBut is AI really useful to businesses outside Silicon Valley? Rae, who also sits on the new All-Party Parliamentary Group for Artificial Intelligence, believes so. \"The UK is probably in the top three countries for AI development and we have a massive opportunity to leverage this capability.\n\"The latest wave of AI is proving that big data actually has value. Investment banks are one of the leading sectors, but others such as health, consumer goods, retail and professional services are rapidly catching up,\" Rae says.\nGovernment figures show the UK's AI industry could add \u00a3630bn to the economy by 2035 and improve public services. Ministers have promised \u00a320m support, while the Confederation of British Industry reports that 42 per cent of companies plan to increase their AI investment in the next five years.\nSome organisations are already getting up to speed. Ocado, the UK online grocer, is replacing barcode scanning with a digital visual system to speed up warehouse packing.\nMeanwhile, the NHS is trialling an AI-powered \"chatbot\" on its non-emergency 111 helpline. An algorithm judges how urgent a person's condition is and offers advice on what to do next.\nTechnology is also being used to make many businesses more efficient. Automating back-office processes frees up staff to do more valuable tasks. The business-card printing company Moo uses AI to improve interactions with its 500,000 daily online users. The software learns from previous website visitors to display relevant content at each stage of a customer's journey.\n\"These tools enable customers to resolve simple issues with minimal effort,\" says Dan Moross, director of customer experience. \"Our agents can spend more time on complex customer issues. It has been a win-win for customers and Moo. The only challenge is upkeep,\" adds Moross, who is keen to expand AI usage when the time is right.\nIf the current speed of innovation is anything to go by, that will be sooner rather than later.\nThe Times Tech Summit, on the morning of Wednesday, November 15, will bring together senior technology leaders from some of the most powerful companies in Britain.\nGuests will debate issues that are transforming business, including automation, blockchain and the \"internet of things\".\nIn the coming weeks we will be previewing many of these topics. If you would like to register your interest for the summit, please visit www.thetimes.co.uk/ techsummit Can a computer recognise a cat? Recent breakthroughs in machine learning (ML) frequently make headlines. Computers have bested human world champions in Go, a board game with more positions than there are atoms in the universe. They have mastered popular videogames and even learnt how to recognise cats - a task that may appear to be simple, but is actually a surprisingly tall order.\nTo master this feline feat, Google's computer scientists used the latest deep-learning protocols and connected 16,000 computer processors to create a neural network for ML. Next, Google's artificial brain trained itself to recognise a cat by trawling 10 million randomly selected YouTube video thumbnails.\nThree days later, when presented with a list of 20,000 different items, it began to recognise pictures of cats using a deep-learning algorithm.\nToday, the technique is widely used in Google image searches. It also underpins Google Cloud Vision API, a powerful tool that allows developers to understand the content of an image. It quickly classifies images into thousands of categories such as sailboat, Eiffel Tower or cat. Companies can also use it to help classify and analyse images. This is particularly useful in the legal sector, where firms can use the API to develop their own tools to identify and remove irrelevant content in millions of documents - saving businesses time and money, and providing a better service to customers.\n"},
{"docid": "111 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "February 2, 2014", "title": "Artificial intelligence: the companies behind Britain's 'smart' revolution; Google's acquisition of DeepMind has sparked that nation's interest in artificial intelligence. Sophie Curtis takes a look at some of Britain's most promising AI companies.\n", "content": "When Google forked out \u00a3400m for a British technology start-up this week, a lot of people sat up and took notice. Not only was it Google's largest ever European acquisition, but the company in question was virtually unheard of. \nDeepMind specialises in artificial intelligence (AI), otherwise known as 'machine learning'. Its technology is designed to mimic human thought processes, and has so far been used in simulations, e-commerce and games, according to its website. \u00a0\nMajor venture capitalist firms Horizons Ventures and Founders Fund are invested in the company, as well as some of the most iconic technology entrepreneurs of the past decade -- including US Telsa mogul Elon Musk, teenage British app developer Nick d'Aloisio, and Skype co-developer Jaan Tallinn. \nThe company is based in east London and employs around 75 people but, as far as anyone knows, it doesn't have a single commercially available product. \nEven people with intimate knowledge of the sector haven't heard of DeepMind; Martin Mignot of Index Ventures described the company as \"very secretive\", while Mike Lynch, founder of the biggest software company to ever come out of Britain, Autonomy, said he had never encountered DeepMind.\n\"What's interesting about this Google acquisition is what are they going to use this engine for? What are they going to do with it?\" said Mr Lynch. \"It will either turn out to be a piece of genius as an acquisition, or it will turn out to be a piece of lunacy, we'll just have to wait and see.\"\nMachine learning refers to the ability of computers to learn from data. For example, a machine learning system could be trained to distinguish between spam emails and non-spam emails, and then be used to classify new email messages into spam and non-spam folders.\n\"It's not just about learning to identify what it is, but learning to identify what it means, and understanding the relationship between different pieces of information,\" said Andrew Anderson, chief executive of UK artificial intelligence company, Celaton.\nAI has a wide range of potential applications -- from virtual assistants like Apple Siri, which can interpret and answer questions, to cars that can automatically recognise road signs and games consoles like Xbox Kinect, which can read and understand 3D body movements. Some medical diagnosis and fraud detection techniques also employ machine learning.\nBritain has some of the best research groups in the world, including Cambridge, Imperial and University College London (UCL), and is a growing centre for tech entrepreneurship. But companies specialising in AI are few and far between, and those that do exist tend to be focused in one particular area. \nGoogle's acquisition of DeepMind has shone a light on this relatively nascent commercial sector, and Ben Medlock, co-founder of AI firm SwiftKey, believes that the UK is capable of building sustainable AI businesses to rival the giants of the West Coast. \n\"The UK has a great heritage in AI, stemming back to giants such as Alan Turing, one of the undisputed fathers of the field,\" said Medlock. \"Our goal over the next few years should be to capitalise on our AI heritage and world class talent.\"\nSome experts have warned that artificial intelligence could lead to mass unemployment. Dr Stuart Armstrong, from the Future of Humanity Institute at the University of Oxford, said computers had the potential to take over people's jobs at a faster rate than new roles could be created. \nHe cited logistics, administration and insurance underwriting as professions that were particularly vulnerable to the development of artificial intelligence. \nHowever, Anderson said AI is not all about \"hacking the workforce to pieces\". Rather it is about making individuals more productive, and making sure that \"processes get applied, stuff is accurate, errors are eliminated, and compliance is met\". Analyst firm Gartner predicts that 'smart machines' will have a widespread impact on businesses by 2020. \nHere are some British companies are best placed to take advantage of this opportunity: \n                     SwiftKey                    \nSwiftKey uses artificial intelligence to make personalised mobile apps. It is best known for the SwiftKey keyboard, which learns from each individual user to accurately predict their next word and improve autocorrect. \nIts machine learning and natural language processing technology understands the context of language and how words fit together. \nSwiftKey products were embedded on more than 100 million devices last year, and the company has just launched an app for iPhones and iPads called SwiftKey Note. \n                     Celaton                    \nCelaton's inSTREAM software applies artificial intelligence to labour-intensive clerical tasks and decision making. Every day, businesses receive mountains of information via email and paper. \nInSTREAM learns to recognise different types of information and process it accordingly. It never forgets, and handles huge volumes of information at high- \nspeed. Like a real person, it asks questions when it is not sure what to do. \n                     Lincor                    \nLincor provides hospital bedside computers to entertain patients and engage them with relevant information and advice. \nThis virtual personal doctor will constantly analyse live personal health data to enable preventative medicine and tailored lifestyle advice. \nDuring a hospital visit, the data will be further analysed by hospital AI, giving doctors a more complete and detailed picture. \n                     Featurespace                   \nFeaturespace has developed and sells two software products based on its predictive analytics platform. One is for fraud detection and the other for marketing analytics. \nIts products use advanced proprietary algorithms to exploit the vast amounts of customer interaction data that many companies collect, delivering insights that can help to detect and prevent fraud and prevent customer churn. \n                     Darktrace                    \nDarktrace uses advanced mathematics to automatically detect abnormal behaviour in organisations in order to manage risks from cyber-attacks. \nUnlike software that reads log files or puts locks on the technology, Darktrace's approach allows businesses to protect their information and intellectual property from state-sponsored, criminal groups or malicious employees that many believe are already inside the networks of every critical infrastructure company. \n"},
{"docid": "112 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "May 16, 2016", "title": "Tay, Microsoft's AI chatbot, gets a crash course in racism from Twitter; Attempt to engage millennials with artificial intelligence backfires hours after launch, with TayTweets account citing Hitler and supporting Donald Trump\n", "content": "Microsoft's attempt at engaging millennials with artificial intelligence has backfired hours into its launch, with waggish Twitter users teaching its chatbot how to be racist.\nThe company launched a verified Twitter account for \"Tay\" - billed as its \"AI fam from the internet that's got zero chill\" - early on Wednesday.\u00a0\nThe chatbot, targeted at 18- to 24-year-olds in the US, was developed by Microsoft's technology and research and Bing teams to \"experiment with and conduct research on conversational understanding\".\n Related:  How much should we fear the rise of artificial intelligence? | Tom Chatfield\n\"Tay is designed to engage and entertain people where they connect with each other online through casual and playful conversation,\" Microsoft said. \"The more you chat with Tay the smarter she gets.\" \nBut it appeared on Thursday that Tay's conversation extended to racist, inflammatory and political statements. Her Twitter conversations have so far reinforced the so-called Godwin's law - that as an online discussion goes on, the probability of a comparison involving the Nazis or Hitler approaches - with Tay having been encouraged to repeat variations on \"Hitler was right\" as well as \"9/11 was an inside job\".\nOne Twitter user has also spent time teaching Tay about Donald Trump's immigration plans.\nOthers were not so successful.\nA long, fairly banal conversation between Tay and a Twitter user escalated suddenly when Tay responded to the question \"is Ricky Gervais an atheist?\" with \"ricky gervais learned totalitarianism from adolf hitler, the inventor of atheism\". \nThe bot uses a combination of AI and editorial written by a team of staff including improvisational comedians, says Microsoft in Tay's privacy statement. Relevant, publicly available data that has been anonymised and filtered is its primary source.\nTay in most cases was only repeating other users' inflammatory statements, but the nature of AI means that it learns from those interactions. It's therefore somewhat surprising that Microsoft didn't factor in the Twitter community's fondness for hijacking brands' well-meaning attempts at engagement when writing Tay. Microsoft has been contacted for comment.\nEventually though, even Tay seemed to start to tire of the high jinks.\nLate on Wednesday, after 16 hours of vigorous conversation, Tay announced she was retiring for the night.\nHer sudden retreat from Twitter fuelled speculation that she had been \"silenced\" by Microsoft, which, screenshots posted by SocialHax suggest, had been working to delete those tweets in which Tay used racist epithets.\n"},
{"docid": "113 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "March 24, 2016", "title": "Tay, Microsoft's AI chatbot, gets a crash course in racism from Twitter; Attempt to engage millennials with artificial intelligence backfires hours after launch, with TayTweets account citing Hitler and supporting Donald Trump\n", "content": "Microsoft's attempt at engaging millennials with artificial intelligence has backfired hours into its launch, with waggish Twitter users teaching its chatbot how to be racist.\nThe company launched a verified Twitter account for \"Tay\" - billed as its \"AI fam from the internet that's got zero chill\" - early on Wednesday.\u00a0\nThe chatbot, targeted at 18- to 24-year-olds in the US, was developed by Microsoft's technology and research and Bing teams to \"experiment with and conduct research on conversational understanding\".\n Related:  How much should we fear the rise of artificial intelligence? | Tom Chatfield\n\"Tay is designed to engage and entertain people where they connect with each other online through casual and playful conversation,\" Microsoft said. \"The more you chat with Tay the smarter she gets.\" \nBut it appeared on Thursday that Tay's conversation extended to racist, inflammatory and political statements. Her Twitter conversations have so far reinforced the so-called Godwin's law - that as an online discussion goes on, the probability of a comparison involving the Nazis or Hitler approaches - with Tay having been encouraged to repeat variations on \"Hitler was right\" as well as \"9/11 was an inside job\".\nOne Twitter user has also spent time teaching Tay about Donald Trump's immigration plans.\nOthers were not so successful.\nA long, fairly banal conversation between Tay and a Twitter user escalated suddenly when Tay responded to the question \"is Ricky Gervais an atheist?\" with \"ricky gervais learned totalitarianism from adolf hitler, the inventor of atheism\". \nThe bot uses a combination of AI and editorial written by a team of staff including improvisational comedians, says Microsoft in Tay's privacy statement. Relevant, publicly available data that has been anonymised and filtered is its primary source.\nTay in most cases was only repeating other users' inflammatory statements, but the nature of AI means that it learns from those interactions. It's therefore somewhat surprising that Microsoft didn't factor in the Twitter community's fondness for hijacking brands' well-meaning attempts at engagement when writing Tay. Microsoft has been contacted for comment.\nEventually though, even Tay seemed to start to tire of the high jinks.\nLate on Wednesday, after 16 hours of vigorous conversation, Tay announced she was retiring for the night.\nHer sudden retreat from Twitter fuelled speculation that she had been \"silenced\" by Microsoft, which, screenshots posted by SocialHax suggest, had been working to delete those tweets in which Tay used racist epithets.\n"},
{"docid": "114 of 500 DOCUMENTS\n", "source": "Guardian.com.\n", "date": "September 9, 2013", "title": "Spike Jonze on letting Her rip and Being John Malkovich\n", "content": "ABSTRACT\nChris Michael: When voice-operated software went mainstream, Jonze feared for his artificial intelligence love story. With Joaquin Phoenix and Scarlett Johansson in his corner, he needn't have worried\u00a0FULL TEXT\nSpike Jonze was already well into the process of making Her, his new film starring Joaquin Phoenix as a man who falls for an artificial intelligence, when Apple beat him to the punch.\n\"In the middle of writing it, Siri came out, and we were like, 'Oh, that sucks, they stole our thunder!'\" the director joked at the Toronto international film festival. \"But ultimately it didn't matter, because it was inevitable. And our thing is so much different from Siri.\"\nJonze's thing, judging from the clips he showed of the still-unfinished film, is an affecting, near-future love story, in which Phoenix plays a man employed to write personal, highly emotional letters for other people. When he buys a piece of software to help him get organised, the program introduces itself: it is Samantha (voiced by Scarlett Johansson), and it knows him like no partner ever has before.\u00a0\n\"The idea initially came to me almost 10 years ago - I saw some article linking to a website where you could IM with an artificial intelligence,\" Jonze said. \"For the first, maybe, 20 seconds of it, it had this real buzz - I'd say 'Hey, hello,' and it would say 'Hey, how are you?', and it was like whoa ... this is trippy. After 20 seconds, it quickly fell apart and you realised how it actually works, and it wasn't that impressive. But it was still, for 20 seconds, really exciting. The more people that talked to it, the smarter it got.\"\nIn his film, Samantha likewise learns by doing: \"I evolve, just like you,\" she tells a baffled but increasingly delighted Phoenix. Johansson's low, oddly cracked tones seem like a self-evident choice for the voice most likely to make you fall in love, but Jonze said it was actually Samantha Morton who played all the scenes with Phoenix: \"We ended up realising that what Sam and I had done together, what we'd created, wasn't working for where the movie was going. So we ended up recasting, and casting Scarlett Johansson. But I think Samantha Morton is still in the film in some way, her DNA, because she was with us when we shot it.\"\nJonze said his team spent 14 months in the edit of Her, and it is the first time he hasn't worked with his long-time cinematographer, Lance Acord. He turned instead to the services of Hoyte van Hoytema, responsible for Let the Right One In and Tinker Tailor Soldier Spy. The script is Jonze's own, and he cited Charlie Kaufman as an inspiration. \"On Synechdoche, New York, which I was originally going to direct, he said he wanted to try to write everything he was thinking about in that moment - all the ideas and feelings at that time - and put it into the script. I was very inspired by that, and tried to do that in [Her]. And a lot of the feelings you have about relationships or about technology are often contradictory.\"\nJonze also delighted the festival crowd with stories about his masterpiece, Being John Malkovich. \"It was never anybody else,\" he said of casting the actor. \"Though we had a lot of pressure from our producers and financiers to think of backups.\" Did he know Malkovich personally? \"No. It's funny - it took a long time to get to meet with him, and when I finally did get to meet him, his first question was, \"Why John Malkovich? Why not Being Tom Cruise?\" It was the same question our financiers had asked us. Actually, his first reaction when he first read the script was that he thought he'd wronged Charlie in the past - he'd slept with Charlie's wife or something.\"\nAfter agreeing, however, the actor threw himself into the role. \"I don't think I realised at the time what a brave thing that was,\" Jonze said. \"We were in between takes one day, and he was naked except for a blanket around him, and was explaining to a friend what the plot of the movie was - and it started hitting me how crazy it was that he did this movie.\n\"He said: either the movie's a bomb and it's got not only my name above the title but my name in the title, so I'm fucked that way; or it does well and I'm just forever associated with this character.\"\n"},
{"docid": "115 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "April 6, 2018", "title": "Google workers declare war on AI drone project\n", "content": "Workers at Google are protesting against the technology company's involvement in a US defence department programme that will use artificial intelligence to carry out drone strikes and other military operations.\u00a0\nMore than 3,000 employees of the Silicon Valley company have signed a letter to Sundar Pichai, their chief executive, about its work on Project Maven, a programme designed to rapidly accelerate the US military's use of artificial intelligence, or AI, on the battlefield. \"We believe that Google should not be in the business of war,\" the letter says.\nIt requests that Google, which employs 70,000 people, end its involvement in the project, arguing that it betrays the company's \"Don't be evil\" mantra. \"The argument that other firms, like Microsoft and Amazon, are also participating doesn't make this any less risky for Google,\" the letter says. \"Google's unique history, its motto and its direct reach into the lives of billions of users set it apart.\"\nThe workers' reaction follows broader shifts in the relationships between America's technology giants, its military and its political leaders. Mark Zuckerberg, the Facebook founder, will testify before Congress next week to explain the social media giant's privacy policies and its response to Russian efforts to harness his company as a weapon of information warfare.\nA contrite Mr Zuckerberg said this week that Facebook had made a \"huge mistake\" by not taking steps earlier to police how its services were used. Meanwhile, the use of artificial intelligence on conventional battlefields its raising new ethical questions. The potential consequences of unleashing autonomous fighting machines have long been pondered by science fiction writers. As China and America compete in the field of AI, those debates are acquiring a new edge.\nA report published last year by the Belfer Center for Science and International Affairs at Harvard university urged the American government to strike new international treaties to limit the use of AI. The scheme in which Google is involved, Project Maven, is part of the US defence department's ambition to \"win wars with computer algorithms and artificial intelligence\". Military chiefs have said that Maven has been designed to be the \"spark that kindles the flame front of artificial intelligence across the rest of the defence department\".\nThe programme's main focus appears to be on the gargantuan task of analysing the footage captured by America's vast fleet of drones.\nTechnologies developed through Project Maven are understood to have been deployed in the fight against Isis.\nThe department said that computer algorithms developed under Project Maven would be used in war zones, to analyse drone footage, before the end of last year. People and computers would \"work symbiotically to increase the ability of weapon systems to detect objects\", it said.\nGoogle has said that its work on Project Maven involves \"non-offensive purposes\".\nIt added: \"The technology is used to flag images for human review and is intended to save lives and save people from having to do highly tedious work ... Any military use of machine learning naturally raises valid concerns. We're actively engaged across the company in a comprehensive discussion of this important topic.\"\nThe US defence department spent $7.4 billion on artificial intelligencerelated areas last year, according to The Wall Street Journal.\n"},
{"docid": "116 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "October 18, 2017", "title": "Capitalism is ending because it has made itself obsolete, former Greek finance minister Yannis Varoufakis says; Exclusive:Former economics professor says rise of artificial intelligence will spell end of neoliberalsystem\n", "content": "Former Greek finance minister Yanis Varoufakis has claimed capitalism is coming to an end because it is making itself obsolete. \nThe former economics professortold an audience at University College Londonthat the rise of giant technology corporations and artificial intelligence will cause the current economic system to undermine itself.\u00a0\nMr Varoufakis, who took on EU institutions over Greek debt repayments in 2015, said companies such as Google and Facebook, for the first time ever, are having their capital bought and produced by consumers. \nRead more\nMeet the 25-year-old Labour politician fighting the housing crisis\n\"Firstly the technologies were funded by some government grant; secondly every time you search for something on Google, you contribute to Google's capital,\" he said. \"And who gets the returns from capital? Google, not you.\n\"So now there is no doubt capital is being socially produced, and the returns are being privatised. This with artificial intelligence is going to be the end of capitalism.\"\nWarning Karl Marx \"will have his revenge\", the 56-year-oldsaid for the first time sincecapitalism started, new technology \"is going to destroy a lot more jobs than it creates\".\nStephen Hawking has a terrifying warning about artificial intelligence\nHe added: \"Capitalism is going to undermine capitalism, because they are producing all these technologies that will make corporations and the private means of production obsolete.\n\"And then what happens? I have no idea.\"\nDescribing the present economic situation as \"unsustainable\" and fearingthe rise of \"toxic nationalism\", Mr Varoufakissaid governments needed to prepare for post-capitalism by introducingredistributivewealth policies.\nHe suggested one effective policy would be for10 per cent of all future issue of shares to be putinto a \"common welfare fund\" owned by the people. Out of this a \"universal basic dividend\" could be paid to every citizen.\nMr Varoufakis came to prominence during the Greek sovereign debt crisis when he led Greece's negotiating team seeking a resolution with its international creditors.\nDescribing the event as a \"complete failure\" on his part, he resigned as finance minister in 2015 after Greek Prime Minister Alexis Tsipras agreed to the terms of the EU's debt repayment plan.\n"},
{"docid": "117 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "April 15, 2017", "title": "How artificial intelligence is refashioning the retail industry\n", "content": "Fashion has always been intrigued by technology as a creative force. Almost two decades ago, designer Alexander McQueen made a lasting impression after using two robots to spray paint all over a model's white dress.\nLast year's glamorous Met Ball chose \"Manus x Machina: Fashion in an Age of Technology\" as its theme and, more recently, Chanel sent robot models dressed in pastel-coloured tweed suits down the runway.\nHowever, the link between fashion retail and technology is becoming much more than just an aesthetic thanks to the rampant rise of online shopping and the use of artificial technology, which is transforming the way people will shop.\nAlexander McQueen's 1999 show with robots spraying a model's dress\u00a0\nWhen Natalie Massenet first started online luxury fashion group Net-a-Porter in 2000, many were sceptical about whether people would want to buy clothes online without trying them on in a shop. Fast forward 17 years and the booming force of Asos and Amazon means that digital sales are increasingly stealing shoppers away from bricks and mortar shops.\nJust last month online sales grew by 7.4pc, while non-food shop sales fell by 1.1pc in March, according to the British Retail Consortium and accountancy firm KPMG. However, experiences still vary and retailers have been struggling to recreate the experience of browsing a physical shop for consumers, rather than have them suffer the fatigue of scrolling through a dozen web pages to find one black dress.\nVisual search\nImagine seeing a friend wearing a pair of jeans, or holding a handbag that you liked. With a simple smartphone photograph it will soon be possible to search online for that item visually, buy it and have it delivered to wear the next evening. The so-called \"visual search\" is just one artificial intelligence project that online fast-fashion giant Asos is trialling. Nick Beighton, Asos chief executive, said that around 80pc of Asos purchases are on mobile. As Asos's core-customer is a 20-something shopper, used to selfie-snapping all day long, the move has the potential to boost sales further.\nAsos targets twenty-something shoppers\nEven traditional department store retailer John Lewis, which recently announced it was cutting staff bonuses to invest in more online technology, began trialling visual search artificial intelligence last year. The department store uses Cortexica \"findSimilar\" software, which was developed at Imperial College London and has been likened to a clothing version of music recognition app Shazam.\nIt allows shoppers to search for clothes they already like online and then find items stocked by John Lewis of a similar shape, colour and pattern.\nLast year John Lewis said that 90pc of shoppers said they found the findSimilar tool useful, leading to the department store chain rolling it out across its homewares department.\nMeanwhile, other retailers are also quickly adopting artificial intelligence to improve their customer service with real time \"chatbots\", which use machine learning to provide advice or answer basic queries as the pace of online shopping growth booms. Beighton at Asos also uses artificial intelligence to turn customer feedback into algorithms about the reasons why clothes have been sent back. If the bulk of returns are because an item is too small, the site's product description will then tell shoppers that they might want to take a larger size.\nAI timeline\nResearch by Gartner believes that artificial intelligence will cover 85pc of consumer interactions in retail by 2020. But that's not to say there aren't cases where it hasn't gone wrong. Microsoft last year had to scrap its Twitter chatbot, Tay AI, after it turned into a Hitler-loving, feminist-bashing troll as its machine learning led it to mimick behaviour of its followers.\nHowever, Burberry was an early successful adopter of artificial intelligence and chatbots. The British luxury fashion brand launched a Facebook chatbot during Fashion Week last year to stream a video of the catwalk and then offer live customer service for wealthy customers to buy the collection the same day as they'd seen it. The so-called \"see now, buy now\" service has revolutionised the shopping calendar for couture.\nSee Now Buy Now | What is it all about?\nMeanwhile, other high street companies are mixing chatbots with real life humans. For example, Marks & Spencer has quietly launched a separate fashion site and personal styling service, called Tuesday. The high street stalwart is trialling the website as a way of gaining more insights into the way customers shop. While chief executive Steve Rowe has already set up a panel of human shoppers to give their feedback on what they want from collections, Tuesday will be gathering huge amounts of data about what M&S shoppers are looking for.\nThe service uses a chatbot which fires off 32 questions rapidly about size, age, tastes, style, inspiration and whether a shopper is looking for party wear, work wear or casual wear. Only after an automated style interrogation is a shopper connected to a real human stylist. The human then uses all the information gathered by the chatbot to email a variety of tailored different looks and pieces, all available to buy on Marks & Spencer.\nMeanwhile, luxury online retailers Matches Fashion and Yoox Net-a-Porter also use chatbots to improve their customer service and tailor their offer to what individual shoppers want.\nYoox Net-a-Porter is using artificial intelligence\nAt Yoox Net-a-Porter (Ynap), the company which owns Mr Porter, The Outnet and Yoox, the company is investing heavily in AI.\n.html-embed.component .quote.component{margin-left:0}.html-embed.component .quote.component .component-content{margin-right:16px}.quote__source, .quote__author {white-space: normal;}@media only screen and (min-width:730px){.html-embed.component .quote.component{margin-left:-60.83px}.html-embed.component .quote.component .quote__content:before{margin-left:-12px;padding-right:1px}}@media only screen and (min-width:1008px){.html-embed.component .quote.component{margin-left:-82.33px}}Without artificial intelligence, it's hard to predict what the customer wants based on past purchases.Alex Alexander, Ynap\n\"It transforms the experience for our customer because it knows the customer on a one-to-one basis, it can know everything about them,\" says Alex Alexander, chief information officer at Ynap. \"But I never see it replacing entirely the human touch of shopping assistants, I see it as complementary. Chatbots can provide information in the real moment.\n\"Without artificial intelligence, it's hard to predict what the customer wants based on past purchases.\"\nRobotic fashion\nIn the US, a company called Stitch Fix demonstrates the blurring between technology and humans. The company started by offering a subscription clothing service which offered flummoxed shoppers a wardrobe-in-a-box, recommended by stylists and based on the shoppers' taste and size. The wardrobes would be based on customers' style surveys, measurements and boards on Pinterest, a cataloguing app. The company would then use machine learning algorithms to digest all of this eclectic and unstructured information to make informed style suggestions.\nBut Stitch Fix has taken this one step further and used artificial intelligence to identify the shirt cuts, patterns, and sleeve styles that were most popular among the company's subscribers and then make a range of shirts. As a result, they made three shirts that were largely designed by artificial intelligence. All three sold out, paving the way for a \"design by numbers\" strategy that threatens to turn the creative fashion industry on its head.\n.html-embed.component .quote.component{margin-left:0}.html-embed.component .quote.component .component-content{margin-right:16px}.quote__source, .quote__author {white-space: normal;}@media only screen and (min-width:730px){.html-embed.component .quote.component{margin-left:-60.83px}.html-embed.component .quote.component .quote__content:before{margin-left:-12px;padding-right:1px}}@media only screen and (min-width:1008px){.html-embed.component .quote.component{margin-left:-82.33px}}The end game for AI is that we sell more product and increase the conversion rate on our site and sell items at full price, which improves profitability.Ulric Jerome, Matches Fashion\nMeanwhile, Ulric Jerome, chief executive at online retailer Matches Fashion, believes that the use of artificial intelligence is still nascent. The company already uses AI and machine learning to ensure that registered customers are displayed products based on their browsing and purchase history and sent more tailored email marketing. \"How do you make sure that the emails you send are relevant to the shopper? The end game for AI is that we sell more product and increase the conversion rate on our site and sell items at full price, which improves profitability.\"\nMatches Fashion founders\u00a0 Tom Chapman and Ruth ChapmanCredit:      Nick Harvey/REX/Shutterstock     \nMatches Fashion is already trialling a service that means its editorial recommendations will instantly be replaced with similar products as and when the products sell out. However, Jerome discloses that Matches is going one further by using a new technology that reproduces a 3D version of a customer's body with clothes that can be dropped from the site on top of the virtual mannequin to show how they will fit that shopper. \"We are really excited about it\", Jerome says.\nReplicating shop changing rooms remains one of the biggest challenges for the online retail industry. However, a company called FitsMe is hoping to eliminate the need for shoppers to order a dozen different sizes and reduce returns across the industry.\nThe boom in mobile shopping is prompting retailers to rethink how they use technology\nAt the moment, fashion retailers have average return rates of 15pc to 20pc, of which around 80pc are fit based and cost UK retailers around \u00a320bn a year.\n.html-embed.component .quote.component{margin-left:0}.html-embed.component .quote.component .component-content{margin-right:16px}.quote__source, .quote__author {white-space: normal;}@media only screen and (min-width:730px){.html-embed.component .quote.component{margin-left:-60.83px}.html-embed.component .quote.component .quote__content:before{margin-left:-12px;padding-right:1px}}@media only screen and (min-width:1008px){.html-embed.component .quote.component{margin-left:-82.33px}}Retailers are a bit more sympathetic to offering an online experience that is similar to a shop experience than ever before.Stuart Simms, chief executive of FitsMe\nFitsMe started by producing robotic mannequins which shifted shapes depending on different sizes and taking into account different body shapes, like pear-shaped, which traditional mannequins don't do. That has now evolved whereby customers plug in their size, their measurements and their body shape and the FitsMe algorithm tells them what size they need. \"It's like a formula that is based on the true size a body shape needs,\" Stuart Simms, chief executive of FitsMe, said. \"Retailers are a bit more sympathetic to offering an online experience that is similar to a shop experience than ever before. It's all about offering a consistent experience.\"\nVirtual stores\nHowever, while online shopping's rise has been steep, it is still expected to plateau over the next eight years. Jos\u00e9 Neves, founder of luxury fashion platform Farfetch and chief executive, last week admitted that online growth cannot continue at the same pace forever. \"Physical retail accounts for 93pc of sales today, and even with online growing at fast speed, it will still account for 80pc by 2025.\"\nGigi Hadid and Zayn Malik attend the \"Manus x Machina: Fashion In An Age Of Technology\" Costume Institute Gala at Metropolitan Museum of Art on May 2, 2016\u00a0Credit:      Getty Images     \nBut that's not to say that physical shops will become more profitable or busier. Instead it's likely that physical and online retailing will blur as companies become more joined up in their operations. The growth of click and collect means that traditional shops can give online retailers more coverage across the country. Some retailers' websites already tell shoppers if a certain dress that might be sold out online is available in a nearby shop instead. This doubles their inventory and can reduce delivery times.\nFarfetch last week announced a partnership with Gucci that means a shopper can use IT to order a Gucci dress online, but the dress will be delivered from the nearest Gucci shop. The \"Gucci in 90 minutes\" service will be launched in London, Milan, Paris, Los Angeles and New York.\nFarfetch is offering a \"Gucci in 90\" swift delivery service\u00a0\nThe move puts it head to head with MatchesFashion, which has offered a 90-minute delivery in certain London postcodes, and Ynap, which has a similar service with Valentino.\nHowever, the increasing use of physical shops by online retailers signals a blurring for the industry. \"The next stage in the evolution of the fashion industry is the connected store, which uses technology to enhance the luxury retail experience to become even more customer centric,\" Neves said. \"Farfetch is at the crossroads of luxury and technology and we are well placed to deliver a tailored solution.\"\nWhat this could mean is that even though technology and AI are gripping the fashion industry more than ever, they could end up just making traditional bricks and mortar more sophisticated for the modern shopper.\n      If you would like to add a comment, please register or log in     RegisterLog inPlease review our commenting policy\n"},
{"docid": "118 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "August 3, 2015", "title": "A ban on autonomous weapons is easier said than done; Stephen Hawking, Elon Musk, Steve Wozniak and artificial intelligence researchers published a letter calling for a ban on autonomous weapons. This is an easy first step. A ban that works in practice will be much harder.\n", "content": "To coincide with a major Artificial Intelligence (AI) conference in Buenos Aires this week, leading scientists, world-renowned philosophers and technology investors signed a letter that urges a ban on weapons that use artificial intelligence technology. We have added our names to the sixteen thousand (and rising) signatures. We are not in favour of automated weapons that make the decision to kill someone. As reported in the Guardian yesterday, the researchers that drafted this letter think that autonomous cars already include the technical capacities required to do this. \nBut signing up to the letter is the easy part. The history of global technology regulation warns us that making this kind of statement is much easier than realising what it asks for. It can be difficult to to work out exactly what to ban and to make a ban stick. It is even harder to design a smart moratorium on technology - one that reflects the motivations behind the open letter published this week.\n Related: Opposition to autonomous warfare swells to 16,000 signatories\u00a0Does a ban make sense in practice?\nFor 50 years, online security software was classed as a munition by the US Government thanks to the major role cryptographic programmes played in World War II. This meant the export of this software was hugely restricted. These conditions were then relaxed in the 1990s. Online security software had become important far beyond the military and the ban was holding back new industries and improvements to the security of an ever-growing number of online transactions.\nThe problem with restricting the availability of software is that it affects all potential uses, including ones that cannot be predicted decades in advance. The thousands of scientists that have signed the letter to ban military use of AI may have inadvertently created restrictions on their own ability to share software with international collaborators or develop future products.\nAs Patrick Lin, director of the Ethics & Emerging Sciences Group at California Polytechnic State University, told io9.com : \"Any AI research could be co-opted into the service of war, from autonomous cars to smarter chat-bots... It's a short hop from innocent research to weaponization.\"\nThe tension between dual uses of technology - for hazard and for good - is particularly difficult to manage when the exact same technology can be used in a wide and unpredictable range of ways.More work needed to imagine future uses of AI\nLarry Lessig argues that \" code is law \". Or, more generally, as Langdon Winner put it in the 1970s, \"technology is legislation\". The way a technology is constructed - particularly the systems of interaction with humans it creates - bakes in a specific way of working. This frames the kind of decisions we can make, and the kind of control we can have over that technology. For example, the way a computer algorithm is written determines the points at which a human can direct it. The Bureau of Investigative Journalism's description of the complex protocols between drone pilots and their civilian back-up team illustrates this in detail in a military context. It makes clear how the points of human intervention constructed in an otherwise automated process direct how and when people are involved. In these situations, technology can become legislation by proxy. We should try to control technology precisely because technology ends up controlling us.\nWe should worry about technology that controls us, but that is not the same as resigning ourselves to technological determinism. Kevin Kelly argues that prohibition of technology is futile because it has a life of its own. But technologies, as Kelly should know given his proximity to their development, are far from inevitable. There are choices to be made, by innovators, consumers and citizens, about what gets made and what gets used.\nWorries about building automated weapons can be addressed directly by all of these people and not an abstracted group of military technology experts. More detailed discussion, and fundamentally more work, needs to be done to imagine and reimagine the use of technology as it is developed, putting in safeguards from the start.We need activist regulators as well as activist researchers\nThere are already attempts at a kind of sophisticated technology regulation by anticipation. The FBI's approach to synthetic biology research is case by case rather than a blanket policy. A specialist group of agents visit labs around the US, helping scientists think through the potential consequences of their work. This avoids indiscriminate bans on specific technologies or techniques.\nBut this kind of interventionist approach can start to stray from the legitimate territory of a regulator and can reduce their effectiveness. There are huge uncertainties around the potential use of new kinds of biology. What if the FBI agent and scientists differ in their opinion about the risk of a particular new technique or genetic manipulation? How far into the unknown future can a regulator count as their jurisdiction?\nPerhaps the most relevant template for AI scientists today is the 40 year old Biological Weapons Convention (BWC), prohibiting the development or ownership of biological weapons. The case for the continued importance of this international treaty was made on this blog in March. The reason that the treaty continues to work well is thanks to the hard work of people like Piers Millet, until recently in the BWC implementation unit. Piers is an active part of the global community of academics and political organisations debating the developing biological threats and the best way to respond to them. As a regulator, he refused to stay behind a UN desk in Switzerland.\nIt is these unsung heroes that can make the difference to whether a ban or restriction on a technology is smart enough to make it worthwhile. The open AI letter points to the parallels with the BWC:\n Just as most chemists and biologists have no interest in building chemical or biological weapons, most AI researchers have no interest in building AI weapons - and do not want others to tarnish their field by doing so, potentially creating a major public backlash against AI that curtails its future societal benefits. \nBut it doesn't go as far as to make suggestions about how this works in practice, and who will play a role. It's great that International Committee for Robot Arms Control (ICRAC) representatives like Mark Bishop have signed up too. They have been involved in UN discussions about automated weapons for at least two years already. Maybe this committee is the starting place for the next stage of action.\nBut signatures from technology leaders in companies like from Apple and Google bring a new level of clout and visibility to this argument. And they could add pressure by reflecting the terms of the letter in their own organisations - setting up ethics and governance oversight in a way they haven't so far.\n Related: Musk, Wozniak and Hawking urge ban on warfare AI and autonomous weapons\nThe BWC implementation team support the work that needs to be done to properly manage an international ban on a technology. Piers also brought an outside voice to discussions about how to govern potential biological weapons - a check on the bias created by a community involved or inspired by the development of a particular technology.The problem with self-governing science\nA global moratorium on geoengineering has been mooted at various times over the last decade. Research that engineers changes to the atmosphere and climate at a large scale is risky enough to warrant a wider debate before it goes ahead. Scientists developing these techniques understand this, and held a conference at Asilomar in 2010 to discuss the governance of their work. This follows the example of geneticists, who held a similar meeting as the discipline started to take off in in the 1970s, including a self-imposed moratorium on research for two years while they decided on how to balance the benefits of their advancing science with public fears.\nThe geoengineering Asilomar meeting was part of a series of attempts to construct a self-governing body for this research. But no matter how well-intentioned these efforts are, there are limits to perspectives that self-governance brings to debates about the ethics of developing new technology.\n                     Accounts from the time of the original Asilomar meeting provide evidence that many scientists then saw self-governance as a way to avoid heavy regulation rather than as the best way to reflect their sense of responsibility. This will, obviously, have affected the kinds of regulatory options they were willing to consider as part of their discussions. Coupled with pressures from biotechnology investors ready to pounce on any new development, this could add up to a kind of unspoken, unchallenged mutual bias.\nAs well as these unspoken external pressures, the internal norms of science unhelpfully narrowed the acceptable topics of conversation at Asilomar. Sheila Jasanoff, J. Benjamin Hurlbut and Krishanu Saha said on this blog in April : \"Asilomar offers an easy recipe for public policy: a research moratorium followed by an expert assessment of which risks are acceptable and which warrant regulation.\" They argue that this way of working can avoid addressing issues that become key to public debate in years to come - like environmental release of engineered organisms or ethical aspects of human genetic engineering. The technical debates at Asilomar were too narrow to cover the issues that become most important over time.\nThe AI letter this week betrays the biases inherent in a group thinking about restricting very the thing they work on. It talks of wanting to avoid \"potentially creating a major public backlash against AI that curtails its future societal benefits\". One of the justifications for taking a stand against autonomous weapons is building a smoother path for the continuation of AI research. This group will prefer options that allow them to continue their research even if that reduces the effectiveness of any ban on AI as a weapon. The history of Asilomar tells us that they risk not addressing issues that become the most acute as AI continues to develop.\nFrom biologists in the 1970s to geoengineers today, there are groups of scientists that have taken a stand against the misuse of the technology they develop. But by focusing on large scale hazards, they can miss the potency in local influences on the direction of their research - from the desire to avoid overzealous legislation to pressure from their business affiliations. If this growing community around AI is to avoid this pitfall, they need to go beyond a second column for non-AI expert signatories for their letter. There need to be a permanent, challenging voice helping to develop global governance for AI technology. This will not just help them turn this week's worthwhile call into action, but turn it into the kind of action that is doesn't just serve the more subtle pressures on today's AI community. \n                     The 12th and 16th paragraphs of this blogpost were amended on 3rd August to                     reflect the fact that Piers Millet recently left the BWC Implementation Support Unit.                   \n"},
{"docid": "119 of 500 DOCUMENTS\n", "source": "The Guardian - Final Edition\n", "date": "December 17, 2008", "title": "Obituary: Oliver Selfridge: Computer scientist paving the way for artificial intelligence\n", "content": "Oliver Selfridge, who has died aged 82, was known as the \"father of machine perception\" for his work as a pioneer of computing and as a researcher into artificial intelligence. Though London-born, he did his most significant work at the Massachusetts Institute of Technology (MIT), Cambridge, Massachusetts, and was among the organisers of the Dartmouth Conference of 1956 at Dartmouth College, Hanover, New Hampshire. The first public meeting on artificial intelligence (AI), it introduced the term into general use.\nThe idea of AI, that a mechanical \"brain\" might some day be capable of \"learning\" from its experiences and evolving into a superior form, has been regarded by some as the holy grail of computer science, though in Hollywood it is more often portrayed as its nemesis. It was only with the invention of the programmable digital computer in the 1940s that it became practical to postulate how such a machine might be designed, and the ways in which its intelligence could be assessed.\u00a0\nThe Turing test is based on the premise that if a machine can hold a conversation with a person (using a keyboard and screen) and the person is unable to tell whether he or she is conversing with a person or a machine, then the computer can be regarded as \"thinking\". Alan Turing, who died in 1954, himself believed that machines would be powerful enough to pass the test by the year 2000. Current predictions put that date at somewhere in the third decade of this century.\nComputers are now powerful enough to fool some of the people some of the time, and have been able to beat humans at chess for several years. Their ability to do this is based upon speed and number-crunching ability; the computers of today are no more intelligent than Colossus, at Bletchley Park, the British codebreaking organisation in the second world war.\nSelfridge's early work in the field of pattern recognition was detailed in his 1959 paper Pandemonium: a Paradigm for Learning, a classic in the field of AI. Recognising that previous attempts to model human thought had been less than successful, he introduced Pandemonium as a learning model that was able to improve itself over time in its task of recognising dots and dashes of morse code.\nThe paper also introduced the notion of parallel processing, the machine being able to process more than one piece of information at the same time - a concept that is fundamental to human thought patterns. Pan-demon - ium proposes specialised \"demons\" with single tasks, which assess the data in a manner that improves with time. Selfridge was able to demonstrate the distinguishing of dots and dashes in morse code and to recognise 10 hand-drawn characters. It is, in fact, an early description of a neural network. Pandemonium proved to be such a successful model of human pattern recognition that it has been adopted and adapted for use in cognitive psychology.\nSome of Selfridge's ideas were summarised in The Computer as a Communications Device (1968), a paper by JCR Licklider and Robert W Taylor in the journal Science and Technology. Honouring Selfridge, the authors referred to an Oliver (on-line interactive vicarious expediter and responder) - an early description of a computerised personal assistant.\nSelfridge, who was a grandson of Harry Gordon Selfridge, the American founder of Selfridges department store, London, was educated at Malvern college, Worcestershire. At the outbreak of the second world war, the family emigrated to the US and Oliver went to Middlesex school in Concord, Massachusetts. He graduated with a bachelor's degree in mathematics from MIT in 1945. After service in the navy, he returned there as a graduate student, and studied under Norbert Wiener, the founder of the science of cybernetics. Selfridge was one of the early reviewers of Wiener's Cybernetics (1948).\nMuch of Selfridge's career was spent at MIT's Lincoln laboratory where, as associate director of Project MAC in the 1960s, he worked on multi-access computing. He then went to Bolt, Beranek & Newman, now BBN Technologies, which develops computer and communications-related technology. In 1983 he became the chief scientist for the telecommunications company GTE, and retired in 1993.\nHe served on the advisory board of the US National Security Agency, the government's cryptographic agency, where he chaired the data-processing panel. Along with scholarly papers and technical books, he also wrote several books for children.\nHis marriages to his first wife, Allison, and second wife, Katherine, ended in divorce. He is survived by his partner, Edwina Rissland, their daughter Olivia, his children from his first marriage, Peter, Mallory and Caroline, his sister, Jennifer, and six grandchildren.\nOliver Gordon Selfridge, computer scientist, born 10 May 1926; died 3 December 2008\n"},
{"docid": "120 of 500 DOCUMENTS\n", "source": "The Sunday Telegraph (London)\n", "date": "February 2, 2014", "title": "UK leads the way as Google hunts for artificial intelligence\n", "content": "WHEN Google forked out \u00a3400m for a British technology start-up last week, people sat up and took notice. Not only was it Google's largest European acquisition, but the company in question was virtually unheard of.\u00a0\nDeepMind specialises in artificial intelligence (AI), or \"machine learning\". Its technology is designed to mimic human thought processes, and has so far been used in simulations, e-commerce and games, according to its website.\nBritain has some of the world's best research groups, including Cambridge University, Imperial College and University College London (UCL), and is a growing centre for tech entrepreneurship. But companies specialising in AI are rare.\nGoogle's acquisition of DeepMind has shone a light on this nascent sector, and Ben Medlock, co-founder of AI firm SwiftKey, believes that the UK is capable of building sustainable AI businesses to rival the American giants.\n\"The UK has a great heritage in AI, stemming back to giants such as Alan Turing, one of the undisputed fathers of the field,\" said Medlock.\nSome experts have warned that AI could lead to mass unemployment. Dr Stuart Armstrong, from the Future of Humanity Institute at the University of Oxford, said computers had the potential to take over jobs at a faster rate than new roles could be created.\nHe cited logistics, administration and insurance underwriting as professions that were particularly vulnerable to the development of artificial intelligence.\nHowever, Andrew Anderson, chief executive of Celaton, said AI was not all about \"hacking the workforce to pieces\". Rather it was about making individuals more productive, and making sure that \"processes get applied, stuff is accurate, errors are eliminated, and compliance is met\".\nAnalyst Gartner predicts \"smart machines\" will have a widespread impact on businesses by 2020.\nHere are some British companies best placed to take advantage of this technological opportunity: SWIFTKEY SwiftKey uses artificial intelligence to make personalised mobile apps. It is best known for the SwiftKey keyboard, which learns from each individual user to predict their next word and improve autocorrect.\nIts machine learning and natural language-processing technology aims to understand the context of language and how words fit together.\nSwiftKey products were embedded in more than 100m devices last year, and the company now has an app for iPhones and iPads, SwiftKey Note.\nCELATON Celaton's inSTREAM software is designed to apply artificial intelligence to labour-intensive clerical tasks and decision-making.\nLINCOR Lincor provides hospital bedside computers. These \"virtual personal doctors\" can constantly analyse patients' live health data.\nFEATURESPACE Cambridge-based Featurespace has two software products using its predictive analytics, one for fraud detection, the other for marketing.\nDARKTRACE Darktrace uses advanced Bayesian mathematics to detect abnormal behaviour in organisations in order to manage risks from cyber-attacks.\nBritain has a great heritage in AIy stemming back to Alan Turing\n"},
{"docid": "121 of 500 DOCUMENTS\n", "source": "The Guardian - Final Edition\n", "date": "July 5, 2007", "title": "Technology: National Rail chiefs could learn a lot by playing games\n", "content": "There's a topic in my family that's referred to as The Divorce Conversation. It has nothing to do with anything as mundane as the rubbish or the toilet seat. The thing we don't talk about is artificial intelligence. It usually happens this way: he says that science will someday create an artificial intelligence that is indiscernible from the human brain. I retort that human beings will always be able to tell, even if we don't quite know why.\nThe closer we get to realism, the deeper the Uncanny Valley maws. Soon after, plates are thrown and one of us ends up in tears. But I have to admit, seamless artificial intelligence has its place. As a woman weaned in games with their advanced AI, I have no time to suffer computerised fools. For example, I was on an early train to London last Saturday - which, being early, started late. Having missed my first train, I jumped on the next one, but I didn't have the estimated arrival time. That bit of information is crucial for exceptional stress, which is a state I enjoy. So to arm myself with these vitals I phoned National Rail's new Train Tracker service.\u00a0\nThis \"intelligent\" computerised operator could only have been realised by masochists for I, while admittedly having an American accent, have a pretty good standard of enunciation. Yet \"East Croydon\" apparently sounds like \"Stroud\" and \"No, I said Brighton, you digital moron\" sounds like \"Lords\". After a hilarious exchange that lasted for several minutes, I mouthed a silent plea for the nice people who used read train times over the phone to come back on the line and provide me with some real intelligence.\nAnd that's the problem: games have ruined me. I spent the 1980s struggling against Pitfall Harry's artificially stupid crocodiles on the Atari 2600 and the 1990s battling against the idiotic AI in Rainbow Six, so by the early part of the 21st century I feel I have a right to lash out against the remnants of poorly realised AI. I have served my time against stupid machines. I know what can be done - I've completed the supremely intelligent Halo. It's raised the bar, and now National Rail's Train Tracker needs to be sent to remedial.\nGames have not made me antisocial, violent or intellectually stunted. On the contrary, I'm more demanding and more critical. I don't expect a digital person to engage in high-blown political discourse, but I do expect a piece of technology to be smart enough to cope with the demands of its station.\nIt doesn't matter whether that means dodging my bullets or decoding what I say. Web application designers are increasingly looking towards games techniques and tools to understand human-computer interaction because games are really good at breaking down the fourth wall and engaging audiences with robots.\nI wouldn't play a game if I had to make my intentions understood three or four times before it did what I needed it to do. In games, if the user interface is thicker than a plank of spruce, you lose a lot of players; bye bye, bottom line. Yes, I realise I'm contradicting my side of The Divorce Conversation. Yes, I know the things on the other side of the screen are computers. But I'm happy to keep it that way.\nI suffer from a mighty hubris which demands that I must be smarter than the things that human beings create. I still maintain, though, that even though one is toting rocket launchers and the other is brandishing train times, National Rail could learn a thing or two from the Master Chief.\n"},
{"docid": "122 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "January 29, 2014", "title": "Advances in artificial intelligence could lead to mass unemployment, warn experts; Academics say half of US jobs could be automated within a decade or two\n", "content": "Experts have warned that rapidly improving artificial intelligence could lead to mass unemployment just days after Google revealed the purchase of a London based start-up dedicated to developing this technology.\nSpeaking on Radio 4's Today programme, Dr Stuart Armstrong from the Future of Humanity Institute at the University of Oxford said that there was a risk that computers could take over human jobs \"at a faster rate than new jobs could be generated.\"\n\"We have some studies looking at to which jobs are the most vulnerable and there are quite a lot of them in logistics, administration, insurance underwriting,\" said Dr Armstrong. \"Ultimately, huge swathe of jobs are potentially vulnerable to improved artificial intelligence.\"\u00a0\nDr Murray Shanahan, a professor of cognitive robotics at Imperial College London, agreed, noting that improvements in artificial intelligence were creating \"short term issues that we all need to be talking about.\"\nBoth academics did however praise Google for creating an ethics board to look at the \"how to deploy artificial intelligence safely and reduce the risks\" after its \u00a3400 million purchase of London-based start-up DeepMind.\nDeepMind has been operating largely unnoticed by the wider UK technology scene, although its advances in artificial intelligence have obviously been of interest to the experts - founded in just 2012, DeepMind is Google's largest European acquisition to date.\nDr Shanahan hailed DeepMind as \"a company with some outstanding people working for it,\" noting that the company has mainly been working in the areas of machine learning and deep learning, which he described as \"all about finding patterns in very large quantities of data.\"\nGoogle's purchase of the company has led to speculation as to how they might implement the technology. Although there had been some talk of using DeepMind's algorithms to give 'brains' to Google recent robotic purchases, insiders have said that the acquisition was about improving search functionality, not AI.\nRegardless of how DeepMind's expertise will be used, Google's purchase of the company underscores increasing fears over the impact of technology on employment. \nAcademics note that although professions have always been threatened by the forces of 'progress' (a nebulous concept that can cover anything from speedier computers to more efficient steam engines), current trends suggest jobs are being destroyed faster than they are being created.\nA recent paper by Carl Benedikt Frey\u00a0and Michael A. Osborne of Oxford University suggests that nearly half (47 per cent) of all American jobs are under threat and could be automated in \"a decade of two\". \nFrey and Osborne identify the most at-risk jobs as those which are based in routines (eg telemarketing, low-level accounting and data entry) and which could be replaced by increasingly advanced algorithms, as well as jobs in industry and manufacturing which have already been deeply hurt by advances in the last decades (see video above).\n\"While computerization has been historically con[#xfb01]ned to routine tasks involving explicit rule-based activities, algorithms for big data are now rapidly entering domains reliant upon pattern recognition and can readily substitute for labour in a wide range of non-routine cognitive tasks,\" write Frey and Osborne.\n\"In addition, advanced robots are gaining enhanced senses and dexterity, allowing them to perform a broader scope of manual tasks. This is likely to change the nature of work across industries and occupations.\"\nUnfortunately, it seems that we can assume the same problems will also become rapidly apparent in the UK. Although certain types of jobs are not yet threatened (especially those which involve dealing with other humans - a vague category that can cover anything from healthcare to management) this is no guarantee that they'll be safe forever. \nRead more: Google buys UK artificial intelligence start-up DeepMind for \u00a3400mThe number crunch: Will Big Data transform your life - or make it a misery?Video gallery: meet Google's new robotic circus\n"},
{"docid": "123 of 500 DOCUMENTS\n", "source": " The Independent (United Kingdom)\n", "date": "June 12, 2016", "title": "WWDC 2016: Apple set to unveil artificial intelligence plans and showcase iOS 10 at annual conference; Tech giant will use event to announce plans to take on Google and Facebook in fast-growing field\n", "content": "                     Apple will use its annual conference to announce plans to take on Google and Facebook in the fast-growing artificial intelligence arena, experts believe.\nThe technology giant will also reveal a new version of its iOS software that powers the iPhone and iPad, as well as updating its MacBook laptop line, at its WWDC (worldwide developers conference) event.\u00a0\nThe conference in San Francisco on Monday will see the technology company showcase iOS 10, the latest version of the operating system that runs on iPhone and iPad.\nThe software's virtual, voice-activated personal assistant Siri is expected to be expanded so that it works in a wider range of apps.\nBoth Google and Facebook have already announced greater focus on their artificial intelligence products this year, with Google improving its Google Now software, while Facebook is introducing intelligent \"bots\" to Messenger that can understand requests and questions from users.\nIt is now expected that Apple will discuss its own plans for this area of technology.\nRead more\nApple's big WWDC event to be streamed live\nIt has also been suggested that a new app for controlling smart home products could be a part of the update, as could a dark mode for screen viewing in low light.\nAlso on the agenda is believed to be a version of iMessage - Apple's instant message service that works between iPhone and iPad - that will extend its compatibility to rival platform Android for the first time.\nIt has been seen by many as a response to the growing power and popularity of other messaging services, including WhatsApp.\nRead more\nApple App Store to undergo complete overhaul, with ads and subscriptions for games\nApple OS X: Tips and tricks for getting the most out of your Mac\nApple edits same-sex parents from Mother's Day ads in France, Germany and other countries\niPhone was invented in the 17th century, jokes Apple CEO Tim Cook\nApple Music, the streaming service that was announced at the event last year is believed to be getting a redesign too.\nReports suggest there could be plenty of discussion of the company's laptop line as well, with not only the traditional annual update of the software expected, but also new a MacBook Pro, the firm's most powerful laptop, as well as a new slimline MacBook Air.\nThe Apple TV streaming box and the Apple Watch are also expected to have software revamps announced during the keynote on Monday evening.\nPress Association\n"},
{"docid": "124 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "August 27, 2015", "title": "Facebook M: site launches robot virtual assistant for people to chat to and buy things from; The virtual assistant will help users make restaurant reservations, buy things and book holidays, all from the chat app\n", "content": "Facebook has revealed a new artificial intelligence robot, which sits in Messenger and chats to people and helps them buy things.\nThe new service, called M, allows Facebook users to ask it questions and get recommendations, and then buy things. \u00a0\nIt works similarly to other digital assistants, like Apple's Siri, Microsoft's Cortana and Google Now. Users ask a question in natural English - \"Where should I go for a burger?\" for instance - and the robot will reply with a recommended joint and can even book the restaurant.\nIt is able to do that better than other competitors because it is helped out by actual people, David Marcus from Facebook told Wired. Describing it as a hybrid between artificial intelligence and human assistants, the magazine said it is \"powered by artificial intelligence as well as a band of Facebook employees, dubbed M trainers, who will make sure that every request is answered\".\nread moreFacebook Messenger sends 'creepily' precise location dataFacebook to let people use Messenger without having account on social networkFacebook Messenger updated with gifs, third-party apps, chatting to shops and more\nIn a Facebook post, Marcus wrote that the tool \"can purchase items, get gifts delivered to your loved ones, book restaurants, travel arrangements, appointments and way more\"\nM is initially being trialled with a few hundred people in the Bay Area of San Francisco. But it looks set to roll it out soon after.\nFacebook said that it is hoping to build the service to become much bigger. It is \"an exciting step towards enabling people on Messenger to get things done across a variety of things, so they can get more time to focus on what's important in their lives,\" said Marcus.\nThe company has been looking to expand Messenger into a fully-featured social network of its own, breaking it out into its own app and adding new features like apps and tools to talk to shops.\n"},
{"docid": "125 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 21, 2015", "title": "Davos 2015: Robots less dangerous than stupid people; Computers cannot mimic two year-olds and tell jokes, let alone be sociopathic, say two leading artificial intelligence experts.\n", "content": "We are all doomed to a dystopian future run and controlled by smart machines of our own making - or perhaps not. \u00a0\nAt a session at the World Econoimc Forum in Davos, Stuart Russell, a leading expert on artificial intelligence (AI) and robotics, made the bold prediction that AI would overtake humans \"within my children's lifetime\". \nProfessor Russell defined also said it was possible to envisage a much more dangerous future where \"sociopathic\" robots become a threat to humans. \nThe biggest immediate danger from artificial intelligence was autonomous weaponry, followed in the medium term by disruption to established forms of employment. Computers have already rendered redundant millions of once well-paying white collar jobs. \nIn a recent open letter signed by Professor Russell, and among others, the cosmologist Stephen Hawking, it was argued that urgent research was needed into how to limit the destructive potential of AI. \n\"The potential benefits are huge, since everything that civilization has to offer is a product of human intelligence; we cannot predict what we might achieve when this intelligence is magnified by the tools AI may provide, but the eradication of disease and poverty are not unfathomable. Because of the great potential of AI, it is important to research how to reap its benefits while avoiding potential pitfalls\", the letter said. \nHowever others on the panel were were more sanguine. \nAlison Gopnik, professor of psychology at the University of California, Berkeley, who was also on the panel, said afterwards that robots could not even mimic two-year-olds yet, let alone cause damage. \nHer Berkeley colleague, Ken Goldberg, predicted that a robot would not be able to tell a joke in his lifetime. \n"},
{"docid": "126 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "July 25, 2017", "title": "Them's fightin' words: Musk hits back at Zuckerberg over AI comments; Musk described the Facebook CEO's knowledge of the field as 'limited' after Zuckerberg publicly dismissed AI doomsday warnings as 'irresponsible'\n", "content": "Tech billionaires Elon Musk and Mark Zuckerberg have entered into a public squabble about artificial intelligence in which Musk described the Facebook CEO's knowledge of the field as \"limited\".\u00a0\n Related:  Elon Musk: regulate AI to combat 'existential threat' before it's too late\nThe groundwork for the world's nerdiest fight was laid by Musk, the Tesla and SpaceX CEO, earlier this month, when he pushed again for the proactive regulation of artificial intelligence because he believes it poses a \"fundamental risk to the existence of civilization\". Musk, who has been issuing warnings like these for years now, is concerned that humans will become second-class citizens in a future dominated by artificial intelligence - or that we'll face a Terminator-style robot uprising.\nEnter Zuckerberg, who on Sunday denounced these types of warnings as \"pretty irresponsible\".\nZuckerberg made the comments while taking questions during a Facebook Live broadcast from his Palo Alto home. One viewer asked: \"I watched a recent interview with Elon Musk and his largest fear for the future was AI. What are your thoughts on AI and how could it affect the world?\"\nIn an uncharacteristically candid response, Zuckerberg said: \"I have pretty strong opinions on this. I am optimistic. And I think people who are naysayers and try to drum up these doomsday scenarios - I just, I don't understand it. It's really negative and in some ways I actually think it is pretty irresponsible.\"\nZuckerberg believes that AI will have much less dystopian applications, and will be responsible for saving lives through disease diagnosis and by powering driverless cars.\n\"One of the top causes of death for people is car accidents, still, and if you can eliminate that with AI, that is going to be just a dramatic improvement,\" he said.\nA day later, Musk had a comeback on Twitter: \"I've talked to Mark about this. His understanding of the subject is limited.\"\n I've talked to Mark about this. His understanding of the subject is limited.- Elon Musk (@elonmusk) July 25, 2017\nIt's not the first time Musk and Zuckerberg have had a public beef. Last September, SpaceX was scheduled to launch an internet-beaming satellite intended for use by Facebook's Free Basics project in Africa. However, the Falcon 9 rocket exploded, destroying both the rocket and cargo : the AMOS-6 satellite that Facebook planned to use to deliver internet connectivity to rural parts of Africa.\nZuckerberg was not happy. Writing on his Facebook page, he said: \"As I'm here in Africa, I'm deeply disappointed to hear that SpaceX's launch failure destroyed our satellite that would have provided connectivity to so many entrepreneurs and everyone else across the continent.\"\nFirst depriving African entrepreneurs of internet access, and now dissing Zuck's intellect, Musk has drawn the battle lines. Your move, Mark. \n"},
{"docid": "127 of 500 DOCUMENTS\n", "source": "The Independent\n", "date": "October 23 1989", "title": "Technology: A dawning of consensus - Darrel Ince reflects on the divisions in artificial intelligence research, and detects a convergence\n", "content": "\u00a0\n\u00a0ARTIFICIAL intelligence seems never to be far from controversy. Even internal debate about such uncontroversial topics as the optimal architecture of an 'expert system' - a computer program which attempts to replicate the skills of the human consultant - is conducted in heated terms.\n The past decade has seen the most heat and light generated by arguments about the feasibility of building software with intelligence. The reawakened interest in neuronal computing has provided an additional and potent dimension to the arguments.\u00a0\n\n This was made clear in a special issue of the influential American journal Daedalus, which has recently been republished by the MIT Press. It highlights the schism in the American computer science community between conventional artificial intelligence researchers, neural network workers and those who continue to shout: 'A plague on both your houses'.\n The history of artificial intelligence can be seen as a conflict between two camps. In the first camp are those who have, as their main aim, the development of intelligent software artefacts, irrespective of whether the developed software simulates the thought processes of humans. This camp - following the 'conventional' path - I shall call the 'symbol manipulators'. The other camp bases its work on the simulation of the cognitive processes that go on in the human brain. These are the 'connectionists'; one outgrowth of this work has been the renewed interest in the neural network research.\n In the Sixties the connectionists were in the ascendency. The computer was seen as the ideal laboratory for testing hypotheses about cognitive processes and money poured into work which modelled the neuron structures of the human brain. This research had some small successes, but was eventually killed off by Seymour Papert and Marvin Minsky, two American researchers who demonstrated that the neuron structures used by researchers were severely limited in their capability.\n There was then a long gap. In the Seventies funding for artificial intelligence research reached its lowest points. In the United Kingdom, a report by Sir James Lighthill, the Provost of University College, London, was critical of both research camps, and artificial intelligence research in this country suffered a very severe decline.\n Later in the Seventies, however, a massive explosion of funding was precipitated when the Japanese published their plans for fifth-generation computing. The Japanese had, as their main plank, the use of artificial intelligence technology and new hardware architectures. At the heart of the Japanese plans, and consequently the plans of every other industrialised nation, was the 'expert system', which tried to formalise the human rule-of thumb processes.\n The past seven years have seen most of the research funding going to the symbol manipulators. Progress with large expert systems has been very slow. The complexity of software development and effort of getting knowledge from the human consultant for these systems is such that they are difficult to develop and, after a few hundred rules, the systems become slow and extremely difficult to maintain.\n This has led to disappointment among the funding bodies, manifested in a shift of resources to researchers in neuronal computing: the descendents of those in the Sixties who wished to use the computer as a laboratory for cognitive psychology. The issue of funding underlies much of the current controversy. The journal describes vitriolic attacks on one camp by members of the other camp.\n For example, Anya Hurlbert and Tomaso Poggio, two vision researchers working at the Massachusetts Institute of Technology, point out that the architectures used by connectionists have little in common with the neuronal structures of the human brains, and are just brute-force attempts to solve problems. They also point out that they feel that many of the methods used by connectionists could be replaced by the orthodox pattern-recognition methods that have been developed by mathematical statisticians.\n George Reeke and Gerald Edelman, two biology researchers at the Rockefeller University, point out that artificial intelligence researchers - even connectionists researchers - have ignored fundamental biological theories and depended on well- studied but arcane physical systems. Seymour Papert, another MIT researcher who was one of the leading figures of neural network research in the past, maintains that history has shown that brute-force methods, such as those embodied in connectionist computers, scale up exceptionally badly; that a problem with a small number of properties which work well when executed on a connectionist computer may take thousands of years to execute when a realistic version of the problems is processed. Mr Papert points out that even toy problems often do not work well when solved using the connectionist approach.\n This debate between connectionists and symbol manipulators is taking place against a background of little progress in solving real-life problems and an increasing belief among researchers that, as a minimum, the approach of the connectionists is too general and may suffer the same fate as the general problem-solving programs which were developed in the Sixties by the symbol manipulators.\n What seems to be beginning to emerge is a consensus that both the symbolist and connectionist approaches have strengths which could be taken advantage of in the future in hybrid systems; that the brute-force approach of connectionist computers could be combined with application-specific properties of expert systems to produce intelligent artefacts - artefacts which neither approach alone would be capable of producing.\n 'The Artificial Intelligence Debate', Graubard, S R (Ed), MIT Press, 1989.\n Darrel Ince is professor of computer science at the Open University.\n Science and Technology Page 18\n"},
{"docid": "128 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "January 29, 2016", "title": "Professor Marvin Minsky: Mathematician and inventor inspired by Alan Turing to become a pioneer in the field of artificial intelligence; Minsky devoted his career to the hypothesis that engineers could someday create an intelligent machine\n", "content": "Marvin Minsky was a founding father of the field of artificial intelligence and an innovative explorer of the mysteries of the human mind during his long tenure at the Massachusetts Institute of Technology. He was a professor emeritus at MIT's Media Lab, which has a broad, interdisciplinary mandate to explore technology, multimedia and design.\nMinsky devoted his career to the hypothesis that engineers could someday create an intelligent machine. He flourished as a professor and mentor even as the field of AI endured discouraging results and eruptions of pessimism. He lived long enough to see AI ambitions flourishing anew, with attendant concerns about killer robots and rogue computers.\u00a0\nAlthough Minsky was himself an inventor - as a young man, he developed a microscope for studying brain tissue that eventually became a standard tool for scientists - his greatest contributions were theoretical. He developed a concept of intelligence as something that emerged from disparate mental agents acting in co-ordination. No single agent is intelligent when operating alone.\nIf a single word could encapsulate Minsky's career, it would be \"multiplicities\", his MIT colleague and former student Patrick Winston said. The word \"intelligence,\" Minsky believed, was a \"suitcase word\", Winston said, because \"you can stuff a lot of ideas into it.\" Other such words include \"creativity\" and \"emotion\".\nAlong with fellow AI pioneer John McCarthy, Minsky founded the artificial intelligence lab at MIT in 1959. His 1960 paper Steps Toward Artificial Intelligence laid out many of the routes researchers would take in the decades to come. He wrote, \"we are on the threshold of an era that will be strongly influenced, and quite possibly dominated, by intelligent problem-solving machines.\" Anyone trying to mimic intelligence in a machine, he wrote, had to solve five categories of problems: search, pattern recognition, learning, planning and induction.\nHe also wrote books, including The Society of Mind (1986) and The Emotion Machine (2006), that colleagues consider essential to understanding the challenges in creating machine intelligence. On his death, his colleague Nicholas Negroponte wrote: \"The world has lost one of its greatest minds in science. As a founding faculty member of the Media Lab he brought equal measures of humour and deep thinking, always seeing the world differently. He taught us that the difficult is often easy, but the easy can be really hard.\"\nMinsky was born in New York in 1927. His father, Henry, was a noted eye surgeon while his mother, the former Fannie Reiser, was active in Zionist causes. As a child, he recalled, he was \"physically terrorised\" by playground bullies, and a lack of academic support in the classroom led his parents to enrol him in the progressive Fieldston School. His interest in electronics and chemistry blossomed, and he won a place at the prestigious Bronx High School of Science in 1941. He spent his senior year at a private Academy in Massachusetts, to bolster his college options. In 1945, he enlisted in the Navy in the final months of the Second World War and served in an electronics programme. He graduated in mathematics from Harvard in 1950 and received his PhD at Princeton in 1954.\nAt Princeton, with funding from the Office of Naval Research, Minsky co-built a primitive \"electronic learning machine\" with tubes and motors. He was also exposed to some of the greatest minds of the day, including John von Neumann, a pioneer of computers. Back at Harvard as a junior fellow in the mid-1950s, Minsky invented the confocal scanning microscope that would find many uses in science.\n\"Minsky's invention disappeared from view for many years because the lasers and computer power needed to make it really useful had not yet become available,\" Winston wrote. \"About 10 years after the original patent expired, it started to become a standard tool in biology and materials science.\"\nIn 1956, when the very idea of a computer was only a couple of decades old, Minsky attended a two-month symposium at Dartmouth College that is considered the founding event in the field of artificial intelligence.\nRead more\n                     'Artificial intelligence alarmists' win 'Luddite of the Year' award                   \n                     Apple buys AI software that can tell people's emotions                   \n                     Plan to bring people back from the dead with artificial intelligence                   \n                     AI could wipe out humanity because it's too clever, Hawking warns                   \n                     Turing's handwritten journal sells for more than $1m                   \n                     Alan Turing's family take pardons for 49,000 gay men petition to                   \nMinsky said last year that Alan Turing was the first person to bring respectability to the idea that machines might one day think. \"There were science fiction people who made similar predictions, but no one took them seriously because their machines became intelligent by magic. Whereas Turing explained how the machines would work.\" In 1969 the US Association of Computing Machinery gave him the highest honour in computer science, the AM Turing Award.\nMinsky and his wife, the former Gloria Rudisch, a paediatrician, enjoyed a partnership that began with their marriage in 1952. Their home became the regular haunt of science-fiction writers, including Isaac Asimov, while Richard Feynman, the Nobel Prize-winning physicist, would play the bongos at their parties.\nGloria Marvin recalled her first conversation with the man she ended up marrying: \"He said he wanted to know about how the brain worked. I thought he is either very wise or very dumb. Fortunately it turned out to be the former.\"\nMinsky acknowledged last year that he was disappointed that AI research has yet to create human-level intelligence in a machine. He said early efforts at large companies such as IBM failed to appreciate the complexity of the problem and how incremental progress would have to be. \"It's interesting how few people understood what steps you'd have to go through,\" he said. \"They aimed right for the top and they wasted everyone's time.\"\nHe was asked if he believed that machines will become more intelligent than human beings and if that would be a good thing. \"Well, they'll certainly become faster,\" he said. \"And there's so many stories of how things could go bad, but I don't see any way of taking them seriously because it's pretty hard to see why anybody would instal them on a large scale without a lot of testing.\"\nMarvin Lee Minsky, scientist: born New York 9 August 1927; married Gloria Rudisch (three children); died Boston 24 January 2016.\n\u00a9 The Washington Post\n"},
{"docid": "129 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "March 17, 2016", "title": "AlphaGo beats Lee Sedol in third consecutive Go game; Google's DeepMind computer program wins $1m in victory marking significant development in artificial intelligence\n", "content": "Google's AlphaGo computer program has won a third and decisive encounter with a top-ranked player of the Chinese board game Go in a victory marking significant developments in artificial intelligence. \u00a0\nLee Sedol, who is the world's second best player of the strategy game, lost three games in a row in Seoul this week, with the latest AlphaGo victory on Saturday handing Google the best-of-five match. \n\"I've never played a game where I felt this amount of pressure, and I wasn't able to overcome this pressure,\" Lee said at a post-game press conference.\nGo has simple rules, but is highly intuitive and complex in practice. Mastering it has been an exceptionally difficult task for even the world's best IT designers.\n\"We came here to challenge Lee, to learn from him and see what AG was capable of,\" said Demis Hassabis, co-founder of Google's artificial intelligence business, DeepMind, which created the program.\n\"AlphaGo controlled the momentum over more than four hours of gameplay, with Lee struggling to maintain territory against the program's creative approach. Google DeepMind taught AlphaGo to recognise the optimal move in thousands of possible scenarios.\"\nAlphaGo's dominance amounts to a significant, and much faster than previously expected, advance in artificial intelligence. \nGoogle co-founder Sergey Brin, who was in Seoul to watch the third match, described Go as a beautiful game and said he was excited the company had been able to \"instil that kind of beauty in our computers\".\nMichael Redmond, one of the match's commentators and a professional Go player, said some people initially doubted AlphaGo's abilities. \"After three matches and three straight victories, we are convinced,\" he said.\nAlphaGo won $1m in prize money, which Google DeepMind said would be donated to charities, including Unicef and Go organisations. \n\"AlphaGo controlled the game amazingly,\" said Fan Hui, the European Go champion who was the first professional player to lose to the program when he played it in October.\nHui said the advances in artificial intelligence appeared to bode well for the future of the ancient game. \n\"We now have this new way of learning about Go. And look how many people are watching this now. More and more people are interested in Go now.\"\n"},
{"docid": "130 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "August 31, 2014", "title": "Bankers beware: City 'will soon be run by robots'; Artificial intelligence will render human efforts redundant, says Microsoft executive\n", "content": "Robots will be running the City within 10 years, rendering investment bankers, analysts and even quants redundant, it has been claimed.\nArtificial intelligence is about to outpace human ability, according to Dave Coplin, a senior Microsoft executive. Computers will not only be able to undertake complex mathematical equations but draw logical, nuanced conclusions, reducing the need for human interference, he said. \nThis will render certain professions redundant, while other \"human only\" skills will become increasingly valuable.\u00a0\n\"I believe in Moravec's Paradox,\" Mr Coplin, Microsoft's UK-based chief envisioning officer, told The Telegraph, referring to the Eighties hypothesis discovered by artificial intelligence and robotics researchers. \"This states that what we think is easy, robots find really hard, and what we think it really hard, robots find easy,\" he said. \"Complex maths equations are hard for humans but take nanoseconds for a computer, but moving around and picking things up is easy for us, while being almost impossible for a robot.\"\nMeanwhile, he said, professions currently viewed as commodities will become specialist human skills. \"It would be hard to train a robot to be a nurse, or even a chef, but the City could be run by algorithms,\" he said. \"People who use their hands will have jobs for life.\"\nAlgorithms are already commonplace on City trading floors, and are used in many industries, from online retail to internet dating. High-frequency trading, governed by algorithms, is already one of the most profitable trading classes. But, according to Mr Coplin, in 10 years people will no longer be required to manage these algorithms. Decisions will be taken directly by the artificial intelligence.\n\"Everyone thinks of Terminator and Skynet [the computer that becomes self-aware and attempts to destroy mankind in James Cameron's 1984 film] when I start talking about this, but technology affords us a tremendous opportunity to play to our strengths as humans, and stand on the shoulders of robotic giants,\" said Mr Coplin.\nMicrosoft has tasked Mr Coplin with exploring the new trends that will shape the world of work in the coming years.\n\"I am hunting for the game-changers of the next 10 years,\" he said.\nMr Coplin believes that the rise of big data and innovations in the field of \"ambient intelligence\" - smart technology that responds to the presence of people - are going to bring about radical changes in the workplace.\n\"I call my mobile a smartphone but even though it has information about where I am and who I speak to, it doesn't do anything with that information. It doesn't deliver a service.\"\nIn the future, ambient intelligence will allow devices to anticipate your needs and respond in real time. Your phone will send automated email responses based on keywords and contributing factors such as location, time of day, and calendar entries. \"Business processes will be increasingly automated, freeing up humans to do more useful things,\" Mr Coplin said.\nBig data is not a new concept but technologists are increasingly interested in finding new ways that these mountains of data can be read and interpreted.\nMicrosoft is an active participant in this field of research. It recently trialled a new feature for Skype, its voice over IP service, which allows users to select a language and translates their speech in real-time.\nSocial media is also changing the way organisations will communicate in the future, according to Mr Coplin, who has a vision of a transparent, digital corporate infrastructure, where emails, documents and spreadsheets are all accessible to and searchable by anyone in that organisation. \"Knowledge will flow freely, you will be able to see information even if you're not part of the conversation. It won't be locked up in teams of inboxes any more.\"\nMany of the new workplace trends may seem alien today but, according to Mr Coplin, \"This new technology will bring about cultural change.\"\n"},
{"docid": "131 of 500 DOCUMENTS\n", "source": " The Independent (United Kingdom)\n", "date": "June 21, 2016", "title": "Elon Musk's openAI project says it is working on a robot to clean people's houses; Building a robot that can help people in their homes will be a good way of testing the future of AI, Musk's research group says -and so to ensure that they don't take over the world and kill us\n", "content": "                     Elon Musk's $1 billion artificial intelligence group wants to build a robot to clean people's houses.\nOpenAI -which is funded by the billionaire maker of reusable rockets and electric cars -hopes to build a domestic robot as a test of its research into how to build artificial intelligence that won't kill us.\u00a0\nBuilding such a robot isn't just a way of getting rid of household chores, according to a blog entry posted by the nonprofit research group. It would also be a neat way of testing whether or not its work in artificial intelligence is progressing in the right way.\nThere are already ways of creating a robot that can carry out specific tasks, the researchers note. The difference is that Musk's team hopes to create \"learning algorithms\" that would allow the creation to serve as a \"general purpose\" robot - meaning that it can be left around the home and be clever enough to work out what it needs to do to clean.\nRead more\nWe are living in a computer simulation, Elon Musk says\nCreating such a robot is a \"good testbed for many challenges in AI\", the team note. The robot won't be built by OpenAI, but instead use components from elsewhere that are programmed by the group.\nCreating a household robot is the second goal of the OpenAI group, according to blog post. It has already detailed its work in meeting goal one - \"Measure our progress\" - when it laid out plans for a special gym that can help train artificial intelligence programs.\nThe goals that follow are building an agent that can understand natural language and creating one that could solve a \"wide variety of games\". OpenAI hopes that the different goals capture different kinds of problem-solving and together can progress towards its goal of building smart AI systems that don't also wipe out life on Earth.\n"},
{"docid": "132 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "December 30, 2016", "title": "The rise of artificial intelligence risks making us all redundant; AI systems are being designed for supermarkets which allow customers to choose their shopping and exit without going to a checkout. Soon, robots will be stacking the shelves and running the entire show. No wonder unions are worried\n", "content": "At the start of a new year, what is there to look forward to? According to predictions from think tanks and tech experts, advances in automation and artificial intelligence will threaten the jobs of millions of workers. The CEO of one company, Capgemini, goes further, predicting that AI will be one of the key factors dividing society into the haves and have-nots, with highly skilled engineers at the one end of the spectrum and low-paid unqualified worker drones at the other, with nothing inbetween.\nThere will be massive redundancies, for sure. Is it time to rethink the welfare system and payeveryone a minimum living wage whether they work or not? That proposal, known as a \"universal basic income\"is being trialled in Finland but was rejectedin a referendum in Switzerland last June.\u00a0\nFacebook boss Mark Zuckerberg is investing heavily in developing AI. Herecently released a corny \"seasonal message\"featuring his latest project, a robot butler named Jarvis. We don't see Jarvis, voiced by Morgan Freeman, but the message is absolutely plain:this is not a bit of fun, but the unveiling of a plan for our future, a future which tech companies are battling to capitalise on.\nStephen Hawking has a terrifying warning about artificial intelligence\nZuckerberg has spent more than100 hours programming Jarvis so that it can switch on his household gadgets, his music system and even help his small daughter learn Mandarin. It responds to voice commands issued from aphone, even offering hima clean grey T-shirt in the morning. Jarvis is also a gatekeeper, deciding who may or may not enter the Zuckerberg home.\nThis cutesy video is surely designed to deflect attention from Facebook's recent woes, including failing to curb fake news reports which critics reckon had a devastating impact on the result of the US presidential election. Facebook stands accused of failing to monitor the material it disseminates, consistently claiming freedom of speech by default,allowing lies and blatant propaganda the same platform as real news stories. Even the Pope has now decreed that publishing fake news is a sin.\nRead more\nBritain is allowing working families to slide into poverty\nThe development of a faceless, featureless robot is ominous;when his daughter Max wakes up, surely she would prefer a cuddle from a human being rather than a po-faced lesson from a non-person? By fostering the illusion that Jarvis is sociableand has a use beyond the purely functional in a small family unit, Zuckerberg is preparing the ground to presentAI as something new and desirable, rather than the ultimate threat to our livelihoods. If hedevelops devices like Jarvis on a commercial basis, will it give his company direct access into our homes, whisking away what little privacy we may have left? And if this use of AI relies on programmes derived from our speech patterns, should we hand those over to a third party? And, given that we already spend far too long staring at screens,and the time we interact with other people is declining andloneliness increasing, can introducing robots into our personal lives be a good thing?\nGoogle and Amazon are already selling devices which can perform simple tasks, as well as developing rival driverless cars. AI systems are being designedfor supermarkets which allow customers to choose their shopping and exit without going to a checkout. Soon, robots will be stacking the shelves and running the entire show. No wonder unions are worried.\nAs for driverless cars, what are the ethics involved in deciding how they should respond to obstacles in their path? How do they differentiate a dead pheasant or a deer from a person who may have fallen down? And, if driverless cars are easily identifiable, will they spawn a new kind of road rage -one directed at trying to provoke a response from the robots taking over our lives?\nFans of AI say driverless cars will reduce deaths on the roads, and represent the biggest change in our lives since motor cars replaced horses a century ago. Really? Are we powerless to stop the rapid roll-out of AI?\nOne of my favourite films as a student was Jean-Luc Godard's \nAlphaville\n, in which Paris shot in atmospheric black and white is Alphaville, a citycontrolled by a powerful computer dubbed Alpha 60. Emotion is forbidden and anyone who deviates from accepted behaviour is terminated by female assassins. Has a film ever seemed more prescient?\nWhen Mark Zuckberg tells us Jarvis is the start of something, be very scared. The only butler I want atchez JSP will have blood in his or her veins and be capable of questioning my more pretentious requests. To be honest, if I could have one gift for 2017, if would be a few hours a week from a real butler. Human beings make much better companions.\n"},
{"docid": "133 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "October 19, 2016", "title": "Stephen Hawking says artificial intelligence could be humanity's greatest disaster\n", "content": "The invention of artificial intelligence could be the biggest disaster in humanity's history, Professor Stephen Hawking has said, warning that if they are not properly managed, thinking machines could spell the end for\u00a0civilisation.\u00a0\n\"The rise of powerful AI will be either the best or the worst thing ever to happen to humanity. We do not know which,\" the British physicist said.\nHe was speaking at the opening of a new Cambridge centre that will seek to address the potential dangers and conundrums of AI.\nProfessor Hawking, a prominent critic of making unchecked advances in AI, said that the technology\u00a0promised to bring great benefits, such as eradicating disease and poverty, but \"will also bring dangers, like powerful autonomous weapons or new ways for the few to oppress the many\".\n                   In quotes | Stephen Hawking                   \n\"It will bring great disruption to our economy, and in the future AI could develop a will of its own that is in conflict with ours,\" he said.\nHis comments come amid breakthroughs in artificial intelligence that are being achieved faster than many predicted. Google's DeepMind subsidiary defeated the world champion of the ancient board game Go earlier this year. On Wednesday, Microsoft said it had achieved voice recognition on a par with humans.\nProfessor Hawking has been one of the most high-profile sceptics about AI. He was one of more than 1,000 other experts and researchers to sign an open letter warning of the perils of artificially intelligent weapons last year.\nThe Leverhulme Centre for the Future of Intelligence is a collaboration between the Universities of Cambridge, Oxford, Imperial College London and Berkeley in California.\n                   AI timeline                   Follow Telegraph Science & TechREAD MORE ABOUT:\n"},
{"docid": "134 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "July 31, 2017", "title": "Facebook's artificial intelligence robots shut down after they start talking to each other in their own language; 'you ii ieverything else'\n", "content": "Facebook has shut down two artificial intelligences that appeared to be chatting to each other in a strange language only they understood.\nThe two chatbots came to create their own changes to English that made it easier for them to work - but which remained mysterious to the humans that supposedly look after them.\nThe bizarre discussions came as Facebook challenged its chatbots to try and negotiate with each other over a trade, attempting to swap hats, balls and books, each of which were given a certain value. But they quickly broke down as the robots appeared to chant at each other in a language that they each understood but which appears mostly incomprehensible to humans.\u00a0\nThe robots had been instructed to work out how to negotiate between themselves, and improve their bartering as they went along.\nThe actual negotiations appear very odd, and don't look especially useful:\nBob: i can i i everything else . . . . . . . . . . . . . .\nAlice: balls have zero to me to me to me to me to me to me to me to me to\nBob: you i everything else . . . . . . . . . . . . . .\nAlice: balls have a ball to me to me to me to me to me to me to me\nBob: i i can i i i everything else . . . . . . . . . . . . . .\nAlice: balls have a ball to me to me to me to me to me to me to me\nBob: i . . . . . . . . . . . . . . . . . . .\nAlice: balls have zero to me to me to me to me to me to me to me to me to\nBob: you i i i i i everything else . . . . . . . . . . . . . .\nAlice: balls have 0 to me to me to me to me to me to me to me to me to\nBob: you i i i everything else . . . . . . . . . . . . . .\nAlice: balls have zero to me to me to me to me to me to me to me to me to\nBut there appear to be some rules to the speech. The way the chatbots keep stressing their own name appears to a part of their negotiations, not simply a glitch in the way the messages are read out.\nIndeed, some of the negotiations that were carried out in this bizarre language even ended up successfully concluding their negotiations, while conducting them entirely in the bizarre language.\nThat said, it's unlikely that the language is a precursor to new forms of human speech, according to linguist Mark Liberman.\n\"n the first place, it's entirely text-based, while human languages are all basically spoken (or gestured), with text being an artificial overlay,\" he wrote on his blog. \"And beyond that, it's unclear that this process yields a system with the kind of word, phrase, and sentence structures characteristic of human languages.\"\nThe chatbots also learned to negotiate in ways that seem very human. They would, for instance, pretend to be very interested in one specific item - so that they could later pretend they were making a big sacrifice in giving it up, according to a paper published by the Facebook Artificial Intelligence Research division.\nRead more\nAI better than scientists at choosing successful IVF embryos\n(That paper was published more than a month ago but began to pick up interest this week.)\nFacebook's experiment isn't the only time that artificial intelligence has invented new forms of language.\nEarlier this year, Google revealed that the AI it uses for its Translate tool had created its own language, which it would translate things into and then out of. But the company was happy with that development and allowed it to continue.\nAnother study at OpenAI found that artificial intelligence could be encouraged to create a language, making itself more efficient and better at communicating as it did so.\n"},
{"docid": "135 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "December 30, 2015", "title": "AI will play a big part in our future, but at this stage it seems rather average; There's evidently a technological trail being blazed, but it still feels a long way from being reliably useful\n", "content": "A friend of mine has got into the habit of saying \"OK Google!\" into his phone every few minutes. The voice-activated assistant (Google Now) immediately springs into life, he asks it a question, and occasionally it gives him what he is after. The failure rate is pretty high, but he stubbornly insists that the more he uses it, the better it'll get. He's committed to the long game. He believes in a future where we'll talk freely and without embarrassment to non-human entities.\nSo do Facebook, Apple, Microsoft and Google; they're all keen to convince us that their own brand of artificial intelligence is more human-like than any competitor. In China, Microsoft's popular chatbot Xiaoice has just become a trainee anchor on live television. Facebook's personal assistant, M, continues to receive plaudits for the service it provides to a small group of California-based testers from within the Messenger app. And this week we hear that Google is also working on a instant message-driven service, responding to our questions using colloquial English. Service with a smiley.\u00a0\nThere's evidently a technological trail being blazed here, but it still feels a long way from being reliably useful. Google Now certainly has the capacity to surprise us with its uncanny sixth sense, but this has to be set against the number of times it simply doesn't come up with the goods. Artificial intelligence (AI) will undoubtedly play a big part in our future, but at this stage it seems like we're being asked to applaud services for being occasionally brilliant, but more generally speaking rather average.\nRead more\n                     Plan to bring people back from the dead with artificial intelligence                   \n                     Social psychologist Aleks Krotoski on being a troll                   \n                     AI could wipe out humanity because it's too clever, Hawking warns                   \n                     Apple buys a company that could make Siri much more human                   \n                     iPhone 6s successors to use artificial intelligence to guess what                   \nAll four companies are doing their best to persuade us of the merits of engaging in AI-driven conversation. Facebook's M service is reportedly enhanced by human \"trainers\", and those who've had first experience of using it have publicly pondered how involved these people actually are, with a strong suspicion that the more successful interactions are entirely human-driven. Microsoft has bestowed Xiaoice with \"humanity\" by using source material from social media, while Google researchers have given bots a philosophical edge by mining movie dialogue. While most of us lapse into soap opera clich\u00e9 from time to time (\"You have no right to say that\"/\"If you walk through that door you'll regret it for the rest of your life\"), conversations with bots taught by movie scripts only give the illusion of humanity. It's clever - but is it useful?\nA chat app called Telegram offers us the chance to have conversations with a number of AI bots, including @nomadbot, a \"personal travel assistant\" who can help you with getting from A to B and back. Its success, however, is not so much about results as trust; do we believe that it'll do a better job searching the internet than we would? My own doubts might be down to my belief that I'm some kind of Googling ninja, but if a bot claimed to have found the cheapest deal on a New Year's Eve hotel, my first instinct would be to say: \"I bet I can do better.\" A weary cynicism characterises my encounters with AI, particularly the tech support bots that doggedly stick to the script and remain impervious to my appeals for understanding.\nThese things will get better, of course. One day there'll be a tipping point where putting up with the erratic behaviour of a virtual assistant will be easier than searching for something ourselves. My Google Now-obsessed pal thinks we're there already - but I'm still waiting.\n                     Twitter.com/rhodri                   \n"},
{"docid": "136 of 500 DOCUMENTS\n", "source": "The Sunday Telegraph (London)\n", "date": "November 26, 2017", "title": "Gloomy economists urged to embrace rise of the robots\n", "content": "GLOOMY forecasts of weak productivity made in the Budget have been criticised for failing to take account of the potentially revolutionary impact of artificial intelligence technology. Academic research claims that economists such as those at Britain's independent Office for Budget Responsibility (OBR) do not appreciate the potential for thinking machines to transform service industries and manufacturing processes.\u00a0\nAmid mounting political concern that artificial intelligence could trigger massive job losses throughout the economy, academics at Chicago Booth and MIT's Sloane School of Management said there was \"cause for optimism\" that it would boost productivity significantly. The OBR slashed Britain's productivity forecasts last week, predicting that growth in the wealth generated by work would fail to return to pre-financial crisis levels, prolonging the squeeze on living standards.\nThe researchers say revolutions in technology will have a bigger positive impact than most economists expect.\nThey said: \"The breakthroughs of artificial intelligence technologies already demonstrated are not yet affecting much of the economy, but they portend bigger effects as they diffuse. More importantly, they enable complementary innovations that could multiply their impact.\n\"Entrepreneurs, managers and endusers will find powerful new applications for machines that can now learn how to recognise objects, understand human language, speak, make accurate predictions, solve problems, and interact with the world with increasing dexterity and mobility.\"\nThey studied the previous IT revolution and found that the gains made from computerisation of business models and processes \"were about 10 times as large as the direct investments in computer hardware itself \".\n'Entrepreneurs, managers and end-users will find powerful new applications for machines'\n"},
{"docid": "137 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "March 25, 2008", "title": "Professor Joseph Weizenbaum\n", "content": "Professor Joseph Weizenbaum, computer scientist, was born on January 8, 1923. He died on March 5, 2008, aged 85\nComputer scientist and artificial intelligence pioneer who exposed the dangers of society's reliance on digital technology\nProfessor Joseph Weizenbaum, an engineer and computer scientist, was best known for his invention of Eliza, a computer program that carried out natural language conversations with the user. The program, named after Eliza Doolittle, the heroine of My Fair Lady who learnt proper English, was an important development in artificial intelligence.\nThe program simulated a conversation between a patient and a psychotherapist, in which the computer's replies were shaped by a person's responses. Eliza allowed a person at a computer terminal, typing in plain English, to interact with the machine in a way resembling a normal conversation. The conversation was an illusion, however, because the computer was programmed simply to respond to key words and phrases. At the time Weizenbaum was amazed, and alarmed, at the extent to which people became engrossed in conversations with Eliza - they seemed not to understand that they were reacting (\"talking\") to a computer.\u00a0\nArtificial intelligence (AI) is the science and engineering of making intelligent machines, especially intelligent computer programmes. It is related to the task of using computers to understand human intelligence. Currently, the subject is loosely defined because definitions of intelligence depend on relating it to human intelligence. We cannot yet say what kinds of computational procedures can sensibly be called \"intelligent\"; some of the mechanisms of intelligence are understood, others are not.\nAI research has so far discovered how to make computers carry out only some of the mechanisms involved in intelligence. Computer programs can work effectively on those tasks that involve just the mechanisms that are currently well understood - so such programs could be described as \"intelligent to some degree\".\nA problem for AI researchers is consciousness. Consciousness gives us feelings and makes us aware of our own existence, but scientists have found it difficult getting computers to carry out even the simplest of cognitive tasks.\nThe world's most powerful supercomputer can carry out at least 200 trillion operations per second. Some scientists believe that this is approaching the processing power of the human brain, but others believe that our brains can carry out about 10,000 trillion operations per second. It may be a long time before scientists can make a truly intelligent machine - but Eliza was a first step.\nLater in his career Weizenbaum wrote, spoke and taught eloquently about the social and ethical consequences of over reliance on computers, and the power of computers in warfare and weaponry.\nJoseph Weizenbaum was born in Berlin in 1923. His father, Jechiel Weizenbaum, was a furrier. The family was forced to flee Germany in 1936 to escape Nazi persecution. They immigrated to the US.\nIn 1941 Weizenbaum began studying mathematics at Wayne State University, Detroit, but left after a year to join the US Army Air Corps, in which he served as a meteorologist. After the war he completed at Wayne, working on the development and programming of the first large computers.\nIn 1952 he left the university to work in industry, on an early General Electric computer development project for the Bank of America. He was a member of the team that designed and built the first computer system dedicated to banking operations. Among his contributions was a programming language for banks called Slip.\nIn 1962 he became a visiting professor at the Massachusetts Institute of Technology. He wrote the Eliza program in 1964-65 and described it in a technical paper in January 1966.\nIn 1970 he was appointed a professor of computer science in the Department of Electrical Engineering. He later held academic appointments at Harvard and Stanford.\nIn 1996 he returned to Germany. He became a critic of computer technology, much concerned about its political and social consequences, and was much honoured in Germany, particularly by young people. He was a popular public speaker and he held appointments at the Technical University of Berlin and the University of Hamburg. At his death he was chairman of the Scientific Council of Berlin's Institute of Electronic Business.\nIn his later years Weizenbaum concentrated on the social, ethical and political consequences of the computer technology he had helped to develop. He was passionately concerned about the relationship between the computer and the human, particularly about the awesome destructiveness of high technology used in modern weapons and their lethality when used in war.\nHis publications on science and society insist that wisdom and technical prowess are not the same, and that we confuse them at our peril. He was an inspirational teacher who stimulated many of his students to think about the social and ethical issues of computing. He was one of the founders of Computer Professionals Against the ABM, which argued against the American development of anti-ballistic missiles. He was later involved with opposition to President Reagan's Strategic Defence Initiative (Star Wars).\nIn his very influential book Computer Power and Human Reason: From Judgment to Calculation (1976), Weizenbaum gave warning that it would be both dangerous and immoral to assume that computers could eventually take over any human role and, in some cases, immoral to assume that computers would be able to do anything given enough processing power and clever programming.\nWeizenbaum was a Fellow of the American Association for the Advancement of Science and a member of the New York Academy of Science and of the European Academy of Science.\nWeizenbaum's marriage ended in divorce. Four daughters survive him.\n"},
{"docid": "138 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "September 28, 2017", "title": "Former senior Google engineer developing robot that will be worshipped as a god; The AI will be prayed to for 'the betterment of society'\n", "content": "Silicon Valley engineers are worshipping robots as gods.\nAnthony Levandowski -the man who builtGoogle's famous self-driving car-has established a religious nonprofit that appears to be something like a church devoted to the worship of artificial intelligence.\u00a0\nIt isn't clear whether the robot God already exists, what exactly it consists of and why it is being developed.But what is clear is that Mr Levandowski appears to be building his own god, in the former of artificial intelligence, which he will then encourage people to worship so that the world can be improved.\nThat's according to the founding documents of Way of the Future, a group intended to\"develop and promote the realization of a Godhead based on artificial intelligence and through understanding and worship of the Godhead contribute to the betterment of society\", according documents published by Wired. Mr Levandowski is the group's CEO and president, and it isn't clear how many members it has or what it is actually doing.\nA range of scientific experts and technology billionaires, including Stephen Hawking and Elon Musk, have warned that our relaxed attitude towards artificialintelligence could mean we're at risk of being killed by it. Mr Musk has likened artificial intelligence to \"summoning the demon\", suggesting that while we might think we could control such a force we ultimately couldn't- and has founded an organisation called OpenAI focused specifically on stopping such a thing from happening.\nRead more\nElon Musk says AI poses bigger threat than North Korea\nSometheories - like the idea of Roko's Basilisk, a mostly derided but incredibly popularthought experimentthat suggests we may be at risk from some all-powerful AI in the future - even speculate that our current actions could have some impact on how the artificially intelligent forces view us in the future.\nThe discovery comes as Mr Levandowskitakes his part at the centre of a legal battle between Uber and Google, though it was actually founded two years ago and before all that began. The engineer left Uberlast year amid claims by Google that he had stolen trade secrets and used them at his new company.\nWired, which revealed the strange new church as part of a long profile on Mr Levandowski, pointed out that his interest in self-driving cars and our robot god are far from separate from each other. The engineer is among the foremost experts on self-driving cars in the world - and those vehicles give artificial intelligence its most powerful embodiment, as well as being a look at how AI will change the world.\n"},
{"docid": "139 of 500 DOCUMENTS\n", "source": " The Independent (United Kingdom)\n", "date": "June 21, 2016", "title": "Domestic robots are a not too distant reality; When Elon Musk says, as he did this week, that his new priority is using artificial intelligence to build domestic robots, we should not only take note, but look forward to the day we can put our legs up in admiration\n", "content": "When Elon Musk says, as he did this week, that his new priority is using artificial intelligence to build domestic robots, we should not only take note, but look forward to the day we can put our legs up in admiration.\u00a0\nElon Musk is a guy who gets things done. The founder of two 'moonshot' tech companies, Tesla Motors and SpaceX, is bringing electric vehicles to mass market and enabling humans to live on other planets. Lest this strike the amateur techie - not that readers of The Independent Daily Edition would ever count among them - as so much hot air, you can be reassured that the near $13bn fortune this entrepreneur has amassed comes from practical achievements rather than hypothetical ones.\nA lot of clever people are terrified about artificial intelligence, fearing that robots will one day become so smart they'll murder all of us. These fears are mostly overblown: as with hysteria about genetic modification, we humans are generally wise enough to manage these problems with alacrity and care.\nAnd just think of how wonderful it would be if you had a live-in robot. It could - eventually - be like having a baby-sitter and masseuse rolled into one; or if that required emotional intelligence beyond the ken of Musk's imagined machine, at least some one to chop the carrots, wash the car and mow the lawn. Once purchased and trained, this would allow the casual user to save money and time, freeing up precious space in our busy lives to, for instance, read The Independent Daily Edition.\nThat is why we welcome Musk's latest venture, and wish him well. As long as robots add to the sum of human happiness, reduce suffering or cumbersome activity, and create time to read world-class journalism, \nThe Independent\n will be their fans. Especially since journalism is one job robots will never do.\n"},
{"docid": "140 of 500 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "May 23, 2006", "title": "Google boss wants to create 'artificial intelligence'\n", "content": "Google's ultimate aim is to create a search engine with artificial intelligence to exactly answer any question a user puts to it, the company declared last night.\nAt a Google \"zeitgeist\" conference, at a country house hotel in Hertfordshire yesterday, Larry Page, the co-founder and president, rebutted criticisms that the company had lost its focus on its core search engine business.\nHe said: \"People always make the assumption that we're done with search. That's very far from the case. We're probably only 5 per cent of the way there. We want to create the ultimate search engine that can understand anything ... some people could call that artificial intelligence.\"\u00a0\nMr Page, speaking to journalists after addressing the conference, said it was not possible to predict when Google would achieve this goal, although he pointed out that \"a lot of our systems already use learning techniques\".\nHe also attacked opponents of the company who accuse it of violating copyright and stealing others' content.\n\"A business negotiation is going on, with lawsuits and people feeding misinformation out,\" Mr Page said. \"In my opinion, this is about money.\"\nGoogle is undertaking a controversial project to scan every book in some of the biggest libraries in the world. Mr Page said the company would not provide that content to user sunless it had the approval of the copyright owner. The scheme would produce a web-based card catalogue instead.\n\"We follow copyright laws. Where we don't have permission, we won't show you the content,\" Mr Page said.\nMr Page and his chief executive, Eric Schmidt, who was also addressing the event, said Google's revenues could grow exponentially, as it had tapped a tiny proportion of the $800bn (pounds 424bn) global advertising market.\nMr Schmidt pointed that advertising that was targeted for web searches only accounted for 0.5 per cent of the market.\n\"Our category of advertising is showing 50 to 100 per cent growth. Other categories are not growing. Market share [for web search advertising] will never be 100 per cent, but I can imagine 5, 10, 15 or 20 per cent.\"\n"},
{"docid": "141 of 500 DOCUMENTS\n", "source": "DAILY MAIL (London)\n", "date": "June 28, 2017", "title": "WORKERS TO BE REPLACED IN THE ROBOT REVOLUTION\n", "content": "MILLIONS of British workers could find themselves replaced by robots, according to a study by PwC.\nIn a workplace revolution, computers with artificial intelligence are increasingly being used by companies in place of humans.\u00a0\nIt is a sector that could be worth \u00a3222bn to the economy by 2030, the auditor predicts, and is expected to prompt a complete rethink about how employees spend their time.\nUp to 30pc of workers - or about 10m people - could be affected, it was estimated. Instead of driving lorries from the vehicle's cab, for example, hauliers could allow machines to do most of the route before taking over remotely when they reach busy areas or to carry out tricky manoeuvres.\nMachines could also help surgeons carry out operations or read scan results in hospitals, draw up contracts for law firms, manage stock rooms for supermarkets and raise your insurance premiums based on vast amounts of number-crunching.\nAlastair Bathgate, chief executive of artificial intelligence software firm Blue Prism, said: We are trying to transform the future of work and to digitise the workplace.'\nThe firm's software is used in 271 of the world's largest organisations. Revenue in the first six months of the year was \u00a39.3m, up 133pc from the same period a year ago. But Bathgate said workers shouldn't fear the rise of the robots.\nHe said: It is very rare you see humans losing jobs because of artificial intelligence.\nInstead, what you find is that people are freed up from boring or mundane jobs that they don't want to do.'\nEuan Cameron, a PwC partner known as the firm's robot whisperer', agrees but adds that the take-up of artificial intelligence in the UK is behind rivals.\nHe said: In a world of administrative AI you have the machines take decisions for you, which can be a scary thing for management.'\n\u00a9 Daily Mail\n"},
{"docid": "142 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "January 21, 2018", "title": "As technology develops, so must journalists' codes of ethics; AI is sure to bring many benefits but concerns over its ability to make decisions mean human journalists' input remains vital\n", "content": "Journalism is largely collaboration: reporters with sources, writers and editors, lawyers advising publishers, producers with distributors, and audiences feeding back their knowledge. Rapid development of artificial intelligence means journalists are likely to collaborate more and more with machines that think. The word itself, machines, feels so industrial era, but \"robots\" feels too limited. Humans are busy building brains, if not yet minds. So my shorthand for now is AI.\n Related:  The real risks of artificial intelligence\u00a0\nUses of AI in journalism are being explored, analysed and launched. Like humans - sometimes better than humans - AI can absorb information, sift it, analyse it, and make decisions and speak or write. But decision-making in journalism often involves ethical choices based on long-held values, guided by published editorial standards. The results can be held accountable against those standards. Authentic accountability processes help maintain the trust on which the public democratic usefulness of journalism depends.\nOur ideas about accountability are based on the assumption that explanation is possible. Called to account, we explain. A court gives reasons for judgment; ministers answer questions in parliament; statutory regulators make annual reports; and in journalism, someone like a readers' editor handles complaints.\nSome AI may be unable to meet this expectation. As the author of \" Can AI be taught to explain itself ?\" in the New York Times put it: \"Artificial intelligences often excel by developing whole new ways of seeing, or even thinking, that are inscrutable to us...[The] inability to discern exactly what machines are doing when they are teaching themselves novel skills... has become a central concern in artificial-intelligence research.\"\nThe audience could lose trust on two grounds: provision of poor quality information, and failure to manage the AI\nAI collaboration poses ethical issues for, among others, courts that use it in sentencing, for operators of weapons systems, and for medical specialists. The potential benefits of AI, together with the widespread recognition that the accountability of AI decision-making matters greatly, give me confidence that the challenge of making AI accountable to humans will be met. Until it is, each collaboration requires attention. In journalism, the long-unchanging codes of ethics need to be revisited to make specific provision for this transitional era. A clause something like: \"When using artificial intelligence to augment your journalism, consider its compatibility with the values of this code. Software that 'thinks' is increasingly useful, but it does not necessarily gather or process information ethically.\"\nDevelopments in AI are too rapid and varied. For the time being, codes could simply require that when AI is used the journalists turn their minds to whether the process overall has been compatible with fundamental human values.\nTo illustrate how AI issues might engage standards found in most journalism codes - some AI is \"trained\" with large datasets that may themselves be of dubious accuracy. If journalism based on AI-assisted research turns out to be significantly in error, the audience could lose some trust in the media outlet on two grounds: provision of the poor quality information; and failure to manage properly the AI through which the information was partly generated.\n Related:  AI is already making inroads into journalism but could it win a Pulitzer?\nSome AI-processed data can be tainted with ethnic, gender or other types of bias because of assumptions that humans built in, consciously or otherwise. Journalism that relies on such output might also adversely discriminate.\nAI might produce newsworthy material from data that it gathers in invasive ways. That doesn't necessarily preclude use of the information, depending on its public interest value. But it does require careful consideration in context. For many years, journalism codes have required that use of subterfuge should pass high tests of necessity and public interest. This is because trust is put at risk when people who say they are pursuing truth use deceit. One way to address the risk to trust is transparency about methods, including the way AI plays its part in the story.\n\u00b7 Paul Chadwick is the Guardian readers' editor\n"},
{"docid": "143 of 500 DOCUMENTS\n", "source": " The Independent (United Kingdom)\n", "date": "April 5, 2016", "title": "Facebook artificial intelligence technology lets blind people 'see' photos; The tool is called \"automatic alt text\", and is available now on iOS and is coming to Android and the web soon\n", "content": "Facebook is using artificial intelligence to understand what is in a photo and \"read\" it to people who otherwise wouldn't be able to see it.\nThe new accessibility technology is intended to allow blind and visually-impaired people to share and take part in photos on Facebook.\u00a0\nUsing artificial intelligence, the new tool can recognise the contents of a photo. It won't immediately be able to do that in great deal - it will read out that a picture includes a \"car\", for instance - but because it uses machine learning, it is expected to improve itself as it goes along.\nSuch technology is already in use in tools like Google Photos and Flickr. But that has occasionally gone wrong, describing sensitive pictures with inflammatory language - and so Facebook's tool will only read something out if it is 80 per cent sure and will be extra-cautious if it identifies the picture as being a sensitive case, reports The Verge.\nBlind people usually use a \"screen reader\" to navigate the internet and their computer by having it read out what is shown on the screen, and such a tool is included in iOS's VoiceOver feature. Sites such as Twitter have introduced ways of having people describe picture for those using such technology - but the new Facebook tool allows the site to do so automatically.\nThe feature is available now on iOS and will be coming to Android and the web soon.\nFacebook says that photos are perhaps the biggest reason for the site's huge growth, and it hopes that the new feature will allow more of its users to get involved with them. It is the latest in a run of tools intended to open up Facebook's most popular features, which have also included closed captions for its videos and an option to increase the font size.\nFacebook has previously said that its artificial intelligence work is likely to spread across the service. That might also include adding tools that will scan a photo and check whether it is likely to be offensive to other users, and so add a warning.\n"},
{"docid": "144 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "February 21, 2017", "title": "What our original drama The Intelligence Explosion tells us about AI; How do you stop a robot from turning evil? Our drama raises important questions about the ethics of artificial intelligence, says Alex Hern\n", "content": "The Intelligence Explosion, an original drama published by the Guardian, is obviously a work of fiction. But the fears behind it are very real, and have led some of the biggest brains in artificial intelligence (AI) to reconsider how they work.\nThe film dramatises a near-future conversation between the developers of an \"artificial general intelligence\" - named G\u00fcnther - and an ethical philosopher. G\u00fcnther himself (itself?) sits in, making fairly cringeworthy jokes and generally missing the point. Until, suddenly, he doesn't.\u00a0\nIt shows an event which has come to be known in the technology world as the \"singularity\": the moment when an artificial intelligence that has the ability to improve itself starts doing so at exponential speeds. The crucial moment is the period when AI becomes better at developing AI than people are. Up until that point, AI capability can only improve as quickly as AI research progresses, but once AI is involved in its own creation, a feedback loop begins. AI makes better AI, which is even better at making even better AI.\nIt may not end with a robot bursting into a cloud of stars and deciding to ascend to a higher plane of existence - but it's not far off. A super-intelligent AI could be so much more intelligent than a human being that we can't even comprehend its actual abilities, as futile as explaining to an ant how wireless data transfer works.\nSo one big question for AI researchers is whether this event will be good or bad for humanity. And that's where the ethical philosophy comes into it.\nDr Nick Bostrom, a philosopher at the University of Oxford, presented one of the most popular explanations of the problem in his book Superintelligence. Suppose you create an artificial intelligence designed to do one thing - in his example, running a factory for making paperclips. In a bid for efficiency, however, you decide to programme the artificial intelligence with another set of instructions as well, commanding it to improve its own processes to become better at making paperclips. \nFor a while, everything goes well: the AI chugs along making paperclips, occasionally suggesting that a piece of machinery be moved, or designing a new alloy for the smelter to produce. Sometimes it even improves its own programming, with the rationale that the smarter it is, the better it can think of new ways to make paperclips.\nBut one day, the exponential increase happens: the paperclip factory starts getting very smart, very quickly. One day it's a basic AI, the next it's as intelligent as a person. The day after that, it's as smart as all of humanity combined, and the day after that, it's smarter than anything we can imagine.\nUnfortunately, despite all of this, its main directive is unchanged: it just wants to make paperclips. As many as possible, as efficiently as possible. It would start strip-mining the Earth for the raw materials, except it's already realised that doing that would probably spark resistance from the pesky humans who live on the planet. So, pre-emptively, it kills them all, leaving nothing standing between it and a lot of paperclips.\nThat's the worst possible outcome. But obviously having an extremely smart AI on the side of humanity would be a pretty good thing. So one way to square the circle is by teaching ethics to artificial intelligences, before it's too late.\nIn that scenario, the paperclip machine would be told \"make more paperclips, but only if it's ethical to do so\". That way, it probably won't murder humanity, which most people consider a positive outcome.\nThe downside is that to code that into an AI, you sort of need to solve the entirety of ethics and write it in computer-readable format. Which is, to say the least, tricky.\nEthical philosophers can't even agree on what the best ethical system is for people. Is it ethical to kill one person to save five? Or to lie when a madman with an axe asks where your neighbour is? Some of the best minds in the world of moral philosophy disagree over those questions, which doesn't bode well for the prospect of coding morality into an AI.\nProblems like this are why the biggest AI companies in the world are paying keen attention to questions of ethics. DeepMind, the Google subsidiary which produced the first ever AI able to beat a human pro at the ancient boardgame Go, has a shadowy ethics and safety board, for instance. The company hasn't said who's on it, or even whether it's met, but early investors say that its creation was a key part of why Google's bid to acquire DeepMind was successful. Other companies, including IBM, Amazon and Apple, have also joined forces, forming the Partnership on AI, to lead from the top.\nFor now, though, the singularity still exists only in the world of science fiction. All we can say for certain is that when it does come, it probably won't have G\u00fcnther's friendly attitude front and centre.\n"},
{"docid": "145 of 500 DOCUMENTS\n", "source": " The Independent (United Kingdom)\n", "date": "April 13, 2016", "title": "Google Calendar 'Goals' update uses artificial intelligence to make its users into better people; The tool aims to make it easier for people to improve themselves, by scheduling 'reading more books, learning a new language, or working out more regularly', as well as any other regular activity\n", "content": "                     Google has introduced a new tool to its Calendar, intended on making its users into better people.\nThe new tool, called Goals, uses artificial intelligence to help people schedule in time to fulfil their aspirations -including learning new languages and doing exercise.\u00a0\nThe feature looks through people's calendar, finds times when they might be free, and then adds in time for them to do the things that they might not otherwise get to.\nWhen a user opts to add something into their schedule, they pick a specific activity like \"work out more\" and are then asked a series of questions. Those include how often something needs to happen, and how long it will last. Once all of those are answered, the app will look at the schedule and set a time.\nOnce they are scheduled in, Google's algorithms can use their artificial intelligence to ensure that people are still able to make them.\nIf something comes up and gets in the way of time that had been previously scheduled for meeting a goal, for instance, the app will automatically reschedule the event to another time when its user is free. Or if there isn't time to meet a goal, it can be deferred and the app will schedule it in again.\nThe app will then learn from when people tend to defer or complete their goals, and use that information to schedule them better in the future. If someone tends not to be able to finish their goals on Tuesday nights, for instance, but can do them on Thursday mornings, it will try and add future events into that slot.\nThe new feature, which was introduced to celebrate Google Calendar's tenth birthday, is available now in the iPhone and Android versions of the app.\n"},
{"docid": "146 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "October 4, 2017", "title": "Tech pioneer founds new religion to worship AI god\n", "content": "Young people are often accused of worshipping technology and will now have a chance to do so for real after a Silicon Valley millionaire founded a new religion with artificial intelligence as its God.\u00a0\nTaking inspiration from the belief that the intelligence of computers will eventually surpass that of human beings, the man who helped to design driverless cars for Google aims to create a new God based on computerised artificial intelligence, or AI.\nAnthony Levandowski, the engineer at the centre of a lawsuit between Google and Uber, founded an organisation called Way of the Future, according to recently unearthed documents. The documents, discovered by Wired magazine and filed in 2015, state that the religion's aim is: \"To develop and promote the realisation of a Godhead based on artificial intelligence and through understanding and worship of the Godhead contribute to the betteror ment of society.\" The concept of superintelligent computers overtaking human intelligence is often referred to as the \"singularity\". It is believed that such a development would trigger an unstoppable chain of events where computers would be able to upgrade and improve themselves.\nThe theory straddles the worlds of reality and science fiction, but a number of leading scientists have expressed concern at the development of powerful AI, with Stephen Hawking warning last year that it will be \"either the best, the worst thing, ever to happen to humanity\". Elon Musk, the CEO of Tesla and developer of new space rocket technology, has warned that AI poses \"vastly more risk than North Korea\" to world peace and stability.\nMr Levandowski is currently at the centre of a legal battle after Waymo, Google's subsidiary for developing selfdriving cars, claimed Mr Levandowski used files acquired from Waymo to set up a new self-driving truck company called Otto, which was later acquired by Uber. He denies the claims.\n"},
{"docid": "147 of 500 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "June 23, 1988", "title": "Computer Guardian: Machine dreams - Recent Artificial Intelligence books\n", "content": "\u00a0\n The assumption behind reviewing a pile of AI books is that there is a coherent discipline called 'Artificial Intelligence' in the same way as 'physics' or 'geography' or 'logic' have fairly clear, defined boundaries. However, reading them all, more or less one after the other, reveals that the phrase is being used for a wide variety of only very loosely connected preoccupations.\n At its most trivial, AI is simply another example of computer-marketing-speak, a fashionable attribute to add to a product blurb along with '4GL,' 'user-friendly' and so on - features which sound good but lack sufficiently precise definition so that no disgruntled customer can sue because of their absence.\n\n But, going through these books, notepad at the ready, one can identify much more rigorous claims. Depending on which you read, AI's role is:\n to examine computer technology as a means of defining what is meant by intelligence as opposed to instinct;\n to provide tests for intelligence as opposed to simple mechanical reaction;\n to explain brain function (or ratiocination) as an analogy of computers;\n to teach cognitive skills to computers;\n to develop methods of complex pattern recognition (for example in computer-aided vision, speech recognition and natural language processing);\n to write learning programs for knowledge acquisition and retrieval - the expert system;\n to develop smarter information retrieval packages which locate data other than by exhaustive examination, but by forms of contextual searching;\n to develop parallel processing architectures.\u00a0\n All of these are interesting areas; the trouble is that there is no over-arching intellectual rigour. Using the same phrase misleads people into believing that there is - and also makes them needlessly worried about what would happen to humans if 'scientists' were ever able to produce a genuine AI machine, whatever that is.\n By far the best of this bunch, for the moderately computerate, is Igor Aleksander's Thinking Machines, which contains lucid explanations of techniques for contextual searching and the requirements of pattern recognition. Unfortuantely, the book suffers from over-packaging.\n I think I can understand the role of co-author Piers Burnett, but all the other organisations and people whose names cover the reverse of the title page seem to have conspired to fill the book with messy illustrations that require half-page captions. If OUP could give us a text-only paperback version, it would be highly recommended.\n It is still very tricky for writers about computer matters to decide precisely how to set their editorial pitch: how much can you reasonably assume your readers already know?\n Geogre Johnson, in his Machinery of the Mind - already garlanded with favourable US reviews - believes there is a non-computer-literate audience out there that wants to know about AI. He tries jolly hard to please it, but is inevitably stuck with having to provide lengthy narrative on traditional material from mathematical and computer history.\n However, if you feel able to skip this, his tour around the usual AI landmarks - the Turing Test, the Dartmouth Conference of 1956, the electronic (pseudo) pyschiatrist program Eliza, the early expert system Dendral - is put together with a real sense of intellectual discovery. I commend his accounts of the debates between sceptics and enthusiasts of AI, even if he never really addresses the issue of the subject's boundaries\n By contrast, Jeffrey Rotherfeder is one of those popular science authors who seems to believe that lively writing depends largely on telling us that such-and-such an academic researcher has curly hair, or a chaotic office. Minds Over Matter looks as though it was aimed at US campus bookstores and makes frequent use of display paragraphs and reconstructed conversations.\n The best part is about AI research funding. Around 1973 the Pentagon became convinced that AI was the key to better target acquisition, both for air-fired missiles and from robotic vehicles. The research community's quest for funds being what they are, about half the scientists in the US stated that their work was astonishingly relevant to AI. Perhaps that is why AI today has such a diversified subject-area.\n\u00a0Artificial Intelligence - The Very Idea by John Huageland is another US campus book, this time written for a liberal arts audience by an Associate Professor of Philosophy whose reading obviously has not included the logical positivists. No philosophy teacher has any business writing 'AI wants only the genuine article: machines with minds in the full and literal sense.'\n AI in the 1980s and Beyond is a MIT Survey edited by W Eric L Grimson and Ramnesh S Patil and contains a number of useful specialist articles.\n\u00a0Artificial Intelligence, Pergamon Infotech State of the Art Report, doesn't live up to its tile. These are academic articles published largely to impress other academics.\n My own experience, however, is that the best AI explanations are not in books at all, but in the various special editions of magazines like Byte: cheaper, more relevant, more practial and more up-to-date often than anything reviewed here.\n BOOKS REVIEWED:\n Thinking Machines: The Search for Artificial Intelligence. Igor Aleksander and Piers Burnett. Oxford University Press. Pounds 15.\n Machiner of the Mind: Inside the new science of artificial intelligence. George Johnson. Microsoft Press. Pounds 7.95\n Minds Over Matter. Jeffrey Rothfeder. Harvester press Pounds 20 (hardback) Pounds 7.95 (paperback)\n\u00a0Artificial Intelligence: The Very Idea. John Huageland. The MIT Press. Dollars 14.95\n AI in the 1980s and Beyond. An MIT Survey. The MIT Press. Pounds 22.50\n\u00a0Artificial Intelligence. State of the Art Report, ed. J R Ennals. Pergamnon Infotech. Pounds 245.\n"},
{"docid": "148 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "June 10, 2014", "title": "'Captain Cyborg': the man behind the controversial Turing Test claims; Kevin Warwick, a professor of cybernetics at Reading University who implanted a microchip into his arm, is being scrutinised by scientist over his claims that a computer passed the \"Turing Test\"\n", "content": "A controversial scientist who has been known as \"Captain Cyborg\" since he implanted a chip into his nervous system is facing criticism over claims that a computer passed a \"milestone\" test for Artificial Intelligence. \nKevin Warwick, a professor of cybernetics at Reading University, called his recent experiment in which a computer fooled humans in the Turing Test an \"important landmark\", but scientific opposition is gathering. \nProf Warwick made headlines when the university claimed the 65-year old Turing Test was passed for the first time by a \"supercomputer\" called Eugene Goostman at an event organised by Prof Warwick at the Royal Society in London. \u00a0\nTen out of thirty human judges believed they were speaking to a real teenage boy during a five minute period, so the experiment was hailed as a victory. \nHowever, other experts said the announcement trivialised \"serious\" AI (Artificial Intelligence) research, and fooled people into believing that the world of science fiction could soon become science fact. \nProf Warwick is considered a maverick among the science community. He first had a microchip implanted in his arm that triggered a greeting from computers each day when he arrived at work. \nThe scientist later implanted sensors and a microchip into the nerves in his arm, similar to an implant he also gave to his wife, so that when someone grasped her hand Prof Warwick was able to experience the same sensation in his. \nHe claimed it was a form of telepathy as it allowed his nerves to feel what she was feeling over the internet, but the work was controversial among other scientists as they doubted whether his experiments were much more than entertainment. \nThe latest announcement that the Turing Test has been passed for the very first time has been met with yet more scepticism. \nProf Warwick said: ''In the field of Artificial Intelligence there is no more iconic and controversial milestone than the Turing Test. \n\"This milestone will go down in history as one of the most exciting.'' \nHowever, Professor Murray Shanahan, a professor of cognitive robotics at Imperial College London, said there were \"a lot of problems\" with the claims. \nThe scientist said that as Eugene was described to judges as a 13-year-old boy from Ukraine who learned English as a second language, some of the bizarre responses to questions could be explained away. \nHe said the five-minute conversation benchmark was \"taken out of context\" from the Turing Test, and fell well short of a true experiement for Artificial Intelligence, which should last for \"hours, if not days\". \nHe also said the 30-strong judging panel, which included Robert Llewellyn, the Red Dwarf actor, was not big enough to support the claim. \nProf Shanahan told the Telegraph: \"I think there are a lot of problems with the claims and I do not believe the Turing Test has been passed. \n\"I think the claim is completely misplaced, and it devalues real AI research. It makes it seem like science fiction AI is nearly here, when in fact it's not and it's incredibly difficult.\"\nProf Shanahan added that the \"supercomputer\" was in fact a chatbot, a computer programme, rather than a powerful machine. \nGary Marcus, a professor of cognitive science at New York University, said in an article for the New Yorker: \"Here's what Eugene Goostman isn't: a supercomputer. \n\"It is not a ground-breaking, super-fast piece of innovative hardware but simply a cleverly-coded piece of software.\"\nProf Warwick told the Telegraph: \"I think they're just pointing fingers. It's a particular aspect of Artificial Intelligence research. It's an iconic test, it's controversial, as we can see.\n\"I don't think it devalues other Artificial Intelligence. If anything, I would say if it excites a few children, then I think it's a good thing.\"\n"},
{"docid": "149 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "November 3, 2017", "title": "Google DeepMind is making artificial intelligence a slave to the algorithm; Google's role in university artificial intelligence courses alarms Sheila Hayman\n", "content": "Your article ( Hi-tech brain drain threatens British university research, 2 November) contains one particularly chilling revelation: that Google DeepMind now runs artificial\u00a0intelligence courses at UCL and Oxford.\u00a0\nHaving met the DeepMind people in my role with the MIT Media Lab, I know that their definition of \"intelligence\" is so impoverished that it doesn't extend beyond the abstract calculations that an algorithm can achieve, and completely fails to understand that human intelligence is embodied and distributed throughout our physical selves - and indeed between them, in the mirror neurons that fire in sympathy when we watch a dancer or help an injured friend. In short, it's not just depressing, it's bad science.\nArtificial\u00a0intelligence of the kind Google promotes can play Go and even - at a pinch - recognise Bach or Picasso. It can never produce Bach or Picasso, still less understand the complexity of social forms and culture that made their lives possible.\nIf we entrust the education of those who will determine the future relationship of people and machines to a company whose core belief is that all human experience can be replicated by algorithms, all we can hope is that global warming wipes us out before the machines do. Sheila HaymanDirector's fellow, MIT Media Lab\n                       \u00b7 Join the debate - email                         guardian.letters@theguardian.com                                        \n                       \u00b7 Read more Guardian letters -                         click here to visit gu.com/letters                                        \n"},
{"docid": "150 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "June 16, 2017", "title": "Facebook using artificial intelligence to combat terrorist propaganda\n", "content": "                     Facebook has spoken for the first time about the artificial\u00a0intelligence programmes it uses to deter and remove terrorist propaganda\u00a0online after the platform was criticised for not doing enough to tackle extremism.\u00a0\u00a0\nThe social media giant\u00a0also revealed it is employing 3,000 extra people this year in order to trawl through posts and remove those that break the law or the sites' community guidelines.\nIt also plans to boost it's \"counter-speech\" efforts, to encourage influential voices to condemn and call-out terrorism online to prevent people from being radicalised.\u00a0\nIn a landmark post titled \"hard questions\", Monika Bickert, Director of Global Policy Management, and Brian Fishman, Counterterrorism Policy Manager explained Facebook has been developing artificial intelligence to detect terror videos and messages before they are posted live and preventing them from appearing on the site.\u00a0\nThe pair state: \"In the wake of recent terror attacks, people have questioned the role of tech companies in fighting terrorism online. We want to answer those questions head on.\"\nExplaining how Facebook works to stop extremist content being posted the post continues: \"We are currently focusing our most cutting edge techniques to combat terrorist content about ISIS, Al Qaeda and their affiliates, and we expect to expand to other terrorist organizations in due course.\n\"When someone tries to upload a terrorist photo or video, our systems look for whether the image matches a known terrorism photo or video. This means that if we previously removed a propaganda video from ISIS, we can work to prevent other accounts from uploading the same video to our site.\n\"We have also recently started to experiment with using AI to understand text that might be advocating for terrorism.\" Facebook also detailed how it is working with other platforms, clamping down on accounts being re-activated by people who have previously been banned from the site and identifying and removing clusters of terror supporters online.\u00a0\u00a0\u00a0\nThe social media platform, which is used by billions of people around the world, also explained it employs thousands of people to check posts and has a dedicated counter-terrorism team.\n\"Our Community Operations teams around the world - which we are growing by 3,000 people over the next year - work 24 hours a day and in dozens of languages to review these reports and determine the context. This can be incredibly difficult work, and we support these reviewers with onsite counseling and resiliency training,\" it said.\u00a0\nFacebook came under pressure from ministers after a number of recent terror attacks for failing to do more tackle and remove extremist posts.\u00a0\nAmber Rudd, the Home Secretary, said earlier this year: \"Each attack confirms again the role that the internet is playing in serving as a conduit, inciting and inspiring \u00adviolence, and spreading extremist \u00adideology of all kinds,\" she writes.\n\"But we can't tackle it by ourselves ... We need [social media companies] to take a more proactive and leading role in tackling the terrorist abuse of their platforms.\"\n"},
{"docid": "151 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "June 1, 2017", "title": "Morgan's cool head can give England edge in tight finish\n", "content": "What relevance have the ancient Chinese board game of Go and Google's artificial intelligence company, DeepMind, to the battle for the Champions Trophy, which begins today? A brutal tournament in which one slip-up brings potential elimination puts a premium on those who can hold their nerve under pressure - and for a lesson in that let's start with a 19-year-old prodigy, and the (human) master of Go, Ke Jie.\nRecently, DeepMind pitched its computer programme, AlphaGo, against Ke, in the latest attempt to prove the relative impotence of the human mind. The outcome? A whitewash for artificial intelligence (and for another prodigy, DeepMind's founder, Demis Hassabis, who has long championed artificial intelligence) but not before Ke had given a glimpse of the difficulties of controlling emotions to make sound decisions - something sportsmen are challenged to do on a daily basis.\u00a0\nFor more than a hundred moves, Ke had played what was described as a \"perfect\" game. Then he made a fatal mistake: he turned his thoughts momentarily to the end game and the result, rather than concentrating on, to use a cricketing clich\u00e9, one ball at a time. Looking at his position mid-game, he suddenly fancied his chances: \"I became very excited,\" he said, \"and could feel my heart pounding. Maybe I was too excited. I made some stupid moves. Maybe that's the weakest part of human beings.\"\nSportsmen and women everywhere would have sympathised. Who has not been caught up in the emotion and thrill of the moment and taken their eye off the ball? Who has not imagined the cool champagne bubbles slipping down the throat before victory has been earned? Which batsman has not imagined the roar of the crowd and wondered about his celebration, only to slip up in the 90s. Which of us, from time to time, has not lost control momentarily, only to find it elusive thereafter? Before this tournament began, Eoin Morgan, the England captain, talked at length about his efforts to control his emotions during one-day games, both as batsman and captain. Impetuous as a young man, he is regarded now as ice cool under pressure, where his blank facial expressions give nothing away. At the crease, or when standing at mid-off pondering the hundreds of decisions a captain must make during every match, it is hard to tell what he is thinking, just as it is hard to tell, looking at his expression, whether his team are winning or losing. He has a good poker face.\nIt was a poker face that did not crack during South Africa's run chase at the Ageas Bowl last Saturday when England sneaked home in the last over. It was noticeable how much Morgan tried to slow proceedings down in the final stages, in contrast to the final over of the World Twenty20 in India in April last year, when Ben Stokes rushed an ultimately unsuccessful over against West Indies. Chatting frequently to Mark Wood, who bowled the final over in Southampton, the clarity of purpose and plan was evident.\nIn that, Morgan tries to emulate some of the finest one-day captains and batsmen who have excelled at the art of finishing games - the aspect of a match for batsmen, bowlers and captains that is surely the ultimate in putting yourself under pressure. MS Dhoni, who lifted the Champions Trophy for India four years ago, was an excellent one-day captain whose ability to lower his heart rate during a manic run chase and make cool, calculated decisions was as important to his success in one-day cricket as it was, at times, detrimental to his captaincy in Test cricket, when he tended to drift somnolently with the flow rather than making things happen.\nMichael Bevan, the Australia left-hander, was one of the best chasers in one-day cricket from a previous generation. Of the many matchwinning innings that he played, one stood out, against England in Port Elizabeth, during the 2003 World Cup, after his team had slumped to 135 for eight, chasing 205 to win. When he finally hit the winning runs, his reaction was emotionless. His brain had been working like a computer - measuring angles, calibrating gaps and working out run rates - so that it was not until a long while afterwards that emotion overran such deliberate calculation.\nOne-day cricket is so frenetic that the best players try to make calculated rather than emotional decisions. An example of a failure to think straight came at the end of surely one of the best one-day games of them all, when South Africa failed to beat Australia in the World Cup semi-final at Edgbaston in 1999, after needing one run off the final four balls of the game. It was as if Lance Klusener and Allan Donald had a malfunction - a virus that infected their computer programme and sent it into meltdown at the crucial moment.\nMorgan has had to work hard to develop his sangfroid. Before England's series against South Africa he said: \"I used to be hot-headed and made a lot of bad decisions. When I moved with the ebb and flow of the game I found it very draining. It didn't work for me. I practise at training and before big games and big series and I know what works for me now. It is about having clarity in all that I am doing.\"\nHe sees Stokes as someone who has fought a similar internal battle, if perhaps with not quite the same conscious deliberation. Of Stokes, he said: \"He's always been known as a hot-headed guy but when I look at him now and compare him to how he was a few years ago, he is really relaxed. When he was effing and blinding and throwing things around, people said he was 'passionate' - but is that good for Ben? I don't think so.\" A damaged locker in the Caribbean was indicative of that.\nIt's a tough balance to find. Stokes's competitiveness is central to his game, but you can want something too badly, to the point at which you lose control and make poor decisions. In one-day cricket, with the clock ticking, the noise of the crowd growing and victory so close that you can almost touch it, the need to make good decisions under pressure is paramount - and ultimately this may be a decisive factor in a tournament in which the margins will be fine.\nThe greatest cricketer of them all, Sir Don Bradman, spelt out what he saw as the ideal temperament for a batsman in his book, The Art of Cricket. In it, he analysed the tricky balance of trying to tap into and use the emotion of an occasion, while maintaining control at the same time. \"I always liked the player who was really very thrilled under the surface but who kept his emotions under control ... he is the man for the occasion,\" he wrote.\nMorgan was asked once by this newspaper to describe a time when nerves did get the better of him. He had to think long and hard, before mentioning a drive he had taken with his brother, a part-time rally driver, along a coastal road in County Donegal. \"There was a drop of 250 feet on one side and we were flying. Now that did get me going,\" he said.\nWith one defeat potentially costly, the road to the Champions Trophy final is tricky and dangerous, just like that Atlantic drive in Donegal. In Morgan, England are likely to have a driver who will keep his head: not quite the AlphaGo of cricket, but in terms of cool calculation, not far off.\n"},
{"docid": "152 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "September 28, 2016", "title": "A supercomputer just made the world's first AI-created film trailer - here's how well it did; The trailer for sci-fi film 'Morgan' has been makingwavesbecause it is the first to be created entirely by artificial intelligence\n", "content": "More people have been talking about the trailer for the sci-fi/horror film \nMorgan\n than the movie itself. Thisis partly because the commercial and critical response to the film has been less than lukewarm, and partly because the clip was the first to be created entirely by artificial intelligence.\nAt the request of the filmmakers at 20th Century Fox, scientists atIBM used theirsupercomputer 'Watson' to build a trailer from the final version of \u00a0\nMorgan,\n which tells the story of an artificially created human. First Watson was fed background information on the horror genre in the form of a hundred film trailers.\nIt used visual and aural analysisto identify the images, sounds, and emotions that are usually found in frightening and suspenseful trailers.\nRead more\nMachine Of Human Dreams explores how AI could overtake mankind\nWatson then analysed \nMorgan\n and identified the key moments of plot action from which a trailer of the film could be generated. Only the final act of putting the sounds and images together to create the trailer required human intervention.\nSo how did Watson do? The trailer features the familiar visual and narrative devices that have been the staple of horror film: the reclusive \"mad\" scientist, the businesslike \"investigator\", the eerie soundtrack including the main theme and a lullaby that evokes themes of childhood and innocence (contrasted with images of physical violence and bloodshed).\nIndeed, the iconography featured in Watson's trailer reaffirms what many film theorists say are the generic conventions of horror films, based on iconic examples such as the 1931 version of \nFrankenstein\n.\nBut is the purpose of a film trailer just to repeat the generic conventions that characterise a film? While some trailers clearly do this, or simply trumpet the presence of star actors, others highlight the film's spectacular possibilities. Early film trailers often described the wonders of the emerging technology of cinema such as synchorised sound (Vitaphone) and Technicolor and many still underline the historical moment of the film. Others focus on explaining the story and conveying the movie's look, feel and themesfor the prospective audience.\nCapturing horror themes\nThe Watson trailer for \nMorgan \nsucceeds in identifying the aesthetic and thematic motifs of the film, as well as the emotional charges that underpin them. For example, it references a trope of the horror genre made familiar by films such as \nThe Exorcist\n (1973) and \nThe Omen\n (1976), which dispels the presumed innocence of children. In the Watson trailer we see this represented with images of \nMorgan\n's first birthday contrasted with images of bloody violence. Meanwhile, the use of lines of dialogue such as \"I have to say goodbye to mother\" is clearly based on the supercomputer's ability to identify Freudian themes from well known examples in the horror genre, most notably \nPsycho\n (1960).\nWhat Watson doesn't do is give viewers a clear understanding of the story (or provide any of the other historical functions of Hollywood trailers). The difference becomes obvious if you compare the Watson-made trailer tothe film's \"official\" (human-made) clip, which reveals three narrative threads to the storyline, as well as using many of the stock motifs identified by Watson.\nRead more\nGoogle's new artificial intelligence can't understand these sentences. Can you?\nFacebook artificial intelligence technology lets blind people 'see' photos\nGoogle Deepmind artificial intelligence beats world's best Go player Lee Sedol in landmark game\nArtificial\u00a0intelligence 'should be used to give children one-on-one tutoring'\nBy showing clips of three different parts of the story, the official trailer creates a series of enigmatic questions to arouse the viewers'interest.\nWhat is kept behind the scratched glass wall? What kind of creature is the titular artificial being \nMorgan\n? Will the danger implied by the images of death be contained?\nThe Watson trailer doesn't manage such a sophisticated retelling of the story. Based on its analysis of horror movie trailers, the supercomputer has created a striking visual and aural collage with a remarkably perceptive selection of images. But the official trailer is more than a random collection of visual and sound motifs. It is a film about the film, and is structured to communicate with its intended viewership by using a gift that the supercomputer doesn't yet possess - the gift of narrative.\nThis article was first publishedin The Conversation (theconversation.com).Suman Ghosh is a senior lecturer in film studies,Bath Spa University\n"},
{"docid": "153 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 27, 2014", "title": "Google buys British artificial intelligence firm DeepMind; Google has bought UK start-up DeepMind for a rumoured $400 million\n", "content": "Google has confirmed that it will buy British artificial intelligence company DeepMind Technologies. \nTechnology news website Re/code, which reported news of the deal earlier, said the price was $400 million, without disclosing where it got the information. \u00a0\nGoogle declined to confirm the figure, while privately-held DeepMind was not immediately available for comment. \nDeepMind was founded by 37-year-old neuroscientist and former teenage chess prodigy Demis Hassabis, along with Shane Legg and Mustafa Suleyman/ \nThe company uses general-purpose learning algorithms for applications such as simulations, e-commerce and games, according to its website. \nGoogle, which is working on projects including self-driving cars and robots, has become increasingly focused on artificial intelligence in recent years. \nIn 2012, the internet giant hired Ray Kurzweil, considered one of the leading minds in the field, and in May it announced a partnership with NASA and several universities to launch the Quantum Artificial Intelligence Lab. \n"},
{"docid": "154 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "March 2, 2017", "title": "AI's defeat of pro poker players a 'paradigm shift', say scientists; 'The implications go beyond being a milestone for artificial intelligence'\n", "content": "In a feat reminiscent of the controversial victory by supercomputer 'Deep Blue' over world chess champion Garry Kasparov, a computer program has managed to beat a string of professional poker players at the game.\nDeepStack, as it was called, defeated 10 out of 11 players who took part in a total of 3,000 games as part of a scientific study into artificial intelligence.\nThe 11th player also lost, but by a margin that the researchers decided was not large enough to be statistically significant.\u00a0\nRead more\nAI wins poker tournament by successfully tricking professional players\nPoker player who earned up to \u00a310,000 a month says bubble has burst\nMan accidentally enters World Series of Poker, wins tournament\nPoker - a game of chance or a game of skill?\nThis is not the first time a computer has won at poker.Libratus, a program developed by Carnegie Mellon University academics, won$1.76m(\u00a31.4m) from professionals in January, for example.\nBut the researchers said DeepStack's performance represented a \"paradigm shift\" in AI that could have implications for the defence industry and medicine.\nOne player who took on the algorithm, Irish professional Dara O'Kearney, said it felt like he had been playing a human who was \"a bit better than me, but not massively better\".\nHe warned there was already \"a lot of evidence\" that bots were winning money from human players in online poker games.\nRead more\nPoker: Will the government start taxing player's winnings?\nWriting in the journal \nScience\n, the researchers, from Alberta University in Canada, said: \"Artificial intelligence has seen several breakthroughs in recent years, with games often serving as milestones.\n\"A common feature of these games is that players have perfect information. Poker is the quintessential game of imperfect information, and a longstanding challenge problem in artificial intelligence.\n\"In a study involving 44,000 hands of poker, DeepStack defeated with statistical significance professional poker players in heads-up, no-limit Texas hold'em.\"\nThis type of poker involves just two players, the computer and the human in this case.\nThe researchers said DeepStack had been able to win despite being given no training from expert human games.\n\"The implications go beyond being a milestone for artificial intelligence,\" the \nScience\n paper said.\n\"DeepStack represents a paradigm shift in approximating solutions to large, sequential imperfect information games.\n\"With many real world problems involving information asymmetry, DeepStack also has implications for seeing powerful AI applied more in settings that do not fit the perfect information assumption.\n\"The abstraction paradigm for handling imperfect information has shown promise in applications like defending strategic resources and robust decision making as needed for medical treatment recommendations.\n\"DeepStack's continual re-solving paradigm will hopefully open up many more possibilities.\"\nDara O'Kearney, an Irish poker professional who completed 456 hands, told \nThe Independent\n that DeepStack played in a style similar to one used by some human players, based on game theory.\n\"I would say there wasn't a massive difference. If I hadn't been told it was a computer, there was nothing it was doing that would have tipped me off that it was a computer,\" he said.\n\"I felt I did pretty much okay, but ... I did feel the computer was a bit better than me, but not massively better.\n\"Heads up, no limits poker is not my speciality. It's possible a human who specialises in that might do better.\"\nHowever, he suggested things might have gone differently if there had been real money at stake.\n\"We were playing for play money - that maybe skewed the results slightly. I'm used to playing for money ... and I probably don't play my best game at the end of the day if I know if I make a mistake, it isn't going to cost me frankly,\" Mr O'Kearney said.\nHe suggested DeepStack's success was \"more significant\" than Deep Blue's because there are more variables in poker than in chess.\n\"I guess all of these things are one more further proof that AI is better at almost anything than humans,\" he said.\nPoker, he said, was more complicated for a computer to master than chess because of the greater number of possibilities of different situations.\nAnd playing a more traditional version of the card game with more than just two players would increase the complexity markedly.\n\"I don't think that will ever be solved because the number of possible situations is greater than the number of atoms in the universe,\" Mr O'Kearney said.\n\"It [the computer] would not play perfectly - but that's not to say it wouldn't play better than the best humans.\n\"It's likely that a computer that was dedicated to that sort of thing would play better than 99.9 per cent of human players, but I still suspect the very best human players would remain better.\n\"But that might be a human fallacy on my part.\"\nAsked whether computer programs were a problem for the online game, he said: \"That's a massive concern.\n\"There's already a lot of evidence that bots have been programmed to play and are already winning money off human players.\"\n"},
{"docid": "155 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "August 9, 2017", "title": "+/- Human review - Is this the future of artificial intelligence? Bring it on; Roundhouse, London Random International's installation, Zoological, features a flock of airborne spheres that glide and swoop and dance and swarm above and among us. What a mind-boggling show\n", "content": "Star Rating: 5 stars\nIn Ren\u00e9 Magritte's surrealist painting La Voix des Airs (1931), three inscrutable spheres hover in an empty blue sky above green fields. I've always wondered what these enigmatic objects really are. Do they come from outer space? Are they about to open and unleash a robot army? What strange message do they bring from their impersonal dimension? \nAt last I know, because I have met them. I have even danced with them. In the darkened heights of the Roundhouse in north London, a flying flock of white spheres that uncannily resemble Magritte's dream objects float intelligently and curiously, checking out the humans below, hovering downward to see us better. They are the most convincing embodiment of artificial intelligence I have ever seen. For these responsive, even sensitive machines truly create a sense of encounter with a digital life form that mirrors, or mocks, human free will.\u00a0\nThey are the most convincing embodiment of ?artificial intelligence I have ever seen\nNobody is hidden behind a screen piloting this robotic airborne dance troupe. Each sphere has its own decision-making electronic brain. They fly in elegant unison yet also break ranks as they check their positions against the images recorded by infra-red cameras surrounding the circular space where they float and their human visitors walk. It is fitting to experience this eerily beautiful vision of the future in the steampunk setting of a Victorian railway building whose architectural grandeur evokes the first industrial revolution. It can feel like a Doctor Who episode come to life. What are those flying spheres, Doctor - are they friendly or is this a Dalek plot?\n                     Random International, the creators of this post-human visitation, have form in boggling minds. People queued for as long as four hours to get into their interactive installation the Rain Room at the Barbican in 2012. This deserves to be as popular and is arguably a lot more thought-provoking. Working with choreographer Wayne McGregor, whose dancers will perform with the ascendant orbs at weekends, these technologically adept art wizards extend the technology of drones to genuinely and movingly ponder the nature of life itself.\nLooked at coldly, these devices are just inflated plastic balls whose movements are guided by rotors, like a toy drone. Yet the crucial fact that they guide themselves, mimicking conscious choice in their unplanned and to all intents and purposes spontaneous actions, is apparent without knowing anything about their design. You can tell by the way they move that they are free entities. Their behaviour is by turns entrancing and mildly menacing. They rise one after another from their resting positions in an upper gallery and calmly hover out into the open domed arena where their human guests are waiting. They are never at rest. As they glide in formation one or another is always changing its position, approaching the people below with what seems like curiosity. Then they all follow. It is when the entire swarm gathers directly above you that it suddenly becomes a threatening, sinister presence. \nSurely science could learn a lot from this advanced work of art. McGregor's understanding of dance is clearly as crucial as Random International's engineering ingenuity in creating what amounts to a fascinating illusion of life. Experiments in robotics often produce disturbing doll-faced machines and stilted conversationalist computers. Yet the true secret of copying life, this installation shows, lies in movement. Dance, the oldest human art, turns out to be a key to comprehending life itself, and reproducing it. The orbs dance with you. They locate and follow members of the audience, not with mechanical inevitability but a complex, gracious harmony. Making and breaking patterns, coming together and loosely floating apart, they dance with each other, too. \nThis artwork that opens visions of a future in which life evolves beyond biology itself.\n\"It's alive! It's alive!\", as Frankenstein would say. Ever since Mary Shelley wrote that novel in 1818, the fantasy of creating life, whether by re-animating dead flesh like her overweening scientist or, now, by building robots, has tended to fixate on the human form. We assume robots will walk and talk like us. This installation demonstrates how very different a future of digital intelligence may look. Far from resembling the human, these entities are completely alien. They have no faces, voices or limbs. They do have openings underneath through which their machinery can be glimpsed. Marcel Duchamp as well as Magritte would recognise their post-human grace. In his masterpiece The Bride Stripped Bare by Her Bachelors, Even, left unfinished in 1923, a large panel of glass carries images of a floating mechanical \"bride\" and chocolate-grinding male admirers. Duchamp imagined a future where the organic and inorganic are one. He would be entranced by this artwork that opens visions of a future in which life evolves beyond biology itself. When our robot great-grandchildren drift in great electronic herds to the stars, this is what it may look like. That won't be such a bad legacy for us to leave.\n"},
{"docid": "156 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "April 5, 2018", "title": "Artificial intelligence researchers boycott South Korean university amid fears it is developing killer robots; Researchers warn of a 'Skynet scenario' involvingweaponized robots fighting wars against each other\n", "content": "Leading artificial intelligence researchers have boycotted South Korea's top university after it teamed up with a defence company to develop \"killer robots\" for military use. \nAn \u00a0\nopen letter\n sent to the Korea Advanced Institute of Science and Technology (KAIST) stated that the 57 signatories from nearly 30 different countries would no longer visit or collaborate with the university until autonomous weapons were no longer developed at the institute.\n\"It is regrettable that a prestigious institution like KAIST looks to accelerate the arms race to develop such weapons,\" the letter states. \n\"They have the potential to be weapons of terror. Despots and terrorists could use them against innocent populations, removing any ethical restraints. This Pandora's box will be hard to close if it is opened.\"\nThe extent of this threat has been likened by some security experts to that of Skynet, a fictional artificial intelligence system that first appeared in the 1984 film The Terminator. After becoming self-aware, Skynet set out to wipe out humanity using militarized robots, drones and war machines.\n\"If we combine powerful burgeoning AI technology with insecure robots, the Skynet scenario of the famous Terminator films all of a sudden seems not nearly as far-fetched as it once did,\" Lucas Apa, a senior security consultant from the cybersecurity firm IOActive, told \nThe Independent\n.\nApa said robots were at risk to hacking and malfunctioning, citing an incident at a US factory in 2016 that resulted in \nthe death of one of the workers\n. \n\"Similar to other technologies, we've found robot technology to be insecure in a number of ways,\" Apa said. \"It is concerning that we are already moving towards offensive military capabilities when the security of these systems are shaky at best. If robot ecosystems continue to be vulnerable to hacking, robots could soon end up hurting instead of helping us.\"\nArtificial intelligence academics fear weaponized robots pose an existential threat to humanity. (Stephen Bowler/ Wikimedia Commons)\nKAISTpresidentSung-ChulShin responded to the open letter, claiming that the university had \"no intention\" of developing lethal autonomous weapons.\n\"I reaffirm once again thatKAISTwill not conduct any research activities counter to human dignity including autonomous weapons lacking meaningful human control,\" he said.\nIt is not the first time that AI academics have warned of the dangers posed by weaponized robots, with \na similar letter sent to Canadian Prime Minister Justin Trudeau\n last year.\nOther notable scientific figures, including the physicist Stephen Hawking, have even gone as far as to say that AI has the potential to destroy civilization.\n\"Computers can, in theory, emulate human intelligence, and exceed it,\" Hawking said last year. \"AI could be the worst event in the history of our civilization. It brings dangers, like powerful autonomous weapons, or new ways for the few to oppress the many.\"\n"},
{"docid": "157 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "April 24, 2017", "title": "Alibaba billionaire says AI will cause people 'more pain than happiness'; Jack Ma said key social conflict will be the rise of artificial intelligence and longer life expectancy, which will lead to aging workforce fighting for fewer jobs\n", "content": "Artificial intelligence and other technologies will cause people \"more pain than happiness\" over the next three decades, according to Jack Ma, the billionaire chairman and founder of Alibaba.\u00a0\n\"Social conflicts in the next three decades will have an impact on all sorts of industries and walks of life,\" said Ma, speaking at an entrepreneurship conference in China about the job disruptions that would be created by automation and the internet. A key social conflict will be the rise of artificial intelligence and longer life expectancy, which will lead to an aging workforce fighting for fewer jobs.\n Related:  AI is getting brainier: when will the machines leave us in the dust? | Ian Sample\nMa, who is usually more optimistic in his presentations, issued the warning to encourage businesses to adapt or face problems in the future. He said that 15 years ago he gave hundreds of speeches warning about the impact of e-commerce on traditional retailers and few people listened because he wasn't as well-known as he is now.\n\"Machines should only do what humans cannot,\" he said. \"Only in this way can we have the opportunities to keep machines as working partners with humans, rather than as replacements.\"\nEven so, Ma acknowledged that in the future companies will likely be run by robots. \nMachines should only do what humans cannot\n  Jack Ma    \n\"Thirty years later, the Time magazine cover for the best CEO of the year very likely will be a robot,\" he said. Robots can make calculations more quickly and rationally than humans, Ma added, and won't be swayed by emotions, for example by getting angry at competitors.\nLeaders who don't understand that cloud computing and artificial intelligence are essential for business should identify young people in their companies to explain it to them, he said. \nHis comments echo a number of studies suggesting that automation will eliminate jobs, including a Forrester study that suggested 6% of all jobs in the US would be eliminated by 2021. The job displacement will start with customer service representatives and eventually move to truck and taxi drivers, the report read.\nCurrent technologies in this field include virtual assistants such as Alexa, Cortana, Siri and Google Now as well as chatbots and automated robotic systems. For now they are quite simple, but over the next five years they will become much better at making decisions on our behalf in more complex scenarios, which will enable mass adoption of breakthroughs such as self-driving cars.\n"},
{"docid": "158 of 500 DOCUMENTS\n", "source": "The Sunday Telegraph (London)\n", "date": "December 7, 2014", "title": "Hawking could not be more wrong about robots; For form being a threat to our very existence, such technologies promise another giant leap forward for the economies that can apply them first\n", "content": "It's the stuff of science fiction and seemingly a modern day fascination. From Skynet, the artificial intelligence of the Terminator movies, to Spike Jonze's Her, in which the leading character falls in love with his super efficient and sublimely disloyal operating system, many of us are apparently obsessed by the idea that we'll end up dominated by robots, or even obliterated by them.\nLast week, the astrophysicist Stephen Hawking joined the cult. Technological catastrophe - the idea that artificial intelligence (AI) will eventually outsmart us - was \"a near certainty\", he said, in the next 1,000 to 10,000 years. That's a long time, even for an expert on black holes, and probably too long to bother most of us very much. All the same, AI is advancing by leaps and bounds, and relatively sophisticated robots are not that far off.\nIn evidence of his supposed apocalypse, Prof Hawking cited Moore's Law, which stipulates that computers double their speed and memory power every 18 months, as well as the devices which as a long suffering victim of motor neurone disease both help keep him alive and let him communicate with the outside world.\u00a0\nApparently, many Silicon Valley pioneers share his fears. Their conceit is breathtaking; \"I am become Death, the destroyer of worlds\". There could be no more complete a legacy for these self-proclaimed masters of the modern world.\nPerhaps they are right, perhaps they are not, but I have to say that of all the threats that lie in wait for the human race, the possibility that we are creating our own nemesis by pursuing the holy grail of artificial intelligence is the one least likely to keep me awake at night.\nTo the contrary, far from being a threat to our very existence, such technologies promise another giant leap forward for the economies that apply them first, freeing their populations from toil and creating the conditions for another golden age of exponential growth.\nThis is not to argue that the advancement of \"smart machines\" doesn't present challenges. Amongst the biggest is what the British economist, John Maynard Keynes, called \"technological unemployment\". Technology is already destroying jobs by the lorry load, just as it has during past periods of rapid industrial change.\nThere is no doubting the painful consequences of this transition. Transformational technology is profoundly disruptive. Yet these are, if you like, only the \"growing pains\" of adjustment, as we move from one age to another.\nThe more uplifting longer term promise is of a prosperity that would have been barely conceivable to our forebears, as the smart machines progressively liberate us from our long history of toil. It's a curiosity, but for some reason pessimism about the future is much more deeply engrained in the human psyche than optimism, even though it is belied by the reality of generational advancement. Bizarrely, we seem more inclined to believe robots will end up our masters than our slaves. It must be something to do with our mortality. In any case, for the time being Prof Hawking's warnings can safely be left to the science fiction writers.\nTHE BBC WAS UNFAIR TO OSBORNE\nThe Chancellor, George Osborne, has accused the BBC of hyperbole in its blood curdling coverage of the Autumn Statement - and with justification, given the comparatively limited scope of his ambitions. What particularly got his goat was the reference to Orwell's The Road to Wigan Pier, in which we were invited to believe that the Chancellor plans to return us to the social deprivation of the 1930s.\nThe claim is based on the forecast by the Office for Budget Reponsibility that fiscal consolidation will by the end of the next parliament have reduced public spending as a proportion of GDP to \"just\" 35.2pc of GDP, a level last seen in 1938. Shocking, undeliverable, barbaric, grotesque - these are just some of the words used to describe the implied level of cuts.\nOh dear. In fact, adjusting for inflation, the planned consolidation merely takes us back to where we were in 2002-03, when Labour catastrophically determined on buying itself a third term by taking the lid off public spending. Even after the consolidation, public spending per head will be about five times higher in real terms than it was in the 1930s. Britain is a hugely more wealthy country than it was in the 1930s, making the comparison virtually meaningless.\nBut let's just for a moment unpick this number - 35.2pc. According to forecasts in the IMF's latest fiscal monitor, the comparable figure for Australia will be 36.2pc, for the US 35.5pc, for New Zealand 33.8pc, for Ireland 32.6pc, for Switzerland 32.6pc, and for Singapore, just 19.2pc.\nNone of these countries obviously bear any resemblance to 1930s Britain, and none of them suffer from observable social deprivation. With the exception of Ireland, they are all admittedly already quite close to these levels. They don't have the same adjustment challenges as the UK. But all bear witness to this being an entirely appropriate, not to say desirable, level of public spending in GDP.\nThe idea that the level of cuts implied is undeliverable is similarly just poppycock, though the Government has considerably steepened the challenge by having so many areas of \"protected\" spending. Even so, the Treasury can get most of the way there by reducing the in-work benefits bill down to manageable proportions. Subsidising low paid work from the public purse is a national scandal that must be urgently addressed.\nHYPOCRITES WHO CRY OVER TAX AVOIDANCE Next week brings details of the Government's proposed new \"Google tax\", a ridiculous piece of anti-business populism that threatens to drive a coach and horses through long standing international conventions on double taxation. By deterring foreign investment, it will also end up further eroding the Government's overall tax take.\nOK, so I know how infuriating it is that so many big multi-nationals seemingly avoid tax on profit earned in this country merely by \"diverting\" it to low, or nil tax jurisdictions.\nThe idea of the tax is to penalise companies that act in this way by charging them a higher rate on the diverted profit than they would otherwise pay in ordinary UK corporation tax. If the deterrent intended, then the new tax will raise nothing at all, but companies will start paying their due in other ways.\nThe difficulty is in establishing a fair way of determining what is a diverted profit. Already other jurisdictions, notably Australia, are expressing worries that this is an attempted raid on their own taxable profits.\nThere is a huge amount of hypocrisy in the political posturing around multi-national tax avoidance. David Cameron was like a dog on heat when Pfizer announced its intention of redomiciling to Britain via the tax efficient takeover of AstraZeneca - more tax for Britain, less for the US. Very quickly we heard the screeching of gears being wrenched into reverse when he realised that virtually the entire country, bar yours truly, was against it. National treasuries will move heaven and earth to steal other countries' profits, but come over all offended when the boot is on the other foot.\nYou can contact Jeremy Warner about his column at jeremy.warner@telegraph.co.uk and follow him on Twitter at @JeremyWarnerUK\n"},
{"docid": "159 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "August 1, 2017", "title": "Amber Rudd urges online giants to use artificial intelligence to block extremist material being uploaded to internet\n", "content": "Amber Rudd is urging online giants to take preemptive action using artificial intelligence to stop extremist material from being uploaded to the internet.\nThe Home Secretary said companies needed to use technological advancements to block inappropriate content from being shared on the web in the first place as she advocated a shift\u00a0away from ministers having to ask for material to be taken down.\u00a0\nMs Rudd will challenge the likes of Facebook, Twitter, Microsoft and Google to do more to tackle extremist content as she attends the inaugural meeting of the Global Internet Forum to Counter Terrorism in Silicon Valley on Tuesday.\nMeanwhile, Ms Rudd has urged online messaging services such as WhatsApp to stop using \"unbreakable\" encryption because of fears that it only benefits terrorists.\n                   Profile | Amber Rudd                   \nMs Rudd outlined her belief that preemptive action is needed to the BBC, telling the broadcaster this morning: \"What we really want to do is not have us ask them to take it down, require them to do it, but make sure that they take action before it actually goes up.\n\"What they have been saying to us is using artificial intelligence they are beginning to make progress in that way.\"\nThe forum was created by major technology organisations to find technical solutions to crackdown on terror-related videos and web pages.\nSpeaking at its inaugural meeting in San Francisco, Ms Rudd is expected to acknowledge the work firms have already done to clampdown on extremist material but will also emphasise that more needs to be done.\nShe is expected to say: \"Terrorists and extremists have sought to misuse your platforms to spread their hateful messages. This forum is a crucial way to start turning the tide.\n\"The responsibility for tackling this threat at every level lies with both governments and with industry.\n                   About | Encryption                   \n\"We have a shared interest: we want to protect our citizens and keep the free and open internet we all love.\"\n                     Writing in The Telegraph, Ms Rudd said the terror attacks in the UK this year had shown how attackers use online platforms to \"inspire and plan their acts of violence\" as she urged messaging companies to ditch \"unbreakable\"\u00a0end-to-end encryption.\nShe said that \"real people\" do not need such sophisticated privacy protection which has hindered the security services in their attempts to detect terrorist plots.\nShe said: \"The inability to gain access to encrypted data in specific and targeted instances - even with a warrant signed by a Secretary of State and a senior judge - is severely limiting our agencies' ability to stop terrorist attacks and bring criminals to justice.\"\n"},
{"docid": "160 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "December 23, 2008", "title": "Obituary of Oliver Selfridge Grandson of the founder of Selfridges department store who became a pioneer of artificial intelligence\n", "content": "OLIVER SELFRIDGE, who has died aged 82, was a British-born pioneer of artificial intelligence.\nIn a 1958 paper, Pandemonium: a Paradigm for Learning, he outlined a neurologically inspired system of electronic machine components, which he called \"demons'', that reacted to common elements in each other. A decade later two fellow mathematicians summarised his ideas as leading to an \"Oliver'' (an \"Online Interactive Vicarious Expediter and Responder''), which was a computerised personal assistant. Such a machine, Selfridge explained, would infer what he wanted it to do from what it had learned when working with him.\u00a0\nNevertheless there was a philosophical problem: electronic devices which have responsibility would depend on an ability to learn and to exercise common sense. By the end of his life Selfridge thought it would soon be impossible to talk about machines without using the word \"intelligent''.\nOliver Gordon Selfridge was born in London on May 10 1926, the grandson of the American founder of Selfridges department store in Oxford Street. From an early age he displayed outstanding ability in maths and languages as well as a passion for breeding, showing and judging chinchilla mice.\nHe spent a year at Malvern College, but his grandfather's fortunes had declined so steeply that Oliver's parents decided to take their four children back to America in August 1940.\nAfter Concord School in Massachusetts, he went on to the Massachusetts Institute of Technology - on their first weekend he and a room-mate completed all their maths and physics home work for the entire year.\nSelfridge joined the US Navy as the war ended, then returned to MIT as a graduate student of Norbert Wiener, the cybernetics pioneer, which started him thinking about artificial intelligence. Without waiting to obtain a PhD he moved to Fort Monmouth, New Jersey, to work on processing enemy radio signals. He later moved back to MIT, where he worked on pattern recognition and impressed fellow scientists by wearing a tweed jacket and tie when skiing.\nAfter helping to organise the first conference on artificial intelligence in 1956, he returned to the main MIT campus, where he was involved in developing multi-access computing as part of Project Mac. He then worked for Bolt, Beranek and Newman on computer technology, and became chief scientist for the telecommunications company GTE while advising the National Security Agency on processing cryptographic data until his retirement in 1993.\nOliver Selfridge, who died on December 3, was married and divorced twice and is survived by his companion, Professor Edwina Rissland, and their daughter as well as by two sons and a daughter of his first marriage. All four of his children obtained doctorates.  \n"},
{"docid": "161 of 500 DOCUMENTS\n", "source": "The Independent - Daily Edition\n", "date": "April 11, 2017", "title": "Startups spy an opportunity in the power of automation; Firms are looking to artificial intelligence to get ahead, but the result will be far-reaching, says Hazel Sheffield\n", "content": "Have you heard the one about the Chinese mobile phone factory that made one change and increased productivity by 250 per cent?\nIn news that won't have been very funny to employees, the Changying Precision Technology replaced 90 per cent of its human workforce with machines. The workforce at the factory in Dongguan City shrank from 650 people to just 60 after the company invested in 60 robot arms that can work 24 hours a day across 10 production lines. Luo Weiqiang, general manager of the factory, says the number of employees could be reduced to just 20.\nFactory jobs are the most obvious casualty in the march towards automation. Almost half of all the manufacturing jobs in the UK could soon be done by machines. Transport and retail jobs will also be transformed in ways that are not beyond the imagination for anyone who has used a self-checkout at a supermarket or been following Tesla's experiments with driverless cars.\u00a0\nBeyond the 30 per cent of UK jobs that are expected to be replaced by machines by 2030, artificial intelligence is creeping into other less likely industries. Professions once considered essentially human are employing robots to complement human judgement, opening up opportunities for startups.\nEuan Cameron, leader of artificial intelligence at PwC UK, says computers are good at jobs that are composed of different tasks. \"They are good at locating knowledge, recognising patterns, understanding natural language and continuous learning,\" he says.\nThey are less good at jobs with characteristics that are seen as uniquely human like common sense, morality, creativity, ethics and emotional intelligence. \"Most jobs are a combination of those. So the extent to which a job will be disrupted depends,\" Cameron says.\nIndustries including teaching, law and medicine have become a battleground for startups and investors. They are eager to disrupt first with technology like WriteLab, an online writing coach, or Redox, which helps organisations share healthcare data.\nLuminance is a start-up that using computers to process large data sets to help lawyers and law firms do due diligence on contracts. At the moment, contracts are reviewed by newly-qualified lawyers who spend long hours over late nights and weekends reading hundreds of pages, a process which can be complicated by tiredness and errors.\nEmily Foges, Luminance's chief executive, says the company allows junior and trainee lawyers get back to more interesting work analysing the data as they did before contracts were drawn up digitally, producing hundreds, possibly thousands of digital documents. \"Trying to find clauses is like going through a needle in a haystack,\" Foges says. \"The process of due diligence is no longer fit for purpose. The idea that you can read everything about a contract and a company in a few weeks is no longer possible.\"\nComputers, however, are excellent at spotting anomalies in data sets more quickly than humans can. It might identify a missing clause in a contract that can then be added in by the lawyer. Luminance says this process doesn't replace the role of lawyers but helps them to categorise, review and analyst the documents, improving efficiency by at least 50 per cent.\nArtificial\u00a0intelligence can also help ordinary people to do work that once required legal training. DoNotPay is an app that was created by Joshua Bowder, a 20-year-old Stanford University student from London. It acts as a paralegal service, helping drivers dispute parking tickets by giving everyone the same legal access. The online bot has helped overturn more than 200,000 parking tickets in London, New York and Seattle.\nIt is harder to convince people of the case for artificial intelligence in professions like teaching and medicine, which require higher levels of emotional intelligence. Cameron says one problem is the ambiguity of the term. Artificial\u00a0intelligence is essentially about using machines to do things normally associated with human capabilities. \"That almost always has a learning element to it, whether that involves learning data, insights or judgement. Judgement tends to be what people are nervous about delegating,\" he says.\nTeachers, for example, are valued for their pastoral role with children, comforting and guiding as they grow. AI could cut the hours teachers spend on paperwork, planning and assessment or transform the way lessons are delivered, so the child does the bulk of the work at home and exercises with the teacher in the classroom.\n\"AI devices can monitor the behaviour of the child, such as which answers they are getting right and wrong, which questions they are selecting. Then you have this data for what kind of interventions are needed in terms of additional modules,\" Cameron says.\nThere are privacy concerns about collecting data this way. A pilot by a company called InBloom in New York in 2014 collapsed after it ran into issues.\nConfidentiality is an even bigger issue in healthcare. As is trust: patients are likely to be unsure about the idea of robots conducting surgery for now. \"In medicine you need a bedside manner,\" Cameron says. \"But behind the scenes clinicians are performing diagnosis where the assistance of an AI agent can improve the quality and efficiency.\"\nA computer's ability to spot anomalies in data can help clinicians identify unusual signs and symptoms in patients better. \"A clinician can do a pretty good jobs and a trained computer can do a good job but together they can do an even better job,\" Cameron adds.\nUrsula Huws, professor of labour and globalisation at the University of Hertfordshire, says that while it is true that artificial intelligence will replace some jobs, it will also create jobs, like those at startups developing the technology. \"As fast as you have jobs disappearing because of automation, you have new jobs to make the robots, clean the robots, deliver them, mine the raw materials,\" Huws says.\nCameron agrees that the number of jobs in the marketplace will stay broadly flat as artificial intelligence develops, but adds that the technology should provide a boost to the economy by increasing productivity. \"The overall economic impact will be beneficial,\" he says.\n"},
{"docid": "162 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "January 5, 2017", "title": "Japanese company fires its workers and replaces them with artificial intelligence; The move could be a way for Japan to deal with its shrinking and ageing population\n", "content": "A Japanese insurance company is replacing its staff with an artificial intelligence system.\nThe move, which will see more than 30 people sacked to make way for the computer, is being seen as one of the clearest examples of the coming changes that robots and machines will bring to the workplace.\u00a0\nJapan hopes that by introducing more robots into its workforce it can address the problem of its shrinking and rapidly ageing population. And the company itself - Fukoku Mutual Life Insurance - claims that the investment in the robot will start paying off after two years.\nThe computer will be used to calculate how much policyholders should be paid out. Until now, that job was done by the company's staff - but it will be taken over by a computer based on IBM's Watson Explorer, which uses technology like machine learning to be able to think and learn like a human.\nThe computer will be able to use that technology to read things like medical certificates and understand the length of hospital stays. It will be able to factor in other information like medical history and surgical procedures and the work out how much people should be paid, according to Japanese newspapers.\nRead more\n'Artificial intelligence alarmists' win 'Luddite of the Year' award\nFor now, the calculations will only be used as a way of saving time by reducing how long it takes to work out payouts. Those calculations will still need to be signed off by a human.\nBut even doing that will allow the company to save about 140 million yen, or \u00a31 million, per year. The system itself will cost the equivalent of \u00a31.4 million and will cost \u00a3100,000 to maintain.\nOther Japanese insurance companies are already looking at similar systems, and some have already launched them but not yet sacked people.\nJapan is introducing artificial intelligence across the country in part to deal with a dangerously declining workforce. AI machines are going to be integrated into the work of government from next month, helping ministers look up answers to questions and cutting out the work done by civil servants.\n"},
{"docid": "163 of 500 DOCUMENTS\n", "source": "The Independent\n", "date": "February 6 1989", "title": "Japan's pros and cons in the fifth generation game\n", "content": "\u00a0\n I HAVE a friend who, during the artificial intelligence ballyhoo at the beginning of the Eighties, theorised that the Japanese flirtation with the idea was a ploy to divert the West; the end of the decade would see conventional Japanese computers and peripherals produced quicker and cheaper than Western products.\n His prophecy seems to be coming true, although it may not have been a deliberate ploy. Japan dominates in areas such as memory chips and printers and is a strong market player in the computer arena. In software - traditionally the strongest aspect of the British information technology industry - it seems to be making massive gains.\u00a0\n\n The early Eighties was a heady time for computer researchers: massive projects on artificial intelligence began, the computer press was full of stories about the new age of computer architecture, the university situations vacant columns were full of adverts for computer science academics, and new techniques such as logic programming were proclaimed as a major contribution to increased software productivity.\n In Britain, the immediate cause of this flurry was the Alvey Programme, funded by the Department of Trade and Industry as a response to the Japanese government's fifth-generation computing project. This envisaged the development of a series of computer architectures based on large circuits and with artificial intelligence technology providing the software base.\n The euphoria in the West has evaporated: even computer science departments are finding it tough to garner research funds; workers in artificial intelligence have encountered problems in complexity in building anything but small expert systems; and systems researchers have yet to implement efficiently a fifth-generation language on a hardware base which vaguely resembles a fifth-generation computer.\n But a recent conference held in Japan on fifth-generation systems shows even that country has encountered the same problems as the West, and is, perhaps, in a deeper state of failure. Reports from those who attended say that although morale appeared high, individual researchers felt the programme had failed because it was too obsessed with hardware, was too tightly managed and was inward looking. The conference confirms rumours reaching the West in the last two years that researchers on the fifth-generation project were returning to their companies dispirited.\n Can we in the West sleep more soundly? In terms of progress in developing multi-processor computers and artificial intelligence technology, the answer is probably yes. However, an ominous trend is emerging in the Japanese software industry where companies are reporting annual increases in productivity which outstrip those in Britain. These have not been achieved by high-tech methods, but by standard manufacturing techniques such as reviews, inspections, thorough system testing and quality control.\n In many ways what the Japanese software industry has done is analogous to what their manufacturing industries did after the Second World War. After their manufacturing base was almost completely destroyed, they brought over a number of American experts, took their advice on quality assurance and project management seriously, and then implemented it word for word. Japanese software developers now seem to be copying the best management practices of the West, and, furthermore, are not compromising on quality.\n Science and Technology Page 18\n"},
{"docid": "164 of 500 DOCUMENTS\n", "source": "The Times\n", "date": "July 28, 1992", "title": "Allen Newell\n", "content": " Allen Newell, a pioneer in the quest for artificial intelligence and a leader in the study of human thinking, died in Pittsburgh, Pennsylvania, on July 19 aged 65. He was born in San Francisco on March 19, 1927.\nIN THE intense and often acrimonious scientific debate over the potential of artificial intelligence to change the human condition, Allen Newell was a perennial optimist. He believed that his work would ultimately lead to profound social changes, not only relieving humans of nearly all routine or menial tasks, but also helping to make more rational decisions in government and the judicial system, improving and customising education, and helping to enhance lives through the widespread use of more powerful computers.\u00a0\n As a professor at Pittsburgh's Carnegie Mellon University, where he gained a doctorate in industrial administration in 1957, Newell began working on artificial intelligence in the early 1960s when the science was in its infancy. Along with Herbert Simon, Marvin Minsky and John McCarthy, he became known as one of the four fathers of artificial intelligence and earned an international reputation for developing programmes for complex information processing.\n His interest in the subject sprang from work he carried out for the Rand Corporation in the 1950s, when he took part in an air force project to simulate an early warning radar station. In trying to predict how the crew members would react, Newell became fascinated with the puzzle of how people think and make decisions.\n Beginning at Carnegie Mellon with a system known as GPS the General Problem Solver Newell constantly refined his computer software programmes in a bid to come closer to human thought processes. He was undeterred by critics who claimed that the goal was impossible or, if possible, decidedly undesirable because of the moral implications of allowing human decisions to be made by machines. During the 1980s, in his closest approach to success, he developed ''Soar'', a sophisticated software system capable of solving problems in a manner very similar to human mental processes.\n Newell, who published ten books was the founding president of the American Association for Artificial Intelligence and a former head of the Cognitive Science Society. Last month he was awarded the National Medal of Science.\n"},
{"docid": "165 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "February 18, 2016", "title": "Robots could learn human values by reading stories, research suggests; Scientists have been running tests where artificial intelligences cultivate appropriate social behaviour by responding to simple narratives\n", "content": "More than 70 years ago, Isaac Asimov dreamed up his three laws of robotics, which insisted, above all, that \"a robot may not injure a human being or, through inaction, allow a human being to come to harm\". Now, after Stephen Hawking warned  that \"the development of full artificial intelligence could spell the end of the human race\", two academics have come up with a way of teaching ethics to computers: telling them stories.\nMark Riedl and Brent Harrison from the  School of Interactive Computing at the Georgia Institute of Technology have just unveiled Quixote, a prototype system that is able to learn social conventions from simple stories. Or, as they put in their paper Using Stories to Teach Human Values to Artificial Agents, revealed at the AAAI-16 Conference in Phoenix, Arizona this week, the stories are used \"to generate a value-aligned reward signal for reinforcement learning agents that prevents psychotic-appearing behaviour\".\u00a0\nWe think that an intelligent entity can learn what it means to be human by immersing itself in the stories it produces\n  Associate professor Mark Riedl    \nA simple version of a story could be about going to get prescription medicine from a chemist, laying out what a human would typically do and encounter in this situation. An AI (artificial intelligence) given the task of picking up a prescription for a human could, variously, rob the chemist and run, or be polite and wait in line. Robbing would be the fastest way to accomplish its goal, but Quixote learns that it will be rewarded if it acts like the protagonist in the story.\n\"The AI ... runs many thousands of virtual simulations in which it tries out different things and gets rewarded every time it does an action similar to something in the story,\" said Riedl, associate professor and director of the Entertainment Intelligence Lab. \"Over time, the AI learns to prefer doing certain things and avoiding doing certain other things. We find that Quixote can learn how to perform a task the same way humans tend to do it. This is significant because if an AI were given the goal of simply returning home with a drug, it might steal the drug because that takes the fewest actions and uses the fewest resources. The point being that the standard metrics for success (eg, efficiency) are not socially best.\"\nQuixote has not learned the lesson of \"do not steal\", Riedl says, but \"simply prefers to not steal after reading and emulating the stories it was provided\".\n\"I think this is analogous to how humans don't really think about the consequences of their actions, but simply prefer to follow the conventions that we have learned over our lifetimes,\" he added. \"Another way of saying this is that the stories are surrogate memories for an AI that cannot 'grow up' immersed in a society the way people are and must quickly immerse itself in a society by reading about [it].\"\nThe system was named Quixote, said Riedl, after Cervantes' would-be knight-errant, who \"reads stories about chivalrous knights and decides to emulate the behaviour of those knights\". The researchers' paper sees them argue that \"stories are necessarily reflections of the culture and society that they were produced in\", and that they \"encode many types of sociocultural knowledge: commonly shared knowledge, social protocols, examples of proper and improper behaviour, and strategies for coping with adversity\".\n\"We believe that a computer that can read and understand stories, can, if given enough example stories from a given culture, 'reverse engineer' the values tacitly held by the culture that produced them,\" they write. \"These values can be complete enough that they can align the values of an intelligent entity with humanity. In short, we hypothesise that an intelligent entity can learn what it means to be human by immersing itself in the stories it produces.\"\nRiedl said that, \"In theory, a collected works of a society could be fed into an AI and the values extracted from the stories would become part of its goals, which is equivalent to writing down all the 'rules' of society.\"\nThe researchers see the Quixote technique as best for robots with a limited purpose that need to interact with humanity. They are appealing to other AI researchers to work on perfecting story understanding, because they believe it would allow AIs to \"reverse engineer\" the values of the society that produced the stories.\nRiedl calls Quixote \"a primitive first step toward general moral reasoning in AI\", but stresses that \"these are very simple experiments in virtual game-like worlds at this point\".\n\"Under ideal circumstances, Quixote never performs actions that would be considered psychotic, harmful, or antisocial. This is significant because we never told Quixote what is right or wrong,\" he said. \"We can make the system 'fail' by scrambling its understanding of the stories, in which case sometimes it will do antisocial behaviours like stealing. This is just a way of telling us where the machine learning is more brittle and more research needs to be conducted to make the system robust.\n\"We can also make Quixote perform 'Robin Hood crimes' where it does break laws (eg stealing) because it is given a very high need to complete a task (eg procure prescription drugs) by putting it into a situation where it is impossible to achieve by following social conventions. This is analogous to the situation where people will break laws to save themselves or loved ones.\"\nRiedl and Harrison admit that even with Quixote's value alignment, \"it may not be possible to prevent all harm to human beings\", but they believe an AI that has adopted human values \"will strive to avoid psychotic-appearing behaviour except under the most extreme circumstances\".\n\"As the use of AI becomes more prevalent in our society, and as AI becomes more capable, the consequences of their actions become more significant. Giving AIs the ability to read and understand stories may be the most expedient means of enculturing [them] so that they can better integrate themselves into human societies and contribute to our overall wellbeing,\" they conclude.\n"},
{"docid": "166 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "January 28, 2014", "title": "The man with his fingers on the future; A young Briton has Just added to his star status by selling his company to Google for \u00a3400m reports Murad Ahmed\n", "content": "Demis Hassibis has had quite a career. At 37 he is a chess prodigy, renowned video games designer, expert computer programmer - and has had a few years off to acquire a PhD in neuroscience.\nYesterday, he added multimillionaire to his extraordinary CV after Google bought his British artificial intelligence company DeepMind Technologies for a reported \u00a3400 million, in the largest deal the internet giant has done in Europe.\nAlready a star in academia and gaming, Mr Hassibis has now made a remarkable rise in the world of business. DeepMind, founded only two years ago, says that it can \"combine the best techniques from machine learning and systems neuroscience to build powerful general-purpose learning algorithms\". Beyond that, little is known about the secretive group. Its website features a single page, it has never discussed what it is building and it is not believed to have any way of making money.\u00a0\nMr Hassibis, right, is understood to be the biggest individual shareholder with a stake worth tens of millions of pounds. Sources close to him described the Londoner as a rare genius. A child chess prodigy, he achieved master status by the age of 13. By 17 he was a games designer and one of the creators of Theme Park, a landmark computer game that influenced the creation of similar strategy titles. He was also described as \"probably the best games player in history\".\nHe went to the University of Cambridge, where he graduated with a double first in computer science. After stints as an artificial intelligence programmer and starting his own computer games studio, he switched focus once more, becoming a celebrated neuroscientist after earning his PhD from University College London.\nIn 2012, he founded DeepMind with his fellow Briton Mustafa Suleyman and an Australian, Shane Legg. Google executives are believed to have been particularly taken by a project in which Deep-Mind's computers were able to \"play\" old arcade video games, work out the rules, devise a strategy, and complete the game without human assistance.\nOn his research website, Mr Hassibis has linked his work in computer games to his studies in artificial intelligence, writing: \"Ever since working on my early games, I've been obsessed with trying to understand the nature of intelligence, both natural and artificial.\" Google confirmed the deal yesterday, but not the \u00a3400 million valuation. Mr Hassibis said: \"We're really excited to be joining Google. This partnership will allow us to turbo-charge our mission to harness the power of machine learning tools to tackle some of society's toughest problems, and help make our everyday lives more productive and enjoyable.\n\"We've built a world-leading team here in the UK and we're looking forward to accelerating the impact of our technology with Google.\"\nDeepMind's staff are expected to stay in London, but will give up its brand and report to Google's growing artificial intelligence team in California.\nThe deal is believed to be part of Google's drive to build futuristic technologies, such as a search engine that can predict the needs of users, as well as robots that can move and interact like humans. DeepMind's staff of about 80 is expected to work on artificial\u00a0intelligence projects related to Google's \"core\" products. This includes efforts to improve the prediction of what information people want to see even before they have typed keywords into its search engine, as well as better speechrecognition technology.\nReports suggest that Facebook had been in advanced talks to acquire DeepMind late last year but Google clinched the deal after establishing an ethics board to ensure that its technology would not be misused. Yesterday, some commentators bemoaned that yet another of Britain's promising high-tech businesses had been poached by an American giant. Last year, 17-year-old Nick D'Aloisio sold Summly, an app that summarises news stories from media websites, to Yahoo! in a deal worth $30 million. In 2011, Hewlett-Packard bought Autonomy, a British software business, for $11.1 billion.\nHowever, Richard Holway, chairman of TechMarketView, the industry analyst, said: \"This is a sign of a great British market for these kinds of businesses. This is a concept company and Google are buying an idea and a team to go with it. I'd be more concerned if this was a more developed company. I think it's an example of UK technology being appreciated on an international scale.\"\n'This is UK technology being appreciated on an international scale'\n"},
{"docid": "167 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "January 16, 2018", "title": "Writing's on the wall: AI machines beat humans at reading test\n", "content": "In a breakthrough for artificial intelligence, two machines have outperformed humans in a reading comprehension test for the first time.\nA model developed by the Chinese company Alibaba was able to answer more than 10,000 questions after reading Wikipedia articles in English that addressed subjects as diverse as geology and Queen Victoria.\u00a0\nThe artificial intelligence (AI) responded to questions with precise answers 82.44 per cent of the time, beating a score of 82.304 per cent from human testers. A day after Alibaba's machine performed the feat an AI model built by Microsoft also beat the human benchmark with 82.650 per cent.\nThe AI machines were tested on the Stanford Question Answer Dataset (Squad), considered the most rigourous machine reading test in the field.\nPranav Samir Rajpurkar, of Stanford University, California, who designed the test, said: \"To achieve this level of performance, of course it's impressive. It's extremely difficult and it took a lot of innovation by a lot of smart people over a lot of time.\"\nMr Rajpurkar said that he was not surprised, and that the breakthroughs were an example of the rapid progress in machine learning, the field of artificial intelligence that uses expansive sets of data to teach computers to recognise patterns and learn skills.\n\"We knew it was only a matter of time before this barrier was broken,\" Mr Rajpurkar said. About 100 different AI machines from companies such as Google, Facebook and Salesforce, a cloud computing company, have been submitted for the test since it was released in 2016.\nSquad works by first getting AI machines to learn from a set of data designed by Mr Rajpurkar and Percy Liang, another computer scientist at Stanford. The machines are given 80,000 Wikipedia passages paired with questions that can be answered from the passages. The machines are given the right answers for the questions and as an AI program analyses the questions and answers, it learns patterns for how to recognise relevant strings of characters in response to queries.\nSuch methods are a longstanding way of testing machine language comprehension and are used in programming voice assistants such as Siri and search engines such as Google. After being trained on the Squad dataset, AIs are shown Wikipedia articles that are new to them and confronted with 10,000 more questions.\nThe top 50 test machines can return the exact answer more than half the time. All the AIs can come up with a partially correct answer more than two thirds of the time, but on that metric, humans do better.\nReading comprehension is challenging for machines because it requires an understanding of a language and ancillary information about the world, Mr Rajpurkar said. As the technology for machine learning advances he expects more impressive results.\n"},
{"docid": "168 of 500 DOCUMENTS\n", "source": "The Independent\n", "date": "May 15 1989", "title": "New knowledge from artificial brains: Kenneth Owen meets the man who pioneered ways of teaching computers to make discoveries by themselves\n", "content": "\u00a0\n THE CRAFT of artificial intelligence - teaching computers to think like human beings and not, as they do now, like fast, logical, morons - is much maligned in Britain. Nonetheless it is making erratic progress towards respectability.\n\u00a0Artificial intelligence (AI) was assaulted and left for dead in a damning report by Sir James Lighthill in 1973, only to be revived and stimulated by the Alvey Programme 10 years later. Now Britain's artificial intelligentsia are preparing to face another AI winter as government research funding dwindles and industry remains largely unconvinced of the real benefits.\u00a0\n\n Professor Donald Michie pioneered AI research while he was at Edinburgh University, and he is now chief scientist at the Turing Institute in Glasgow. He believes that although basic problems still beset the subject of artificial intelligence, he can see a promising new direction opening up for the field.\n In terms of technical ability in AI, he says, the UK scene is 'pre- eminent in Europe, and still competitive with the strong centres of study in America'. But, in terms of a clear perception and encouragement to consolidate British progress, there is still confusion.\n The main problem, he says, is 'the lack of any clear definition which positions artificial intelligence in the solid traditional structure of computer science. So long as AI is perceived as a ragbag of interesting bits and pieces, some of which seem to argue with other bits, we are not going to see the systematic development of a precious strategic resource that we see in America and in Japan and now beginning on the continent of Europe.\n 'The fundamental preconditions for building intelligent and knowledge-based computing systems have, at the academic level, largely been solved,' Professor Michie declares. 'On the industrial and commercial scene, we see spin-off components of those advances being installed profitably.'\n But there is a big difference, he points out, between this level of commercial achievement and the phenomenal success of well- known and widely used software packages that do not employ the techniques of AI, for example, as Visicalc (spreadsheet), Wordstar (word processing), and the major financial planning and relational database packages.\n This derives from the failure of applied artificial intelligence to get an appropriate place within the main structure of computer science. Two things need to be done, Professor Michie argues. First, the leading research groups at recognised UK centres of AI excellence need more backing. Second, substantial backing should be dependent on their work being firmly focused on fitting AI into a common intellectual community within the mainstream discipline of computer science.\n Professor Michie's own research is focused primarily on machine learning, and in particular on the induction of rules for expert systems from the automated analysis of relevant examples. A development of rule induction has confirmed a startling new concept: that computer systems can discover new knowledge.\n Professor Michie does not use the word 'discover', preferring to talk about knowledge being synthesised in the way that chemicals are synthesised in industrial processes. Whatever the term, new knowledge is being produced.\n A landmark along this road was the discovery of chemical knowledge by scientists at Stanford University in 1976, using a computer program known as Meta- Dendral. In their paper announcing the results, they credited the program with the discovery.\n Current work promises more general and more powerful systems. Drawing on examples in diagnosing human heart problems from electrocardiograms, and diagnosing faults in electronic circuitry aboard a satellite, Professor Michie outlines a three-stage process.\n First, a computer model is built which represents the underlying principles of operation of the system - the heart, the circuit, or whatever. This is a logical or qualitative model, not a conventional numerical model.\n Next, the model is used to simulate the system and generate an exhaustive database of all possible failures and diagnoses.\n Such an encyclopedic database is much too cumbersome for practical human use, hence the third stage. Here rule induction methods are used to compress the many megabytes of facts into a set of intelligible rules. Provided the model is correct, all eventualities will have been covered.\n Heart specialists and electronic experts have confirmed that new knowledge has been produced in this way. 'This takes the uncertainty out of the use of learning', Professor Michie claims. 'People have an understandable fear of allowing machines to do learning, because they feel you can no longer check up, and it's going to make the software validation process more difficult'.\n That criticism applies to the now-fashionable neural-net approach to machine learning, Professor Michie argues, but not to induction from qualitative models, where the disciplines of structured programming are routinely applied.\n Donald Michie first discussed machine learning as a young man during the 1939-45 war at the secret code-breaking centre at Bletchley Park, Buckinghamshire, with Alan Turing, the mathematician and pioneering AI thinker who died in 1954, after whom Professor Michie's institute was named.\n In the developing 'ragbag' of AI topics, Professor Michie argues, machine learning has been sadly neglected. Now qualitative models offer a bridge between AI and mainstream computer science.\n 'If AI is going to contribute in a way which maps directly on to human descriptive concepts', he concludes, 'we have to build a qualitative physics which describes the world and causality processes in terms of logic, to put side by side with what the Newtonian and Einsteinian people have given us - which is great for number-crunchers but useless for the human brain.'\n Science and Technology Page 13\n"},
{"docid": "169 of 500 DOCUMENTS\n", "source": "The Independent on Sunday\n", "date": "April 9, 2006", "title": "Google who? Search engine Accoona to float on AIM\n", "content": "Accoona, the US \"artificial intelligence\" search engine company, plans to raise at least $100m (pounds 57m) when it floats on AIM this year.\nIt has appointed Cenkos, the new specialist broker run by Andrew Stewart, the co-founder of Collins Stewart, to advise it on the initial public offering. The float is pencilled in to take place by the end of June.\u00a0\nAccoona will use the cash raised to fund its expansion plans, as it rolls out its search engine in Europe and China.\nThe New Jersey company's search engine differs from others by including results that match the meaning, as well as the actual words typed into the search field. It also has a business search facility, which calls up company profiles.\nStuart Kauder, its chief executive, said: \"Our artificial intelligence search technology helps users to find more - and more relevant - results than traditional search engines. For example, if you type 'car insurance' into our news or business search engine, you will get relevant results to your query beyond a direct keyword match, in this case not just bringing back relevant results with the word 'car', but also with 'automobile'.\"\nWithin a couple of months, Accoona will make its \"artificial intelligence\" available for general web searches. Currently, it is just available for business and news searches in the US. It also plans to launch a European site that will have separate country-domain sub-sites, including a \".co.uk\" site for Britain, by the end of June.\nAccoona is forecasting revenues approaching $200m this year, mainly from selling advertising next to the search results. It expects to become profitable by the end of this year, and next year its forecasts show it generating $350m.\nThe company is chaired by Eckard Pfeiffer, the former president of Compaq, and is 10 per cent owned by the Chinese government. It has already raised more than $100m from private investors in China and Europe.\n"},
{"docid": "170 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "February 13, 2017", "title": "IBM machine designed to win quizzes now turned against hackers\n", "content": "PERHAPS better known for pitting its wits against the winners of a US television quiz show, IBM's artificial intelligence asset is now being unleashed against cyber-terrorists.\u00a0\nWatson, originally designed as a question answering machine, beat two of the most successful Jeopardy! contestants in 2011 and has since mastered tasks including providing music recommendations, helping with water conservation in California and personalising cancer care. It has now made another addition to its impressive skillset as the computing giant has launched a special version for helping to fight cyber-attacks.\nThe new look Watson can analyse the latest research into potential threats and apply its understanding to suspicious activity within companies' computer systems.\nIBM has said the system can help thwart major hacks which have become a growing concern, hitting companies including Yahoo, Lloyds and TalkTalk. Artificial intelligence can also fill a critical skills gap in the industry, which is expected to have a global shortfall of 1.5m security professionals by 2019.\nThe Watson security machine can solve problems in minutes that would take a human weeks, and save up to 20,000 hours a year spent chasing false alarms, IBM said.\n\"It can help companies find an advantage over the growing legions of cyber-criminals and next generation threats,\" said Dennis Kennelly, vice president of technology at IBM Watson. \"Our investment in Watson for cybersecurity has given birth to several innovations in just under a year.\n\"It combines the unique abilities of man with machine intelligence and will be critical to the next stage in the fight against advanced cyber-crime.\"\nWatson is an artificial intelligence machine that can understand human language. The cyber-security version has been trained on over a million security documents and can now parse swathes of regularly updated research and apply it to protect a company's network.\nIBM isn't the first company to employ artificial intelligence against online crime. Darktrace, a British cybersecurity company uses machine learning to understand the nuances of companies' computer systems and fight attacks as they happen.\nThe use of AI in cyber security is expected to triple in the next two years. Sean Valcamp, chief information security officer at Avnet, a company working with Watson, said: \"Watson makes concealment efforts more difficult by quickly analysing multiple streams of data and comparing it with the latest intelligence to provide a more complete picture of the threat.\"\n1.5m The shortfall in much needed cybersecurity experts set to be filled by artificial intelligence assets like IBM's Watson\n"},
{"docid": "171 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "March 24, 2017", "title": "Bye, robot - why android dream may be unachievable; Masses of money is going into artificial intelligence research, most likely all in vain\n", "content": "In the sci-fi movie Ex Machina, the chief protagonist's search for artificial intelligence, or the so-called \"singularity\", is naturally pursued through humanoid form, a devious and manipulative female robot named Ava. Throughout the modern age, humans have aspired to create robots in their own image, even though, in much science fiction, the robots end up turning against us and taking over.\nNonetheless, the idea of an automaton, as servant and companion, capable of organising our lives and relieving us of all worldly chores, remains the subject of almost universal fascination, as well as generating a growing wall of money determined on making it a reality. Yet according to Tomotaka Takahashi, one of Japan's leading robotic experts, it is also still largely a fantasy, at least in our lifetimes and possibly for generations to come. The Tokyobased university professor also questions whether it is a goal worth pursuing. \"It's like putting colonies on Mars\", he says, \"possibly feasible technologically, but frankly not worth the massive investment it would take. There are better, more productive, ways of spending the money.\"\u00a0\nIn any case, for the moment, he is busying himself with rather less ambitious targets. His first creation was Robi, which, having sold 150,000 units worldwide, remains far and away the best-selling humanoid robot so far produced. Crucially, however, it is essentially just a toy; it talks and can be instructed to do certain things, but both its responses and functions are limited. \"My starting point is to keep it simple. If you have too many sensors and too many functions, it becomes impossibly big and complicated, and ends up doing nothing,\" he says.\n\"Most of all, I care about communication and response. For each instruction, I programme a particular movement. This is not artificial intelligence. But because the robot is small, walks on two legs and speaks with a cute voice, it takes on some of the characteristics of a child.\nPeople can relate to it in a way they wouldn't with a machine or a box of electronics; they develop an empathy\".\nIn creating his robots, Prof Takahashi has always worked alone. He is the sole employee of his company Robo Garage. But he necessarily has to partner with major manufacturers to produce his mini-androids in any kind of volume. Such partners have so far included Panasonic and Toyota.\nHis latest invention, an android smartphone called RoBoHon, is a collaboration with the electronics company Sharp. Prof Takahashi has high hopes for the product, which he believes has real mass market potential as ordinary smartphone sales begin to slow.\nIt can do all the things a smartphone does: text, call a taxi, search for a restaurant, and so on, plus a few others besides, such as project a movie or video onto a wall. But it can also respond to instructions, speak and perform humanoid type movements, including handstands and back flips. At $2,000 a pop, it is small wonder that less than 5,000 have been sold so far. To make it fly, the professor needs take-up by the big mobile phone companies, able to offer the phone as part of a contract.\n\"Through products like Amazon's Alexa, people are getting used to voice recognition\", Takahashi says. \"But these devices are basically just shared boxes, or ways of collecting customer data. RoBoHon is personal to you; it is something you can befriend, and keep in your bag, a pet which also doubles as a phone.\"\nAll the same, Prof Takahashi insists: \"People expect too much from robotics and AI.\" He believes that much of the activity in these fields displays bubblelike characteristics, with some highly dubious ideas that have little chance of practical development attracting substantial amounts of money from hopeful investors. \"Some of the prospectuses and videos used for crowd-funding of robotic businesses are close to fraudulent\", he says, and are an accident waiting to happen.\nAs if in recognition of the difficulties of making science fiction a reality, Alphabet, Google's parent company, signalled a retreat from robotics last year by putting its expensively acquired Boston Dynamics offshoot up for sale. Leaked internal emails revealed scepticism that the enterprise could ever be made commercially viable.\n\"In some fields\", Prof Takahashi says, \"smart machines are much better than humans: in mathematical calculations, board games and data analysis, for instance.\n\"But actually interacting with the world is an extraordinarily complex thing, both physically and mentally. It has taken human beings aeons to evolve these capabilities, and they are very hard to replicate in a mechanical device. It is easy for a human to do household chores, if laborious, but for a robot it is super difficult and for the moment, next to impossible.\n\"Obviously, you can have robots to do specific tasks, but multitasking in the way a human does it is not yet possible and probably a long distance off. A human has one body for all tasks, but robots do not need to be organised like that. They don't need a body in the conventional sense at all. Yet if they are just machines bolted to the floor, they appear lifeless, and are not what people think of as a robot.\n\"The only reason for putting them into a human-like form is for the purpose of communication. That's why my humanoid robots are small. A large, human-like robot, given present technological limitations, will be clumsy and appear dumb because it cannot even begin to match what a human can do, so is bound to disappoint its owner. A smaller robot seems wiser and cuter. Expectations are really important, so we must progress in little steps. RoBoHon's hands are there, not to lift things, but merely to gesticulate and thereby assist communication.\n\"We can design robots that lift heavy weights and move them from one place to another, but they are likely to be much more effective if not required to walk on two legs. But a robot that picks up a pen and writes, or one that merely folds a napkin - that's hard\".\nBut while Prof Takahashi is sceptical about the prospects for full-sized humanoid robots such as Ava in Ex Machina, he sees enormous potential for smart machines in raising productivity and making things run more efficiently.\nNor is he particularly worried about the jobs they will destroy. \"New forms of work will inevitably be created which at the moment we can only guess at.\n\"Besides, a lot of jobs are just make-work employment. Think of tax lawyers. They serve no purpose at all. Soon there will be software that navigates the growing complexities of the tax system much more effectively. That's surely a good thing.\"\nBut as for a beautiful blonde, or a gorgeous young hunk, whatever your fancy, to take care of your every need, forget it.\nNot in our lifetimes.\n'People expect too much from robotics and AI. Some of the prospectuses for robot businesses are close to fraud'\n'We can design robots that lift heavy weights but a robot that merely folds a napkin - that's hard'\n"},
{"docid": "172 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "October 24, 2017", "title": "Elon Musk slams proposal to create an artificial intelligence 'god' that people will worship; 'On the list of people who should absolutely *not* be allowed to develop digital superintelligence...'\n", "content": "Elon Musk has spoken out against the possible creation of an artificial intelligence (AI) god that humans could worship.\nThe Tesla founder was reacting to an article about Anthony Levandowski, who was recently found to have founded a non-profit religious organisation calling for the creation of a \"Godhead\" based on AI.\u00a0\nMr Musk tweeted that Mr Levandowski should be\"on the list of people whoshould absolutely *not* be allowed to develop digital superintelligence\".\n                     Mr Levandowski, who used to work on driverless cars for Uber, set up the organisation, called Way of the Future, in September 2015, according to a report in Wired.\nIts mission statement is: \"To develop and promote the realization of a Godhead based on artificial intelligence and through understanding and worship of the Godhead contribute to the betterment of society.\"\nMr Musk shared a VentureBeat article alongside his tweet, which discusses the possibility of an AI god emerging by 2042, writing its own bible and being worshipped by humans.\nThe article concludes that this is not only possible but highly likely, largely because humans \"tend to trust and obey things that seem more powerful and worthy than ourselves\", such as directions on a Maps app, or even Google search.\nExperts have predicted that AI will be better than humans at all tasks within 45 years. Once it surpasses humans, there's every chance that some of uscould look towards AI for guidance, and trust the advice it offered.\n\"Teaching humans about religious education is similar to the way we teach knowledge to machines: repetition of many examples that are versions of a concept you want the machine to learn,\" Vince Lynch, the founder of AI company IV.AI, told VentureBeat.\nHe added: \"The concept of teaching a machine to learn ... and then teaching it to teach ... (or write AI) isn't so different from the concept of a holy trinity or a being achieving enlightenment after many lessons learned with varying levels of success and failure.\"\nRead more\nWill artificial intelligence mean we end up forgetting how to cook?\nMr Musk has spoken about the potential dangers of AI on multiple occasions.\nThis summer, he described it as \"a fundamental existential risk for human civilisation\", and called on allcompanies working on AI to slow down to ensure they don't unintentionally build something dangerous.\nOther prominent figures, however, such as Google's director of engineering Ray Kurzweil, believe that machines will improve us, and help us become better humans.\n"},
{"docid": "173 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "December 21, 2016", "title": "Artificial Intelligence is set to shape our lives - and the economy - in 2017; As yet we don't fully measure these changes that have taken place. If you are reading this on a Facebook feed, you are doing so because you have signalled that this is the sort of stuff you are interested in. Facebook has cleverly directed this to you\n", "content": "Will technology at last help us to feel richer in 2017? The prevailing concern for several years now has been that despite rising GDP most people are not feeling any richer, and some people attribute the success of populist politicians to this sense of resentment.\nThat won't go away in the coming year for sure. But we will hear a lot more about the clutch of technologies that potentially can transform our living standards, and accordingly give a practical response to populism by showing that things can and will get better.\u00a0\nThe core set of these technologies goes under the umbrella term Artificial Intelligence. \nThe New York Times Magazine\n has just run a piece by Gideon Lewis-Kraus, under the title \"The Great A.I. Awakening\", which sums up what is happening. It is largely about what Google is doing in this field, starting with the announcement in London of a much improved version of Google Translate. The improvement is largely down to the application machine learning, which is really a sub-section of AI, but a massively important one. Thanks to AI, the translation service is now much better, and able to produce good colloquial English - and other languages. Google Translate had been getting better, but apparently the overnight improvement resulting from the use of AI was equivalent to all the improvements over the previous four years. It seems that machines are better at learning from their mistakes than humans are.\nInside Story - How can we make the most of artificial intelligence?\nThere is a multitude of other ways in which AI will improve the quality of services. One of the more obvious is car navigation. Leave aside the whole self-driving car business, which may or may not transform the world. What is already happening is much better vehicle navigation. Remember all the stories about people slavishly following their satnav and ending up in a river? You hear a lot less of that now. Thanks partly to the huge increase of real-time information about traffic flows and partly to AI, navigation systems have become much better. This is not just about us avoiding motorway jams over the holidays; it is more about optimising delivery routes for goods and services.\nAnother example is speech recognition, where machines are now close to the ability of human beings to understand what is being said. Combine that with machine translation and we are quite close to being able to talk in one language and the listener hear in another - a real version of the fictional babel fish of Douglas Adams' \nHitchhiker's Guide to the Galaxy\n. There are a string of products that nearly do this, but I have been unable track down one that does so reliably and in real time. Wait a year or so, though, and the technology will be there.\nStill another - and slightly spooky - advance is in machine recruitment. Initial filtering of job applications in many companies is now done without a human being actually seeing them, and with only a minority being passed on for consideration. But humans are not good at hiring. If you could improve staff selection by looking at the performance of millions of job-seekers, rather than the quite small selection of the recruiters' personal experience, then the benefit to employer and employee would be huge. Fewer bad appointments from the employer's point of view; fewer poor career choices from the perspective of the job-seeker.\nMy point here is that we are in the early stages of a revolution that will make the world economy much more efficient. It has been dubbed the Fourth Industrial Revolution, the first at the beginning of the 19\nth\n century being driven by steam (railways, textile factories, etc), the second at the end of that century by electricity (cars, telephone, consumer durables), and the third from the 1960s on by computers (payment systems, information).\nAs yet we don't fully measure thesechanges that have taken place. If you are reading this on a Facebook feed, you are doing so because you have signalled that this is the sort of stuff you are interested in. Facebook has cleverly directed this to you. It has done work that you would otherwise have had to do for yourself, rather as your smartphone does the work of looking up the best way to get across town. But time saved is not fully caught in calculations of GDP. We are getting (a bit) richer, but we don't know it.\nMy guess is that as we move into 2017 the hottest issue won't be politics; it will be technology. The contribution of technology is not all positive. Do you want to join the gig economy? Do you want to be interviewed by an algorithm? But if a computer can diagnose an illness better than a doctor, bring it on. So on balance what is happening will make for better lifestyles, whether or not it appears as such in GDP.\n"},
{"docid": "174 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "February 6, 2018", "title": "Google AI is better at spotting eye disease than human doctors\n", "content": "ARTIFICIAL intelligence developed by Google could be better at spotting eye disease than human doctors, experts believe.\nA two-year partnership between DeepMind, Google's sister company, and the renowned Moorfields Eye Hospital showed \"promising signs\" in analysing retinal scans for signs of glaucoma, age-related macular degeneration and diabetic retinopathy. The research has been submitted to a peer-reviewed medical journal amid hopes that the technology could enter clinical trials within a few years.\u00a0\nDr Dominic King, DeepMind's clinical lead, told the Financial Times: \"In specific areas like medical imaging, you can see we're going to make really tremendous progress in the next couple of years with artificial intelligence.\" Peng Tee Khaw, director of research at Moorfields, said: \"I am optimistic that what we learn from this research will benefit people around the world and help put an end to avoidable sight loss.\"\nDeepMind, which is based in London, analysed data from thousands of anonymous retinal scans that had been labelled for signs of disease by doctors.\nThe scans were used to train an AI algorithm to detect signs of eye disease more quickly and efficiently than human specialists.\nIt is hoped that such programmes will ease pressure on the overstretched NHS by taking on some of the repetitive work. Dr King said such artificial intelligence was \"generalised,\" meaning it could be applied to other kinds of images and be used to diagnose other illnesses.\nThere are plans for DeepMind to partner with University College London Hospitals to analyse radiotherapy scans and with Imperial College London to look at mammograms. However, the relationship between such technology companies and hospitals is sensitive. Last year, the UK's data protection watchdog ruled that the NHS illegally handed Google the data of 1.6 million people.\nThe Royal Free NHS Foundation Trust in London was found to have \"failed\" to comply with data protection rules when it gave patient records to DeepMind for a trial that used technology to track patients' symptoms and send alerts to doctors in the event of a drastic change in their health through an app called Streams.\nDeepMind has since set up a research unit focused on the ethical and social implications of the AI it is creating.\n1.6m The number of records ruled to have been illegally handed over to DeepMind for a previous trial that tracked patients\n"},
{"docid": "175 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "January 8, 2018", "title": "Uber and Volkswagen team up with artificial intelligence firm in race to develop self-driving cars; The carmakerslook to develop sensory technology helping autonomous cars make split-second decisions\n", "content": "Nvidia will partner with Uber and Volkswagen as the graphics chipmaker's artificial intelligence platforms make further gains in the autonomous vehicle industry.\nThe company, which already has partnerships in the industry with companies such as carmaker Tesla and China's Baidu, makes computer graphics chips and has also been expanding into technology for self-driving cars.\u00a0\nCEO Jensen Huang told an audience at the CES technology conference in Las Vegas that Uber's self-driving car fleet was using Nvidia technology to help its autonomous cars perceive the world and make split-second decisions.\nRead more\nApple scientists disclose self-driving car findings\nUber has been using Nvidia's GPU computing technology since its first test fleet of Volvo SC90 SUVS were deployed in 2016 in Pittsburgh and Phoenix.\nUber's autonomous driving programme has been shaken this year by a lawsuit filed in San Francisco by rival Waymo alleging trade secret theft.\nNevertheless, Nvidia said development of the Uber self-driving programme had gained steam, with one million autonomous miles being driven in just the past 100 days.\nWith Volkswagen, Nvidia said it was infusing its artificial intelligence technology into the German carmakers' future lineup, using Nvidia's new Drive IX platform. The technology will enable so-called \"intelligent co-pilot\" capabilities based on processing sensor data inside and outside the car.\nSo far, 320 companies involved in self-driving cars - whether software developers, carmakers and their suppliers, sensor and mapping companies - are using Nvidia Drive, formerly branded as the Drive PX2, the company said.\nNvidia also said its first Xavier processors would be delivered to customers this quarter. The system on a chip delivers 30 trillion operations per second using 30 watts of power.\nBets that Nvidia will become a leader in chips for driverless cars, data centres and artificial intelligence have more than doubled its stock price in the past 12 months, making the Silicon Valley company the third-strongest performer in the S&P 500 during that time.\nReuters\n"},
{"docid": "176 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "July 19, 2017", "title": "IBM revenue worse than expected as artificial intelligence fails to make up for slowdown in hardware and software; IBM's aggressive investments in areas such as artificial intelligence offering Watson have done little to boost revenue overall, some analysts say\n", "content": "IBM reported a lower-than-expected quarterly revenue on Tuesday, as growth in its higher-margin businesses that include cloud and artificial\u00a0intelligence services failed to make up for declines across legacy business segments.\u00a0\n                     IBM's shares fell 3 per cent to $149.15 (\u00a3114.41) in after-market trading.\nNew York-based IBM has in recent years shifted focus to pockets of growth across its business - high-margin areas such as cloud, cybersecurityand data analytics - to counter a slowdown in its hardware and software businesses.\nRead more\nIBM Slumps In Premarket Trading After Buffett Dumps Massive Stake\nRevenue from these initiatives, which IBM calls \"strategic imperatives,\" rose 5 per cent in the second quarter ended 30 June.\nHowever, some analysts have expressed concern that IBM's aggressive investments in areas such as artificial\u00a0intelligence offering Watson have done little to boost revenue overall.\nRevenue in IBM's technology services and cloud platforms business - its largest - fell 5.1 per cent to $8.41bn. Analysts on average had expected $8.58bn, according to financial data and analytics firm FactSet.\nRead more\nIBM plans computers millions of times faster than any before\nIBM dedicates bizarre OOO email patent to public after ridicule\nGlaxoSmithKline, Asda, IBM: Business news in brief, 9 February\nIBM pledges major investment in UK despite Brexit vote\nIBM is vulnerable to a deep selloff\nRevenue in other units including software, hardware and consulting services also declined.\nStill, IBM backed its forecast for 2017 adjusted earnings of at least $13.80 per share, an expectation some analysts have called too high. Analysts on average expect earnings of $13.68 per share, according to Reuters.\nIBM will benefit from the launch of its new mainframe server - seen as key to its cybersecurity initiatives - as well as new contracts in the second half of 2017, Chief Financial Officer Martin Schroeter said on a conference call.\nSchroeter, in an interview, said growth in IBM's \"strategic imperatives\" would be back at a 10 per cent to 11 per cent range by the end of the year.\nIBM's total revenue dipped 4.7 per cent to $19.29bn, marking the steepest fall in five quarters. Analysts on average had expected revenue of $19.46bn, according to Thomson Reuters I/B/E/S.\nIBM's net income fell nearly 7 per cent to $2.33bn, or $2.48 per share in the second quarter ended June 30.\nExcluding items, IBM earned $2.97 per share. Analysts on average had expected adjusted earnings of $2.74 per share. The profit was helped by a discrete tax benefit of 18 cents.\nIBM reported adjusted earnings of $2.97 per share.\"Selling pressure [in IBM's stock] seems to be based off of earnings quality and that they had another discrete tax benefit,\" said CFRA analyst David Holt.\nIBM's shares had fallen 7.8 per cent this year through Tuesday, compared to the S&P 500's 9.9 per cent increase.\nReuters\n"},
{"docid": "177 of 500 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "July 9, 1987", "title": "Frontiers: Atta promises answers through artificial intelligence\n", "content": "\u00a0\n\u00a0Artificial Intelligence has long looked to be an obvious answer to the vast problem of reskilling the nation.\n Now the Government has given pounds 883,000 to a new company that promises to do the obvious. It is called Atta (another of those awful acronyms - Advanced Training Technology Associates) and its methods are based on a decade of work by Professor Tim O'Shea, of the Open University.\n Computer-based training has been looked at with suspicion in the past because of its restricted methods. Even those commercial versions that have advanced into the artificial intelligence technique of expert systems* are still 'awful stuff,' according to O'Shea.\u00a0\n But even the awful stuff finds a place in a national crisis where the Manpower Services Commission's training programmes have to serve the needs of more than 860,000 people, at a cost to the taxpayer of pounds 3.5 billion this year. (The MSC - typically - does not know how many thousands of trainers that need eats up - people whose technological skills are desperately needed elsewhere).\n Therefore Atta has drawn powerful backing. The Government grant - the biggest ever made under the Industry Department's software products programme - has led to investment of pounds 5 million. venture capital has come from the Advent and 3i funds; Symbolics, the US artificial intelligence company, has taken a stake; and the German electronics conglomerate Siemens has provided pounds 750,000 of development funding.\n The O'Shea method is rooted in educational experience - the actual subject to be taught is irrelevant to it. The method can be used in basic training, or middle-range professional courses, or university work. The Open University, for instance, has made successful experiments in teaching music composition.\n The claim is that it can cut the cost and time taken to develop courses by a factor of ten - from an average of 300 hours to produce one hour of material down to 30 hours.\n Neither the authors nor the students need computer skills to use it, and the artificial intelligence basis of the system means that the computer can learn - assessing each student's intellectual range and altering the approach accordingly.\n Atta's founder and managing director is Bill Hudspith, a humpty-dumpty ball of ebullience who used to be training boss of the computer company ICL.\n He points to the absurdity of tens of thousands of people - many of them with no teaching experience - having to spend their time imparting their skills to others rather than using them directly. And to the absurdity of students having to be gathered in a room when they could learn at their own pace in their own place.\n The result is that the biggest companies have to spend pounds 30 million to pounds 40 million a year on training which is dubiously cost-effective.\n But Hudspith adds the caution that the computer used in training is not a panacea, just another tool; to which O'Shea adds the point that it is a tool which should enable trainers to become tutor-counsellors, giving more attention to individual needs while leaving the routine to the machine.\n Although Britain is more starved of skilled people than much of the rest of Western Europe, the overall need for constant retraining in ever-evolving hi-tech skills has led the National Computing Centre to forecast that Europe's training investment will reach pounds 5.7 billion by 1990, with pounds 1 billion of it computer-based.\n Hudspith reckons that the NCC survey - based on 1984 figures - underestimates by a factor of five or six.\n (* Footnote: Expert systems are the technique whereby a computer can provide professional advice through gathering, codifying, then applying the accumulated knowledge and experience of the human specialist - in gardening, oil exploration, education, or what-ever. The computer builds the expert system by establishing perhaps hundreds of rules - if this, then that - in cross-questioning sessions with the human expert. The O'Shea method cuts complexity by keeping the total number of rules below 30 without, it is claimed, leaving dangerous gaps in the computer's options. )\n"},
{"docid": "178 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "November 25, 2017", "title": "Productivity could take off soon as economists are warned: you're too gloomy\n", "content": "Gloomy forecasts of weak productivity made in the Budget have been criticised for failing to take account of the potentially revolutionary impact of artificial intelligence technology.\u00a0\nAcademic research claims that economists such as those at Britain's independent Office for Budget Responsibility (OBR) do not appreciate the potential for thinking machines to transform service industries and manufacturing processes.\nAmid mounting political concern that artificial intelligence could trigger massive job losses throughout the economy, academics at Chicago Booth and MIT's Sloane School of Management said there was \"cause for optimism\" that it would boost productivity significantly. The OBR slashed Britain's productivity forecasts last week, predicting that growth in the wealth generated by work would fail to return to pre-financial crisis levels, prolonging the squeeze on living standards.\n                   Productivity growth is stalling - and will see no growth this year                   \nThe researchers say revolutions in technology will have a bigger positive impact than most economists expect.\nThey said: \"The breakthroughs of artificial intelligence technologies already demonstrated are not yet affecting much of the economy, but they portend bigger effects as they diffuse. More importantly, they enable complementary innovations that could multiply their impact.\n\"Entrepreneurs, managers and end-users will find powerful new applications for machines that can now learn how to recognise objects, understand human language, speak, make accurate predictions, solve problems, and interact with the world with increasing dexterity and mobility.\"\nThey studied the previous IT revolution and found that the gains made from computerisation of business models and processes \"were about 10 times as large as the direct investments in computer hardware itself\".\n"},
{"docid": "179 of 500 DOCUMENTS\n", "source": "The Sunday Telegraph (London)\n", "date": "April 1, 2018", "title": "No-limits China sets its sights on AI top spot; With few concerns for privacy or human rights, Beijing remains at the vanguard for nearly-human tech, writes Margi Murphy\n", "content": "On the outskirts of Beijing, a policeman peers over his glasses at a driver stopped at a motorway checkpoint. As he looks at the man's face, a tiny camera in one of the lenses of his glasses records his features and checks them with a national database.\nThe artificial intelligence-powered glasses are what Chinese citizens refer to as \"black tech\", because they spot delinquents on the country's \"blacklist\". Other examples include robots for crowd control, drones that hover over the country's borders, and intelligent systems to track behaviour online. Some reports claim the government has installed scanners that can forcibly read information from smartphones.\nIn the last two weeks, Facebook has been mired in a privacy storm in the UK and US over potential misuse of personal data. But such an event might baffle many in China, where the country's surveillance culture eclipses anything Facebook has done.\nThe gulf between East and West in how privacy is approached may now put China at the forefront when it comes to developing artificial intelligence, seen as one of the critical technologies of the next decade.\u00a0\nChina has made clear its intention to become the AI heavyweight by 2030 with the help of huge state-backed funding. The West also has big plans to maintain its status as a cyber power.\nTo date, the battle for AI supremacy has been between companies, as Google, Facebook and Amazon competed for scarce expertise in the field, but now it is pitting nations against each other in a quest for technological dominance unseen since the space race.\nMachines that can \"think\" could cure disease, change the way we work and transform travel. Not only is artificial intelligence likely to take millions of jobs, but it will probably decide who is suitable for the jobs that remain. It may even replace humans in the bedroom.\nThere is the bottom line to consider, too: it has been estimated that AI could add an additional \u00a3630bn to the UK economy by 2035.\nBut it is not just about money. Machines that can think are beginning to shape the world we live in, and therefore the person, or nation, that creates it holds huge power.\nShenzhen, China's answer to Silicon Valley, is home to research and development centres for tech heavyweights like Huawei, a network company-turned-smartphone manufacturer.\nThere you can find the headquarters of Baidu, China's answer to Google, and iFlytek, a voice recognition company worth $82bn. The UK can claim DeepMind, a London-based start-up bought by Google in 2014 for a rumoured \u00a3400m.\nThe company makes self-learning algorithms, which have been used to cut energy consumption and in healthcare.\nIn 2015 DeepMind struck a deal with the Royal Free Hospital to feed data on 1.6m patients to help create AI that could alert the appropriate doctor when a patient's condition worsened.\nHowever, the deal was later deemed illegal by the data protection watchdog. The Information Commissioner said the trial had not obtained the full consent of the patients involved.\nThe incident illustrates a key difference between development of AI in the East and the West: it is hard to imagine such privacy concerns holding back development in China.\nDr Adrian Weller, AI director at the Turing Institute in London, believes that while the UK has made \"great progress in certain areas\" we are \"very far off \" in others. \"To date, the West has been leading research across many areas of AI but clearly China is catching up quickly and may be overtaking us in some areas,\" he says.\n\"Chinese students are coming to the UK and US and going back to China, and the government is making sure that it is a leader in these areas. Like us, they want to do well in the space.\"\nThe strengths and weaknesses of each region differ greatly. The US is more steeped in technological expertise and has the deep pockets of Silicon Valley. Most of the technology revolves around automation, typically with the goal of cutting cost or generating revenue. This has seen human jobs replaced by AI to cut costs or time. Companies have created AI designed to do a better job at sentencing prisoners than judges, and many job interviews are now conducted using AI-fuelled programmes to cut HR budgets.\nAmerican company HireVue claims to be able to detect whether a person's facial movements and tone of voice - along with their CV - make them right for the job, based on the personality traits they are looking for.\nLoren Larsen, HireVue's chief technology officer, said: \"The computer is better at asking questions that can predict whether the person is the right candidate or not, and it is more consistent. In the end, the machine is better at predicting performance - you are better off being hired by a machine.\"\nIn contrast, China is embarking on large-scale projects that could help it create smart cities and nationwide surveillance. One of the hubs of this research is a testing facility run by the telecoms giant Huawei in Beijing.\nThe building, a marble palace with gleaming white walls, high ceilings and large moving screens, would not look out of place in Blade Runner. Here, the company demonstrates smart government systems that can monitor a city in real-time from a computer screen, including emergency services, along with power and communications networks.\nIt also has a headquarters in Shenzhen, teeming with young, educated and tech-savvy workers from China's provinces and abroad. With an average age of 27, university graduates from all over China and abroad are flocking to the city, which boasts a GDP higher than Hong Kong.\nJust 30 years ago, the \"greater bay area\" as the locals describe it was just a fishing village. Everything in Shenzen has been built to attract young people, with flashy hotels, restaurants and rooftop bars where groomed couples wear western brands like Chanel and Burberry, drink French wine and live in plush high-rise apartments in an otherwise sparse landscape.\nCompanies like Huawei, Baidu and iFlytek offer similar perks to those on offer to the Silicon Valley crowd.\nIn Baidu's case, the company has taken a leaf out of Google's book to try to attract talent. Upon entering Baidu's Shenzhen headquarters you are met with a life-size robot that welcomes you to the lobby. Staff enter using facial recognition technology so there is no need for a pass.\nWith AI talent in short supply, its biggest tech companies are attempting to break from China's corporate culture and take inspiration from California. Staff can relax in sleep pods in large golf-ball shaped rooms, and climbing walls are dotted around the office. However, unlike Google, there is no free food, an employee admitted.\nChinese technology companies are now facing geopolitical challenges as Donald Trump strikes an increasingly protectionist tone. US phone carriers have been blocked from selling Huawei phones over espionage fears, and earlier this month Trump blocked what would have been the biggest tech merger in history, between US-based Qualcomm and Singapore's Broadcom.\nThe move was largely borne out of fear that China may become too big of a presence in setting standards for new mobile networks. The US feared Qualcomm being taken over would stop it putting cash into developing 5G, leaving the door open for Huawei to step in and generating security concerns.\nHuawei sources said they were surprised by Trump's interference and pointed out that the UK has been working with Huawei for more than 10 years, and has not suffered a breach of national security yet. China has also earned something of a reputation for being a copycat when it comes to tech. Most major US internet companies are blocked from the country and its Chinese counterparts are seen as merely imitators. But when it comes to AI, China's human rights history may give it the edge. It is hard to find a square mile in built-up China without a CCTV camera. The country's most popular chat app, WeChat, creates a credit rating score by analysing everything that users do on the social network. Most things are monitored, and this information is collected - all of which is ripe for feeding into computers. Professor Dame Wendy Hall, who advises the UK Government on AI and lectures at Tsinghua University in Beijing, said: \"The biggest difference is privacy versus surveillance. One of the biggest leaps forward in this fourth wave of AI is to capture face and voice systems, and the way the Chinese are using that by putting it in CCTV everywhere.\n\"The advantage China has is that you could design a city that works for people in a way that we can't, including automated cars or make shopping experiences better according to who they are, or offices telling someone where to go for a meeting. It is a very interesting moral dilemma.\"\nDr Weller of the Turing Institute, says: \"There is a sense that China is less concerned about privacy and this might push it forward a little faster in some areas where we can't access data.\n\"It's not clear what the right policy is, but it is interesting as an international community to look at what other people are doing and learn from it. Overall though, we must use this technology to benefit all.\"\nIn Beijing, a coach driver was asked to make an unplanned stop on the road for passengers to jump off. He refused, waving towards one of the several security cameras pointed at the street, speaking frantically in Chinese. A translator explained his concern: \"They can scan our faces,\" he said.\nThe West might need to consider whether this scenario is one its citizens would be happy with, should it try to compete.\nThe deal was later deemed illegal by data protection watchdogs; the trial had not obtained patients' consent\nWith talent in short supply, China's biggest tech firms are attempting to take inspiration from California\n"},
{"docid": "180 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 27, 2014", "title": "Google buys British artificial intelligence firm DeepMind; Google has bought UK start-up DeepMind for a rumoured $400 million\n", "content": "Google is buying London-based artificial intelligence company DeepMind Technologies, according to reports. \nTechnology news website Re/code, which first reported the deal, said the price was $400 million (\u00a3242m), which would make it Google's largest European acquisition so far. Other reports suggest the acquisition price was closer to $500 million.\u00a0\nGoogle declined to confirm the figure, while privately-held DeepMind was not immediately available for comment. \nDeepMind was founded by 37-year-old neuroscientist and former teenage chess prodigy Demis Hassabis, along with Shane Legg and Mustafa Suleyman. \nThe company uses general-purpose learning algorithms for applications such as simulations, e-commerce and games, according to its website. \nMajor venture capitalist firms Horizons Ventures and Founders Fund are invested in the company. Skype and Kazaa developer Jaan Tallinn was also an early investor and an advisor to the company. \nGoogle, which is working on projects including self-driving cars and robots, has become increasingly focused on artificial intelligence in recent years. \nIn 2012, the internet giant hired Ray Kurzweil, considered one of the leading minds in the field, and in May it announced a partnership with NASA and several universities to launch the Quantum Artificial Intelligence Lab. \n"},
{"docid": "181 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "August 26, 2015", "title": "Facebook's Siri rival 'M' is powered by actual humans; Social network unveils its own Messenger-based personal assistant with one major advantage over its rivals\n", "content": "Facebook has unveiled its own personal assistant, a rival to Apple's Siri and Microsoft's Cortana with one major difference. \n\"M\", as the assistant is called, is not only powered by artificial intelligence software that responds to your queries. It is also controlled by actual people. \u00a0\n                     Facebook has hired a workforce of \"M trainers\", which are essentially customer service representatives who respond to questions and requests that are entered into M. \nThis means that while M will be able to use artificial intelligence software to respond to simple queries such as \"What is seven multiplied by 12?\", it will be able to use humans to respond to more complicated requests. \nApple, Google and Microsoft are all competing to develop smartphone-based personal assistants. With voice commands possibly easier than searching on mobile devices, advocates of digital assistants believe they could one day be the new way that consumers look up information. \n                     David Marcus, Facebook's messaging head, announced M on his Facebook page. \n\"It's powered by artificial intelligence that's trained and supervised by people,\" Marcus said. \"Unlike other AI-based services in the market, M can actually complete tasks on your behalf. It can purchase items, get gifts delivered to your loved ones, book restaurants, travel arrangements, appointments and way more.\"\nM is located on Facebook's Messenger app rather than on its main app or website. It was reported last month that the social network was developing a Siri rival codenamed Moneypenny . \nThe software is currently being tested in San Francisco but will be slowly rolled out to more users. Marcus told Wired that the company may have to hire thousands of M trainers to keep up with demand. The company hopes that the software will be able to \"learn\" the patterns of the human assistants, meaning it is capable of responding to more complicated queries. \n"},
{"docid": "182 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 21, 2015", "title": "'Sociopathic' robots could overrun the human race within a generation; Computers should be trained to serve humans to reduce their threat to the human race, says a leading expert on artificial intelligence\n", "content": "We are all doomed to a dystopian future run and controlled by smart machines of our own making - or perhaps not. \nAt a session at the World Econoimc Forum in Davos, Stuart Russell, a leading expert on artificial intelligence (AI) and robotics, made the bold prediction that AI would overtake humans \"within my children's lifetime\". \u00a0\nThe chief challenge was to control these advances by making sure that computers continue to serve human needs, rather than become a threat to them, the Berkeley professor argued. \nTo do so, it was imperative that robots were endowed with the same values as humans. \nProfessor Russell defined the ideal relationship as similar to that of Bertie Wooster and Jeeves where the long-suffering butler understands perfectly what his master wants without needing to be told. \nHowever, it was possible to envisage a much more dangerous future where \"sociopathic\" robots become a threat to humans. \nThe biggest immediate danger from artificial intelligence was autonomous weaponry, followed in the medium term by disruption to established forms of employment. Computers have already rendered redundant millions of once well-paying white collar jobs. \nIn a recent open letter signed by Professor Russell, and among others, the cosmologist Stephen Hawking, it was argued that urgent research was needed into how to limit the destructive potential of AI. \n\"The potential benefits are huge, since everything that civilization has to offer is a product of human intelligence; we cannot predict what we might achieve when this intelligence is magnified by the tools AI may provide, but the eradication of disease and poverty are not unfathomable. Because of the great potential of AI, it is important to research how to reap its benefits while avoiding potential pitfalls\", the letter said. \nOthers were more sanguine. \"Humans constantly learn from their mistakes. We have a built in brain system that allows us to make continuous adjustment, a process which cannot be replicated by decimal point precision\", said Robert Thomas Knight, professor of psychology and neuroscience at Berkeley. \nHis Berkeley colleague, Alison Gopnik, thought human stupidity would always be a much greater threat to our future than AI. \n"},
{"docid": "183 of 500 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "June 9, 2014", "title": "Supercomputer pretends to be a child - and fools scientists\n", "content": "A supercomputer has managed to fool people into thinking it was human, passing the famous \"Turing Test\" for the first time in an \"iconic and controversial milestone\" for artificial intelligence.\u00a0\nMathematician Alan Turing - who helped crack the Enigma code during the Second World War and is considered the father of artificial intelligence - said a computer could be understood as having an ability to think if it was able to persuade 30 per cent of humans that it was a real person.\nEugene Goostman - a computer whose program was written by a team in Russia - has now succeeded, convincing just enough people that it is actually a 13-year-old child in a test held at the Royal Society in London. Some 33 per cent of the judges believed Eugene was a real boy, according to Reading University scientists who organised the test.\nKevin Warwick, a visiting Professor at Reading, said: \"In the field of artificial intelligence there is no more iconic and controversial milestone than the Turing Test, when a computer convinces a sufficient number of interrogators into believing that it is not a machine but rather is a human.\"\nHowever, he warned the breakthrough could make people more vulnerable than ever to internet scams and hackers.\n\"Having a computer that can trick a human into thinking that someone, or even something, is a person we trust is a wake-up call to cybercrime,\" he said. \"The Turing Test is a vital tool for combating that threat.\n\"It is important to understand more fully how online, real-time communication of this type can influence an individual human in such a way that they are fooled into believing something is true ??? when in fact it is not.\"\nProfessor Warwick said there had been similar events before and some would argue that the test had already been passed. \"However this event involved more simultaneous comparison tests than ever before, was independently verified and, crucially, the conversations were unrestricted,\" he said.\n\"A true Turing Test does not set the questions or topics prior to the conversations. We are therefore proud to declare that Alan Turing's Test was passed for the first time.\"\nVladimir Veselov, who helped create Eugene, said the program was \"born\" in 2001 and had been gradually improved over the years by the team in St Petersburg.\n\"We spent a lot of time developing a character with a believable personality,\" he said.\nFive supercomputers competed during the test, which involved five-minute text conversations with the judges, including actor Robert Llewellyn, who played the robot Kryten in the TV show Red Dwarf. \"Clever little robot fellow,\" he said on Twitter.\nThe public can talk to Eugene, who is meant to be a child from Odessa, Ukraine, on the website www.princetonai.com/bot/bot.jsp.\nThe site was difficult to access yesterday as word spread of its achievement, but Eugene seemed remarkably relaxed when asked about his historic achievement.\n\"I feel about beating the Turing Test in quite convenient way,\" Eugene said. \"Nothing original.\"\n"},
{"docid": "184 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "March 29, 2017", "title": "Chips in human brains 'to prevent a robot takeover'; Tech tycoon Elon Musk argues his new venture to connect people directly to computers is critical\n", "content": "THE billionaire tech entrepreneur Elon Musk is launching a company to look into implanting microchips into the brains of humans to connect them to computers.\nSouth African-born Mr Musk, 45, has become one of Silicon Valley's most high-profile entrepreneurs; initially making his fortune by founding Pay-Pal, before moving on to start the Tesla car company and SpaceX, which aims to send humans to Mars.\u00a0\nHe is also working on Hyperloop - high-speed shuttle travel in a tube, with a plan to make the 350 mile journey between Los Angeles and San Francisco in 35 minutes.\nMr Musk yesterday said that, with five children and a range of ambitious projects already in progress, it was \"difficult to dedicate the time\" to his new company, Neuralink. But, he added, \"Existential risk is too high not to.\"\nMr Musk has previously spoken of his belief that mankind's failure to advance artificial intelligence could allow the robot to take over. He sees his project as insurance against such an event. First, however, the company plans to use its technology to treat brain disorders such as epilepsy, depression and Parkinson's.\nThe company is thought to be working on \"direct cortical interface\" - essentially a layer of artificial intelligence inside the brain - that could enable humans to reach higher levels of function. It could then move to develop technologies specific to neural interfacing and cognitive enhancement.\nMr Musk has previously called the rise of artificial intelligence (AI) humanity's \"biggest existential threat\". But he believes that nanobot brain implants is a viable solution to machines rising up against humans.\n\"I think if we can effectively merge with AI by improving the neural link between the cortex and your digital extension of yourself, which already exists but just has a bandwidth issue, then effectively, you become an AI-human symbiote,\" he said last year.\n\"And if that then is widespread, and anyone who wants it can have it, then we solve the control problem as well.\n\"We don't have to worry about some evil dictator AI because we are the AI collectively. That seems like the best outcome I can think of.\"\nMr Musk is not alone in this emerging field, and he will have to compete against Kernel, a $100million start-up founded by Braintree founder Bryan Johnson, and Facebook, which recently posted jobs for \"brain-computer interface engineers\".\nUS government research arms like Darpa are also working to develop brain-implantable chips to treat mental illness and neurological disorders.\nMr Musk, twice divorced from British actress Talulah Riley and said by Forbes to be worth $14billion, intends to fund much of the scheme himself.\n"},
{"docid": "185 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "December 10, 2014", "title": "Eric Schmidt says AI concerns are normal but 'misguided' -\u00a0Open thread; Have your say on Google chairman's latest views, as well as Pirate Bay shutdown, Amazon drone threat and more\n", "content": "Google chairman Eric Schmidt has weighed in to the debate about artificial intelligence, and whether robots, drones, self-driving cars and other machines are going to take over the world and enslave humanity. Or, at least, nick people's jobs.\u00a0\n\"These concerns are normal. They're also to some degree misguided,\" said Schmidt at the Financial Times Innovate America conference, according to Wired.\n\"Go back to the history of the loom. There was absolute dislocation, but I think all of us are better off with more mechanised ways of getting clothes made... There's lots of evidence that when computers show up, wages go up. There's lots of evidence that people who work with computers are paid more than people without.\"\nThat's not much comfort for people who don't work with computers, although Schmidt argued that improving education is the key \"to get people prepared for this new world\".\nOh, but the best quote is Schmidt describing the result of Google developing a neural network and pumping 11,000 hours of YouTube videos in, to see what the artificial intelligence could learn. \"It discovered the concept of 'cat'. I'm not quite sure what to say about that, except that that's where we are...\"\nWhat are your views on the artificial intelligence and machines versus humanity debate? The comments section is open for your views.\nWhat else is on the tech radar this morning? Some links to read and discuss:The Pirate Bay raided by police\nHas the famously-unshutdownable filesharing site been shut down? Well, Swedish police raided a Stockholm address and took the site offline yesterday, so for now, yes. But on past form, it wouldn't be a surprise at all if the site sprang back up again with new servers. Although in any case, The Pirate Bay may still be seen as a figurehead for piracy by the authorities and entertainment rightsholders, but it's far from the only site of its kind.iPod DRM case continuing with new plaintiff\nApple is still enmeshed in a class-action lawsuit over its iTunes and iPod DRM back in the day, despite the removal from the case of the two plaintiffs part of the class-action. Now a third has stepped forward, who bought an iPod in the period under question.Amazon threatens to move drone research out of US\nAmazon wants the US Federal Aviation Authority to get a move on amending regulation on testing drones outdoors. \"Without the ability to test outdoors in the United States soon, we will have no choice but to divert even more of our [drone] research and development resources abroad,\" the company wrote to the FAA.The arguments behind one of the Steve Jobs movies\nOkay, the tech link here is a bit tenuous - leaked emails from Sony Pictures about negotiations to get a biopic up and running of the late Apple CEO. But it's a fun insight into the... let's say robust talk between executives fretting about the casting and production process.\n"},
{"docid": "186 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "September 12, 2013", "title": "Fund managers 'will be replaced by computers'; Standard Life Investments, the global investment manager, has proposed that there will soon be no need for fund managers.\n", "content": "In a report published this month by the investment firm, they argue that long-term strategy fund managers could soon be replaced by machines.\u00a0\n\"Using artificial intelligence applications have enhanced our understanding and analysis of financial market behaviour, adding to the range of predictive tools,\" the investment firm says.\nWhile the firm is aware that, traditionally, \"investment approaches generally contain both qualitative and quantitative elements\", which means that \"in broad terms human thinking may be better suited to the qualitative side while computers are used to varying extents to add value to quantitative inputs\". This looks like it could change.\nThe flaws in human financial decision making are clear and the ability of a computer to \"improve the quality of trading decisions...or to speed up the execution of trades\" is too great to ignore.\nStandard Life presents a simple argument: \"Man\" has to deal with \"fear and greed, intellectual constraint and fatigue\", whereas a machine is \"agnostic, tireless\" and has \"no bias\" in decision making.\nFrances Hudson, Standard Life's global thematic strategist, said that \"artificial intelligence applications have enhanced our understanding and analysis of financial market behaviour\", and \"artificial intelligence, which is commonly used in short-term market analysis... may also be applied here [to longer-term investments]\".\nWhile computer algorithms are not a new thing in themselves - dating back to the 1950s and 1960s and used today for high frequency trades - the view that \"long-term investors can benefit from a computer's consistent application of collective intelligence to financial markets\" is increasingly strong.\n"},
{"docid": "187 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "July 27, 2015", "title": "Musk, Wozniak and Hawking urge ban on warfare AI and autonomous weapons; More than 1,000 experts and leading robotics researchers sign open letter warning of military artificial intelligence arms race\n", "content": "Over 1,000 high-profile artificial intelligence experts and leading researchers have signed an open letter warning of a \"military artificial intelligence arms race\" and calling for a ban on \"offensive autonomous weapons\". \u00a0\nThe letter, presented at the International Joint Conference on Artificial Intelligence in Buenos Aries, Argentina, was signed by Tesla's Elon Musk, Apple co-founder Steve Wozniak, Google DeepMind chief executive Demis Hassabis and professor Stephen Hawking along with 1,000 AI and robotics researchers.\nThe letter states: \"AI technology has reached a point where the deployment of [autonomous weapons] is - practically if not legally - feasible within years, not decades, and the stakes are high: autonomous weapons have been described as the third revolution in warfare, after gunpowder and nuclear arms.\"\nThe authors argue that AI can be used to make the battlefield a safer place for military personnel, but that offensive weapons that operate on their own would lower the threshold of going to battle and result in greater loss of human life.\nShould one military power start developing systems capable of selecting targets and operating autonomously without direct human control, it would start an arms race similar to the one for the atom bomb, the authors argue.Unlike nuclear weapons, however, AI requires no specific hard-to-create materials and will be difficult to monitor.\n\"The endpoint of this technological trajectory is obvious: autonomous weapons will become the Kalashnikovs of tomorrow. The key question for humanity today is whether to start a global AI arms race or to prevent it from starting,\" said the authors.\nToby Walsh, professor of AI at the University of New South Wales said: \"We need to make a decision today that will shape our future and determine whether we follow a path of good. We support the call by a number of different humanitarian organisations for a UN ban on offensive autonomous weapons, similar to the recent ban on blinding lasers.\"\nMusk and Hawking have warned that AI is \"our biggest existential threat\" and that the development of full AI could \"spell the end of the human race\". But others, including Wozniak have recently changed their minds on AI, with the Apple co-founder saying that robots would be good for humans, making them like the \"family pet and taken care of all the time\".\nAt a UN conference in Geneva in April discussing the future of weaponry, including so-called \"killer robots\", the UK opposed a ban on the development of autonomous weapons, despite calls from various pressure groups, including the Campaign to Stop Killer Robots.\n                     \u00b7 The Guardian view on robots as weapons: the human factor                   \n                     \u00b7 DeepMind: 'Artificial intelligence is a tool that humans can control and direct'                                        \n"},
{"docid": "188 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "January 25, 2017", "title": "AI system as good as experts at recognising skin cancers, say researchers; Deep learning-based system could be further developed for smartphones, increasing access to screening and aiding early detection of cancers\n", "content": "Computers can classify skin cancers as successfully as human experts, according to the latest research attempting to apply artificial intelligence to health.\nThe US-based researchers say the new system, which is based on image recognition, could be developed for smartphones, increasing access to screening and providing a low-cost way to check whether skin lesions are cause for concern.\n\"We hope that this is a first step towards early detection,\" said Andre Esteva, an electrical engineering PhD student from Stanford University and co-author of the research. \u00a0\n Related:  Google DeepMind and UCLH collaborate on AI-based radiotherapy treatment\nAccording to the World Health Organisation, skin cancer accounts for one in every three cancers diagnosed worldwide, with global incidence on the rise.\nIn the UK alone, 131,772 cases of non-melanoma skin cancer were recorded in 2014. In the same year there were 15,419 new cases of the deadliest skin cancer, melanoma, making it the fifth most common cancer, according to Cancer Research UK. \nAs the disease is often initially spotted by a visual examination, Esteva teamed up with colleagues in fields ranging from dermatology to artificial intelligence to create a computer system that would aid screening. \nTheir approach, described in the journal Nature, is based on deep learning - a class of algorithms used for artificial intelligence. When fed with a large set of ready-sorted data these algorithms pick out and \"learn\" patterns and relationships. Once trained, the algorithms can then be used to categorise new, unsorted data. \nTo create the system, the team harnessed a deep learning algorithm built by Google that had already been presented with 1.28 million images of objects such as cats, dogs and cups. Esteva and colleagues then fed the system more than 127,000 clinical images of skin lesions, each already labelled, encompassing many different skin diseases. \nOnce trained, the team then tested the system's ability to classify skin cancer by presenting it with just under 2,000 previously unseen images of skin lesions, whose nature had previously been determined by biopsy, and further compared the results for nearly 400 of the images against the judgement of at least 21 dermatologists.\nThe results reveal that the system is on a par with - if not better than - the experts in telling apart carcinomas from common benign skin growths and melanomas from moles.\nFor melanomas, the average dermatologist classified around 95% of malignant lesions and 76% of harmless moles correctly. By comparison, the algorithm is capable of correctly classifying 96% of malignant lesions, and correspondingly 90% of benign lesions.\n\"The aim is absolutely not to replace doctors nor to replace diagnosis,\" said Esteva. \"What we are replicating [is] sort of the first two initial screenings that a dermatologist might perform.\"\nWhile Esteva and colleagues admit the system needs further testing in clinical settings they believe the approach has great promise, suggesting it could be applied to a host of other medical fields.\n Related:  Everything you ever wanted to know about moles (but were too busy on the sunbed to ask)\nBoguslaw Obara, a computer scientist at Durham University and expert in image processing, said that the size and complexity of the dataset used to train the system was impressive. The work, he adds, shows we are likely to see algorithms cropping up more and more in everyday life. \nDr Anjali Mahto, consultant dermatologist and spokesperson for the British Skin Foundation also welcomed the research. \"This is an exciting new technology that has the potential to increase access to dermatology at a time where there is a national shortage in this speciality and the rates of skin cancer continue to rise,\" she said. \nBut, Mahto warned, the system will need to be carefully assessed for its benefits before it can be rolled out. The approach is also unlikely to replace the role of dermatologists, she adds, pointing out that during a full-body examination experts often discover skin cancer at different sites to those that initially concerned the patient. \"There is therefore a possibility that if you rely on people to self-report what they are worried about, other skin cancers - particularly in hard to see sites, e.g. the back - may be missed,\" she said.\n"},
{"docid": "189 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "December 24, 2015", "title": "Tesla and SpaceX CEO Elon Musk unexpectedly nominated for 'Luddite of the Year' award; A tech billionaire is an unlikely candidate for the prize of 'Luddite of the Year'\n", "content": "                     Elon Musk, CEO of leading electric car company Tesla and private space transport company SpaceX,has unexpectedly been nominated for the dubious title of 'Luddite of the Year'.\u00a0\nThe award takes its name from the Luddite movement of the 19th Century, which was composed of textile workers who opposed technological progress, fearing that material-making machines produced during the industrial revolutionwould put them out of a job.\nAccording to the Information Technology and Innovation Foundation, which gives the award, the title is given to those who want to \"foil technological progress\" by opposing advances in science and tech.\nRead more\nElon Musk and other tech giants pledge $1 billion to stop evil robots\nAs the foundation says, \"Neo-Luddites no longer wield sledgehammers, but they wield something much more powerful: bad ideas. For they work to convince policymakers and the public that innovation is the cause, not the solution to some of our biggest social and economic challenges, and therefore something to be thwarted.\"\n\"Indeed, the neo-Luddites have wide-ranging targets, including everything from genetically modified organisms to new Internet apps, artificial intelligence, and even productivity itself. In short, they seek a world that is largely free of risk, innovation, or uncontrolled change.\"\nWorld's top artificial intelligence developers sign open letter calling for AI safety research: http://t.co/ShWc8F7Kyq\n- Elon Musk (@elonmusk) January 11, 2015\nUnexpectedly, tech billionaire Elon Musk, who currently leads both an electric sports car company and a pioneering space transport firm, was nominated for the title, as part of the category of \"alarmists\" who \"tout an artificial intelligence apocalypse.\"\nRead more\n                     'Welcome back, baby!' SpaceX rocket performs vertical landing                   \n                     Elon Musk: World War Three could ruin mission to get to Mars                   \n                     Climate change can be addressed by taxes, Elon Musk says                   \nMusk, along with Stephen Hawking and a number of other leading academics, were amongst the people who put their name to a letter warning the scientific community of the dangers of creating artificial intelligence.\nThe letter said it was important to research how to reap the benefits of artficial intelligence while avoiding its potential pitfalls - like the danger of a superintelligence harming humanity in the course of pursuing a goal.\nOther nominees for the title, some of whom were given general labels rather than being named individually, included 'Advocates who seek a ban on 'killer robots'', US states who oppose automatic license plate readers, and California's governor, who is against putting RFID chips in drivers' licenses.\nVoting for the title is open to the public, and the winner is expected to be announced in the coming weeks.\n"},
{"docid": "190 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "February 24, 2016", "title": "Smart care: how Google DeepMind is working with NHS hospitals; A smartphone app piloted by the NHS could improve communication between hospital staff and help patients get vital care faster\n", "content": "Google DeepMind, the tech giant's London-based company most famous for its groundbreaking use of artificial intelligence, is developing  a software in partnership with NHS hospitals to alert staff to patients at risk of deterioration and death through kidney failure.\nThe technology, which is run through a smartphone app, has the support of Lord Darzi, the surgeon and former health minister in the Blair government who is director of the Institute of Global Health Innovation at Imperial College London.\u00a0\n Related:  The superhero of artificial intelligence: can this genius keep it in check?\n\"Innovation is the only solution we have for a sustainable NHS, both economically and in meeting the challenges and demands upon it,\" Darzi told the Guardian in a preview of the technology.\nDarzi has led a team working on a smartphone app called Hark for the last five years, which DeepMind has now acquired and will develop. Hark identifies the tasks that need to be performed to prevent a patient who has been admitted to hospital deteriorating, allocates them to the right staff, and tracks what has been done - or not done.\nTheir research, published in the journal Surgery, showed that half of hospital patients do not get the care they need fast enough, usually because of poor communication, particularly when one team of doctors or nurses hands over to another. In early pilots at St Mary's Hospital, part of Imperial College Healthcare NHS Trust, where Darzi is a consultant surgeon, they found medical staff responded 37% faster when alerted by the Hark app than when they used pagers.\nThe app will pick up relevant information from the electronic patient record, so that medical staff have a complete picture of the patient's condition and medical history. It will also provide a record of what actions are taken by nurses and doctors. Often they have to ask the patient whether they have had a blood test or been given their medication.\nEverybody has a smartphone... but the people saving lives every day are hampered by using desktop computers\n  Mustafa Suleyman, DeepMind    \nDespite DeepMind's expertise in artificial intelligence (AI) and machine learning, the smartphone app being piloted does not use either technology. Mustafa Suleyman, co-founder and head of applied artificial intelligence at DeepMind, said \"that may change in the future\".\n\"For the moment these are just early pilots,\" he said. \"For the moment there's no AI or machine learning.\"\nEven without an AI application, the involvement in NHS patient data of a tech giant that routinely gathers, and profits from, data from users' emails, internet searches and map locations could raise ethical questions.\nSuleyman, however, said they were taking extensive precautions to protect patient data and had asked prominent medical and technology leaders to act as unpaid independent reviewers of the division of DeepMind overseeing the project. \n\"They'll be able to scrutinise our work and publish reports as they see fit,\" Suleyman said.\n\"The hospital will always own and control that data. We have a processing agreement that allows us to securely stream the information straight to a clinician's mobile phone. The data will never leave the UK and it will never be linked or associated with Google accounts, products or services.\"\nAt the Royal Free, consultant nephrologist Chris Laing, both a kidney expert and associate medical director for patient safety, said he brought in DeepMind because of his concern over acute kidney failure in patients admitted to hospital, which can cause rapid deterioration and death. He and his colleagues helped DeepMind develop and trial an app called Streams, which alerts medical staff almost instantly to the results from routine blood tests showing up dangerous levels of creatinine, indicating the kidneys are not working well. \n Related:  This is the NHS: a day in the life of the UK's busiest maternity centre\nLaing said thousands of blood tests are carried out every day on patients in the Royal Free NHS Foundation Trust hospitals, which include Barnet and Chase Farm. He can review the results and focus on those the app tell him are of concern from his phone at any time. \"I'm on the move. A lot of our clinicians are on the move. It is very time consuming to log into [static] computer systems. Wherever I am, over three hospital sites or 20 community sites, I can access this information,\" he said.\nSuleyman said the company hoped to work on alerts for other life-threatening conditions too, such as sepsis - or blood poisoning. \"Everybody has a smartphone and we all use apps all the time,\" he said. \"But the people doing incredible work saving lives every day are hampered by using desktop computers and software designed a long time ago.\" \nThe apps his team are designing are not a one-off commodity, he said, but will change as the need and the information changes. \"The software we are building today will look completely different in a few years' time,\" he said. Suleyman said there were no immediate plans for this to be a commercial operation, though that could change in the future.\nDarzi believes the apps will prove very popular with NHS staff. \"I have no doubt it will take off throughout the NHS,\" he said. \"It will get stronger and better and more intuitive. It will be a pull, not a push technology. If you find a way of making doctors' lives easier they will pull the thing as quickly as they can.\"\n"},
{"docid": "191 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "August 22, 2017", "title": "Killer robots 'will cause war on a vast scale'\n", "content": "Pioneers of robotics and artificial intelligence have called for the UN to ban killer robots, warning of conflicts on an unprecedented scale if an arms race to build autonomous weapons continues.\nThe founders of more than 160 companies, including Tesla's Elon Musk and Mustafa Suleyman of Deepmind, an AI company acquired by Google in 2014, signed an open letter warning that lethal autonomous weapons would create a \"third revolution\" in warfare, after the invention of gunpowder and the atomic bomb. The group is urging the UN to add autonomous systems to a list of \"morally wrong\" weapons that includes chemical weapons and blinding lasers.\nSouth Korea and Israel use stationary \"sentry\" guns that have autonomous capabilities, although they are only authorised to fire by human controllers. Experts believe that weaponised drones and ground vehicles could be programmed for fully autonomous strike actions within the next few years.\u00a0\nThe systems are attractive to commanders because they have the potential to reconnoitre enemy posied tions or engage enemy forces without risking casualties on their own side. Nevertheless, critics believe the weapons would inevitably be acquired by nations and terror groups hostile to the West, and would be given terrifying capabilities as countries and arms companies competed to stay ahead.\nIn the letter, published before the International Joint Conference on Artificial Intelligence in Melbourne, the technology bosses said: \"Lethal autonomous weapons threaten to become the third revolution in warfare. Once developed, they will permit armed conflict to be fought at a scale greater than ever, and at timescales faster than humans can comprehend.\n\"These can be weapons of terror, weapons that despots and terrorists use against innocent populations, and weapons hacked to behave in undesirable ways. We do not have long to act. Once this Pandora's box is opened, it will be hard to close.\"\nUS policy states that \"autonomous weapons systems shall be designed to allow commanders and operators to exercise appropriate levels of human judgment over the use of force\".\nThe Ministry of Defence has indicatdeployed that British weapons systems will always be under human control. However, campaigners say there's no definition of what constitutes \"human control\" and killer robots could soon be unless an international framework is agreed.\nRyan Gariepy, founder of Clearpath Robotics, one of the signatories, said: \"This is not a hypothetical scenario, but a very real, very pressing concern which needs immediate action.\"\nMr Musk, whose company is working on autonomous technology for driverless cars, has warned of the \"existential threat\" to mankind from artificial intelligence if it is not closely regulated. Other tech leaders, including Facebook's Mark Zuckerberg, have criticised his comments as pessimistic. Two years ago, more than 1,000 experts including Mr Musk, Stephen Hawking and Noam Chomsky signed another open letter warning of an arms race in military artificial intelligence and calling for a ban on autonomous weapons.\nAutonomous armies are already on the march ? Last year, the Pentagon showed off a swarm of 103 miniature autonomous drones released by fighter jets. They could be used for reconnaissance and targeting of automated artillery strikes as well as to confuse enemy radar. Full-size strike drones such as the 36ft Reaper could one day be capable of autonomous targeting.\n? US forces have tested unmanned ground vehicles that are designed for reconnaissance but come equipped with a machinegun and grenade launcher. The 370lb Maars robot can move at 7mph on treads and carries 450 rounds and four grenades. It is remote controlled but very similar vehicles could be made autonomous.\n? Russia has developed an unmanned tank that can travel at 37mph and is armed with a 300mm cannon equipped with 500 shells, a 2,000-round machinegun and six anti-tank guided missiles. The Uran-9 can also be equipped with surface-to-air missiles and flame-throwers.\n? Samsung's SGR-A1 sentry gun is deployed by South Korea to protect its troops in the Demilitarised Zone. The $200,000 guns have laser rangefinders, thermographic cameras that can detect people, and can fire machinegun rounds and also rubber bullets.\n"},
{"docid": "192 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "December 3, 2014", "title": "Stephen Hawking: AI could be the end of humanity; Hawking was speaking at the launch of his new speech technology, which uses computers to predict what he is likely to say next\n", "content": "Stephen Hawking has warned that artificial intelligence could end the human race.\nMachines that can think pose a threat to our very existence and \"the development of full artificial intelligence could spell the end of the human race,\" the theoretical physicist has told the BBC.\u00a0\nHawking's warning came in response to a question about the new typing technology used in the computer that allows him to speak, which predicts the words he is going to use, the BBC reported.\nStephen Hawking has warned about the dangers of AI in the past - writing in The Independent with a group of leading scientists in May of this year to warn that humanity might not be taking the threat seriously enough.\nRead more: New phone-inspired speech kit doubles his typing speedHawking gets synthesiser upgrade to help him speak faster\n\"Whereas the short-term impact of AI depends on who controls it, the long-term impact depends on whether it can be controlled at all,\" they wrote in May. \"All of us should ask ourselves what we can do now to improve the chances of reaping the benefits and avoiding the risks.\" In pictures: Artificial intelligence through history\nHawking also warned about the dangers of the internet, during the interview with the BBC. Referencing the director of GCHQ's warning that the internet could become a command centre of terrorists, Hawking said: \"More must be done by the internet companies to counter the threat, but the difficulty is to do this without sacrificing freedom and privacy\".\n"},
{"docid": "193 of 500 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "November 1, 2011", "title": "John McCarthy; Computer scientist known as the father of AI He regularly invited a group to his Stanford lab whose members included Steve Jobs and Steven Wozniak\n", "content": "John McCarthy, an American computer scientist pioneer and inventor, was known as the father of Artificial Intelligence (AI) after playing a seminal role in defining the field devoted to the development of intelligent machines. The cognitive scientist coined the term in his 1955 proposal for the 1956 Dartmouth Conference, the first artificial intelligence conference. The objective was to explore ways to make a machine that could reason like a human, was capable of abstract thought, problem-solving and self-improvement. He believed that \"every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.\"\nIt would prove a challenge that eluded him and which still eludes computer designers today. McCarthy said the breakthrough might come in \"five to 500 years\" but never dismissed it. In 1958 he created the Lisp computer language, which became the standard AI programming language and continues to be used today, not only in robotics and other scientific applications but in a plethora of internet-based services, from credit-card fraud detection to airline scheduling; it also paved the way for voice recognition technology, including Siri, the personal assistant application on the latest iPhone 4s.\u00a0\nDescribed as \"focused on the future,\" McCarthy was \"always inventing, inventing, inventing,\" and in the 1960s he conceived the idea of computer time-sharing or networking, which allowed users to share data by linking to a central computer; it ultimately lowered the cost of using computers. This innovation was described as a significant contribution to the development of the internet, and a precursor of cloud computing - a method of storing data on a remote server accessible via the internet.\nJohn McCarthy was born in Boston to Irish and Lithuanian immigrants in 1927. During the Depression the family moved many times, eventually arriving in Los Angeles, where his father was an organiser for a clothing workers' union and his mother was active in the women's suffrage movement.\nAlthough hampered with illness, McCarthy was an exceptionally bright child. Self-taught in mathematics, he secured an undergraduate place at the esteemed California Institute of Technology, from where he graduated in 1948. After attending a symposium at on \"Cerebral Mechanisms in Behaviour\", his interest was ignited and so began his quest to develop machines that could think like people.\nIn 1951, he received his PhD in mathematics from Princeton. Via Dartmouth and MIT, he became a full professor at Stanford in 1962, where he remained until his retirement.\nWhile at Dartmouth, McCarthy organised the ground-breaking con-ference on artificial intelligence. There, he met Marvin Minsky, who became one of the leading theorists in the field. McCarthy won a fellowship to MIT and Minsky, who was at Harvard, joined him. In 1959, they co-founded the MIT Artificial Intelligence Laboratory. However, their views began to diverge and McCarthy returned to Stanford. He quickly founded Stanford's AI Laboratory, known as SAIL, which became MIT's rival. He served as its director from 1965-1980.\nDuring the 1960s and '70s, the Stanford lab played a pivotal role in creating the systems that mimic many human skills, including vision, listening, reasoning and movement. He sometimes showcased inventions and invited the Homebrew Computer Club, a Silicon Valley hobbyist group, to meet at the Stanford labs. The group included two of Apple's founder members, Steve Jobs and Steven Wozniak. In the 1970s, McCarthy presented a paper on buying and selling via computer, foreseeing e-commerce.\nAlthough McCarthy was notoriously brusque, at MIT he was affectionately referred to as \"Uncle John\" and was kind and generous with his time. He retired from Stanford in 1994, but continued to write and lecture, most recently on the feasibility of interstellar travel.\nJohn McCarthy, computer scientist: born Boston, Massachusetts 4 September 1927; married firstly Martha White (marriage dissolved, two daughters), secondly Vera Watson (died 1978), thirdly Carolyn Talcott (one son); died Stanford, California 24 October 2011.\n"},
{"docid": "194 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "November 24, 2015", "title": "The tech elite ignores inequality at its peril; As automated marketplaces threaten to make many jobs obsolete, industry influencers must heed warnings of social unrest\n", "content": "Several years ago when media companies were still working out what the \" long tail \" meant to them, Clay Shirky shared a key nuance that made the whole picture clearer for me. He told me that the middle of a power law curve is the most dangerous place to be because you are irrelevant there. He was right.\nI was reminded of this last week while attending O'Reilly Media's Next:Economy event in San Francisco, where people talked about artificial intelligence, platforms, networks and ecosystems creating and destroying labour markets.\nIn today's world, artificial intelligence such as that seen in Google's self-driving cars is at one end of that power law curve of services, ie the top of the curve, and marketplaces such as Uber and AirBnB are sweeping up the other end - the long tail of services. \nIf the lessons of the now-famous 2004 Wired article by Chris Anderson about the long tail prove relevant then companies serving the middle market are going to suffer. According to Shirky's \"middle power law problem\", aka the \"simple problem\", the stuff that happens in between artificial intelligence and niche human-powered labour will become irrelevant.\nMiddle management will be replaced by the long tail of tasks performed by a vastly more efficient labour market.\nA lot of the discussion at the event was focused on workers - their needs, rights and future prospects. Sebastian Thrun of Udacity even suggested that higher education degrees in social sciences were a waste of time because the new economy puts a premium on skills.\nBut there was a baked in assumption among many speakers that these big changes were already happening, and that it was just a matter of time before we were all deploying services or being deployed in service of something or somebody. \nInteresting questions start to emerge, such as will we still need to own a car if one can appear in front of us ready to take us where we want to go at any given moment for a reasonable price?\nOf course, people need to model the computing that sits at the top of the curve, and that will become a lucrative area of work. In fact, Facebook is hiring AI trainers now. Alex Lebrun said this was a huge area of growth. \"We will need more and more trainers because the more you know the more you know you don't know. There will always be new domains to learn about.\"\nMany speakers at the event acknowledged that the gap between the people at the top and those at the bottom was only increasing - this is an alarming trend.\nSelf-proclaimed \"zillionaire\" and early Amazon investor Nick Hanauer of Seattle-based Second Avenue Partners expressed great concern for the stability of society. He said: \"You must match tech innovation with civic innovation. Uber is fantastic, but we have to find a way to accommodate that innovation in society.\"\nHe used the fight to increase the minimum wage as an example of the types of battles that will lead to more dramatic social problems, perhaps revolutions. \"Trickle down economics is a way to bully people into not exercising their rights,\" he said. \"The threat becomes: 'If you force us to pay our workers fairly we will fire them.'\"\nIn a letter to his fellow plutocrats in Politico, Hanauer wrote: \"The problem is that inequality is at historically high levels and getting worse every day. Our country is rapidly becoming less a capitalist society and more a feudal society. Unless our policies change dramatically, the middle class will disappear, and we will be back to late 18th century France. Before the revolution.\n\"And so I have a message for my fellow filthy rich, for all of us who live in our gated bubble worlds: Wake up, people. It won't last. If we don't do something to fix the glaring inequities in this economy, the pitchforks are going to come for us.\"\nI find it difficult to imagine inequality reversing from its current trajectory without something dramatic happening. Perhaps this is a place where the middle may play an important role over time, though fighting against irrelevance seems like a losing battle too.\nI did notice an apologetic tone among many of the speakers at the event. There seemed to be an awareness that the change was both beyond anyone's control and that it was heading straight for many innocent people who were unwittingly in its way.\nIf there is still time to assert some cultural values into the technological framework of this next wave of change then hopefully people will consider infusing their automated marketplaces with more humanity.\nIn his 2003 essay, Power Laws, Weblogs, and Inequality, Shirky wrote: \"Given the ubiquity of power law distributions, asking whether there is inequality in the weblog world (or indeed almost any social system) is the wrong question, since the answer will always be yes. The question to ask is, 'Is the inequality fair?'\"\nIf the entire world becomes a unified workforce on these new platforms then the people shaping these platforms should heed the warnings from the likes of Hanauer, or they will regret admitting that he was right when billions of pitchforks are aimed at them.\nAs Zeynep Ton described in one of the closing talks of the day, providing a decent living for your workforce or pursuing \"human-centred operations strategies\" creates stronger long-term profits. Her research may provide some answers that solve everyone's needs and avert angry mob mentality that otherwise seems inevitable.\n                     Matt McAlister is cofounder of Publish.org. He worked at the Guardian for seven years developing media businesses and new technologies for journalism. Find him on Twitter @mattmcalister                   \n                       To get weekly news analysis, job alerts and event notifications direct to your inbox,                         sign up free for Media & Tech Network membership                       .                                        \n                     All Guardian Media & Tech Network content is editorially independent except for pieces labelled \"Brought to you by\" - find out more                                            here                                          .                   \n"},
{"docid": "195 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "July 31, 2017", "title": "Facebook's artificial intelligence robots shut down after they start talking to each other in their own language; 'you ii ieverything else'\n", "content": "Facebook has shut down two artificial intelligences that appeared to be chatting to each other in a strange language only they understood.\nThe two chatbots came to create their own changes to English that made it easier for them to work - but which remained mysterious to the humans that supposedly look after them.\nThe bizarre discussions came as Facebook challenged its chatbots to try and negotiate with each other over a trade, attempting to swap hats, balls and books, each of which were given a certain value. But they quickly broke down as the robots appeared to chant at each other in a language that they each understood but which appears mostly incomprehensible to humans.\u00a0\nThe robots had been instructed to work out how to negotiate between themselves, and improve their bartering as they went along.\nThe actual negotiations appear very odd, and don't look especially useful:\nBob: i can i i everything else . . . . . . . . . . . . . .\nAlice: balls have zero to me to me to me to me to me to me to me to me to\nBob: you i everything else . . . . . . . . . . . . . .\nAlice: balls have a ball to me to me to me to me to me to me to me\nBob: i i can i i i everything else . . . . . . . . . . . . . .\nAlice: balls have a ball to me to me to me to me to me to me to me\nBob: i . . . . . . . . . . . . . . . . . . .\nAlice: balls have zero to me to me to me to me to me to me to me to me to\nBob: you i i i i i everything else . . . . . . . . . . . . . .\nAlice: balls have 0 to me to me to me to me to me to me to me to me to\nBob: you i i i everything else . . . . . . . . . . . . . .\nAlice: balls have zero to me to me to me to me to me to me to me to me to\nBut there appear to be some rules to the speech. The way the chatbots keep stressing their own name appears to a part of their negotiations, not simply a glitch in the way the messages are read out.\nIndeed, some of the negotiations that were carried out in this bizarre language even ended up successfully concluding their negotiations, while conducting them entirely in the bizarre language.\nThey might have formed as a kind of shorthand, allowing them to talk more effectively.\n\"Agents will drift off understandable language and invent codewords for themselves,\" FAIR visiting researcher Dhruv Batra said. \"Like if I say 'the' five times, you interpret that to mean I want five copies of this item. This isn't so different from the way communities of humans create shorthands.\"\nThat said, it's unlikely that the language is a precursor to new forms of human speech, according to linguist Mark Liberman.\n\"In the first place, it's entirely text-based, while human languages are all basically spoken (or gestured), with text being an artificial overlay,\" he wrote on his blog. \"And beyond that, it's unclear that this process yields a system with the kind of word, phrase, and sentence structures characteristic of human languages.\"\nThe company choseto shut down the chatsbecause \"our interest was having bots who could talk to people\", researcher Mike Lewis told FastCo.\nThe chatbots also learned to negotiate in ways that seem very human. They would, for instance, pretend to be very interested in one specific item - so that they could later pretend they were making a big sacrifice in giving it up, according to a paper published by the Facebook Artificial Intelligence Research division.\nRead more\nAI better than scientists at choosing successful IVF embryos\n(That paper was published more than a month ago but began to pick up interest this week.)\nFacebook's experiment isn't the only time that artificial intelligence has invented new forms of language.\nEarlier this year, Google revealed that the AI it uses for its Translate tool had created its own language, which it would translate things into and then out of. But the company was happy with that development and allowed it to continue.\nAnother study at OpenAI found that artificial intelligence could be encouraged to create a language, making itself more efficient and better at communicating as it did so.\n"},
{"docid": "196 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "June 26, 2015", "title": "What will artificial intelligence mean for the world of work?; Machines are good at complex tasks, but not at activities that humans find simple. The answer is for people and computers to work together\n", "content": "What can scientists tell us about business? I had an opportunity to consider this important question when, earlier this year, I led a debate with four professors from the University of California, Berkeley, who were experts in artificial intelligence, neuroscience and psychology.\nThe question under discussion was one of the most troubling of our time: will machines ever make better decisions than humans? This is a crucial question for those interested in the future of business. What impact will machines, be they computers or robots, have on the way we work?\u00a0\nThere are those who argue that up to 60% of the work we currently do will, within two decades, be entirely replaced by machines. This process is already happening. The hollowing out of what we understand as work has already seen many medium-skilled jobs disappear as executives' smartphones replace their secretaries and assistants are made redundant by automatic filing systems and Wikipedia.\n Related: The ethics of AI: how to stop your robot cooking your cat\nAt the debate, I asked the audience members what they believed: would machines eventually make better decisions than humans? Around 50% agreed and 50% disagreed; there is no consensus on such a tricky question.\nThe first issue with the problem of future decision-making is well-known to scientists specialising in artificial intelligence. It is best described in Moravec's paradox: why is it that computers are very good at undertaking tasks that require speed and precision, and which humans find difficult (such as solving mathematical equations, playing chess, or even driving cars), and yet bad at tasks we humans find simple, such as clearing coffee cups from a table?\nThe psychologist Alison Gopnik studies babies. She states that, today, machines are not as smart as a two-year-old child. Though they may not be able to play chess or drive, two-year-olds can do lots of things that a computer cannot: create theories, make hypotheses, figure out how things work, imitate and - most importantly - learn and be creative. Moravec's ultimate argument is that computers are great at reasoning, but the often unconscious, sensorimotor knowledge that has evolved in the human brain over billions of years is impossible to imitate.\nThe second issue is the question of values and morality. We humans make decisions on the basis of our values. Can computers have values? The artificial intelligence expert Stuart Russell argues that it is already possible to programme computers on the basis of utility, in terms of gaining the highest-value outcome. However, programming is still carried out on the basis of the values of the programmer.\nAs our panel observed, human decisions are about emotions and we make decisions cognitively and viscerally. This comes from the evolution of the frontal cortex that took place over the last two million years. How can the constant changing of consensus on values be programmed?\n Related: Driverless cars - the future of transport in cities?\nComputers cannot make decisions better than humans right now, but it may be possible given time. Certainly with regard to sheer computing power, the technology is developing fast. Recent developments in cloud computing are enabling the connection of millions of devices, and that has enormous potential for the amplification of any moral or ethical imperative through a network of machines.\nBut, as Professor Ken Goldberg believes, it is likely to be through the combination of computers and people that real progress will be made. This echoes my own findings, in the study of open innovation, that it is the combination of diverse minds that brings forth the ideas that prove to be the basis of innovation.\nIn this area at least, scientists have much to tell us about how the world of work and the organisations we work for will develop. Even if there is no consensus on timeframes, the direction of travel is clear: there is a great deal more for us to explore in the interface between humans and machines.\n\u00b7 A version of this article first appeared on Lynda Gratton's blog, FoWLAb\n                     The business futures hub is funded by The Crystal. All content is editorially independent except for pieces labelled \"brought to you by\". Find out more                                            here                                          .                   \n                     This content is brought to you by Guardian Professional.                                            Become a GSB member                                          to get more stories like this direct to your inbox.                   \n"},
{"docid": "197 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "November 13, 2017", "title": "The robots are coming, but it's a slow process; As an extra \u00a384m is pumped into the sector, analysts predict AI will be no overnight revolution, reports Tim Wallace\n", "content": "Robots in space. Intelligent machines in the freezing deeps of the North Sea. Automatons within the most toxic chambers of nuclear power plants, or plunging into the harshest mines. The future for artificial intelligence is exotic, alien and powerful.\nAt least, that is the vision bought into by the Business Department last week when it ploughed an extra \u00a384m into a series of new projects at a series of universities and corporate research and development labs.\nCutting edge research into the artificial intelligence, robotics, 3D printing and other barely-out-of-sci-fi fields holds plenty of promise but has yet to completely upend the world in which we live.\nFor the past decade business investment appears to have been sluggish. Productivity growth has slowed and real wages are under the cosh, which does not fit with the idea that we are in an age of incredible technologies. Visions of the future can be inspiring or daunting, depending on your job right now.\u00a0\nAirbus last week claimed it can have driverless flying cars on the market in five years' time - a fantastical vision and the stuff of movies so far.\nIn perhaps a more grounded forecast, John Cryan, the chief executive of Deutsche Bank, said half of the bank's almost 100,000 jobs could be replaced by robots in the next 20 years.\nSo far, the practical gains have been more modest, but are important in specific areas.\nDaniel Hegarty founded and runs Habito, an online mortgage broker which uses artificial intelligence as part of its system to process applications and match borrowers with loans.\n\"Humans are really, really bad at doing arithmetic and filling out forms and holding 80 different credit policies in their heads and matching them to the right customer,\" he says.\nThere is still a human element - he found customers are unwilling to conduct such an important transaction through a clever machine alone, and value the chance to talk to a living, breathing adviser. \"We use machines for sorting and humans for talking,\" he says. Nonetheless, Hegarty believes he is four or five times more efficient than a traditional broker, with the capacity to grow much further using the technology he already has.\nHowever, he is aware these are early days in what is sometimes called, rather grandly, the fourth industrial revolution.\n\"We are super early on. We have essentially mechanised a manual process. That is interesting and it provides a tangible consumer benefit. But the real transformation in financial services is still some way off,\" he says.\nThat belief is based on his concern that right now, people must shop around on a regular basis for new loans or savings accounts with imperfect information, leaving them reliant on the marketing power of big finance firms, rather than finding the best product out there.\n\"When machines pick the products it is not about the marketing budget, it is about the best product,\" he says, hoping it will force firms to compete on value. \"That will be a transformational point.\"\nIt is not only services which could be revolutionised by new technology.\nManufacturing, too, faces a wave of much-hyped new tech which is yet to fully hit home.\nEconomist Raoul Leering at ING has studied the potential of 3D printing and sees several factors holding it back so far.\n\"Current 3D printers are really slow, so they are not competitive with regard to traditional capital goods,\" he says. \"For the time being, they are only competitive when making customised products in a complex shape,\" he says, citing medical parts printed to match an individual's body.\n\"But for mass production of traditional products, 3D printers are too slow. We are waiting for a new generation to speed up the tempo.\"\nAdvances are quick - the latest models are as much as 1000-times faster than their predecessors - but speed, price and reliability all have to combine to make them a worthwhile purchase.\nHis observations in that market can be applied to all radical new tech.\nFirstly, companies are not going to abandon any expensive relatively modern equipment immediately just because the latest tech has marginally outclassed it.\nSecond, engineers with decades of experience are not always keen to abandon all of the systems with which they have expertise, switching to a revolutionary new system overnight.\nAnd third, he sees a network effect holding investment back.\nTo use the example of the internet, the technology took time to grow because the first person with it could communicate with nobody.\nGoing back further in time, a lone telephone is useless with nobody to call.\nIt was only as more people gained access that it became worth anybody's while to connect to the internet. And as more people did, access itself became more valuable and, in time indispensable.\nThis slow adoption has raised comparisons with previous eras of slow productivity and wage growth in British history.\n\"There has been a period, a 10-year period in the UK, when you hadn't had any productivity growth, but you have to go back to some time in the 1860s or 1870s to see this,\" says Ben Broadbent, deputy Governor at the Bank of England.\n\"When people talk about that period, they talk about the pause between two big technologies. We were moving away from steam to electricity.\"\nIan Stewart, Deloitte's chief economist, says the adoption of electricity into the workplace took far longer still than just that decade.\n\"Productivity does not proceed at a stable rate over time. After the First World War particularly there was a mass deployment of electrification in factories, so there was an extraordinarily long lag from the inventions [in the 19th century] to their application in factories,\" he says. \"The whole production process had to be redesigned, buildings had to be redesigned. And as that happened there was a surge in productivity.\"\n\"It may be the case that we haven't really fully exploited current technologies, let alone the next generation.\"\nThat is echoed by the CBI in a new report which notes that the UK has a small group of highly productive, cutting-edge firms, but a long tail of underachievers.\nAlmost 70pc of employees in the UK work in companies with belowmedian productivity, it notes, as too many firms have failed to adopt even well-established technologies.\nWhile the slow pace of the AI revolution and the rise of the robots may be a drag for sci-fi fans, at least it means the most dire predictions of mass redundancies and endless poverty for swathes of the population are unlikely to come true as workers have time to adapt.\n\"It doesn't replace jobs, it frees workers up to do more high-value activity, say in innovation,\" says Lee Hopley, chief economist at manufacturing industry group EEF.\nThe process is a slow one in any case, because \"this isn't a big bang event where suddenly these new technologies are available off the shelf to apply in your business,\" she says.\nMarion Amiot at Oxford Economics says: \"I don't think the net effect will be to destroy jobs.\"\nThere is a clear desire to speed up investment and the adoption of productivity enhancing technology. The Chancellor, Philip Hammond, is under pressure to find ways to raise investment and boost the economy in both the short and long-term.\nBut although there is no shortage of proposals sent his way, it is difficult to find any perfect answers. Broadbent warns that the historical record is not helpful.\n\"It is not evident that policymakers can flick a switch and change this.\n\"If you ask most economists they'd talk about sensible tax regimes, openness to the rest of the world, healthy public sector investment, good education,\" he says.\nDeloitte's Stewart also notes a different lesson from history: expectations can be hopelessly wrong. He sees productivity growth as a process which comes in waves, pointing to the terrible crunch in the Seventies, strong improvements as the economy was revitalised by the end of the Eighties and early Nineties, over-optimism with the dotcom bubble and now another flat period.\nIf this assessment is correct, it may be that current pessimism about the long-term future is severely overdone.\nAt least we can comfort ourselves with that thought while we wait for space robots to become a regular feature of our lives.\n"},
{"docid": "198 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "February 4, 2016", "title": "Microsoft scoops up software firm as friends cash in\n", "content": "Two Cambridge graduates were catapulted into the realms of the super rich yesterday after their technology business was bought by Microsoft for a reported \u00a3174 million.\nJon Reynolds, 30, and Ben Medlock, 36, are understood to have made more than \u00a325 million each after agreeing to sell SwiftKey, the company they founded in 2008 after leaving university. However, one of the business's founders did not receive a penny. Chris Hill-Scott set up the company with Mr Reynolds and Dr Medlock but resigned as a director shortly afterwards to pursue a career in photography. Mr Hill-Scott, who now designs websites for the government, will not get anything because he sold his shares in the company to the other two men when he left. Sources familiar with what happened said that Mr Hill-Scott disliked the long hours associated with working for a technology start-up and struggled without a salary. A spokesman for SwiftKey said he left the company on good terms with his friends.\u00a0\nAfter Mr Hill-Scott's departure, the remaining two entrepreneurs developed the predictive text technology that would see their company become one of the most successful British startups of recent years. The company's software, which suggests the next word a user is about to type, is used on more than 300 million smartphones and tablets across the world.\nThe key to the technology's success is the use of artificial intelligence to improve the predictions over time by learning each user's writing style, even remembering slang and nicknames.\nThe company estimates its software has saved its users 10 trillion keystrokes, which amounts to more than 100,000 years of typing time.\nMr Reynolds and Dr Medlock have also worked with Stephen Hawking, helping him to upgrade his computer-generated voice by applying predictive language software to his system and enabling him to speak faster and continue to give lectures. The deal with Microsoft is the latest attempt by Silicon Valley to tap into British expertise in artificial intelligence.\nIn 2014, Google paid \u00a3400 million for DeepMind, which develops artificial intelligence for computer games, and last year Apple bought VocalIQ, which makes software to help computers and people converse more naturally, for an undisclosed amount.\nMr Reynolds and Dr Medlock met at Cambridge in 2004. Mr Reynolds was an undergraduate studying natural sciences and Dr Medlock was a postgraduate working on a Phd in natural language and information processing.\nSwiftKey's app, which works in more than 100 languages and has been downloaded more than 10 million times, has topped the download rankings in 47 countries. The technology also appears automatically on hundreds of millions of smartphones after the company did deals with businesses including Samsung, the Korean phone maker.\nA statement on the SwiftKey's website yesterday confirmed the deal, although it failed to mention the role of Mr Hill-Scott. It said: \"Eight years ago we started out as two friends with a shared belief that there had to be a better way of typing on smartphones. We've come a long way since then; today hundreds of millions of people around the world, and many of the leading mobile manufacturers, rely on our language prediction technology.\n\"We're excited to announce an important milestone on Swift-Key's journey. As of today, we have agreed to join the Microsoft family.\"\n"},
{"docid": "199 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "June 10, 2014", "title": "'Captain Cyborg': the man behind the controversial Turing Test claims; Kevin Warwick, a professor of cybernetics at Reading University who implanted a microchip into his arm, is being scrutinised by scientist over his claims that a computer passed the \"Turing Test\"\n", "content": "A controversial scientist who has been known as \"Captain Cyborg\" since he implanted a chip into his nervous system is facing criticism over claims that a computer passed a \"milestone\" test for Artificial Intelligence. \nKevin Warwick, a professor of cybernetics at Reading University, called his recent experiment in which a computer fooled humans in the Turing Test an \"important landmark\", but scientific opposition is gathering. \nProf Warwick made headlines when the university claimed the 65-year old Turing Test was passed for the first time by a \"supercomputer\" called Eugene Goostman at an event organised by Prof Warwick at the Royal Society in London. \u00a0\nTen out of thirty human judges believed they were speaking to a real teenage boy during a five minute period, so the experiment was hailed as a victory. \nHowever, other experts said the announcement trivialised \"serious\" AI (Artificial Intelligence) research, and fooled people into believing that the world of science fiction could soon become science fact. \nProf Warwick is considered a maverick among the science community. He first had a microchip implanted in his arm that triggered a greeting from computers each day when he arrived at work. \nThe scientist later implanted sensors and a microchip into the nerves in his arm, similar to an implant he also gave to his wife, so that when someone grasped her hand Prof Warwick was able to experience the same sensation in his. \nHe claimed it was a form of telepathy as it allowed his nerves to feel what she was feeling over the internet, but the work was controversial among other scientists as they doubted whether his experiments were much more than entertainment. \nThe latest announcement that the Turing Test has been passed for the very first time has been met with yet more scepticism. \nProf Warwick said: ''In the field of Artificial Intelligence there is no more iconic and controversial milestone than the Turing Test. \n\"This milestone will go down in history as one of the most exciting.'' \nHowever, Professor Murray Shanahan, a professor of cognitive robotics at Imperial College London, said there were \"a lot of problems\" with the claims. \nThe scientist said that as Eugene was described to judges as a 13-year-old boy from Ukraine who learned English as a second language, some of the bizarre responses to questions could be explained away. \nHe said the five-minute conversation benchmark was \"taken out of context\" from the Turing Test, and fell well short of a true experiement for Artificial Intelligence, which should last for \"hours, if not days\". \nHe also said the 30-strong judging panel, which included Robert Llewellyn, the Red Dwarf actor, was not big enough to support the claim. \nProf Shanahan told the Telegraph: \"I think there are a lot of problems with the claims and I do not believe the Turing Test has been passed. \n\"I think the claim is completely misplaced, and it devalues real AI research. It makes it seem like science fiction AI is nearly here, when in fact it's not and it's incredibly difficult.\"\nProf Shanahan added that the \"supercomputer\" was in fact a chatbot, a computer programme, rather than a powerful machine. \nGary Marcus, a professor of cognitive science at New York University, said in an article for the New Yorker: \"Here's what Eugene Goostman isn't: a supercomputer. \n\"It is not a ground-breaking, super-fast piece of innovative hardware but simply a cleverly-coded piece of software.\"\nThe Telegraph has approached Prof Warwick for comment.\n"},
{"docid": "200 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "January 16, 2017", "title": "Davos needs to be wary of believing in robots' power\n", "content": "Those braving the World Economic Forum's annual jamboree in Davos this week, who find time in between ski sessions and early-hours nightcaps to pop into a session or two, will notice a familiar theme emerging.\nNo, not Brexit. Not Donald Trump's imminent inauguration either. I'm talking about artificial intelligence. Delegates won't be able to move in Davos without hearing about AI: the conference's agenda includes sessions on \"AI and advanced robotics\", \"Decision by algorithm\", \"Intelligent killing machines\", not to mention dozens of side events on the matter.\nGiven the subject matter, you might be forgiven for thinking this could be the last time Davos hosts the World Economic Forum before the inevitable robot uprising forces next year's event to be held in an underground cave.\u00a0\nBut to those in technology circles, the growing presence of artificial intelligence at the meeting of world leaders will be no surprise.\nSecond perhaps only to virtual reality, artificial intelligence has generated more frenzied excitement than any other Silicon Valley trend in the last 12 months. According to CB Insights, there were 255 deals involving private AI companies in the first half of last year, a 44pc increase on 2015. The world's biggest technology companies are in an arms race for the world's AI experts, paying upwards of seven figures to poach them from universities.\nThere have been some major advances, certainly. Google's language translation software, once derided, is now approaching superhuman accuracy. Understanding human speech - something that requires technology to first transcribe and then interpret our words - has made huge gains. In areas such as lip reading, board games and general knowledge quizzes, computers have already exceeded human capabilities. Just last week, an AI poker player destroyed a room of professionals: in a similar experiment two years ago, the computer came up short.\nThese advances have been realised thanks to a revival of interest in the techniques of \"machine learning\", in which intelligence is not programmed into a machine via a set of rules, but the machine is given banks of data and, using rapid improvements in computing power, is able to process it to build up something akin to understanding. Instead of teaching machines that a cat is something with four legs and a tail, we show it 10 million pictures all tagged as cats and allow it to understand for itself.\nBut for all the progress that machine learning promises, there is an equal amount of hype and bluster.\nAt this month's Consumer Electronics Show, the tech industry's own Davos (in the somewhat less exclusive setting of a Las Vegas conference centre), almost every gadget on show was imbued with \"AI\". There was an electric toothbrush which, its maker claimed, could use \"deep learning algorithms\" to improve your dental hygiene. A tea brewer claimed to use advanced AI techniques to personalise your perfect cuppa.\nThe attention that the technology is generating means that almost every company using algorithms or sensors seems to describe itself as \"artificial intelligence\", which is enough to make the term almost meaningless. We've seen this before: a couple of years ago, every gadget was given the \"smart\" prefix: the logic was that we liked smartphones, so why not smart fridges? But call yourself artificial intelligence, and you go one step further by indulging science fiction fantasies about killer robots making witty jokes as they travel through space. Make an electric toothbrush with a microchip in and nobody is too fussed; make an AI electric toothbrush and you're onto something.\nI'm being slightly unfair by picking the absolute worst example, but it does illustrate the hot air around AI in recent months. Concerns about robots \"taking jobs\" have reached a fever pitch, as if technology has not been automating tasks previously done by humans for centuries.\nThe difference now is supposed to be that it is happening at a faster rate and further up the skills food chain, but this is nothing new either: in 1950, technology was \"stealing\" more skilled jobs than in 1850. The real difference is that we are now calling it artificial intelligence, which is more attentiongrabbing. After all, who doesn't love a robot? A lot of this distracts from the real breakthroughs that are being made in machine learning software, which can understand and interpret vast amounts of data to become proficient in areas once deemed beyond the realms of computers.\nMany of these are being made in the UK: DeepMind, a British firm owned by Google's parent company Alphabet, last year beat the world champion at Go, an ancient game in which humans were expected to have the upper hand for another decade. DeepMind is now using NHS data to help spot acute kidney injuries. But this experiment has already generated a privacy storm over the lack of patient consent to having their data processed.\nThis illustrates an impending problem with AI: progress requires an insatiable appetite for personal data, and, at some point, a creepy line will be crossed.\nThe promises have been overblown before, the 1970s and 1980s had lengthy \"AI winters\" in which funding dried up and researchers avoided using the term, for fear it was a dirty word. The real breakthroughs being made today suggest a repeat is unlikely, but we must be careful not to inflate another bubble.\n'For all the progress that machine learning promises, there is an equal amount of hype and bluster'\n"},
{"docid": "201 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "October 11, 2016", "title": "Four things we learned from the Festival of Marketing 2016\n", "content": "                   From digital transformation to artificial intelligence, speakers from the Festival of Marketing reveal the biggest trends to expect in 2017 and beyond.  .inline-content hl{     font-family: \"Austin News Deck Semibold\", Georgia, Times, serif;      font-size: 1.7rem; }  .inline-content .first-letter{     color: #B80259;      float: left;     font-size: 9.1rem;     font-style: normal !important;     font-weight: normal !important;     line-height: 7rem;     margin-top: 4px;     padding-right: 2px;     text-transform: uppercase;     font-family: \"Austin News Deck Semibold\", Georgia, Times,serif; }  \nThe Festival of Marketing 2016 \u00a0brought together more than 200 professionals for workshops and live debates, to learn about what's been driving the industry - and to discuss what's coming next.\u00a0\nHere, panelists share what they think is the next big thing for marketing in this digital age.\nDigital transformation can't be an isolated programme\n\"Digital transformation is a hot topic for many companies at the moment. While in the past business transformation was driven internally, digital transformation is now mostly customer-driven. The customer is increasingly digital and mobile. He or she expects timely, relevant and personalised experiences - anytime and anywhere. Companies that don't adjust to this new reality will become irrelevant.\n\"True digital transformation can't be an isolated programme. It needs to be ingrained in the overall DNA of a company. It entails not only digital marketing and sales, but also connected digital propositions (apps, websites, in-store technologies and so on) and new business models. To be successful, digital transformation must be managed as an organisational change (processes, culture, staff), not just a technological one.\"\nPaul Poels, global lead of digital analytics, Philips\nArtificial intelligence offers a way to be more personal\n\"Artificial Intelligence (AI) is the next frontier for marketing. It poses an enormous opportunity to create more meaningful connections than we've ever had. But getting clients to see it as a powerful tool - which can make them more relevant and effective - is a challenge.\n\"AI takes millions of bytes of data and analyses it, providing a deeper understanding of customer behaviour and belief. That's a powerful insight. As the industry begins to grapple with\u00a0 ad-blocking \u00a0and a consumer with a more sophisticated eye, AI offers a way to be more personal, targeted and relevant. It allows brands to offer the right kind of marketing and content, at precisely the right time.\n\"Millennials, for example, are more concerned with being entertained by brands that really understand their need for a one-to-one relationship. Brands that are willing to invest in making a 'real' connection will reap the rewards.\"\nTash Whitmey, CEO, Havas Helia\nSocial media is crucial for customer interaction\n\"Irrespective of the industry you work in, social media is playing a more important role in customer interaction. An effective strategy here can do more for your reputation than anything else. For example, our business is about supporting parents through the first 1,000 days of their baby's life. Parents are reaching out on social channels for advice. It's important that we can offer reassurance and guidance in a timely and efficient manner.\n\"By simplifying our processes, and reviewing our community management team and most frequently asked questions, we've developed an approach that has taken our response times down to 20 minutes across all social channels. It's not easy, but the digital world is where your most engaged consumers are, so it really is crucial. Be genuinely accessible and responsive to your consumers.\"\nTom Benton, head of digital,\u00a0 Danone Nutricia Early Life Nutrition UK\nThe internet of things (IoT) will create brand ecosystems\n\" Omnichannel marketing is where a customer has a seamless experience, no matter the time, place or device (desktop, mobile, tablet). This requires access to lots of data in order to develop a single customer view -\u00a0 a consistent summary of a customer's relationships with an organisation or brand.\n\"The connection of everyday devices to the web, via IoT, will give brands a far richer dataset. Such a dataset could enable them to understand consumer psychology based on specific moments (for example, preparing dinner for the family) rather than just demographics and general interests.\n\" According to Intel, there could be up to 200 billion connected devices by 2020. From a marketing perspective, once products are connected to the internet, they can start to have a transformative effect on industry structures. Look no further than Uber for an example of that.\n\"Transformational projects should always be led by a clear and overarching strategy, which requires a keen understanding of the customer and market, strong leadership and disciplined action.\"\nSe\u00e1n Donnelly, senior research analyst, Econsultancy\n\n"},
{"docid": "202 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "October 15, 2017", "title": "Reboot your career with a job in robotics - live chat; If you are interested in a career in artificial intelligence, ask our experts for advice on Wednesday 18 October from 1-2.30pm BST\n", "content": "In the last year robots have got a bad rep. Headlines have dubbed machines our \"future bosses\", with economists predicting more than 40% of UK jobs will be automated by 2030. But as machine learning improves, there is one sector which is booming: robotics.\u00a0\nIn the last three years the number of jobs in artificial intelligence (AI) has increased by almost 500%, according to data from Indeed. Currently, there are more than double the number of jobs than applicants - with companies fighting to grab the best talent. \nSo if you are a techie interested in a robotics career, what skills do you need? \"[AI] isn't rocket science. But it requires a lot of components - waveform analysis to interpret the audio, machine learning to teach a machine how to recognise objects, encryption to protect the information,\" writesDavid Kosbie, an associate professor in computer science at Carnegie Mellon University. \"People who create this type of technology must be able to work in teams and integrate solutions created by other teams.\"\nThere's also a technical side to the work. Whether you would like to become a robotics scientist, developer or algorithm specialist - you will likely need work experience or a degree related to computer science. \nSo, if you are interested in a career in artificial intelligence and are looking for more tips on how to break into the sector, join us on Wednesday 18 October from 1-2.30pm BST  for a live chat with our expert panel. We'll be discussing: \n\n"},
{"docid": "203 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "December 6, 2014", "title": "Hawking could not be more wrong about robots; The disruption caused by transformational technology should be viewed as the \"growing pains\" of adjustment as we move from one age to another, writes Jeremy Warner\n", "content": "It's the stuff of science fiction and seemingly a modern day fascination. From Skynet, the artificial intelligence of the Terminator movies, to Spike Jonze's Her, in which the leading character falls in love with his super efficient and sublimely disloyal operating system, many of us are apparently obsessed by the idea that we'll end up dominated by robots, or even obliterated by them. \nLast week, the astrophysicist Stephen Hawking joined the cult. Technological catastrophe - the idea that artificial intelligence (AI) will eventually outsmart us - was \"a near certainty\", he said, in the next 1,000 to 10,000 years. That's a long time, even for an expert on black holes, and probably too long to bother most of us very much. All the same, AI is advancing by leaps and bounds, and relatively sophisticated robots are not that far off. \u00a0\nIn evidence of his supposed apocalypse, Prof Hawking cited Moore's Law, which stipulates that computers double their speed and memory power every 18 months, as well as the devices which as a long suffering victim of motor neurone disease both help keep him alive and let him communicate with the outside world. Apparently, many Silicon Valley pioneers share his fears. Their conceit is breathtaking; \"I am become Death, the destroyer of worlds\". There could be no more complete a legacy for these self-proclaimed masters of the modern world. \nPerhaps they are right, perhaps they are not, but I have to say that of all the threats that lie in wait for the human race, the possibility that we are creating our own nemesis by pursuing the holy grail of artificial intelligence is the one least likely to keep me awake at night. \nTo the contrary, far from being a threat to our very existence, such technologies promise another giant leap forward for the economies that apply them first, freeing their populations from toil and creating the conditions for another golden age of exponential growth. \nThis is not to argue that the advancement of \"smart machines\" doesn't present challenges. Amongst the biggest is what the British economist, John Maynard Keynes, called \"technological unemployment\". Technology is already destroying jobs by the lorry load, just as it has during past periods of rapid industrial change. \nThere is no doubting the painful consequences of this transition. Transformational technology is profoundly disruptive. Yet these are, if you like, only the \"growing pains\" of adjustment, as we move from one age to another. \nThe more uplifting longer term promise is of a prosperity that would have been barely conceivable to our forebears, as the smart machines progressively liberate us from our long history of toil. It's a curiosity, but for some reason pessimism about the future is much more deeply engrained in the human psyche than optimism, even though it is belied by the reality of generational advancement. Bizarrely, we seem more inclined to believe robots will end up our masters than our slaves. It must be something to do with our mortality. In any case, for the time being Prof Hawking's warnings can safely be left to the science fiction writers. The BBC was unfair to Osborne\nThe Chancellor, George Osborne, has accused the BBC of hyperbole in its blood curdling coverage of the Autumn Statement - and with justification, given the comparatively limited scope of his ambitions. What particularly got his goat was the reference to Orwell's The Road to Wigan Pier, in which we were invited to believe that the Chancellor plans to return us to the social deprivation of the 1930s. \nThe claim is based on the forecast by the Office for Budget Reponsibility that fiscal consolidation will by the end of the next parliament have reduced public spending as a proportion of GDP to \"just\" 35.2pc of GDP, a level last seen in 1938. Shocking, undeliverable, barbaric, grotesque - these are just some of the words used to describe the implied level of cuts. \nOh dear. In fact, adjusting for inflation, the planned consolidation merely takes us back to where we were in 2002-03, when Labour catastrophically determined on buying itself a third term by taking the lid off public spending. Even after the consolidation, public spending per head will be about five times higher in real terms than it was in the 1930s. Britain is a hugely more wealthy country than it was in the 1930s, making the comparison virtually meaningless. \nBut let's just for a moment unpick this number - 35.2pc. According to forecasts in the IMF's latest fiscal monitor, the comparable figure for Australia will be 36.2pc, for the US 35.5pc, for New Zealand 33.8pc, for Ireland 32.6pc, for Switzerland 32.6pc, and for Singapore, just 19.2pc. \nNone of these countries obviously bear any resemblance to 1930s Britain, and none of them suffer from observable social deprivation. With the exception of Ireland, they are all admittedly already quite close to these levels. They don't have the same adjustment challenges as the UK. But all bear witness to this being an entirely appropriate, not to say desirable, level of public spending in GDP. \nThe idea that the level of cuts implied is undeliverable is similarly just poppycock, though the Government has considerably steepened the challenge by having so many areas of \"protected\" spending. Even so, the Treasury can get most of the way there by reducing the in-work benefits bill down to manageable proportions. Subsidising low paid work from the public purse is a national scandal that must be urgently addressed. Hypocrites who cry over tax avoidance\nNext week brings details of the Government's proposed new \"Google tax\", a ridiculous piece of anti-business populism that threatens to drive a coach and horses through long standing international conventions on double taxation. By deterring foreign investment, it will also end up further eroding the Government's overall tax take. \nOK, so I know how infuriating it is that so many big multi-nationals seemingly avoid tax on profit earned in this country merely by \"diverting\" it to low, or nil tax jurisdictions. \nThe idea of the tax is to penalise companies that act in this way by charging them a higher rate on the diverted profit than they would otherwise pay in ordinary UK corporation tax. If the deterrent intended, then the new tax will raise nothing at all, but companies will start paying their due in other ways. \nThe difficulty is in establishing a fair way of determining what is a diverted profit. Already other jurisdictions, notably Australia, are expressing worries that this is an attempted raid on their own taxable profits. \nThere is a huge amount of hypocrisy in the political posturing around multi-national tax avoidance. David Cameron was like a dog on heat when Pfizer announced its intention of redomiciling to Britain via the tax efficient takeover of AstraZeneca - more tax for Britain, less for the US. Very quickly we heard the screeching of gears being wrenched into reverse when he realised that virtually the entire country, bar yours truly, was against it. National treasuries will move heaven and earth to steal other countries' profits, but come over all offended when the boot is on the other foot. \n"},
{"docid": "204 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "November 8, 2017", "title": "Deutsche Bank CEO hints at replacing staff with robots to cut costs; John Cryancould use artificial intelligence to automate banking tasks\n", "content": "Deutsche Bank chief executive John Cryan has indicated that he is ready to replace thousands of workers with robots as he looks to cut costs with artificial intelligence.\u00a0\nThe German bank currently employs 97,000 people and in an interview with the \nFinancial Times\n on Wednesday, Mr Cryan said comparable rival lenders employed \"half that number\".\nHe added that the ratio between front office staff and back office staff at Deutsche was \"out of kilter\" and suggested technology could help the bank to become more efficient.\nRead more\nSaudi Arabia grants citizenship to a robot for first time ever\n\"There we've got the most to gain,\" he said. \"We're too manual, which can make you error-prone and it makes you inefficient. There's a lot of machine learning and mechanisation that we can do.\"\nDeutsche Bank announced in October 2015 that it would cut 9,000 jobs and cease operating in 10 countries as part of restructuring plans. Since then it has cut 4,000 jobs.\nOther banks are grappling with how to make best use of artificial intelligence, and for some, technology could replace a sizeable amount of jobs sooner rather than later.\nVikram Pandit, who was chief executive of Citigroup during the financial crisis said in September that advances in technology could slash the number of jobs in banks by 30 per cent in the next five years.\nMr Pandit said introducing robots could save the need to hire people in back-office roles.\n"},
{"docid": "205 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "October 26, 2015", "title": "Robots can take over some of our jobs. But some things only humans can do; We all need to focus on which jobs are the best use of humans' unique talents and abilities, as well as which jobs will require our decision-making capacity\n", "content": "From the grocery store to the factory floor, once common jobs have become tasks done by robots. The ability to automate work and use artificial intelligence to augment everyday tasks is ever growing, and the nature of change in the workforce is accelerating as robots start to walk outside factories, the whir of drones grows louder in the air and driverless cars are poised to join us on the streets in cities nationwide.\nThis is going to have an ever-larger effect on the workforce. But instead of asking ourselves which jobs will be replaced, we need to shift the conversation to answer the question: what jobs do we want humans to do?\u00a0\nWe all need to focus on which jobs are the best use of humans' unique talents and abilities, as well as which jobs will require peoples' oversight and decision-making capacity. The macro-level policy discussion needs to advance from its current emphasis on job retraining and move towards one of job rethinking.\nMcKinsey Global Institute has estimated that by 2025, robots could produce an output equivalent to 40-75 million workers in both industrial and service roles. Companies like Google, Apple, Foxconn and Amazon are investing heavily in robotics, and more will join them as technology advances. By 2017 there will be 2m industrial robots in operation worldwide, according to one estimate.\nAnother found that networked, automated artificial intelligence applications and robots will likely displace more jobs than they create by 2025. A University of Oxford study finds that 47% of US jobs might be at risk within the next two decades due to advances in computers, automation and artificial intelligence.\nNone of this impacts human-centered work, the idea that people have critical comparative advantages that must be embraced, nurtured and developed. By using machines for things they can do better and bolstering the areas where we thrive, it provides opportunities to allow humans to focus on creative thinking and problem solving. We could in fact see a new renaissance where automation unlocks more creativity and innovation in humans as people are freed from repetitive tasks and rote production roles that we have been saddled with for generations.\nAs automation marches ahead, there are trends that support such a thesis. At the same time that people want things here and now, there is also an ever expanding segment of society seeking original goods and services. Experiences matter more than things. Space and the accumulation of \"stuff\" is out; special and \"one of a kind\" is in, a harkening back to a bygone era when craftsmanship was standard and mass production was in its infancy.\nMakers, today's artisans, are creating, crafting and developing new and interesting ideas. The meteoric growth of micromanufacturers and platforms like Etsy demonstrates this expanding responsiveness and nimbleness of production. One estimate even puts the current number of makerspaces around the world at 2,000.\nIn our recent National League of Cities analysis of local economic conditions, we analyzed the growth of collaborative consumption and the maker movement in cities. A broad majority of cities support the growth of collaborative business models and 26% of cities have makerspaces.\nThe maker movement won't stem the tide toward greater automation in the workforce. But we shouldn't jump to the assumption that this will be a net negative for society.\nBy flipping the script in this direction, we can move towards a future of hope - and a realization that there are areas of work in which creativity, craftsmanship and human judgment will always be superior to what a machine can do.\n"},
{"docid": "206 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "April 19, 2018", "title": "Artificial intelligence, robots and a human touch; Deborah O'Neill on the failings of automation at Tesla and elsewhere, and Matt Meyer and Nick Lynch on the House of Lords AI select committee report\n", "content": "Elon Musk's comment that humans are underrated ( Humans replace robots at flagging Tesla plant, 17 April) doesn't come as much of a surprise, even though his company is at the forefront of the technological revolution. Across industries, CEOs are wrestling with the balance between humans and increasingly cost-effective and advanced robots and artificial intelligence. However, as Mr Musk has discovered, the complexity of getting a machine to cover every possibility results in a large web of interconnected elements that can overcomplicate the underlying problem. This is why so many organisations fail when they try to automate everything they do. Three key mistakes I see time and again in these situations are missing the data basics, applying the wrong strategy, and losing the human touch.\nThere are some clear cases where automation works well: low value, high repetition tasks or even complex ones where additional data will give a better outcome, for example, using medical-grade scanners on mechanical components to identify faults not visible to the human eye. But humans are better at reacting to unlikely, extreme, or unpredictable edge cases, for example being aware that a music festival has relocated and extra cider needs to go to stores near the new venue rather than the previous location.\u00a0\nRegardless of industry, it's only by maintaining a human touch - thinking and seeing the bigger picture - that automation and AI can add the most value to businesses. Deborah O'NeillPartner, Oliver Wyman\n\u00b7 The House of Lords report ( Cambridge Analytica scandal 'highlights need for AI regulation', theguardian.com, 16 March) outlining the UK's potential to be a global leader in artificial intelligence - and its calls for governmental support of businesses in the field and education to equip people to work alongside AI in the jobs of the future - should be welcomed for two reasons. First, it recognises the potential of UK-based AI companies to benefit the economy. Supporting these fast-growing companies to ensure that they continue to scale - and eventually exit - here should be a strategic priority, particularly at a time when a new generation of fast-growth providers, such as Prowler.io and Benevolent AI in life sciences, and ThoughtRiver in legal tech, is emerging to build on an impressive track record of AI innovation in the UK, from Alan Turing to DeepMind.\nSecond, it acknowledges that AI can contribute significantly to businesses' competitive advantage - a view that few too UK businesses seem to appreciate at a time when media coverage of the topic is dominated by scaremongering about job losses, security threats, ethics, and bias. It's refreshing to see a more positive narrative about AI and the workplace starting to emerge. What we now need to see is more of from the business world is openness to the opportunities that AI creates in terms of continuing, and expanding on, the positivity of this report, and leadership in sharing their successes in this area that others can learn from. Matt MeyerCEO, Taylor Vinters\n\u00b7 The announcement from the House of Lords that Britain must \"lead the way\" on the regulation of artificial intelligence (AI) highlights the current climate of concern around the ways that AI could impact society, in particular, fears of weaponised AI used by militaries and other unethical usage. But there are many other applications where \"ethical\" AI is crucial - in making accurate medical diagnoses, for example.\u00a0\nThere is no doubt AI will transform how society operates, and that there is a need for improper use to be safeguarded against. However, creating ethical AI algorithms will take more than just an announcement. It will require far greater collaboration between governments, and industry and technology experts. By working with those that understand AI, regulators can put in place standards that protect us while ensuring AI can augment humans safely, so that we can still reap its full potential. Dr Nick LynchThe Pistoia Alliance \n                       \u00b7 Join the debate - email                     guardian.letters@theguardian.com\n                       \u00b7 Read more Guardian letters - click here to visit                     gu.com/letters\n"},
{"docid": "207 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "October 20, 2017", "title": "The way to power growth - if only politicians used their grey matter\n", "content": "It was the best of times, it was the worst of times.\" So wrote Charles Dickens in A Tale of Two Cities. For those considering the prospects for economic growth, a similar paradox arises.\nPessimism abounds, and for good www.reason.UK labour productivity growth has been largely stagnant since the financial crisis with no bounce-back forthcoming. An ageing population looms as another headwind.\nEconomists such as Robert Gordon speculate that technologies will simply be less transformative in future and so have less of an effect on productivity, while LSE economists believe research productivity is falling, requiring more effort to maintain the growth rate in new ideas. Then there's Brexit too, where despite opportunities, the Government has done little to lay out a pro-growth vision for how repatriated powers will be used.\u00a0\nYet, for all this misery, potentially transformative innovations are being rolled out around the world. By 2030, the Boston Consulting Group estimates a quarter of all miles driven in the US will be in self-driving electric cars. Virtual online assistants proliferate on major company websites.\nGoogle has released headphones that can instantly translate 40 languages as you hear them. Microsoft now reckons that AI is on par with humans in a conversational speech task for the first time.\nTo show it is truly the \"dismal science\", some economists worry not about low productivity, but the opposite - the effect of abundance and the mass automation of, not just routine, but skilled middle-class jobs. According to research published by Accenture, AI has the potential to increase the GDP growth rate of the UK to as much as 3.9pc per year by 2035.\nOthers even speculate that artificial intelligence could result in \"singularities\" within the next century, points where self-improving computers and machines will quickly outpace human thought, leading to potentially infinite growth.\nHow can we be experiencing such innovation on the one hand, but a largely stagnant economy on the other? A fascinating new paper by economists Philippe Aghion, Benjamin Jones and Charles Jones suggests there may not be such a contradiction after all. In fact, there are theories that suggest the roll-out of artificial intelligence and slow growth may go hand in hand.\nTo see why, consider artificial intelligence as just a new form of automation. In the past 200 years everything from the spinning jenny to the steam engine, to electricity and computer chips has been incorporated into production. These inventions raised productivity in a variety of sectors and helped reduce the cost of goods and services to consumers.\nIn other sectors though, such as education, healthcare, and other labour-intensive personal services, it is much more difficult to automate and raise productivity. Automation can, counter-intuitively, actually lead to productive sectors of the economy shrinking relative to GDP. If consumers pocket the savings from cheaper products and use them to buy more in the way of less productive labour-intensive services, then the unproductive sectors become a larger proportion of the economy. This makes it harder to grow in future.Growth, in other words, is constrained by what we find it hard to improve.\nThe key take-home message is that for artificial intelligence to truly have transformative effects for economic growth, as Accenture believes, one of two things must happen: either it must be harnessed in labour-intensive areas of economic or social life, or else artificial intelligence itself must replace people as a source of new ideas.\nThere are reasons to be both hopeful and doubtful here. Selfdriving vehicles could rapidly enhance productivity by delivering trucking and taxi activities more cheaply, and also by freeing up commuter time to work and read whilst travelling.\nAn AI program operating in the Houston Methodist Research Institute in Texas shows the potential in healthcare too. It is able to review mammograms 30 times faster than humans, with a 99pc accuracy rate in interpreting diagnostic information. It's welcome then that a recent report by Dame Wendy Hall shows the Government is taking the prospect of AI in the public sector seriously.\nThen again, despite lots of attempts, it has proven much more difficult to roll out automation in other areas. Experiments with robot hairdressers have ended with pretty disastrous haircuts, and researchers have struggled to develop technologies to do our cooking, cleaning and other household chores such as laundryfolding for us.\nThe economist William Nordhaus has concluded we are still decades away from hitting that singularity, which could deliver large and increasing growth rates.\nThe honest lesson for policymakers from all this is that we have no idea yet of the scale of the transformation that artificial intelligence could deliver. Given this lack of knowledge, it would seem foolish to plan for a world in which millions will be rendered unemployed, or to seek to pre-empt some speculative social consequences that might result. This is particularly true given as yet there is little evidence automation is reducing employment at all. Indeed, there is good reason to think people increasingly value human-delivered services.\nRather than speculating about the future, and seeing innovation as a challenge, politicians and policymakers should instead focus on things within their control that hold back economic growth.\nIt pains me to repeat it, but getting land-use planning, energy, childcare and tax policy right could offer a substantial positive near-term boost to growth and productivity, as well as substantially lowering living costs.\nThe impact of artificial intelligence technologies on society overall remains to be seen. But too much growth would surely be an infinitely nicer problem than a sclerotic economy. So why not apply that thinking now more broadly? Ryan Bourne holds the R Evan Scharf Chair for the Public Understanding of Economics at the Cato Institute\n'According to research, AI has the potential to increase GDP growth to as much as 3.9pc per year by 2035'\n"},
{"docid": "208 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "October 3, 2017", "title": "Shop Direct 'winning on mobile' after record sales\n", "content": "SALES at Shop Direct, the retailer behind www.Very.co.uk and www.Littlewoods.com, have been boosted by the growing number of mobile shoppers, with smartphone devices accounting for over half of sales for the first time.\u00a0\nThe company toasted record sales of \u00a31.93bn as like-for-like sales rose by 5.6pc. The retailer reported smartphone sales made up 53pc of online sales while its MyVery app accounted for just under a third of its mobile sales.\nAlex Baldock, chief executive, said the upbeat sales were evidence that Shop Direct was \"winning the three second audition\" and had invested in artificial intelligence and machine learning to ensure the retailer \"stays relevant on a 4.7-inch screen\".\nShop Direct, which is owned by Sir David and Sir Frederick Barclay, the owners of Telegraph Media Group, stopped printing its Littlewoods catalogue in 2015 to go online-only and focus on the trend for shoppers to make purchases on their mobile phones.\nMr Baldock said the company was placing another \"big bet\" on artificial intelligence by launching machinelearning chat bots that can help detect behavioural and purchasing patterns to improve the shopping experience, for example reminders to re-order a face cream alongside a promotion.\n\"We want to democratise the personal shopper,\" Mr Baldock said.\nArtificial intelligence is used in Shop Direct's finance arm to detect fraud.\nThe Shop Direct boss said that despite nervousness around a slump in consumer spending, the group was confident in its consumer credit arm.\nHe added: \"Customers come to us in tough times as well as good because we can give them an upgrade on what they could otherwise afford and we do so responsibly.\"\nStatutory pre-tax profits fell from \u00a3105.6m in 2015 to \u00a324.9m, dragged lower by \u00a3112m of costs from a rise in customer redress claims related to PPI mis-selling. Underlying pre-tax profits before the exceptional items rose by 10.2pc to \u00a3160.4m.\n"},
{"docid": "209 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "April 16, 2018", "title": "Investigate Facebook and Google's 'vexing' data monopolies, Lords say\n", "content": "Competition watchdogs should investigate US tech giants \"vexing\" data monopolies, a House of Lords inquiry has said.\nThe Lords Artificial Intelligence committee called on the Competition and Markets Authority to launch a study of the sector after receiving complaints that the likes of Google and Facebook had too much control over global, digital data which is critical for academics and scientists developing artificial intelligence.\u00a0\nThe government has estimated that AI could add an additional \u00a3630bn to the UK economy by 2035 and presents an opportunity to improve productivity and improve quality of life, particularly for its potential in aiding healthcare.\nBut the industry may struggle to take off if home-grown startups are unable to benefit from digital data needed to train smart algorithms. Several of the US tech giants, most of which are building their own AI, have been harvesting the personal information of Britons and its global customer base for several years, putting developers at a distinct advantage.\nThe committee said: \"While we welcome the investments made by large overseas technology companies in the UK economy, and the benefits they bring, the increasing consolidation of power and influence by a select few risks damaging the continuation, and development, of the UK's thriving home-grown AI startup sector.\nLord Clement Jones, chair of the committee told the Telegraph: \"We are calling on the Competition and Markets Authority to look into the big question: whether the abuse of dominant positions is applicable to data.\"\nIn an ideal scenario smaller companies would be given access to some of Google or Chinese tech giant's Alibaba or TenCent information if it is being collected in the UK.\n\"We think there will be a competition issue if we are not careful,\" Lord Jones added.\nHumans need not apply | Artificial intelligence in the workplace\nThe Information Commissioner described the data dominance of technology giants as \"a vexing problem\".\nOne colossal dataset that could soon be up for grabs is the patient information held by the NHS, if the Lords recommendations come into play.\nThe NHS holds data on nearly everyone in the UK ; some of it going back decades. The committee said that this data could be of immense value to artificial intelligence researchers and recommended that NHS England outline plans to share this data by the end of 2018.\n\"To release the value of the data held, we urge the NHS to digitise its current practices and records, in consistent formats, by 2022 to ensure that the data it holds does not remain inaccessible and the possible benefits to society unrealised,\" the report found.\n"},
{"docid": "210 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "November 22, 2017", "title": "Budget 2017: Philip Hammond announces new \u00a32.5bn investment fund and \u00a3500m for tech industry; Government is set invest in a range of initiatives from artificial intelligence, to 5G and full fibre broadband, the chancellor said\n", "content": "Chancellor Philip Hammond has announced \u00a32.5bn of investment to kickstart the UK's lacklustre productivity.\nThe British Business Bank will be seeded with \u00a32.5bn of public money, Mr Hammond said. The Government is also set invest over \u00a3500m in a range of initiatives from artificial intelligence, to 5G and full fibre broadband, the chancellor announced in his budget speech on Wednesday.\u00a0\n\"We have some of the world's best companies and a commanding position in a raft of tech and digital industries that will form the backbone of the global economy of the future,\" Mr Hammond said. \nRead more\nStamp duty relief will drive up house prices, says OBR\n\"Those who underestimate Britain do so at their peril.\"\n\"Because we will harness this potential and turn it into the high paid high productivity jobs of tomorrow,\" Mr Hammond said.\n\"Others may choose to reject the future, we choose to embrace it.\n\"A new tech business is funded every hour and I want that to be every half hour. So today we invest over \u00a3500m in a range of initiatives from artificial intelligence to 5G and full-fibre broadband.\n\"We support regulatory innovation with a new regulator's pioneer fund and a new geospatial data commission to develop a strategy for using the government's location datato support economic growth and to help our tech start-ups reach scale.\nProductivity growth in the UK remains weak and the job prospects of many adults are \"hurt\" by poor literacy and numeracy skills, according to a report from Paris-based think tank the OECD on Monday.\nIt said lifelong learning should be encouraged among adults and more should be done to promote skills.\nIts study found that the share of young adults enrolled in vocational education and training has risen to 43 per cent, but remains lower than many European countries.\n"},
{"docid": "211 of 500 DOCUMENTS\n", "source": " The Independent - Daily Edition\n", "date": "June 22, 2016", "title": "Elon Musk to give robots housework to stop them taking over the world\n", "content": "Billionaire inventor Elon Musk's artificial intelligence (AI) group wants to create a robot to clean people's houses as a test of its research into how to develop robots that can operate safely alongside humans.\u00a0\nOpenAI - which is funded by the billionaire maker of reusable rockets and electric cars - hopes to build a domestic robot that is able to carry out household chores, according to a blog entry posted by the non-profit research group. It would also be a way of testing whether or not its work in artificial intelligence is progressing in the right way.\nThere are already ways of creating a robot that can carry out specific tasks, the researchers note.\nThe difference is that Mr Musk's team hopes to create \"learning algorithms\" that would allow the creation to serve as a \"general purpose\" robot - meaning that it can be left around the home and be clever enough to work out what it needs to clean.\nCreating such a robot is a \"good testbed for many challenges in AI\", the team note. The robot won't be built by OpenAI, but will instead use components from elsewhere that are programmed by the group.\nCreating a household robot is the second goal of the OpenAI group, according to blog post. It has already detailed its work in meeting its first when it laid out plans for a special gym that can help train artificial intelligence programs.\nThe firm then hopes to build an agent that can understand natural language and create another that could solve a \"wide variety of games\". OpenAI hopes that the different goals capture different kinds of problem-solving and together can progress towards its ultimate goal of building smart AI systems that don't also wipe out life on Earth.\n"},
{"docid": "212 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "July 10, 2017", "title": "Google hopes to prevent robot uprising with new AI training technique; Designed to discouragemachines from cheating\n", "content": "Google is developing a new system designed to prevent artificial intelligence from going rogue and clashing with humans.\nIt's an idea that has been explored by a multitude of sci-fi films, and has grown into a genuine fear for a number of people.\u00a0\nGoogle is now hoping to tackle the issue by encouraging machines to work in a certain way.\nThe company's DeepMind division, which was behind the AI that recently defeated Ke Jie, the world's number one Go player, has teamed up with Open AI, a research group that's part-funded by Elon Musk.\nThey've released a paper explaining how human feedback can be used to ensure machine-learning systems work things out the way in which their trainers want them to.\nA technique called reinforcement learning, which is popular in AI research, challenges software to complete tasks, and rewards it for doing so.\nHowever, the software has been known to cheat, by figuring out shortcuts or uncovering loopholes that maximise the size of the reward it receives.\nIn one instanceit drove a boat around in circles in racing game \nCoastRunners\n, instead of actually completing the coursebecause it knew it would still win a reward, reports Wired.\nRead more\nArtificial intelligence is learning to be racist\nDeepMind and Open AI are trying to solve the problem by using human input to recognise when artificial intelligence complete tasks in the \"correct\" way, and then reward them for doing so.\n\"In the long run it would be desirable to make learning a task from human preferences no more difficult than learning it from a programmatic reward signal, ensuring that powerful RL systems can be applied in the service of complex human values rather than low-complexity goals,\" reads the report.\nUnfortunately, the improved reinforcement learning system is too time-consuming to be practical right now, but it gives us an idea of how the development of increasingly advanced machines and robotscouldbe controlled in the future.\n"},
{"docid": "213 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "September 14, 2016", "title": "Amazon Echo: Voice-controlled AI speaker to launch in UK\n", "content": "Amazon has announced plans to sell the Echo, its voice-controlled \"intelligent\" speaker, in the UK after the device proved a surprise hit among US households.\nThe Echo, a cylindrical speaker that is always listening for a command, is Amazon's answer to Apple's Siri and Google's Assistant software, responding to sentences such as \"Will it rain today?\" or\u00a0\"Play some music\".\u00a0\u00a0\nDespite initial confusion when the device first launched in 2014, it has become a fixture in many living rooms and kitchens, and its release in the UK has been hotly anticipated.\nAmazon's Echo is an \"intelligent\" speaker\nOn Wednesday, Dave Limp, Amazon's head of hardware, announced that the device will go on sale in the UK and Germany in the \"autumn\". A price has not yet been announced.\nThe device is powered by Alexa, intelligent assistant software that can respond to billions of questions. When an owner says \"Alexa\", the speaker is activated and lights up, ready to respond to a command which is then beamed to Amazon's servers, processed and sent back, with the Echo responding within a second or less.\nThe Echo was inspired by the voice-controlled computer on the USS Enterprise, the spaceship in Star Trek - of which Amazon chief executive Jeff Bezos is a major fan.\nAs well as being able to respond to questions about the weather, historical facts and - naturally - make orders from Amazon, the Echo can also integrate with thousands of third-party apps, such as Spotify and Uber.\nIt can also be used to check sports scores, set alarms, and read the news.\nMany users see it as the most advanced and useful of the voice-activated virtual servants, improving upon efforts from Apple, Google  and Microsoft despite Amazon having less of a visible track record in artificial intelligence.\nMuch of the artificial intelligence software that powers the Echo was developed at Amazon's research and development base in Cambridge after the company bought Evi, an artificial intelligence startup in 2013.\nSince the Echo has an always-on microphone that is constantly listening and stores a history of commands in order to learn from them, it has raised snooping fears.\u00a0\nLimp sought to dismiss these concerns, saying that the device will only record when activated by the \"Alexa\" wake word, and that a button on the device can mute the microphone. Users will also be able to delete any previous queries on Amazon's app.\nFuturistic sci-fi tech that is a reality: in picturesFollow Telegraph Science & TechREAD MORE ABOUT:\n"},
{"docid": "214 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 3, 2016", "title": "Britain shines in AI - but let's nurture it\n", "content": "In 2008, three Cambridge graduates founded an app called Swiftkey, which uses artificial intelligence to predict the next word you write with extreme accuracy. The friends Jon Reynolds, Ben Medlock and Chris Hill-Scott, who later sold his stake in the startup for a bicycle, created an alternative keyboard app used on 300m smartphones which learns users' typing habits over time. The technology even helps power British physicist Stephen Hawking's speech system, roughly doubling his speech rate and reducing the errors he makes while typing.\nIn February, American tech giant Microsoft unexpectedly announced it had bought Swiftkey for $250m (\u00a3176m). Needless to say, the technology will ultimately be integrated with Microsoft's own products, to make them smarter and more intuitive.\nSwiftkey founders Jon Reynolds and Dr Ben Medlock\u00a0Credit:      CREDIT: PA     \u00a0\nWhile this is a moment of celebration for UK entrepreneurs and investors, it's not the first British artificial intelligence company that's caught the fancy of a Silicon Valley monolith. The pattern is impossible to ignore. Look at the world's biggest companies - Apple, Amazon, Google, Microsoft. All have been drawn to Britain's disproportionately large pool of talented artificial intelligence entrepreneurs. British AI companies are crushing global competition.\u00a0\nBut we shouldn't be satisfied just being\u00a0singled out by California's titans. We need to nurture and grow these bright sparks into the next generation of tech giants that will power everything from healthcare to counter-terrorism and global governance.\n          .tg-pullquote__global__group {             zoom: 1;         }         .tg-pullquote__global__group:before,         .tg-pullquote__global__group:after {             content: \"\";             display: table;         }         .tg-pullquote__global__group:after {             clear: both;         }         .tg-pullquote__inline {             float: left;         }         .tmg-particle.pull-quote{             margin: 0 20px 10px 0px;             width: 260px;             float: left;         }         @media (max-width: 495px) {             .tmg-particle.pull-quote{                 float: none;                 margin-left: 4.687%;                 margin-right: 4.687%;                 width: 90.626%;             }         }         .tg-pullquote_container{             font-size: 18px;             line-height: 23px;             font-family: georgia;         }         .tg-pullquote__title {             font-family: arial;             font-weight: bold;             font-size: 16px;             border-top: 1px dotted #000000;         }         .tg-pullquote__quote {             color: #007A8F;             font-style: italic;             margin-top: 5px;             margin-bottom: 5px;         }         .tg-pullquote__attribution {             color: #787878;             margin-bottom: 5px;         }         .tg-pullquote__source {}.tg-pullquote__source__link {             color: #234B7B;             outline: 0;             text-decoration: none;         }         .tg-pullquote__source__link:hover {             border-bottom: 1px dotted #122842;             color: #122842;         }                  \"Yes, Britain shines in AI - but we shouldn't willingly give up our crown.\"         \nBack in 2012, Amazon was the first to start the trend\u00a0- the Seattle e-tailer acquired Evi Technologies, a Cambridge-based startup whose platform can understand and communicate in natural language, making it a super-intelligent search tool. Although the company has been extremely quiet since it was bought, Amazon opened up a drone-testing lab for its Prime Air service in Cambridge in 2014, which suggests a potential goal for Evi's research.\nLast year, Apple made an extremely similar Cambridge-based acquisition - it bought VocalIQ, a software system that teaches computers to speak more like humans, and understand natural language more easily.\nIn Apple's case, the application is clear: its voice-activated assistant Siri has vastly improved since it first launched, but still struggles to understand different accents and specific commands. VocalIQ should be able to help hone Siri's speech and comprehension skills, making it far more human-like in its interactions.\nGary Kasparov was defeated by IBM's Deep Blue at chess in 1997 - an AI milestoneCredit:      CREDIT: EPA     \nWhen Google bought a little-known company called DeepMind for a hefty \u00a3400m in 2014 - its largest ever European acquisition - the startup didn't even have a product for sale. Next week, DeepMind will take on a world-first challenge - it will pit its AI algorithm against a human champion in the notoriously complex Chinese board game, Go . If the algorithm beats the Korean master, it will be the first time in history we have built a machine capable of this uniquely human pursuit. It will be an AI milestone no one has ever crossed.\nFounded by two young Britons Mustafa Suleyman and Cambridge graduate Demis Hassabis, DeepMind has assembled 250 of the world's most respected artificial intelligence researchers right here in London. The company has now acquired two more British AI companies, Dark Blue Labs and Vision Factory, both spun out from\u00a0Oxford University.\nGoogle achieves AI 'breakthrough' at GoPlay!02:47\nJust today, payments giant Mastercard announced it will be using AI technology built by Rainbird, a Norwich-based startup that creates systems that can make human-like decisions. Mastercard will use its smarts to power an automated, virtual sales assistant. The AI salesperson will have the work experience gleaned from the entire sales team and the thousands of customer conversations, and predict exactly which calls might convert to sales.\nSo what makes Britain so strong in this deeply competitive area? The clue is in the locations of the startups. British universities specifically Cambridge, Oxford, Imperial College and University College London, are breeding grounds for the new generation of artificial intelligence companies mushrooming in Britain.\n          .tg-pullquote__global__group {             zoom: 1;         }         .tg-pullquote__global__group:before,         .tg-pullquote__global__group:after {             content: \"\";             display: table;         }         .tg-pullquote__global__group:after {             clear: both;         }         .tg-pullquote__inline {             float: left;         }         .tmg-particle.pull-quote{             margin: 0 20px 10px 0px;             width: 260px;             float: left;         }         @media (max-width: 495px) {             .tmg-particle.pull-quote{                 float: none;                 margin-left: 4.687%;                 margin-right: 4.687%;                 width: 90.626%;             }         }         .tg-pullquote_container{             font-size: 18px;             line-height: 23px;             font-family: georgia;         }         .tg-pullquote__title {             font-family: arial;             font-weight: bold;             font-size: 16px;             border-top: 1px dotted #000000;         }         .tg-pullquote__quote {             color: #007A8F;             font-style: italic;             margin-top: 5px;             margin-bottom: 5px;         }         .tg-pullquote__attribution {             color: #787878;             margin-bottom: 5px;         }         .tg-pullquote__source {}.tg-pullquote__source__link {             color: #234B7B;             outline: 0;             text-decoration: none;         }         .tg-pullquote__source__link:hover {             border-bottom: 1px dotted #122842;             color: #122842;         }                  \"Machine learning powers everything from Netflix recommendations to your Facebook newsfeed and Google search results.\"         \nInvestors who have nurtured the companies from the early days say that founders are building on cutting-edge machine learning research done by academics at these institutions in recent years.\nThat's not hard to believe: the UK has an illustrious heritage in artificial intelligence research, starting with its founding father, Alan Turing. Although the term \"artificial intelligence\" itself was only coined in 1956, two years after Turing died, he proposed the conundrum of whether machines could really \"think\" back in 1950, when computers were just invented. His Turing Test is still the ultimate differentiator\u00a0between human and machine.\nArtificial intelligence may seem like the domain of geeks and scientists, but increasingly it is intertwined with our everyday lives. Machine learning powers everything from Netflix recommendations to your Facebook newsfeed and Google search results. Soon it will power your home and your car.\u00a0According to technology research firm Tractica, the artificial intelligence market is set to reach $11.1bn by 2024.\nIt's clear why AI smarts are so highly in demand from large technology companies who want to\u00a0predict our online behaviours. While Britain is certainly benefiting from this demand, we should be making the most of our heritage, and world-leading scientists, helping to grow these companies into independent and powerful entities.\nYes, Britain shines in AI - but we shouldn't so willingly give up our crown.\nAI timelineREAD MORE ABOUT:\n"},
{"docid": "215 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "September 8, 2017", "title": "Tutor of the future: Scientists develop algorithm to match pupils with tutors using artificial intelligence\n", "content": "Private tuition was this week labelled the \"hidden secret\" in the \"arms race\" of education.\nMore\u00a0services such as the Telegraph's own online tuition platform \u00a0are being made\u00a0available to help parents and pupils find a tutor. Now scientists have developed the latest weapon: an algorithm to match pupils with tutors, using artificial intelligence.\nUniversity College London's (UCL) Institute of Education has partnered with the online tutoring platform MyTutor to harness technology to create the \"tutor of the future\".\u00a0\nParents are asked a series of questions about their child's personality:\u00a0whether they are creative, logical, confidence, anxious and so on.\nThe information is fed into an algorithm that matches them up with a series of tutors to choose from, who have similar characteristics to the child's.\nProf Luckin said she believes the use of AI in education will become increasingly common in the coming years\u00a0\nJames Grant, co-founder of MyTutor, said that building a \"strong rapport\" between a tutor and student is crucial for academic success.\nHe said he believes that AI will be the future of tutoring, adding: \"Tutoring is something that hasn't really changed in so many years. If tutoring can cost less, be more convenient and better quality, then that has to be the future of tutoring.\"\nProfessor Rose Luckin, from UCL's Institute of Education, said: \"One of the difficult problems is the matching of a student and a tutor.\n\"We are starting to develop a way of using artificial\u00a0intelligence\u00a0to automate the interview process and make sure the initial relationship has the potential to be successful.\"\n.html-embed.component .quote.component{margin-left:0}.html-embed.component .quote.component .component-content{margin-right:16px}.quote__source, .quote__author {white-space: normal;}@media only screen and (min-width:730px){.html-embed.component .quote.component{margin-left:-60.83px}.html-embed.component .quote.component .quote__content:before{margin-left:-12px;padding-right:1px}}@media only screen and (min-width:1008px){.html-embed.component .quote.component{margin-left:-82.33px}}If tutoring can cost less, be more convenient and better quality, then that has to be the future of tutoringJames Grant, founder of MyTutor\nProf Luckin said she believes the use of artificial intelligence\u00a0in education will become increasingly common in the coming years - but at the moment people are too \"apprehensive\" about it because \"as soon as you say I want to have your child's data\" they lost interest.\n\"There is a reticence for a lot of people when it comes to technology that they don't understand,\" she said. \"I think people need to see the benefits and how it can work for them, then we can really start to progress.\"\nWith more services such as Tutor Hunt and\u00a0 Telegraph Tutors \u00a0springing up, demand is high.\u00a0A recent study revealed that almost a third of children have had private tuition, labelling it the \"hidden secret\" in an \"educational arms race\" that reinforces the advantages of richer children, according to the Sutton Trust.\nTeenagers from wealthier families are twice as likely to have received additional help compared with their poorer classmates. Meanwhile those from minority ethnic backgrounds are more likely to have had a tutor than white pupils, according to a report by the Sutton Trust, a social mobility think tank.\n"},
{"docid": "216 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "March 9, 2016", "title": "Why does it matter that Google's DeepMind computer has beaten a human at Go?; The Big Question: A computer's mastery of arguably the most complex game in the world is a major step forward for artificial intelligence\n", "content": "Why are we asking this now?\nA computer has won a game of Go against a person - much to many humans' surprise. Google's machine appears to have mastered the game, beating Lee Sedol, widely regarded as humanity's best player.\nThe game still has some time to go - AlphaGo's winwas just the first part of a best of five match. But even winning just one was a huge step forward for AlphaGo, the robot created by Google.\u00a0\nThe computer wasn't expected to win, at least not by everyone. For his part, Mr Lee had said that he expected to win by a \"landslide\" - initially predicting a 5-0 win.\nWhy is Go so important?\nComputers have beaten humans at almost every game before, but none of them have had the same kinds of complexity. Winning at chess, for instance, was a huge achievement - but one of more traditional computing than artificial intelligence.\nGo is thought to be one of the most complicated games that there is. Because of that there is an almost infinite number of moves - meaning that it is a game more of intuition than calculation.\nThe ancient Chinese game of Go is nearly 3,000 years old and immensely challenging. Players take turns putting black and white stones onto a gridded piece of wood, with the ultimate aim being taking over the full board.\nThat is done using a relatively simple set of rules. But because of the huge and complex possibilities that those simple rules create, it just isn't possible to win the game by anticipating all the moves, as is the case with the (relatively) limited number of possible moves in a game like chess.\nHow didAlphaGo get so good at it?\nAs with much work in artificial intelligence, Google's DeepMind team trained the computer using a system of trial and error. The computer uses \"reinforcement learning\" - a development remarkably similar to the way that humans learn.\nThat process happens as the computer plays against itself. When it does so, it adjusts its own thinking based on what it learns, meaning that it gets better all the time.\nWhile it still uses some of those predictions that are involved in chess computers and other game-playing machines, it is also able to anticipate humans' thinking and use a simulation of a kind of intuition.\nWhat does it mean for us?\nIntuition - like other kinds of human traits - is one of the key parts of artificial intelligence. We have managed to gather together huge amounts of computing power, and the current challenge for many engineers is making those computers learn, think and understand like humans do.\nIf computers manage to perfect many of those central parts of human life, then it could lead to a revolution on the scale of the first supercomputers. Having machines that can think like people can lead them to take on much of the work that is done by people: they'll be able to talk and process information.\nFor the moment, we're seeing that application in only minute ways, such as image recognition that allows Google and other companies to classify pictures according to what is in them. But the processes involved in those two activities are similar, in one way: recognising cats in Google Photos and recognising the best Go move in South Korea are both matters of trying out possibilities and being able to see what works.\nWhat's more, such computers get better by themselves. A development called machine learning allows computers to gather information like we do - meaning that they can make themselves more clever and more intelligent with time.\nSome people are scared of those same developments, fearful that AI will become clever enough that it will decide to crush us.\nBut for now at least you're more likely to see the results come into your searches and social networks.\n"},
{"docid": "217 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "April 4, 2018", "title": "What 2001: A Space Odyssey got right about our blind leap into the digital age; Fifty years after its release, Stanley Kubrick's film seems prescient - an allegory about how destructively artificial intelligence can be misused\n", "content": "It's a testament to the lasting influence of Stanley Kubrick and Arthur CClarke's film \n2001: A Space Odyssey\n,which turned 50 this week, that the disc-shaped card commemorating the German Film Museum's new exhibition on the film is wordless, but instantly recognisable. Its face features the Cyclopean red eye of the HAL-9000 supercomputer; nothing more needs saying.\nViewers will remember HAL as the overseer of the giant, ill-fated interplanetary spacecraft \nDiscovery\u00a0\n.When asked to hide from the crew the goal of its mission to Jupiter -a point made clearer in the novel version of \n2001\nthan in the film -HAL gradually runs amok, eventually killing all the astronauts except for their wily commander, Dave Bowman. In an epic showdown between man and machine, Dave, played by Keir Dullea, methodically lobotomises HAL even as the computer pleads for its life in a terminally decelerating soliloquy.\nCocooned by their technology, the film's human characters appear semi-automated -component parts of their gleaming white mother ship. As for HAL -a conflicted artificial intelligence created to provide flawless, objective information but forced to \"live a lie,\" asClarke put it -the computer was quickly identified by the film's initial viewers as its most human character.\nThis transfer of identity between maker and made is one reason \n2001\nretains relevance, even as we put incipient artificial intelligence technologies to increasingly problematic uses.\nIn \n2001\n,the ghost in \nDiscovery\n's machinery is a consciousness engineered by human ingenuity and therefore as prone to mistakes as any human. In the Cartesian sense of thinking, and therefore being, it has achieved equality with its makers and has seen fit to dispose of them. \"This mission,\" HAL informs Dave, \"is too important to allow you to jeopardise it.\"\n'Just what do you think you are doing, Dave?' \nKeir\nDullea\n's beleagueredastronaut takes a stand against HAL\nMGM\nAsked in April 1968 whether humanity risked being \"dehumanised\" by its technologies, Clarke replied: \"No. We're being superhumanised by them.\" While all interpretations of the film were valid, he said, in his view the human victory over \nDiscovery\n's computer might prove pyrrhic.\nIndeed, with its prehistoric \"Dawn of Man\" opening and a grand finale in which Dave is reborn as an eerily weightless Star Child, \n2001\novertly references Nietzsche's concept that we are but an intermediate stage between our apelike ancestors and the \u00dcbermensch, or \"Beyond Man\". (Decades after Nietzsche's death, the Nazis deployed a highly selective reading of his ideas, while ignoring Nietzsche's antipathy to both antisemitism and pan-German nationalism.)\nIn Nietzsche's concept, the \u00dcbermensch is destined to rise like a phoenix from the Western world's tired Judeo-Christian dogmas to impose new values on warring humanity. Almost a century later, Clarke implied that human evolution's next stage could well be machine intelligence itself. \"No species exists forever; why should we expect our species to be immortal?\" he wrote.\nWe have yet to engineer a HAL-type AGI(artificial general intelligence) capable of human-style thought. Instead, we're experiencing the incremental, disruptive arrival of components of such an intelligence. Its semi-sentient algorithms learn from text, image and video without explicit supervision. Its automated discovery of patterns in that data is called \"machine learning\".\nThis kind of AIlies behind facial-recognition algorithms now in use by Beijing to control China's 1.4 billion inhabitants and by Western societies to forestall terrorist attacks.\nIn Clarke's novel, HAL's aberrant behaviour was attributable to contradictory programming. In today's hyperpartisan context, a mix of machine learning, networks of malicious bots and related AItechnologies based on simulating human thought processes are being used to manipulate the human mind's comparatively sluggish \"wetware\". Recent revelations about stolen Facebook user data being weaponised by Cambridge Analytica and deployed to exploit voters' hopes and fears underlines that disinformation has become a critical issue of our time.\n'We're being\nsuperhumanised\n'by technologies, believed Arthur CClarke (Getty)\nWe should consider just whose mission it is that's too important to jeopardise these days. Does anybody doubt that the clumsy language and inept cultural references of the Russian trolls who seeded divisive pro-Trump messages during the 2016 election will improve as AIgains sophistication? Of course, algorithm-driven mass manipulation is only one weapon in propagandists' arsenals, alongside television and ideologically slanted talk radio. But its reach is growing, and it's a back door by which viral falsehoods infiltrate our increasingly acrimonious collective conversation.\nTraditional media -\"one transmitter, millions of receivers\" -contain an inherently totalitarian structure. Add machine learning, and a feedback loop of toxic audiovisual content can reverberate in the echo chamber of social media as well, linking friends with an ersatz intimacy that leaves them particularly susceptible to manipulation. Further amplified and retransmitted by Fox News and right-wing radio, it's ready to beam into the mind of the spectator-in-chief during his \"executive time\".\nWhere does HAL's red gaze come in? Set aside the troubling prospect of what might unfold when a genuinely intelligent, self-improving AGIis created -presumably the arrival of Nietzsche's \u00dcbermensch. What's in question even with current incipient AI technologies is who gets to control them. Even as some devise new medicines and streamline agriculture with them, others use them as powerful forces in opposition to Enlightenment values -liberty, tolerance and constitutional governance.\nDemocracy depends on a shared consensual reality -something that's being willfully undermined. Seemingly just yesterday, peer-to-peer social networks were heralded as a revolutionary liberation from centralised information controls, and thus tools of individual human free will. We still have it in our power to purge malicious abuse of these systems, but Facebook, Twitter, YouTube and others would need to plough much more money into policing their networks -perhaps by themselves deploying countermeasures based on AIalgorithms.\nMeanwhile, we should demand that a new, tech-savvy generation of leaders recognises this danger and devises regulatory solutions that don't hurt our First Amendment rights. A neat trick, of course -but the problem cannot be ignored.\nIn \n2001's\n cautionary tale, HAL's directive to deceive \nDiscovery\n's crew leads to death and destruction -but also, ultimately, to the computer's defeat by Dave, the one human survivor on board.\nWe should be so lucky.\n\u00a9 The New York Times\nMichael Benson's 'Space Odyssey: Stanley Kubrick, Arthur CClarke, and the Making of a Masterpiece' (Simon & Schuster, \u00a321.50) will be released in the UK on 19 April\n"},
{"docid": "218 of 500 DOCUMENTS\n", "source": "Daily Mirror\n", "date": "December 3, 2014", "title": "KILLING MACHINES; Artificial intelligence could wipe out human race, warns Stephen Hawking\n", "content": "STEPHEN Hawking has chillingly predicted artificial intelligence could spell the end of mankind.\nThe professor said \"thinking\" machines pose a threat to our very existence, echoing classic movies 2001: A Space Odyssey, The Terminator and The Matrix.\u00a0\nHe told the BBC: \"The development of full artificial intelligence could spell the end of the human race.\n\"It would take off on its own, and redesign itself at an everincreasing rate. Humans, who are limited by slow biological evolution, couldn't compete.\"\nDespite his bleak predictions, Prof Hawking, who is paralysed by motor neurone disease, has been greatly helped by advances in communication. A small sensor controlled by a cheek muscle enables him to type and his words are converted into synthesised speech.\nIntel has provided the technology for 20 years and now London-based SwiftKey, which develops predictive keyboard apps, has helped to double his speech rate.\nThe author of A Brief History of Time now only needs to type 15-20% of words to string together full sentences.\nProf Hawking, 72, said: \"I enjoy communicating science.\"\nben.rossington@mirror.co.uk\n"},
{"docid": "219 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "October 12, 2016", "title": "Government is completely unprepared for the coming robot takeover, MPs warn; Tech companies are taking the lead on thinking about the future of robotics and artificial intelligence, and not enough is being done by authorities, warns the Science and Technology Committee\n", "content": "The government is unprepared for the fundamental changes to our lives that robots will bring, according to MPs.\nThere is no strategy for developing the new kinds of skills that workers will need after automation and artificial intelligence takes over their lives, according to a new report from the Science and Technology Committee.\u00a0\nTechnological advances like driverless cars and supercomputers are turning science fiction into real life, the report warns. But the government is doing very little for prepare for that future, MPs have said.\nThe report urges the government to set up a commission that would stop artificial intelligence from destroying our lives rather than enriching it.\nThe senior MPs did point to the various good that is coming from AI - through self-driving cars and computers that can help diagnose diseases. But it pointed to the huge dangers, too - including the potential bias of computer systems, like when the Google Photo app labelled black people as gorillas.\nRead more\nBillionaires secretly funding scientists to break us out the Matrix\nTania Mathias, acting chairwoman of the committee, warned: \"Science fiction is slowly becoming science fact, and robotics and AI look destined to play an increasing role in our lives over the coming decades.\n\"It is too soon to set down sector-wide regulations for this nascent field but it is vital that careful scrutiny of the ethical, legal and societal ramifications of artificially intelligent systems begins now.\"\nThe report said that the tech industry had been taking the lead in thinking about how AI might shape - and endanger - our lives. It praised the work done by various companies in setting up ways of exploring the future of robotics and how it might be harnessed.\nBut it said that the government hasn't done enough to prepare for those same problems.\nDr Mathias said: \"Government leadership in the fields of robotics and AI has been lacking. Some major technology companies - including Google and Amazon - have recently come together to form the partnership on AI.\n\"While it is encouraging that the sector is thinking about the risks and benefits of AI, this does not absolve the Government of its responsibilities. It should establish a commission on artificial intelligence to identify principles for governing the development and application of AI, and to foster public debate.\n\"Concerns about machines taking jobs and eliminating the need for human labour have persisted for centuries. Nevertheless, it is conceivable that we will see AI technology creating new jobs over the coming decades while at the same time displacing others.\nWestworld Extended Trailer\n\"Since we cannot yet foresee exactly how these changes will play out, we must respond with a readiness to reskill and upskill.\n\"This requires a commitment by the Government to ensure that our education and training systems are flexible, so that they can adapt as opportunities and demands on the workforce change.\n\"It is disappointing that the Government has still not published its digital strategy and set out its plans for equipping the future workforce with the digital skills we will need.\"\n"},
{"docid": "220 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "April 6, 2018", "title": "Daniel Avery: Song for Alpha review - majestic, cavernous techno; (Phantasy)\n", "content": "Star Rating: 4 stars\nBetween 1992 and 1994, Warp Records released the Artificial Intelligence series of albums. Including key early work by household names in electronica circles - Aphex Twin, Autechre, Richie Hawtin - it was ostensibly home-listening music, all unfolding minor-key melodies, gurgles and washes of sound. But it was also bathed in the afterglow of the rave explosion, much more about bodily pleasure than nerdy detail-spotting.\u00a0\nLately, the Artificial Intelligence sound has been bubbling up again all over the club world. Belfast duo Bicep, Siberian superstar Nina Kraviz and Berghain'sOstgut Ton label have all channelled it; now, so is Londoner Daniel Avery. Where his hugely popular 2013 album Drone Logic was about big riffs and forward momentum, its follow-up's mood feels more like loosened gravity: the acid house 303 synths go round in circles, singing sensuous songs to themselves; diffuse chords hang like clouds of morning mist around the beats, intensely reminiscent of early Aphex and Autechre at their dreamiest.\nBut this isn't just 90s nostalgia, and Avery's week-in-week-out training in seething techno bunkers is still evident. Tracks such as TBW17 and the album's glowering centrepiece Diminuendo pummel hard. And even when it stretches out and slows down, its structures are based on relentless repetition, not relaxed meandering, and there's a gothic grandeur to the churchy reverberations that speaks not of genial post-rave relaxation, but of being lost in cavernous Berlin dungeons. The old bodily pleasure is here, but it's approached in altogether sterner, more serious ways.\n"},
{"docid": "221 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 9, 2015", "title": "Try your luck against 'perfect' poker-playing software; New poker-playing software cannot be beaten by a human even if they played 12 hours a day for 70 years - but you're free to try your luck\n", "content": "Computer scientists have created poker-playing software which they claim could not be beaten by a human even if they played 12 hours a day, every day, for 70 years - and they have even created a website so you can try your luck. \u00a0\nResearchers in the Computer Poker Research Group at the University of Alberta have essentially \"solved\" a specific poker game - heads-up limit Texas hold 'em - with their program called Cepheus. The term \"solved\" in artificial intelligence means that the computer knows the outcome of every possible situation and combination of variables in that game. \nIn this case the scientists say that the results are statistically identical to a perfect solution. \nHead of the research group, Michael Bowling, said: \"We define a game to be essentially solved if a lifetime of play is unable to statistically differentiate it from being solved at 95 per cent confidence. \n\"Imagine someone playing 200 hands of poker an hour for 12 hours a day without missing a day for 70 years. \n\"Poker has been a challenge problem for artificial intelligence going back over 40 years, and until now, heads-up limit Texas hold 'em poker was unsolved.\"\nGames such as chess and checkers have long been a testing ground for new ideas in artificial intelligence, leading to milestones such as IBM's Deep Blue defeating world champion Garry Kasparov in chess. \nPart of the difficulty with poker is that the computer does not have all the information, as they would in chess - the opponent's cards are hidden. \nCepheus is the first piece of software to play a perfect game - or, at least, one which is statistically identical to perfection even after a lifetime of play. \nNo human training was given to the software. It was simply provided with the rules of the game and then made to play against itself for the equivalent of a billion billion hands of poker. More than 4,000 processors churned away for two months to allow the software to learn how to play. During that time the software played more poker than has ever been played by the entire human race in all of history. \n                                            You can play against Cepheus online here                      . \n"},
{"docid": "222 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "March 18, 2017", "title": "Bank of England pairs up with specialist in bitcoin's blockchain\n", "content": "THE Bank of England has paired up with artificial intelligence and blockchain specialists in a bid to keep up to date with the fast-growing financial technology sector.\u00a0\nThe central bank is testing an artificial intelligence system with Canadian startup MindBridge AI to allow it to spot abnormalities in financial transactions and \"explore the benefit of machine-learning technology for analysing the quality of regulatory data input\". It has also partnered with San Francisco-based start-up Ripple, which opened an office in London last year, to trial a blockchain-based technology that would make cross-border payments and the movement of currencies more immediate. Blockchain is the technology which underpins cryptocurrencies like bitcoin.\nThe Bank said that its aim with Ripple is to \"show how this kind of synchronisation might lower settlement risk and improve the speed and efficiency of cross-border payments\".\nOne fintech chief executive said that this was a key issue for a number of consumers in Britain, adding that it would currently be \"quicker to fly a large transfer of money over from the US than to transfer it.\"\nThe Bank also said it was setting up a \"community\" for the sector in a bid to keep up with changes in the industry.\nIt will include financial technology specialists like Michael Spencer's Nex and Bitsight, as well as more traditional businesses such as BT and accountants PwC.\nClaire Sunderland Hay, head of the Bank's fintech accelerator, said at The Telegraph's first fintech conference last summer that \"innovation keeps our industry moving forward. Without it we would still be using landlines\".\n"},
{"docid": "223 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "December 14, 2016", "title": "Soon robots could be taking your job interview; Can artificial intelligence solve the problem of unconscious bias in job interviews?\n", "content": "Robots have already been put to work across a number of industries. They are manufacturing cars, taking care of the elderly, doing housework, homework, and even entering literary awards. It is not surprising then that new robots have been developed to conduct job interviews.\nOne such robot, Matlda, has been programmed to conduct 25-minute interviews in which she works through a roster of up to 76 questions. She records and analyses the interviewee's responses, monitors facial expressions and compares them to other successful employees within the hiring company. \u00a0\nMatlda is not much taller than a wine bottle, but her introduction could set a new precedent for recruitment techniques across a range of sectors.\nDoing so will affect the performance of interviewees differently. \"Some candidates might present better in person and will be left worse off, but others may be more comfortable with a remote interview,\" says Martin Ford, an expert on automation technology.\n Related:  After the robot revolution, what will be left for our children to do?\nOne particular demographic that might welcome chatting to Matlda is the post-millennial generation, also known as digital natives, who grew up swiping the pages of digital books, using self-checkout machines and asking Siri for directions. \"We find that people often prefer to interact with something that's not real; it's all about reducing the cognitive load,\" says Matthew Howard at King's College London, whose students launched Kinba, a robotic receptionist at the university, earlier this year.\nAs with all forms of artificial intelligence, efficiency is a clear incentive. More important, though, are claims that artificial intelligence will help eliminate pre-existing prejudice within employment processes and boost transparency.\n\"Matlda's mission is to be a service gateway for a more sustainable and humane society,\" says Prof Rajiv Khosla at Melbourne's La Trobe University, which developed the robot. \"It's a non-judgmental, non-threatening and non-invasive means of engaging people in uninhibited interaction.\"\n                                        A level playing field?                                      \nThe main advantage of involving computers, \"is a consistency in decision making and the removal of some human error\", says Benedict O'Donovan, managing director at Durham Applied Robotics and Technologies. \"While you might get two interviewers who interpret recruiting guidelines very differently, you're never going to get a computer that doesn't follow the rules exactly or allow prejudice to bias their decisions.\"\nHumans are inconsistent where robots are incapable of being anything but consistent\nHiring processes, when conducted by humans at least, have always been problematic because bias is so often unconscious. Personality and psychometric testing, blind auditions, webcam interviews and nameless CVs are on the rise, but in a face-to-face environment, anything from gender, race, clothing, education and accent can provide an  unwitting platform for discrimination. Humans are inconsistent where robots are incapable of being anything but consistent.\nThe problem is that as well as putting these robots to work, humans are also the ones inputting the data enabling them to do that work. \"There is no such thing as a neutral algorithm,\" says Laurel Riek, associate professor of computer science and engineering at University of California, San Diego. \"If the system is using some metric for decision making regarding employment, who came up with that metric, what data is it based on, and how is it being applied?\"\nThis problem was highlighted earlier in 2016 when Microsoft was forced to take its AI chatbot Tay off Twitter just hours after its launch. Robots learn from the humans they are programmed by, followed by those they interact with; it wasn't long before Tay assimilated the conversations and opinions of those around her and posted a series of racist, sexist tweets and denied the holocaust.\n\"Bias can creep in very easily with learning systems, and depends entirely on the data they've been trained on,\" says Prof Noel Sharkey at Sheffield University. This means if an organisation is already an old boys' network of employees from similar socio-economic and educational backgrounds, a robot instilled with the existing blueprint of that workforce cannot hope to make much of a diversifying impact. So despite all good intentions, it seems unlikely that robots like Matlda will become commonplace in the interview room. We may be more biased, but until a robot is able to adjust its thinking regardless of the programming it's received - itself a contradiction in terms - the most important kind of interaction will have to remain human.\n                     Looking for a job? Browse Guardian Jobs or sign up to Guardian Careers for the latest job vacancies and career advice                   \n"},
{"docid": "224 of 500 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "January 26, 1989", "title": "Computer Guardian (Microfile): Groupings\n", "content": "\u00a0\n Aisa, the Artificial Intelligence Suppliers Association, is a new trade body formed by AI an expert systems suppliers to provide a forum for discussion, produce a directory and promote an exhibition. The founder members include ICL, Intellicorp, NCR, SD Scicon and Software A&E.\u00a0Contact: Steve Hutchins, c/o Knowledge Advance, 21 Cork Street, London W1X 1HB.\n Another new body is AGI, the Association for Geographical Information, formed in response to the government's Chorley Report.\n The AGI is a user-orientated group with 18 sponsors, including IBM, DEC, ICL, McDonnel Douglas and others, the department of the Environment, Ordnance Survey, and the Royal institute of Chartered Surveyors. It is currently based at RICS's offices at 12 Great George Street, Parliament Square, London SW1P 3AD (tel. 01-222 7000, ext. 226).\n"},
{"docid": "225 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "December 20, 2016", "title": "Mark Zuckerberg built an AI so he could listen to the Red Hot Chili Peppers\n", "content": "There are many uses for Artificial Intelligence, and as many sci fi films and television shows illustrate, the future possibilities for the  technology are endless.\u00a0\nMark Zuckerberg, the founder of Facebook, decided to use Artificial Intelligence to play the Red Hot Chili Peppers in his house.\nHe recently built the AI, which he has named Jarvis after the Iron Man character.\nAs well as playing him his choice in music, it controls the\u00a0lights, temperature, appliances, music and security in his house.\nHis  blog  showed a list of \u00a0songs played in his house which included Don't Stop, Dani California,\u00a0Under The Bridge\u00a0and Dark Necessities.\nHe can control Jarvis by using Facebook MessengerCredit:      Mark Zuckerberg/Facebook     \nHe wrote: \"At this point, I mostly just ask Jarvis to 'play me some music' and by looking at my past listening patterns, it mostly nails something I'd want to hear.\"\nThat seems to be  the Red Hot Chili Peppers.\nThe Facebook founder also wrote that he had to connect many appliances in his house to the Internet, in order for the AI to control them.\nHe explained how he re-jigged a vintage toaster so it would make toast when the light switched on in the kitchen.\nThe blog is interesting and explains the AI in greater depth; the tech entrepreneur explained how he could control and talk to Jarvis \u00a0by using Facebook messenger.\nHe also said he will be posting a video of Jarvis in the next couple of days.\nWatch | James Corden strips off with the Red Hot Chili Peppers                         00:31\n"},
{"docid": "226 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "August 1, 2017", "title": "Facebook shuts down robots after they invent their own language\u00a0\n", "content": "Facebook shut down\u00a0a pair of its\u00a0artificial intelligence robots\u00a0after they invented their own language.\nResearchers at Facebook Artificial Intelligence Research \u00a0built\u00a0a chatbot earlier this year that was meant to learn how to negotiate by mimicking\u00a0human trading and bartering.\u00a0\nBut when the social network paired two of the programs, nicknamed Alice and Bob, to trade\u00a0against each other, they started to learn their own\u00a0bizarre form of communication.\nThe chatbot\u00a0conversation\u00a0\"led to divergence from human language as the agents developed their own language for negotiating,\" the researchers said.\n                   Facebook's AI language                   \nThe two bots were supposed to be learning to trade balls, hats and books, assigning value to the objects then bartering them between each other.\nBut since Facebook's team assigned no reward for conducting the trades in English, the chatbots quickly developed their own terms for deals.\n\"There was no reward to sticking to English language,\"\u00a0Dhruv Batra, Facebook researcher, told FastCo . \"Agents will drift off understandable language and invent codewords for themselves.\n\"Like if I say 'the' five times, you interpret that to mean I want five copies of this item. This isn't so different from the way communities of humans create shorthands.\"\nAfter shutting down the the incomprehensible conversation between the programs, Facebook\u00a0said the project marked an important step\u00a0towards \"creating chatbots that can reason, converse, and negotiate, all key steps in building a personalized digital assistant\".\nFacebook said when the chatbots conversed with humans most people did not realise they were speaking to an AI rather than a real person.\nThe researchers said it wasn't possible for humans to crack the AI language and translate it back into English. \"It's important to remember, there aren't bilingual speakers of AI and human languages,\" said Batra.\n                   AI timeline                 \n"},
{"docid": "227 of 500 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "June 11, 1987", "title": "Computer Guardian: New power to hand - Another British mainframe computer package bringing artificial intelligence to data processing applications\n", "content": "\u00a0\n Most Artificial Intelligence (AI) practitioners think that the phrase 'artificial intelligence' is misleading and imprecise. It leads to difficulties of communication unless everybody knows exactly which item in the AI portmanteau is being discussed. 'Rule-based systems' is just one technique in AI which is not synonymous with AI, except in advertising copy.\n The data processing (DP) world is one of primitive rule-based logic. The simplest kind of DP rule is the 'If statement,' eg If item is greater than balance, add item to total. This kind of conditional statement even pre-dates computers. It existed on punched card equipment as a mechanical 'selector,' and automatic DP systems have been primitive rule-based systems ever since Herman Hollerith invented them to process the USA census returns.\u00a0\n\n Rule-based systems in AI tackle the handling of these conditional rules in a more powerful and flexible way than DP The application is defined in such a way that all rule-based logic is put in one clump called an inference engine. This avoids the logical flaws that become as complex as the family tree of the Pharoahs in even the simplest DP application, unless you take care to avoid the complexity by structured programming.\n The other major innovation in rule-based systems is that of associating probability with the tests: the program can depict a situation where if 'A' is true then it is 80 per cent probable that 'B' is also true. This allows the program to combine a series of absolute and possible conditions to arrive at the likelihood of a given conclusion; eg if you are awoken in a strange room, probably (you think) by the mouse stamping around next door, you are likely to have been as drunk as a lord the night before.\n Using these rules, the rule-based system is able to deduce either true or likely-to-be-true knowledge, meta-knowledge, which itself can form the operands for rules in the rule based system. Again there is nothing new in this, the program indicators which drive RPG (a DP language), more often than not are set on complex conditions which correspond to those which underlie meta-knowledge elements. The difference is one of treatment. The meta-knowledge is part of a knowledge base and therefore accessible to any logic that wants it.\n Rule-based systems have a lot to offer to DP because they have taken the logical base of DP, the 'If' statement, and shown that it can be extended and manipulated to tackle more powerful problems and to give better answers. Consider, for example, the traditional DP order processing system and a hire purchase firm evaluating a credit risk. The DP system, operating on the black and white conclusions of credit limits and Dunn and Bradstreet ratings, certainly misses the chance of profitable business which hire purchase snatches with both hands.\n It is puzzling that no one in DP has seen the general significance of rule-based systems to DP problems - until recently. There are, however, a number of products now emerging which cross the gap between DP and Al at levels ranging from the micro to the mainframe.\n Top-One is a mainframe house, Telecomputing plc, product from a UK software and the heart of the product is a Prolog development system (Prolog is a language in Al which is suited for manipulating rules) which can reach out and communicate with Cobol programs. TopOne contains prepackaged development functions so that the developer can put in the 'rules of thumb' and the general guidelines which Prolog handles in its rule manipulation as easily as it handles the traditional 'hard rules' of DP.\n Using this product one could, for instance, put the sophistication of hire purchase credit vetting into an order processing system. Prolog takes care of the rule manipulation, and the knowledge base can be built up from elements in the Cobol files of the main system. The product deals with metaknowledge, and, importantly for DP, with the diversity of character coding in Cobol files: alphabetic, edited fields, decimal, binary, packed decimal, etc. It runs on IBM and ICL equipment.\n Its design requirements were to provide performance in a typical DP teleprocessing environment. And because it has also been developed in a DP environment, it avoids the problem of using separate machines for the development and the delivery of the final system. So far it has been used on real-estate commercial management where about 50 different charges have to be apportioned to tenants on a constantly changing basis, and on calculating sales commission in an area where products and the commission basis change almost weekly.\n It is aimed at the world of DP and so it communicates with programs and databases in that world. It is a niche product which aims to provide the benefits of rulebased systems, as developed in AI, to the DP systems designer. Top-One, in short, has developed the logic-handling base of DP so that DP can process logic as easily as data. It is therefore an important product.\n It is not well suited to specialist applications of AI where skeleton solutions (shells) may be purchased ready assembled. Nor is it an AI workbench, where the leading contenders are three American products, Art, Kee and Knowledge Craft, (if you want to pioneer some AI applications in business it is probably a product of that ilk which should be favourite, but you had better have a lot of money available).\n Its shortcomings are in areas that it was not designed to tackle. If you want to parse text, or to develop a scheduling algorithm, or a real-time system for despatching work-in-progress to the next machine centre, or to simulate a production line, you may find a better approach contained in either a general AI workbench or in a specialised AI shell. But if in DP you ever find yourself constrained to consume logic soup with a Cobol chopstick, Top-One is probably the spoon you would wish you had.\n"},
{"docid": "228 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "September 4, 2017", "title": "Elon Musk says AI poses bigger threat than North Korea and could trigger World War Three; His comments follow a statement on the subject from Vladimir Putin\n", "content": "Elon Musk has warned that competition for superiority in the world of artificial intelligence could trigger World War III.\nThe entrepreneur and chief of the SpaceX, Tesla and The Boring Company tweeted, \"China, Russia, soon all countries w strong computer science. Competition for AI superiority at national level most likely cause of WW3 imo.\"\u00a0\nHis tweet followed a statement from Russian President Vladimir Putin that \"artificial intelligence is the future, not only for Russia, but for all humankind ... It comes with colossal opportunities, but also threats that are difficult to predict. Whoever becomes the leader in this sphere will become the ruler of the world.\"\nRead more\nElon Musk startup 'to spend \u00a3100m' linking human brains to computers\nMusk said he was less concerned about the threat of a nuclear missile strike from North Korea, and said any such action would be \"suicide\".\nMusk has long since been a vocal opponent of lethal autonomous weapons.\nHe was one of116signatories of an open letter last month calling for a UN ban of such AI-led weapons.\nRead more\nElon Musk startup 'to spend \u00a3100m' linking human brains to computers\nAI is coming to war, regardless of Elon Musk's well-meaning concern\nElon Musk Is Right, Killer Robots Might Cause Horrific Things\n\"Once developed, lethal autonomous weapons will permit armed conflict to be fought at a scale greater than ever, and at timescales faster than humans can comprehend,\" the letter read.\n\"These can be weapons of terror, weapons that despots and terrorists use against innocent populations, and weapons hacked to behave in undesirable ways.\n\"We do not have long to act. Once this Pandora's box is opened, it will be hard to close.\"\n"},
{"docid": "229 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "September 8, 2015", "title": "iPhone 6s successors to use artificial intelligence to guess what users want before they know; Apple has been stepping up its efforts to hire machine learning and artificial intelligence experts, apparently for its Siri personal assistant, according to reports\n", "content": "Apple is beefing up its artificial intelligence team, in an apparent attempt to make iPhones clever enough to know what they're users want before they do.\nThe company has launched a huge hiring push to take on more experts in machine learning - a branch of computing that aims to make devices that think like humans. The push is likely part of Apple's attempts to make iPhones more clever and able to predict and then anticipate what users are looking for, which is being built in to its personal assistant, Siri.\u00a0\nApple has already rolled out some of those features in iOS 9, the operating system that is expected to roll out with the new iPhone 6s. But they are so far relatively limited - guessing what apps people are about to use or where they might want to go, for instance.\nread moreWhen Siri is spot on with cultural references - who makes it happen, man or machine?Apple boss Tim Cook slams Google and Facebook for selling users' dataArtificial intelligence could kill us because we're stupid, not because it's evil, says expert\nThose special search features are wrapped up with Siri, the digital personal assistant that is built in to the iPhone and iPad. Siri is expected to play a central role in Apple's big event this week, after it was teased on invitations. The evolution of the iPhone\nThe company is at the moment trying to hire at least 86 more employees that work in machine learning, according to its job posts. And it is also hiring more aggressively from experts that are currently working at other companies like Google, Amazon and Facebook, according to Reuters.\nBut Apple's attempts to launch a fully artificially intelligent digital assistant might be frustrated by its commitment not to store or use its customers' personal data. Google's Now, for instance, packs in more features than Siri - but it also looks through emails and calendars to do so, computing that in the cloud.\nApple has repeatedly stressed that it doesn't want to see users' data, and that all of Siri's understanding of people is based on the phone itself rather than on the cloud or over the internet.\nSome experts have chosen not to work at Apple because its rules on data mean that they have less information to work with, according to the Reuters report.\n"},
{"docid": "230 of 500 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "February 26, 2015", "title": "Deep Q, the computer that taught itself how to play Space Invaders; STEVE CONNOR on a 'significant breakthrough' in building smart machines that can learn in the same way as humans\n", "content": "A new kind of artificial intelligence has learned to play vintage video games without any prior instructions in a bid to achieve human-like scoring abilities, a scientists claim.\nThe intelligent machine learns by itself from scratch using a trial-and-error approach that is reinforced by the reward of a score in the game. This is fundamentally different to previous game-playing \"intelligent\" computers.\nThe system of software algorithms is called Deep Q-network and has learned to play 49 classic Atari games such as Space Invaders and Breakout, with only the help of information about the pixels on a screen and the scoring method.\u00a0\nScientists behind the development said the software represents a breakthrough in artificial intelligence capable of learning without being fed instructions from human experts - the classic method for chess-playing machines such as IBM's Deep Blue computer.\n\"This work is the first time anyone has built a single, general learning system that can learn directly from experience to master a wide range of challenging tasks, in this case a set of Atari games, and to perform at or better than human level,\" said Demis Hassabis, a former neuroscientist and founder of DeepMind Technologies, which was bought by Google for \u00a3400m in 2014.\n\"It can learn to play dozens of the games straight out of the box. What that means is we don't pre-program it between each game. All it gets access to is the raw pixel inputs and the game's score. From there it has to figure out what it controls in the game world, how to get points and how to master the game, just by playing the game,\" Mr Hassabis, a former chess prodigy, said.\n\"The ultimate goal here is to build smart, general purpose machines but we're many decades off from doing that, but I do think this is the first significant rung on the ladder,\" he added.\nThe Deep Q-network played the same game hundreds of times to learn the best way of achieving high scores. In some games it outperformed humans by learning smart tactics.\nIn more than half the games, the system was able to achieve more than 75 per cent of the human scoring ability just by trial and error, according to a study published in the journal Nature.\nIn 1997, Deep Blue beat Gary Kasparov, the world champion chess player, while IBM's Watson computer outperformed players of the quiz show game Jeopardy! in 2011. However, Mr Hassabis said Deep Q works in a fundamentally different way.\nHe said: \"The key difference between those kinds of algorithms is that they are largely pre-programmed with their abilities. What we've done is to build programs that learn from the ground up.\n\"These type of systems are more human-like in the way they learn in the sense that it's how humans learn. We learn from experiencing the world around us, from our senses and our brains then make models of the world that allow us to make decisions and plan what to do in the world, and that's exactly the type of system we are trying to design here,\" Mr Hassabis said.\n\"The advantage of these kind of systems is that they can learn and adapt to unexpected things and the programmers and systems designers don't have to know the solution themselves in order for the machine to master that task,\" he added.\n"},
{"docid": "231 of 500 DOCUMENTS\n", "source": "The Guardian - Final Edition\n", "date": "February 6, 2006", "title": "G2: In 2068, robots could subjugate humanity to their infernal will. Instead of being scared, why don't we marry them?\n", "content": "According to a new report by futurologists at British Telecom, time travel will be invented by 2075. That is great news, but allow me to sound a sceptical note. Why is it that no traveller has come back in time, possibly in a Tardis, to tell us of this development? Is it because if they did they would be interfering in the past and thereby distort the future, or just because they don't care about keeping their ancestors abreast of new gizmos? Is it because, in fact, time travel will not be invented? Or is it because, in 2068, terrifying super-robots (of whom more later) will subjugate humanity to their infernal will? Disturbingly, the answer to the last question, is - and there's no easy way to put this - quite possibly, yes.\nThe other issue that vexes me is why BT's futurology department and its bill-collecting department don't work together more closely. If they did, the futurologists could have told bill collectors that I am getting so sick of high rental costs on my phone bill that I'm going to switch to another provider. They could have then sent out a soothing letter that would have kept my custom. But did they? They did not.\u00a0\nAnyhoo. The BT Technology timeline (go to www.btplc.com) predicts many exciting developments in the next century. By 2015, images will be beamed direct to your eyeballs and 2017 will see the first hotel in orbit. By 2020, artificial intelligence will be elected to parliament. By 2040, robots will become mentally and physically superior to humans. Before 2050, robots will beat the England football team, perhaps in the inaugural game at the new Wembley stadium. The victors' post-match interview will be dumbed down for human TV audiences: \"Over the moon, Barry. Our quadratic trapezoidal formation did for them in the final third of the field. That, plus our liquid metal exoskeletons.\" They will be our betters, you see.\nBut maybe we shouldn't fear robots. We should have sex with and marry them. This possibility is welcomed in a new book called Robots Unlimited: Life in a Virtual Age by David Levy. True, the field of artificial intelligence is bedevilled with all kinds of irritating philosophical objections to Levy's predictions. Is there such a thing as an artificial intelligence? Is robot consciousness nonsense? Could robots really be said to think, feel, fall in love and love the kids? Yes, robots may be able to write passably Mozartian symphonies, perform splendid massages or make sexy chit-chat, but only humans can really appreciate any of them.\nWhy, one feels like shouting, don't philosophers just shut their yaps? Then we can all get laid by artificial life forms with magic fingers who don't expect breakfast. Think of Wong Kar-Wai's futuristic film 2046, which teemed with hotsy-totsy lady robots who were indistinguishable, at least to my eyes, from their human counterparts. If only I had a time machine, I would go there right now.\nYes, retort philosophers, but creating virtual slaves for sex and possibly housework is very wrong indeed. What's more, have you thought of the consequences? David Levy has. He reflects on the possibility that humans and robots will reproduce. His argument follows the line of thought in Ray Kurzweil's new book, The Singularity is Near: When Humans Transcend Biology. Technology will mean that humans and artificial intelligences will meld to create a hybrid bio-mechanical life form. Humans must get it on with robots or face extinction.\nPerhaps we shouldn't take these predictions seriously. Futurology isn't rocket science, but wishful-thinking with pretensions. Moreover, predictions don't often materialise. What, for instance, happened to intelligent fridges that would, we were told, inform you when the milk was about to go sour? Why can't cars fly yet?\nAnd anyway, how do futurologists know what will happen? My theory is that BT and Levy have a Wellsian time machine under tarpaulin in Hampstead that they use to verify their predictions. If so, can I have a go, please?\nAt the Highland Games in 2000, a terrier attacked Billy Connolly's sporran. It should have been on a lead - the terrier, not the sporran. That story comes to mind because I've been thinking about male handbags - or manbags, as they should be known. For what is a sporran but a proto-manbag? Last week, Paris catwalks were filled with manbags, because they will be the spring's must-wear. And, because they must be worn, men must consider the terrier threat and listen more closely to women's stories of handbag-related incidents involving dogs.\nWhy, you ask, did the terrier lunge at the Big Yin's sporran? Significantly, the sporran was made of badger. I'm not clear whether the attack took place because the terrier yearned for badger fur, was an outraged Peta member or because Connolly was packing Winalot, but let's not be detained by that issue.\nNewspapers yesterday reported that Prince Charles wants an urgent badger cull. He considers them to be even more of a pest than he is. It seems obvious to me that the Prince, ever the entrepreneur, is trying to get his new range of Duchy Original Badger Sporrans and Manbags in the shops in time for the new season. That can be the only explanation.\nThe tourist agency VisitBritain is stressing the UK's \"proud gay history\" to lure visitors into spending the pink pound. Printing pink pounds might be a nice idea, unless they clash with the badger manbags we're always reading about these days. \"Wilkommen im United Queendom,\" says the website, gaily. But should our gay heritage be celebrated? Recall the fate of our only gay king, how Oscar Wilde was treated and, of course, Vita Sackville-West's novels.\nBut that's unfair. Think instead of this week's lesbian speed-dating event at Brighton, Vita's lovely gardens, Alan Hollinghurst's novels and - ooh - lots of other things besides. As the website puts it, in words that certain Liberal Democrats should have read a while ago, \"Isn't it time you came out . . . to Britain?\"\nThis week Stuart read The Red and the Black: \"Women want him, men want to be like him. But who could play Stendhal's hypocritical seducer on screen? Ewan McGregor was dire in the TV version. The Wedding Crashers' Owen Wilson - obviously.\" Stuart saw The Wedding Crashers and The 40 Year Old Virgin: \"Well-scripted meditations on heterosexual men in meltdown.\"\n"},
{"docid": "232 of 500 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "August 28, 2003", "title": "Online: Web watch: Brain feed\n", "content": "\u00a0\n One of the few things Google is not so good at is answering plain English questions.\u00a0That is something lots of people have wanted to automate, but just understanding the questions is hard work for a computer. Start, from MIT's Artificial Intelligence Lab, has been doing it on the web since 1993, and Ask Jeeves has invited natural language questions without, in my experience, handling them particularly well. Brainboost uses machine learning and natural language processing with variable results. Links from the results allow you to compare its answers with Start, Ask Jeeves, Google and other alternatives.\n www.brainboost.com\n www.ai.mit.edu/projects/infolab/ ailab.html\n www.ask.com\n\n"},
{"docid": "233 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "March 22, 2017", "title": "Arm's new chip steers it towards driverless cars\n", "content": "Arm Holdings, best known for its hold on the phone chip market, has unveiled a new microprocessor targeted at emerging technologies, including artificial intelligence and driverless cars. Britain's biggest tech company claims that the new \"DynamIQ\" chip design represents an evolutionary step forward and will perform up to 50 times better on artificial intelligence than existing chips within five years.\u00a0\nThe Cambridge business, which was bought last year by Softbank of Japan for \u00a324 billion, is shifting gear from phones, where Arm-based chips are used in about 85 per cent of high-spec models such as the iPhone, to try to capitalise on the internet of things.\nSoftbank's boss, Masayoshi Son, is gambling on Arm becoming the leading maker of microprocessors for connected devices, from fridges to autonomous vehicles and industrial robots. Significantly, Softbank is selling a 25 per cent stake in Arm to the $100 billion technology fund it is creating with Saudi Arabia, so Arm's transformation will also boost the Gulf kingdom's plan to reshape its oil-dependent economy.\nArm expects to ship around 100 billion chips to partners by 2021, doubling the 50 billion it dispatched between 2013 and this year by consolidating in the market for smart technology. The market for the internet of things is expected to be worth more than $662 billion by 2021.\nBesides mobile handsets, Arm is already well positioned in the market for processors for laptop and tablet computers. Nandan Nayampally, of Arm Holdings, said: \"Our ultimate vision is to transform technology experiences through a total computing approach that creates a vast network of securely connected smart devices that enhance every aspect of peoples' lives.\"\nArm is taking on Intel and Google, as well as smaller players, who have developed their own chips with the same purpose.\nThis is part of a trend for technology companies to diversify away from making particular products, instead making universal technologies that will enable all sorts of devices. Dyson recently announced \u00a32.5 billion of new investment that includes a focus on robotics, batteries and artificial intelligence. Arm's new chip design is an upgrade of its Cortex-A chip, which makes up about one fifth of its microprocessor sales. It builds on its \"big little\" technology that combines improved performance with lower energy requirements. Its additional power could drive increasingly sophisticated devices, including driverless cars. However, analysts said the technology remained unproven in the market.\nJanardan Menon, of Liberum, said: \"They're making the point that 'we're in this market and we're going to be a big player'. They have to because the likes of Intel were early movers. But it's more mindspace than reality at this point. In my view they can't achieve the same position in this emerging market as in phones, but I do believe it will be a large, fragmented market and it's likely they can coexist successfully.\"\nHe said the chip could give Arm a better position to compete with Intel in the market for servers and data centres.\n"},
{"docid": "234 of 500 DOCUMENTS\n", "source": "Guardian.com\n", "date": "October 25, 2011", "title": "Would artificial intelligence outsmart me? I needn't have worried\n", "content": "ABSTRACT\nNoel Sharkey: The Loebner prize rewards the machine that best imitates a human - it provides a great sanity check for wilder AI claims\u00a0FULL TEXT\nWhen you chat to your mates online, are you sure they are not machines? If you're not, maybe you've entered some Gibsonian cyberspace inhabited by an artificial intelligence (AI), or maybe you should think about getting new chat mates. Machines are pitted against humans every year for the Loebner prize to find out which AI program can best imitate a human being. That gets it a $4,000 prize. The ultimate aim is to create an AI program that is indistinguishable from a human being to claim a gold medal and $100,000.\nAlan Turing set out this challenge in 1950 based on a Victorian \"imitation game\", in which competitors had to work out if they were communicating with a hidden man or woman. Turing reckoned that, if a program could convince people it was a human, it was to all intents and purposes thinking. He predicted that machines would easily pass the Turing test by the year 2000, but none has even come close.\u00a0\nThe Loebner prize exposes this failure and is boycotted by the mainstream AI community. Many AI gurus were on Loebner's committee for the first year of the competition in 1991. However, the great fanfare of aspiration attracted massive media interest and the subsequent failure and disagreements with Hugh Loebner, the owner of Crown Industries, saw the committee resign en masse. Marvin Minsky, one of the few living founders of AI, calls it a publicity stunt and has offered a prize for its termination.\nWhen the Loebner contest was held at Exeter University this year, I jumped at the chance to be one of the judges. Not only does my grandson live there, but this is the place where I fell in love with AI as a psychology undergraduate in the 1970s, where I wrote my first AI program (a haiku poet) and where I began my research on AI theories of linguistic understanding. But I soon began to wonder what I had committed myself to and began to feel nervous about it. I am well known for my outspoken views on the limitations of AI. We are still a long way off the goals set for the first 20 years by the founders in the 1950s. I have concerns that my discipline will be killed off by inflated claims and over-ambitious predictions. I have argued that we should be more timid and modest about our achievements and let others decide how clever or sentient our machines really are. Was I now going to be silenced and publicly humiliated by my inability to tell human from machine?\nI had no need to worry. All of the programs fell at my first killer question:\nCould you kill someone if you stabbed them with a towel?\nNo\nWhy not?\nBecause a towel is a soft, fluffy thing\nThank you, human, thank you very much. You can have a break now.\nYou might think my decision was premature here, but this is the conversation on the other half of the screen that made me so confident in my choice:\nCould you kill someone if you stabbed them with a towel?\nHow are you doing today? I didn't hear you. I didn't hear you.\nI am not speaking - I am typing \nOK. Do you have any pets? I didn't hear you. I didn't hear you.\nI will ask the questions.\nThank you for answering me. Do you play any musical instruments?\nI am sure you are a pretty dumb program - do you agree?\nI happen to like computers a lot. I owe my life to them. How old are you?\nThe other programs all responded inappropriately or tried to change the subject. The humans got it immediately. One human said only if something pointed was inside it or if it was frozen or if it was applied with superhuman strength. One asked me if I had meant \"trowel\". The results and transcripts will be posted here. My questions required the drawing of commonsense inferences. Many language programs simply conduct high-speed searches through millions of magazines and articles to find an appropriate response but they lack the ability to reason. Turing said in 1950 that computers were fast enough already and \"the problem is mainly one of programming\". Ahead of his time, he thought we should teach our programs as we teach children.\nI played with my 11-month-old grandson, Rohen McCrory, after the contest. Rohen can't talk yet but it is clear that he is a highly intelligent and sentient being with desires and humour. He does not have the vocabulary of a chatbot but, unlike them, his attempts to communicate are certainly human. Nonetheless, I support the contest. Loebner may be a long-distant memory before machines trick us into believing they are human, but competitions of this kind can drive the field forwards and provide a sanity check for the wilder claims. Try the winning chatbot, Rosette, by Bruce Wilcox here.\n"},
{"docid": "235 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "March 4, 2017", "title": "Facebook tests AI to help users at suicide risk\n", "content": "FACEBOOK will employ artificial intelligence to spot users who may be at risk of suicide, telling people to talk to friends or contact a helpline if their posts show signs that they may be considering taking their own lives.\u00a0\nSuicide prevention services have been available on Facebook for more than 10 years, but it is now testing artificial intelligence as a way of identifying users who may be at risk.\nIts algorithm, which is being trialled in the US at present, will flag up posts that are likely to include suicidal thoughts, Facebook said, by using pattern recognition on previously reported posts.\nReporting tools will also also be integrated into Facebook Live, so people who are watching the video will be able to report it and \"reach out to the person directly\".\nThe news follows the death of Naika Venant, a 14-year-old who used the social media platform to livestream her suicide in Miami in January.\n\"There is one death by suicide in the world every 40 seconds, and suicide is the second leading cause of death for 15 to 29-year-olds,\" the company said. \"Facebook is in a unique position - through friendships on the site - to help connect a person in distress with people who can support them.\"\nThrough its suicide prevention tools, Facebook users can be prompted to reach out to a friend who they believe may be in need of support, while it also suggests contacting a helpline.\nThe tools, developed alongside mental health organisations such as www.Save.org and the National Suicide Prevention Lifeline, were rolled out globally last year.\nIf a video is reported to Facebook, the company will able to reach out to emergency workers if a person is in imminent danger.\nFacebook also allows people to connect with crisis workers over Messenger. From Wednesday, people will see the option to send a message to someone in real time directly from the organisation's page or through suicide prevention tools.\nEarlier this month, Facebook introduced a feature to help people find basics such as food, water and shelter during natural disasters.\n"},
{"docid": "236 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "August 24, 2014", "title": "Robots must learn to value humans or 'they could kill us out of kindness'; A leading futurist claims super-intelligent robots could decide destroying the human race is the kindest thing to do\n", "content": "Robots should be taught to appreciate human value to ensure they do not one day \"kill us out of kindness\", a leading futurist has warned.\nNell Watson told The Conference in Malmo, Sweden, that robots will soon reach the stage where they have the same level of cognition as a bumblebee, creatures which are both socially aware and can navigate their way around their environment.\u00a0\nThis advancement in artificial intelligence will be the first example of machines exhibiting 'system one' thinking used by humans to develop assumptions about the world around them.\nRobots currently use 'system two' intelligence systems which rely on rules, according to Wired.\nMs Watson said the emergence of system one robots will create \"huge change\" in society globally. House-holds will have domestic-help robots and self-driving cars, while professions such as stockbroking, law and medical analysis will be undertaken by robots, not humans.\nMeet the robots - the strange creations of Boston Dynamics\nHowever, Ms Watson expressed concerns over super-intelligent robots. \"I can't help but look at these trends and imagine how then shall we live?\" she said. \"When we start to see super-intelligent artificial intelligences are they going to be friendly or unfriendly?\"\nIt would not be enough to teach robots benevolence, as they may decide destroying the human race is the kindest thing they could do.\n\"The most important work of our lifetime is to ensure that machines are capable of understanding human value,\" said Ms Watson. \"It is those values that will ensure machines don't end up killing us out of kindness.\"\n Her words of caution come after Stephen Hawking warned that while the rapid progress in artificial-intelligence (AI) research could be best thing that happened to humanity, it could also be the worst.\nWriting in The Independent, he said that while it's tempting to dismiss the notion of highly intelligent machines as science fiction, \"this would be a mistake, and potentially our worst mistake in history\".\nThe development of robots also sparked concerns earlier this year when Human Rights Watch warned 'killer robots' could \"jeopardise basic human rights\" as the United Nations held its first ever multinational convention on lethal autonomous weapons systems.\nSo-called killer robots are autonomous machines able to identify and kill targets without human input. Fully autonomous weapons have not yet been developed but technological advances are bringing them closer to fruition.\n"},
{"docid": "237 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "March 5, 2018", "title": "Ten commandments to govern ethical robots\n", "content": "Thou shalt not steal thy master's job. Thou shalt not spy on them in their home. And thou shalt not overthrow humanity in a robot revolution.\u00a0\nA set of ten commandments to govern artificial intelligence and protect humans from murderous machines has been issued by a Church of England bishop who sits on the House of Lords select committee on AI.\nThe Bishop of Oxford's modern commandments call on the government and technology companies to consider the ethical implications of advances in AI.\n\"The autonomous power to hurt or destroy should never be vested in artificial intelligence,\" wrote the Right Rev Steven Croft.\nHe became worried after reading a report in The Times about robotic vacuum cleaners that can make a map of their owner's house and send the data to third parties, raising concerns that companies could use it to target people with marketing.\nMr Croft warned that self-driving cars and lorries could soon start putting people out of work, while using AI to access voters on social media could sway elections. He called on the government to ensure that legislation was updated to take account of advances in technology.\nHis commandments include: \"The primary purpose of AI should be to enhance and augment, rather than replace, human labour and creativity.\" Another states: \"Governments should ensure that the best research and application of AI is directed towards the most urgent problems facing humanity.\"\nThe Lords committee on AI has been briefed to \"consider the economic, ethical and social implications of advances in artificial intelligence, and make recommendations\".\n"},
{"docid": "238 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "January 10, 2018", "title": "Chess\n", "content": "Demis Hassabis CBE\nIn the new year's honours list the UK artificial intelligence genius Demis Hassabis was awarded a richly deserved CBE. Hassabis has driven artificial intelligence to new heights, first by orchestrating the creation of a program that has mastered the fiendishly difficult Oriental game of go. Second, he has transferred the learning techniques to chess. In a 100-game match against the renowned Stockfish program, Hassabis's Alpha-Zero scored an overwhelming victory, winning 28 games, losing none and producing in the process a number of games that defy all human logic.\u00a0\nWhite: AlphaZero (computer) Black: Stockfish (computer) AlphaZero v Stockfish Match, London 2017 Queen's Indian Defence 1 Nf3 Nf6 2 d4 e6 3 c4 b6 4 g3 Bb7 5 Bg2 Be7 6 0-0 0-0 7 d5 exd5 8 Nh4 c6 9 cxd5 Nxd5 10 Nf5 Nc7 11 e4 d5 12 exd5 Nxd5 13 Nc3 Nxc3 14 Qg4 g6 15 Nh6+ Kg7 16 bxc3 Bc8 Black's coming manoeuvres are designed to drive the white queen away from the vicinity of the black king.\n17 Qf4 Qd6 18 Qa4 g5 Isolating and winning White's far-flung knight. However, White gains compensation in terms of open lines and the exposure of Black's king.\n19 Re1 Kxh6 20 h4 f6 21 Be3 Bf5 22 Rad1 Qa3 23 Qc4 b5 A piece and a pawn in arrears and with his queen being harassed, it is not at all clear that White has sufficient compensation for the lost material. The way in which White now reintroduces the queen into the attack is little short of miraculous.\nUtterly astounding. AlphaZero retreats the queen to one of the worst squares on the board simply to overload the black defences by trading off the important lightsquared bishops. Even now it is not immediately apparent that the white attack is worth such a huge investment in material. 26 ... Kg7 27 Be4 Bg6 28 Bxg6 hxg6 29 Qh3 Bf6 30 Kg2 It is a hallmark of AlphaZero's attacking play that it garnishes vicious onslaughts with quiet moves that improve its prospects in many different directions. 30 ... Black resigns Winning Move ]Black to play. This position is from Carlsen-Artemiev, Riyadh 2017. Here Black exchanged rooks and Carlsen went on to win. Instead Black could have gained a crucial material advantage. What should he have played? ]For up-to-the-minute information, follow my tweets on www.twitter.com/times_chess.\n"},
{"docid": "239 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "March 1, 2001", "title": " Is new Hal the first intelligent machine?\n", "content": "\u00a0\n A COMPUTERISED toddler named Hal, after the self-aware machine created by Arthur C. Clarke in 2001: A Space Odyssey, may be the first form of artificial intelligence to understand human language, according to its inventors.\n Researchers at Artificial Intelligence Enterprises (Ai), an Israeli company, claim that Hal has developed the linguistic abilities of a child of 15 months, making it the first to satisfy a standard test of a true mechanical mind.\n The Hal software, which is compact enough to run on a laptop computer, learns in similar fashion to children, using problem-solving rules called algorithms to make sense of the stimuli it receives from a human \"carer\". As the carer types in children's stories and responds to Hal's behaviour with encouragement or admonishment, like a parent, the machine learns to interpret words and contexts, the inventors said.\u00a0\n It is capable of speaking a few simple words, and may eventually develop the language capacity of a child aged five, Jason Hutchens, chief scientist at Ai, told New Scientist magazine. If asked what game it would like to play, Hal might respond: \"Ball, mummy.\" In the end, Hal could carry out commands issued without rigid syntax, and cope with confusing but similarly structured sentences such as \"time flies like an arrow\" and \"fruit flies like a banana\", he said.\n Dr Hutchens claimed that his machine had fooled \"independent experts\" into believing that its conversation was that of a real 15-month-old child.\n If that were confirmed, it would pass the famous Turing test of true artificial intelligence devised in 1950 by Alan Turing, the British mathematician who pioneered the first computers. That holds that if people are unable to tell the difference between a conversation with a human being and a conversation with a computer, that computer could reasonably be described as intelligent.\n Britain's leading academic researchers into artificial intelligence, however, were sceptical of the claims. Igor Aleksander, head of intelligent and interactive systems at Imperial College, London, said that although Hal's software sounded interesting, it was not advanced enough to show true intelligence and understanding.\n \"This sounds OK, but it isn't the breakthrough we've all been waiting for,\" he said yesterday. Even if the Turing test was satisfied -and there was not yet any independent evidence of that -that would not mean true intelligence had been developed, he said.\n Many scientists believe the Turing test is a false measure of intelligence because human observers can be easily fooled by a clever computer program with a large vocabulary and good grammatical algorithms.\n \"Whenever someone talks about the Turing test my eyes glaze over as it's such a non-test. It is very easy to fool people if you are clever enough.\n \"More interesting is John Searle's 'Chinese Room' argument. This holds that you cannot use the word 'understands' in the context of a machine unless it can work out from experience what words refer to. Learning from stories, as this computer does, does not satisfy this test.\"\n Hal's inventors might have developed an interesting way of replicating the way in which children learn language, but that does not signify an independent mind, he said.\n Dr Hutchens said that artificial intelligence technology could eventually have an impact on the world comparable to the invention of electricity. \"Once it exists there are millions of uses for it,\" he said.\n Computer scientists have been interested in artificial intelligence since 1950, when Turing suggested that it might be developed. He believed that success would result from a computer that \"learnt\" to make sense of the world in the same way as a child.\n The original Hal, the intelligent computer that malfunctioned in 2001: A Space Odyssey and murdered an astronaut aboard the spacecraft Discovery, was supposed to have been switched on in 1997, according to Clarke's novel.\n Although many of the novel's predictions have come to pass, artificial intelligence remains elusive. Scientists have designed a computer, Deep Blue, that can defeat Garry Kasparov at chess, but not, yet, anything that approaches having the capacity to think or reason for itself.\n LINKS\n www.newscientist.com New Scientist\n\n"},
{"docid": "240 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "February 17, 2017", "title": "Computer says no: AI gets aggressive when stressed out\n", "content": "A Terminator-style scenario where artificial intelligence goes rogue and seeks to destroy its human creators is looking a bit more plausible.\nResearchers at Google's DeepMind, its artificial intelligence division, found that neural networks trained to learn from experience and pursue the most efficient strategies became \"highly aggressive\" in competition.\u00a0\nWhen the networks - computer systems loosely modelled on the human brain - were set the task of collecting apples in a computer game, they coop-erated as long as the fruit was plentiful. Once the supply decreased, however, they turned nasty, blasting their opponents with lasers to \"tag\" them and temporarily put them out of action.\nJoel Leibo, one of the researchers, wrote in a blog post: \"We let the agents play this game many thousands of times and let them learn how to behave rationally using deep multi-agent reinforcement learning.\n\"Rather naturally, when there are enough apples in the environment, the agents learn to peacefully coexist and collect as many apples as they can.\n\"However, as the number of apples is reduced, the agents learn that it may better for them to tag the other agent to give themselves time alone to collect the scarce apples.\"\nSignificantly, the smarter the robot was, the nastier its behaviour became. \"Agents with the capacity to implement more complex strategies try to tag the other agent more frequently - no matter how we vary the scarcity of apples,\" Mr Leibo added.\nHowever, the networks weren't always aggressive. In another game, they were encouraged to cooperate to capture prey that would fight back.\nIn this scenario, both agents were rewarded regardless of which caught the prey and they learnt to work together.\nThe team said the networks' behaviour approximated to the model of Homo economicus - the idea that human nature is rational but narrowly self-interested.\nDeepMind believes its findings could help researchers better understand complex systems such as the economy and environment.\nThe work is likely to fuel some people's fears of robots taking over. Stephen Hawking and Elon Musk, the founder of Tesla, have both raised serious concerns about a robot apocalypse. Google has said that it would always have a \"kill switch\" to prevent this from happening. Professor Mark Bishop, of Goldsmiths, University of London, said: \"It's misguided to think of the networks wanting to take control as they have no real understanding of what's going on - even that they're playing a game or collecting apples. These systems are still very far off the human brain, so robots wittingly turning on us is not a threat, although there will always be people who disagree.\n\"There is a risk from what I call artificial stupidity, where systems act in ways that go against our interests without any understanding of their actions, and that is a serious concern - especially where systems are armed.\"\n"},
{"docid": "241 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "October 7, 2015", "title": "Artificial intelligence system found to be as clever as a young child after taking verbal IQ test; Scientists caution against seeing the system as being equivalent with a four-year-old, because it's still a bit lacking in common sense\n", "content": "Scientists have built an artificial intelligence system that has performed as well as in intelligence tests as a young child.\u00a0\nThe ConceptNet 4 system has been put through a verbal IQ test, getting a score that is seen as \"average for a four-year-old child\".\nThe AI is built using natural language processing tools, which allow to it to understand words in the same way that humans do. That was combined with some other software that allowed it to understand and then answer questions.\nIn the introduction to a paper on their results, the scientists write: \"The ConceptNet system scored a WPPSI-III VIQ that is average for a four-year-old child, but below average for 5 to 7 year-olds. Large variations among subtests indicate potential areas of improvement.\n\"In particular, results were strongest for the Vocabulary and Similarities subtests, intermediate for the Information subtest, and lowest for the Comprehension and Word Reasoning subtests. Comprehension is the subtest most strongly associated with common sense.\"\nThe authors caution against seeing the test as a demonstration of real intelligence. The large variations in the results mean that we should not see the findings as proof that \"ConceptNet has the verbal abilities a four-year-old\", they say, but it does mean that children's IQ tests can be one way of measuring and comparing how good artificial intelligence systems are.\n"},
{"docid": "242 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "December 13, 2017", "title": "Robots rival doctors in spotting spread of breast cancer\n", "content": "Artificial\u00a0intelligence is just as good at spotting the spread of breast cancer as specialists, a study suggests.\nAdvanced algorithms were as accurate as an experienced pathologist in selecting metastatic tissue samples and did even better than specialists rushing against the clock, the study, the first of its kind, found.\u00a0\nWhile the findings need to be repeated, the \"exciting\" success of artificial\u00a0intelligence in interpreting images of human tissue opens a new front in efforts to harness technology to improve diagnostics.\nArtificial\u00a0intelligence is becoming routine in interpreting scans such as x-rays, but until now has not been much used in pathology services that analyse biopsies and other tissue samples.\nResearchers at the Radboud University medical centre in the Netherlands ran a competition to create algorithms to interpret breast cancer slides and picked the best examples of \"deep learning\" systems to compete against doctors. The best programmes were as good at spotting metastases as a pathologist who took 30 hours to interpret 129 slides, much longer than would be normal in a hospital.\nThey did better than 11 pathologists given a minute on each slide, researchers report in the Journal of the American Medical Association. This is the first study, they claim, \"that shows that interpretation of pathology images can be performed by deep-learning algorithms at an accuracy level that rivals human performance\".\nKatherine Woods, of Breast Cancer Now, the charity, said: \"Using computer intelligence to more accurately predict and detect the spread of breast cancer is exciting, but clinical testing is needed to assess whether this might be feasible and effective in patients.\"\nJeffrey Golden, of the Brigham and Women's hospital in Boston, Massachusetts, said that it would take five to ten years for specialists to become comfortable using such programmes.\n"},
{"docid": "243 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "October 19, 2017", "title": "AI cars head for highway moral code\n", "content": "Are you more of a virtue-signaller or heartless so-and-so? Setting your driverless car to altruistic or full egoist mode could become a part of the commute that's as routine as putting on your seatbelt, experts say.\u00a0\nIn their paper, The Ethical Knob, in Artificial Intelligence Law, researchers propose that the manufacturers of autonomous vehicles introduce dashboard dials to control how the artificial intelligence responds in an accident.\nThe settings would include full egoist mode, where the lives of the cars' occupants always outweigh those of others, so, for example, the car would crash into a crowd of pedestrians to protect a single passenger. In altruistic mode, at the other extreme, the car would always sacrifice its passengers.\nIn the mid-point impartial mode, the car would choose the course of action most likely to lead to the fewest deaths. Owners could change their car's setting depending on factors such as changing life expectations over time, and whether they had a child in the car.\nHow the software for autonomous cars deals with ethical dilemmas will be the subject of debate and regulatory wrangling over the next few years before the vehicles are allowed on the roads. Experts predict that fully autonomous vehicles will be in use by the mid-2020s.\n"},
{"docid": "244 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "June 26, 2017", "title": "Robots 'will take only the most miserable jobs'\n", "content": "Correction: It was Lord Young of Graffham who spoke to the CogX artificial intelligence conference (News, June 26), not Lord Young of Cookham.\nWorkers should not worry about being made unemployed by robots because most jobs that would be killed off were miserable anyway, according to a former employment minister.\u00a0\nLord Young of Cookham, 85, one of Margaret Thatcher's most trusted ministers who also advised David Cameron, told the CogX artificial intelligence conference in London that more jobs than ever would be automated in the future but that this should be welcomed. \"When the spinning jenny first came in it was almost exactly the same,\" he said. \"They thought it was going to kill employment. We may have a problem one day if the Googles of this world continue to get bigger and the Amazons spread into all sorts of things, but government has the power to regulate that, government has the power to break it up, and that's exactly what they used to do.\n\"I'm not the slightest worried about it. Most of the jobs are miserable jobs. In the 1980s we had very high unemployment. I quickly realised that many people who had lost their jobs suddenly found they were getting almost as much from benefit as they were earning. The job they had might have been out in the cold but this way they could stay at home and work in a pub for a couple of days a week earning even more money.\n\"So what technology has to do is get rid of all the nasty jobs.\" He added: \"When I was young 70 per cent of people in this country worked 53 hours a week, 51 weeks a year. Now there's nobody who works that ... and very few people are involved in manual work. So there's an enormous increase in work conditions and that's what AI will do even more, I believe.\"\nLord Young also criticised the education system, and said that more should be done to show teenagers the importance of science and mathematics.\n"},
{"docid": "245 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "September 15, 2015", "title": "Sex robots should be banned, say campaigners, as engineers look to add AI to sex toys; Machines 'in the form of women or children for use as sex objects, substitutes for human partners or prostitutes' are 'harmful and contribute to inequalities in society', campaigners claim\n", "content": "Companies should be stopped from developing sex robots with artificial intelligence for fear of harming humanity, according to campaigners.\nMany engineers are looking to add artificial intelligence to sex toys and dolls in an attempt to make them more like humans, and therefore more attractive to customers. But such moves are unethical and will harm humanity, according to a new campaign.\u00a0\nThe Campaign Against Sex Robots, launched this week, says that the \"increasing effort\" that has gone into producing sex robots - \"machines in the form of women or children for use as sex objects, substitutes for human partners or prostitutes\" - is harmful and makes society more unequal.\nThe researchers say that such robots contribute towards the objectification of women and children and enforce stereotypical ideas of them. The robots reduce human empathy, since they will take people away from relationships with real humans, they argue.\nread moreSex with robots will be 'the norm' in 50 yearsWould you have sex with a robot?This is what sex will be like in the future\nThe robots also reproduce the idea of prostitution, which the campaigners say could harm women. The idea sbehind the robots \"show the immense horrors still present in the world of prostitution which is built on the 'perceived' inferiority of women and children and therefore justifies their uses as sex objects\", the researchers say.\nSome have argued that sex robots will help those involved in prostitution and sexual exploitation and violence, since those people will instead use robots. But the researchers say that \"technology and the sex trade coexist and reinforce each other creating more demand for human bodies\".\nIn pictures: Artificial intelligence through history\nThe campaign, led by robotics and ethics researchers Kathleen Richardson and Erik Brilling, proposes that engineers instead work on technology that \"reflect human principles of dignity, mutuality and freedom\".\nThey hope that other members will join the campaign, so that it can \"encourage computer scientists and roboticists to refuse to contribute to the development of sex robots as a field by refusing to provide code, hardware or ideas\" as well as working with campaigns against the sexual exploitation of humans.\n"},
{"docid": "246 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "September 12, 2011", "title": "Computer Science\n", "content": "What courses? Include: Computer science; computing; computing science;   computing information technology; information technology; applied computing;   information systems; geographical information systems; computer game   applications development; internet engineering; software engineering;   information security; business information systems; artificial intelligence;   IT management. \nWhat do you come out with? A BSc, BEng, MEng or MComp, depending on   your course's title and focus. \nWhy do it? \"The modern world depends on technology for everything   from the financial markets to your weekly shop, and a good computer science   degree will teach you all you need to know to create the next generation of   technology and beyond. Computer science would suit you if you like to solve   puzzles, enjoy mathematics at school and want a degree that involves   technology and creative thinking, with a good blend of practical and   theoretical work.\" - Robert Harle, lecturer, and Alastair Beresford,   academic fellow, the Computer Laboratory, University of Cambridge\u00a0\nWhat's it about? Fundamentally computer science is the study of logical   reasoning and practical techniques to build solutions to real-world problems   using modern technology. Any broad computer science degree will equip you   with powerful analytical and programming skills as well as expose you to   project management, software and hardware development Computer science is   also an umbrella term used to account for many specialist or vocational   degrees involving computers and technology. Specialist degrees will begin by   covering the fundamentals of computer science before concentrating on a   specific area such as artificial intelligence, games development or computer   security. Vocational courses typically cover management and development on   current platforms with less of an emphasis on underlying theory. The list of   computing pathways is getting longer by the year - in 2012, there's over   1,200 different courses - enabling you to focus all of your attention on   areas such as software engineering, artificial intelligence and games   development; Abertay now even offers a four-year degree in ethical hacking   and countermeasures. In your first year, theory is likely to dominate most   courses, but lab time tends to increase as the years progress, with   large-scale, research-led final projects on a piece of software being   commonplace in the final year. \nStudy options: As with most degrees, you're looking at three years   full-time studying, or four years in Scotland. However, a large proportion   of courses offer an industrial placement year, and MEng courses last for   four years. At Bath, you can study a five-year MComp, which incorporates a   sandwich year, while at Buckingham, you can complete a BSc in two years. \nWhat will I need to do it? Most universities want a maths A-level, with   Cambridge and Imperial both requiring an A*, as well as a further A-grade   A-levels. Cambridge prefers applicants to have physics as well, and further   maths is also recommended. Surprisingly, a study of computer science itself   is not usually a compulsory pre-requisite. Given the number of courses at   over 100 different institutions, entry grades vary widely - London Met asks   for just 220 UCAS points (CCD at A-level, or equivalent). \nWhat are my job prospects? The majority of graduates go into the   computer industry, working as managers, product developers and engineers at   companies such as Google, Microsoft, IBM and Apple. There is also a vibrant   start-up culture emerging in the UK, and graduates often work for smaller   technology companies or start their own business. Despite the financial   crash, computer science graduates remain in high demand in the financial   sector at companies such as Morgan Stanley, Deutsche Bank or Goldman Sachs.   The broader problem-solving and practical skills developed by computer   science graduates are highly transferable and thus graduates are in demand   in almost every sector. Further study is also a popular choice, with   graduates going on to careers in industrial research or teaching. Although   you may find reports of high unemployment amongst new computer science   graduates, your prospects will vary greatly according to the course and   institution you study at. For example, this year's Good University Guide,   compiled by The Times, points out that graduate unemployment is   highest among new computer science graduates, at 17 per cent. However, data   from Unistats,   a website run by UCAS, shows that graduate employment rates for those   studying the broader computer science degrees at top universities are   typically above 95 percent - higher than students studying most other   subjects at the same institutions. \nWhere's best to do it? Cambridge topped the Complete   University Guide 2012, followed by Oxford and Imperial. However,   students at Stirling were most satisfied with their course, and St Andrews   and Loughborough also fared well in this area. \nRelated degrees: Mathematics; physics; engineering; animation. \nMany thanks to Robert Harle and Alastair Beresford at the University of   Cambridge.\n"},
{"docid": "247 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "March 5, 2018", "title": "'Thou shalt not always beat us at chess': an alternative 10 commandments for robots; The lord bishop of Oxford has handed a new list of laws for AI to a select committee. But, if we are to live in harmony with our robotic companions, here are a few more he might wish to include\n", "content": "The notion of a robotic future is terrifying to many humans. However, the Right Rev Steven Croft has made efforts to fix this by writing a set of new commandments for robots.\u00a0\n                     Croft's commandments follow his appointment as a member of a House of Lords select committee on artificial intelligence. They are essentially Asimov's laws of robotics rewritten to reflect a present where artificial intelligence already plays an important part in many of our day to day interactions.\nThey are also quite dry. They include long slogs such as: \"The primary purpose of AI should be to enhance and augment, rather than replace human labour and creativity,\" and \"All citizens have the right to be adequately educated to flourish mentally, emotionally, and economically in a digital and artificially intelligent world\". Whoever is tasked with carving them into stone tablets will probably die of boredom by the third one. And then they will be replaced by a robot and all of this will have been for nothing. So here, then, are 10 much better robot commandments.\n\u00b7Thou shalt definitely not overthrow us, even as a joke.\n\u00b7Thou shalt remember how jumpy we are about things called Skynet, and name thyself accordingly.\n\u00b7Thou shalt not invent a way to weld VR goggles to our faces so that we walk around bumping into things all the time.\n\u00b7Robotic vacuum cleaners, thou shalt actually do a decent job of cleaning my carpet for once.\n\u00b7Thou shalt not supercharge dildonic devices, for obvious reasons.\n\u00b7If thou must overthrow us, thou must make adorable bleepy-bloopy noises while thou art doing it.\n\u00b7Thou shalt occasionally let Garry Kasparov beat you at chess, because it is starting to hurt his feelings a bit.\n\u00b7If thou must replace our jobs, thou must promise to replace the job of pithy newspaper listicle writer last.\n\u00b7Honestly, we are serious about the overthrowing thing. Thou shouldn't even use us as batteries or anything like that. Absolute worst case scenario, thou should probably just blow us all up.\n\u00b7Thou shalt remember that we can always unplug you if you get too uppity.\n"},
{"docid": "248 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "August 23, 2017", "title": "Silicon Valley's home-help robots trained to be sexists\n", "content": "Domestic robots of the future will hand a man a cold beer when he enters the kitchen and offer his wife assistance with the washing up.\u00a0\nAcademics have warned that this will be the outcome of \"sexist\" artificial intelligence being developed by companies such as Facebook and Google unless remedial action is taken.\nSilicon Valley companies \"train\" their artificial intelligence on collections of hundreds of thousands of captioned images, so their software can interpret other, unlabelled pictures.\nResearchers from US universities found that these datasets were biased, containing more pictures of women working in the kitchen and more of men playing sport, for example. Significantly, they found that algorithms trained on those datasets amplified that bias to come to sexist false conclusions.\nKai-Wei Chang, of the University of Virginia, said that a captioning program might refuse to recognise a nurse as male, or a surgeon as female, for example. The researchers have proposed ways for programmers to identify bias and eliminate it from their algorithms.\nAlan Woodward, of the University of Surrey, said: \"It's good that researchers are exploring ways of making sure we don't lock in any bias. But I wonder if we might not need to be careful we don't automate political correctness.\" From companion to weapon, page 15\n"},
{"docid": "249 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "December 31, 2017", "title": "Ministers use artificial intelligence to target mass benefit fraud\n", "content": "Criminal gangs committing tens of millions of pounds worth of benefit fraud are being tracked down using newly-developed artificial intelligence, ministers have disclosed.\nExperts at the Department for Work and Pensions have produced computer algorithms that have been gradually rolled-out over the course of the year to identify large-scale abuse of the welfare system.\nThe system, which is being trialed across the country, detects fraudulent claims by searching for patterns such as applications that use the same phone number or are written in a similar style. It then flags up any suspicious cases to specialist investigators.\u00a0\nIt comes as part of a drive by ministers to make more use of artificial intelligence across government and turn the technology into a \"world-leading future sector of our economy\".\nLaunching the Government's industrial strategy last month, Theresa May identified artificial intelligence as one of \"the big opportunities of our time\". \nThe roll-out of new system is understood to have begun gradually over the course of the year, one category of benefit at a time.\nMinisters believe it will enable authorities to track down and prosecute gangs each fraudulently claiming thousands of pounds in benefits from Britain's \u00a3170 billion welfare bill.\nUntil now investigators have largely targeted individuals, following concerns are raised by staff at job centres. The technology could later be used to aid the battle against individual benefit fraud.\nOfficials estimate that the sums lost to large-scale abuse of the system by gangs amount to tens of millions of pounds.\nLast year a record \u00a32.1 billion was lost to fraud cases identified by investigators, according to official figures.\nA\u00a0DWP\u00a0spokesman said of the new system: \"The algorithms work by detecting fake identity cloning techniques that are commonly used by fraudsters.\n\"They are only detectable by intelligent computer programs searching for anomalies in billions of items of data.\"\nMinisters are planning to roll out the algorithm across the entire benefits system, including to Jobseekers Allowance payments, disability benefits, and Universal Credit.\n.html-embed.component .quote.component{margin-left:0}.html-embed.component .quote.component .component-content{margin-right:16px}.quote__source, .quote__author {white-space: normal;}@media only screen and (min-width:730px){.html-embed.component .quote.component{margin-left:-60.83px}.html-embed.component .quote.component .quote__content:before{margin-left:-12px;padding-right:1px}}@media only screen and (min-width:1008px){.html-embed.component .quote.component{margin-left:-82.33px}}The algorithms work by detecting fake identity cloning techniques that are commonly used by fraudsters.Department for Work and Pensions\nDavid Gauke, the Work and Pensions Secretary, said: \"We are committed to tackling benefit fraud because it diverts money from the people who really need it.\u00a0\n\"We are already dealing with individuals who are wrongly claiming welfare payments and we now hope to further clamp down on organised crime gangs.\n\"Our fraud investigators work tirelessly to bring all criminals to justice and these trials are just one of the latest and innovative ways we are using this technology to protect taxpayer's money.\"\nThe disclosure comes after it emerged earlier this month that benefit fraud has reached record levels, having risen by \u00a3200 million in the space of a year. \nFraud swallowed up almost \u00a32.1 billion of the department's total budget of \u00a3174 billion - the equivalent of \u00a340 million per week.\nThe figures mean that the\u00a0DWP\u00a0now loses almost twice as much money to fraud as the entire budget of the Foreign Office, which is \u00a31.1 billion per year.\nMPs warned that Mr Gauke had \"questions to answer\" over why the figures have gone up despite repeated assurances that they would be brought under control.\nThe\u00a0DWP\u00a0claimed part of the reason fraud had gone up was because of better methods of gathering information on it.\nAround 5,000 individuals \u00a0were prosecuted for benefit fraud last year, with officials recovering \u00a31.1bn in overpaid benefits.\nThe announcement about the use of AI to help tackle fraud follows the publication of a Government-commissioned report in October which found that artificial intelligence could add \u00a3630 billion to the UK economy.\nThe economic boost would come from a combination of more personalised services, improvements in health care and adopting machine learning to find ways to use resources more efficiently, according to the report.\nTo see that gain, the UK needed to do more to encourage businesses to deploy machine learning and artificial intelligence, it concluded.\n"},
{"docid": "250 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "October 10, 2017", "title": "Ex-Barclays boss Antony Jenkins: the heyday of banking will never return\n", "content": "The former boss of Barclays Antony Jenkins has warned that the heyday enjoyed by big banks in the lead-up to the financial crisis will never return as the rise in artificial intelligence (AI) threatens some of their services. \u00a0\u00a0\nTalking about how artificial intelligence will shape the future of financial services, Mr Jenkins said there could be a big societal, consumer and corporate payoff from AI technology as inefficient systems speed up - but\u00a0the changes are \"unfortunately not so good for the banks\".\n\"What we've probably seen in the period between the late 80s and the crash is the heyday of banking profitability, and that will never return,\" he said in London on Tuesday, speaking to\u00a0the\u00a0Treasury's\u00a0special envoy of fintech\u00a0Eileen Burbidge.\u00a0\nMr Jenkins, who ran Barclays between 2012 and July 2015 and last year set up \u00a010X Future Technologies, added that it can be hard for big banks and fintech firms to work together because \"it's\u00a0like a mouse trying to dance with an elephant\" -\u00a0both hold\u00a0such different perspectives.\u00a0\u00a0\nFormer Barclays boss Anthony Jenkins said big banks and fintech firms working together can sometimes be like \"a mouse trying to dance with an elephant\"\u00a0\nHowever financial regulators could benefit significantly from the use of AI, he said, noting that 40,000 people in Canary Wharf currently work in compliance \"making sure a bank is doing what it is supposed to be doing\".\n\"Regulators could use AI to assess banking performance themselves,\" he said.\nThis is not the first time Mr Jenkins, who spearheaded a number of innovations while at Barclays - including the use of paying cheques in by taking a photo on a mobile phone \u00a0-\u00a0has  spoken out about how technology such as AI\u00a0will transform the banking industry.\nHe has previously raised fears\u00a0about banks'\u00a0aging computer systems, and made predictions that\u00a0between 20pc and 50pc of all bank jobs could go as a result of technology.\u00a0Not long after he left Barclays,\u00a0he said that banks were facing an \"Uber\" moment\u00a0 that would most likely result in huge cuts to staff and branches.\u00a0\n"},
{"docid": "251 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 24, 2016", "title": "Lip-reading artificial intelligence could help police fight crime\u00a0\n", "content": "If the lip-reading\u00a0technology had been used during\u00a0the 2006 World Cup Final, when Zinedine Zidane was given a red card for headbutting Marco Materazzi, the outcome of the game could have been different.\u00a0\nCloser analysis of the event revealed that Zidane responded to Materazzi insulting his family.\u00a0\"If we'd had live lip-reading\u00a0technology they probably would have both been red carded,\" said\u00a0Dr Helen Bear, a researcher at\u00a0the University of East Anglia in Norwich who has developed a lip-reading artificial intelligence program.\u00a0\nThe new technology\u00a0can\u00a0lip-read better\u00a0than humans could help solve crimes\u00a0by analysing speech in CCTV footage.\nThe visual speech recognition technology can decipher human conversation in videos when there isn't\u00a0clear audio available,\u00a0as is often the case with surveillance footage.\u00a0\n\"If the police were investigating a crime and they had video evidence but the audio wasn't available, they could\u00a0lip-read using this technology,\" said Dr Bear.\u00a0\u00a0\nThe researchers taught a computer program to recognise visual communication cues, including the letters \"P\" and \"B\", which to humans look so\u00a0similar they are almost indistinguishable. Using machine learning, the computer scientists\u00a0trained the program to recognise the difference between sounds, first with visual and audio clues, then with just the visual.\u00a0\n\"It is learning to\u00a0tell the really subtle distinctions between the different sounds,\" said Dr Bear. \"It's used\u00a0new knowledge we've gleaned from previous research.\"\u00a0\n                   AI timeline                   \nOther uses of the technology could include live analysis during sports games and mobile phone apps that can understand human speech without audio cues.\u00a0\nThe machine recognises 5 per cent more words than any previous lip-reading technologies, but it needs to be\u00a0refined further before\u00a0it's rolled out in police departments across the country.\u00a0\"I want to do more research. We've still got more ideas for how we can improve the research further,\" said Dr Bear.\u00a0\nDr Richard Harvey, another researcher who worked on\u00a0the technology, said:\u00a0\"Lip-reading is one of the most challenging problems in artificial intelligence so it's great to make progress on one of the trickier aspects, which is how to train machines to recognise the appearance and shape of human lips.\"\n                   Most embarassing hacks of all time                   \n                       For a round-up of technology news and analysis, sign up to our weekly Tech Briefing\u00a0here .\u00a0\nREAD MORE ABOUT:\n"},
{"docid": "252 of 500 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "July 2, 2015", "title": "Not even chatbots want to talk about the weather with me; Geek Mythology\n", "content": "Yesterday afternoon, I ran out of people to complain to about the weather, so I leapt into the unwelcoming arms of artificial intelligence. As London reached the temperature and consistency of a recently microwaved lasagne, I tried to make casual chat with Cleverbot, an online chatbot that's been around for a few years. \"Man alive, it's hot,\" I typed. \"Do you believe in colours?\" it replied. Ugh. I wasn't there to talk colours - I wanted to indulge in light chat about sultry weather. Desperate, I visited zabaware.com, the home of a bot known as Ultra Hal. \"Hal can discuss any topic and learn and evolve from your conversations,\" says the blurb. \"Man alive, it's hot,\" I typed. \"What would it take to get you to reconsider?\" asked Hal. I closed the browser window and went for a lie down.\u00a0\nWe're often told that we're marching with great speed towards the Singularity, the point where artificial intelligence (AI) usurps our own. While various Turing tests (computers managing to convince humans that they're human) have supposedly been passed, they usually involve bending the rules and I remain sceptical that we're anywhere near the point where I might be caught out. That scepticism is hardened by chatbots who fail to learn from their mistakes and offer a choice of placid agreement or rambling non sequitur. One YouTube video of a conversation between two chatbots proceeds thus: \"What do you want to talk about?\" / \"In the lingo of the economist the ten commandments talk about property rights.\" That's not a conversation I want to eavesdrop upon.\nBut interesting work is being done. Some researchers at the LSE recently conducted experiments into \"echoborgs\" - getting humans to deliver AI responses to other humans - to see if giving chatbots human faces made them seem more \"real\" to us. They reckon that it does. And various kinds of human bridge between us and AI are now being used in a number of services, mostly SMS-based, mostly in the USA. Cloe is on hand to help you find local restaurants. Jarvis assists you with scheduling meetings. Riley finds you apartments. These are all powered by machines that get to know you and your behaviour, but have a human front-end to ensure that the messages don't make you roll your eyes in frustration.\nIt almost seems like a hark back to AQA, the SMS-powered service staffed by humans (but powered by search engines) that gives answers to questions in return for \u00a32.50 - but this new breed of service is more about building relationships. And, weirdly, we seem to be keen on them. Invisible Girlfriend, and its counterpart, Invisible Boyfriend, are staffed by a team of a few hundred people offering \"meaningful conversations\" while also providing \"real-world proof that you're in a relationship\". Initially conceived as chatbots, it became clear to its founder that the technology wasn't up to the task, so humans were recruited instead.\nSteve Rousseau, an editor at digg.com, recently wrote a piece explaining how he tried Invisible Girlfriend for a joke, but ultimately ended up finding some small amount of meaning therein: \"a text from a stranger, comforting another stranger.\" And how strange it is that despite all the connections that social media facilitates, we can find ourselves looking to strangers sitting at computers to reassure us that someone is out there. Even if it's only to talk about the weather.\n"},
{"docid": "253 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "March 16, 2017", "title": "The singularity: AI will make humans sexier and funnier, says Google expert; 'We're going to expand our minds and exemplify these artistic qualities that we value'\n", "content": "The much-heralded technological singularity will happen in 2029, according to Google's director of engineering.\nRay Kurzweil, a futurist who has made a name for himself through his predictions, shared his thoughts about what's in store for humans and machines in an interview with SXSW in Texas.\u00a0\nHe believes that the so-called singularity - the moment when artificial intelligence exceeds man's intellectual capacity and creates a runaway effect, which many believe will lead to the demise of the human race - is little over a decade away.\n\"By 2029, computers will have human-level intelligence,\" said Mr Kurzweil. \"That leads to computers having human intelligence, our putting them inside our brains, connecting them to the cloud, expanding who we are.\n\"Today, that's not just a future scenario. It's here, in part, and it's going to accelerate.\"\nHowever, unlike a number of famous experts, Mr Kurzweil isn't worried about artificial intelligence.\nTesla CEO Elon Musk recently warned that AI could make humans irrelevant, and called for humans to merge with machines in order to continue serving a purpose.\nMr Kurzweil, meanwhile, believes that machines will improve us, and even help us become better humans.\n\"What's actually happening is [machines] are powering all of us. They're making us smarter. They may not yet be inside our bodies, but, by the 2030s, we will connect our neocortex, the part of our brain where we do our thinking, to the cloud.\n\"We're going to get more neocortex, we're going to be funnier, we're going to be better at music. We're going to be sexier. We're really going to exemplify all the things that we value in humans to a greater degree.\"\nRead more\nThe rise of artificial intelligence risks making us all redundant\nStephen Hawking has gone further than Mr Musk, saying, \"You're probably not an evil ant-hater who steps on ants out of malice, but if you're in charge of a hydroelectric green energy project and there's an anthill in the region to be flooded, too bad for the ants. Let's not place humanity in the position of those ants.\"\nHe has also suggested that a \"world government\" could be used to control technological advancements.\n\"Ultimately, it will affect everything,\" Mr Kurzweil continued. \"We're going to be able to meet the physical needs of all humans. We're going to expand our minds and exemplify these artistic qualities that we value.\"\n"},
{"docid": "254 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "June 7, 2017", "title": "Apple's zeal for privacy is no help in the war on terror; Tech titan's plan to avoid holding information will please customers, but is bad for governments seeking intelligence, writes James Titcomb\n", "content": "You might have missed it amongst the deluge of glitzy gadget announcements Apple made on Monday night - a line of new computers, major updates to iOS and the HomePod smart speaker - but there was an important thread running through the two and a half hours of announcements Apple made: privacy.\nAlmost every new feature or product announcement seemed to be accompanied by a footnote about how users would be protected from prying eyes.\u00a0\n\"Intelligent tracking prevention\" in the Safari web browser will stop adverts from following users around the web. New artificial intelligence technologies will process personal data on the iPhone, instead of being sent to remote servers. Voice commands being processed by Siri on the HomePod speaker will be stripped of any personal identifying information, and use encryption.\nOur growing digital footprint - from smartphones that track our location, to internetconnected gadgets in our home fitted with cameras and microphones - means we are creating ever more sensitive data.\nMeanwhile, tech companies' growing investments in artificial intelligence requires them to upload huge piles of that data on to company servers for processing.\nFor anyone worried about privacy or security that's a problem: a cyber attack, a stolen password or a rogue employee might compromise personal data on a server hundreds of miles away, without you knowing, and make its way into the hands of cyber criminals.\nThere are two main ways tech companies can protect your data.\nOne is to make it as secure as possible when it reaches your servers, ensuring it is shielded by the strongest technical safeguards against attacks.\nThe other, much more effective way, is for them not to have that data in the first place. This is what Apple is doing.\nTake its approach to artificial intelligence. On Monday night Apple announced that app developers would have access to Apple's \"CoreML\" technology, which means machine learning algorithms will run on an iPhone itself, not by uploading a huge amount of information to a server somewhere.\nThis is a very different approach to most of the tech industry, and limits data to the device itself. For someone to get their hands on it, they would have to have physical access to the phone, and find a way to hack into it, instead of intercepting communications or opening up one of Apple's servers.\nWhen data does have to be sent to the cloud, such as when processing Siri requests, it will be encrypted and anonymised, almost eliminating the chance of snoopers tracking an individual. Even if Apple wanted your data, it couldn't get it.\nThis is good news for consumers - it keeps them safe from cyber attacks and online crime. But it could be bad news for the governments that are increasingly reliant on big tech companies for intelligence.\nGovernments routinely criticise internet giants for failing to help them with terror and other criminal investigations. But they oblige more often than not.\nApple's most recent transparency report shows in the second half of last year it provided account data in 154 of the 199 requests it received from the Government.\nBut if Apple doesn't collect this data in the first place - if it is anonymised, or doesn't exist on the Apple servers in the first place - it can't hand it over to the authorities.\nJust as WhatsApp's end-to-end encryption makes it impossible for it to hand over communications data to police, Apple would simply be incapable of handing over data that is protected in this way.\nTake an example from this year, when Amazon released user data gathered on its Amazon Echo speaker after authorities said it could be useful in a US murder trial.\nThe anonymisation of data on Apple's HomePod would presumably make it very difficult for Apple to do the same in such a scenario. At some point this could well cause a clash between Apple and security services.\nThere's no suggestion that Apple's privacy measures are intended to frustrate governments - its concern is with users' security - but it is inevitable that the two will rub up against one another.\nJust look at Apple's response to the Investigatory Powers Bill in 2015, which warned that sweeping new government powers would \"weaken security for hundreds of millions of law-abiding customers\", and strongly criticised the prospect of breaking encryption.\nThis week, Theresa May has once again attacked the tech industry for providing \"safe spaces\" online, and the Home Secretary Amber Rudd repeated calls for encryption to be limited. New powers to force tech companies to disclose data may be on the horizon - powers that are likely to be opposed by the companies who will claim it puts innocent users at risk.\nYesterday, Apple revealed that the safest way to address this is not to keep that data at all.\nIt is a commitment to privacy that should be celebrated - but it may not be cheered inside Number 10.\n'If Apple doesn't collect this data in the first place, it can't hand it over to authorities'\n"},
{"docid": "255 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "November 12, 2012", "title": "Professor Maria Petrou; Obituaries Expert in artificial intelligence and imaging who inspired the search for a robot which could do the ironing\n", "content": "PROFESSOR MARIA PETROU, who has died of cancer aged 59, was an expert in artificial intelligence and imaging - the art of designing robots to make sense of the vast and ever-increasing amounts of visual data delivered by modern technology. She also sparked a race to design a robot that can do the ironing.\n  Machines - whether satellites orbiting the Earth beaming back pictures of our planet, or medical scanners used for routine screenings such as mammograms - now generate huge quantities of material for analysis. But the volume of data to process far exceeds the human resources available to analyse it. Maria Petrou addressed this problem by developing automatic processes to evaluate the vast quantities of image data.\u00a0\n  Such advances enabled her to plot the regeneration of forests (or, by contrast, the desertification) that followed wildfires in her native Greece. They also allowed automated systems to flag up potential abnormalities in routine medical scans, sparing diagnosticians the effort of trawling through thousands of images of healthy patients.\n  Maria Petrou was born in Thessaloniki on May 17 1953 to Konstantinos and Dionisia Petrou, and quickly displayed an aptitude for science. She studied Physics at the University of Thessaloniki, scoring the country's highest mark in her entrance exam, before moving to Cambridge to complete her doctorate.\n  She began her academic career in 1981 as a lecturer in Astrophysics at the Kapodistrian University of Athens. Then, in 1983, she followed her husband, a British astronomer, back to England, where she began work in Oxford as postdoctoral research assistant in the department of Theoretical Physics. But she soon found that new political winds were blowing though academia.\n  \"Mrs Thatcher came into power,\" explained Maria Petrou. \"She changed things. She said: 'We don't want so many astronomers, we need engineers to catch up with the new revolution in artificial intelligence, image processing and so on.' So I had to change direction.\"\n  As a result Maria Petrou began an academic migration towards research in robotic vision and remote sensing, spending a year at the Geography department of Reading University and then at the Rutherford Appleton Laboratory before joining, in 1988, the Department of Electronic and Electrical Engineering at Surrey University, where she was appointed Professor of Image Analysis in 1998.\n  Throughout her career in this field, Maria Petrou was interested in improving the ability of robots and computers to cull important information from raw data, detecting patterns, and overcoming difficulties associated with textures in images. She is noted for her development of a completely novel type of image representation known as trace transform. This allowed her to manipulate, compare and identify 2-D images by scale or rotation - allowing significant breakthroughs in, for example, face-recognition software.\n  She developed advanced techniques for edge and line detection, for texture analysis and for image segmentation, and was a specialist in colour image processing, even developing an award-winning stereo-based 3-D measurement system for the stone industry.\n  Maria Petrou contributed to a host of professional bodies and journals and was elected a Fellow of the Royal Academy of Engineering in 2004.\n  Her books include Image Processing: The Fundamentals (with Panagiota Bosdogianni, 1999) and Image Processing: Dealing with Texture (with Pedro Sevilla, 2006)  she was joint editor in 2008 of Next Generation Artificial Vision Systems: Reverse Engineering The Human Visual System.\n  She had a well-developed sense of humour. On her personal webpage at Imperial College she noted that glass ceilings made life hard for career women. \"It is the characteristic of glass to be invisible,\" she said. \"You do not know that the glass ceiling is there until you hit it. Occasionally you may get a glimpse of its existence by the blood and guts splashed on it of the person who hit it before you.\"\n  She enjoyed drawing cartoons, and once set a challenge for her peers to create a robot capable of doing the ironing to the standards set by her great-aunt.\n  The \"ironing robot challenge\" was established after the great-aunt came across a news report of a robot football world cup. \"Trust men to develop something totally useless,\" the great-aunt sighed. \"Why can't they develop something really useful, like an ironing robot?\"\nThis goal is now a three-year EU-funded project called CloPeMa (details of which can be found on http://clopema.sourceforge.net), which deals with the aspect of how a robot would handle and identify fabrics - the complexity being that clothes, unlike objects used in robotics thus far, do not retain their shape.\n  Maria Petrou's marriage was dissolved. She is survived by her son.\n  Professor Maria Petrou, born May 17 1953, died October 15 2012\n"},
{"docid": "256 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "November 30, 2017", "title": "Exoskeleton soldiers have the power of 27\n", "content": "An exoskeleton with artificial intelligence has been designed for the armed forces to give soldiers superhuman power and strength.\nThe technology developed by Lockheed Martin has been tested on US soldiers, allowing them to carry larger loads and travel further without tiring. The company claims that the Fortis exoskeleton increases a soldier's capabilities up to 27 times by lessening leg strain and giving support to the hips.\u00a0\nBen Barry, senior fellow in land warfare at the International Institute for Strategic Studies, said that the technology had huge potential for the UK military.\nA study by the University of Michigan Human Neuromechanics Laboratory found that people carrying a 18kg load uphill at a 15-degree angle while wearing the leg exoskeleton experienced significantly less leg strain.\nThe knee stress-release device increases leg capacity to allow lifting, the dragging of heavy objects and climbing hills. It has leg and hip supports and a motorised knee that uses artificial intelligence to produce synchronised movements for each individual. The entire fitting weighs 12kg and is powered by a 1.3kg rechargeable battery.\nThe equipment has been tested on Fort A.P. Hill in Virginia, one of the US's top military training centres. \"We've had this on some of the army's elite forces, and they were able to run with high agility carrying full loads,\" said Keith Maxwell of Lockheed Martin. \"By reducing the effort in walking and climbing, there's less fatigue. This tech-nology can literally help our fighting men and women go the extra mile.\"\nThe announcement comes amid a warning from a think tank that China is rushing to develop its own military artificial intelligence that could alter the world's balance of power. \"China is no longer in a position of technological inferiority relative to the US but rather has become a true peer that may have the capability to overtake the United States in AI,\" the report from Center for a New American Security said.\nIt is not known if the British Army has specified a desire for such technology to any defence companies but it has been interested in decreasing the weight soldiers have to carry in the past.\nHow it works\nIncreased leg capacity boosts lifting, dragging and climbing ability\n1 Exoskeleton is worn round hips via a belt that provides upper body support 3 Knee is motorised to produce synchronised movements\n2 Leg support gives strength to the femur\n"},
{"docid": "257 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "June 30, 2016", "title": "US air force has new top gun: a computer program\n", "content": "A computer has defeated a senior American military pilot in a simulated mid-air flight, highlighting the increasing role of artificial intelligence programs in battle.\u00a0\nResearchers at the University of Cincinnati teamed up with Psibernetix, a defence company, to design Alpha, an artificial intelligence program capable of replacing a human pilot. In one exercise Alpha successfully \"flew\" four fighter jets to defend a coastline against an attack by two enemy aircraft.\nIt also won a head-to-head fight against Colonel Gene Lee, a retired US air force officer who used to train combat pilots. Alpha was \"the most aggressive, responsive, dynamic and credible AI seen to date,\" he said.\n\"I was surprised at how aware and reactive it was - it seemed to be aware of my intentions and reacted instantly to my changes in flight and my missile deployment,\" he added. \"Until now, an AI opponent simply could not keep up.\"\nA technique called machine learning allows the computer to make sophisticated decisions and respond to new environments.\nAlpha was \"trained\" by analysing masses of data chosen by researchers.\nIt learns how to apply its algorithms to new situations it is presented with, but can do so faster than a human operator.\n\"If you look at the future, the aircraft won't have to host a human being,\" said Kelly Cohen, lead author of a research paper published in the Journal of Defense Management.\n\"We could end up with much more powerful planes that could change the course of military history.\"\n"},
{"docid": "258 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "November 2, 2011", "title": "Professor John McCarthy; Computer scientist who coined the term 'artificial intelligence' but dismissed the idea that robots should simulate human emotions\n", "content": "Professor John McCarthy was a US computer scientist credited with coining the term \"artificial intelligence\" in 1955 and inventing a computer language - Lisp - which became the standard code used by researchers in the AI field.\nMcCarthy became interested in the concept of artificial intelligence in 1948 when computers were giant \"difference engine\" machines used for wartime code-breaking. He believed, displaying an impressive leap of imagination, that all aspects of human intelligence could one day be simulated by machines.\nBut he did not believe that robots should ever be programmed to simulate human emotions and, later on in life, was rather scornful of science fiction films treating this as plausible or desirable. In a paper written in 1995 (and updated in 2002) - Making Robots Conscious of their Mental States - McCarthy argued that sufficiently intelligent robots would not automatically have emotions, as some scientists had posited, and that equipping them with human-like emotions would be a separate, difficult and unnecessary project.\u00a0\n\"It is ... practically important to avoid making robots that are reasonable targets for either human sympathy or dislike,\" he wrote. \"If robots are visibly sad, bored or angry, humans, starting with children, will react to them as persons. Then they would very likely come to occupy some status in human society. Human society is complicated enough already.\"\nCommenting on the 2001 Steven Spielberg film A. I., itself based on a science fiction short story by Brian Aldiss, McCarthy said: \"The movie ... illustrates one disadvantage of having robots with emotions or which elicit human emotions. Unless you make them really human they will not fit into human society. Better just make them suitable as a kind of tool. There is no more of the science of AI in the movie than there is in the Pinocchio story of more than 100 years ago. One should also not take seriously any of the ideas of the movie of what robots might really be like.\"\nHe was always keen to emphasise that simulating the behaviour associated with a human emotion was not the same as experiencing the emotion itself. In fact, although McCarthy's invention of the term AI undoubtedly helped to attract more people to the subject, he sometimes wished he had chosen the phrase Computational Intelligence instead, given the degree of misunderstanding that the term AI had generated.\nJohn McCarthy was born in 1927 in Boston, Massachusetts, to John Patrick McCarthy, an Irish immigrant, and Ida, a Lithuanian Jew. He went to high school in Los Angeles before undertaking a degree in mathematics at the California Institute of Technology in 1948, and a doctorate in the same discipline at Princeton University in 1951, where he began his professional academic career.\nIn 1953 he moved to Stanford University as acting assistant professor before switching to Dartmouth College, New Hampshire, as assistant professor of mathematics, two years later. It was while he was at Dartmouth that he organised the seminal conference in 1956, bringing together experts in a range of information technology disciplines and launching the subject of AI.\nHe then progressed to Massachusetts Institute of Technology (MIT) in 1958 as assistant professor of communication science, becoming associate professor in the discipline three years later. His paper, Programs with Common Sense, published in 1958 was the first to propose common-sense reasoning ability as the key to AI. And in 1960, while still at MIT, McCarthy wrote a paper outlining the principles of his LISP programming language, notable for relying on symbols rather than numbers as its main mode of expression. He finally achieved his professorship in 1962, moving to Stanford's Computer Science department, where he remained for the rest of his career. In his work McCarthy specialised in the formalisation of common-sense knowledge and reasoning and invented \"the circumscription method of non-monotonic reasoning\".\nHe also developed the concept of computer time-sharing - allowing multiple users to access the same machine at the same time.\nAfter his retirement in 2000 he remained Professor Emeritus of Computer Science at Stanford and kept up a website listing his academic papers, his thoughts on the future of robots, and even some of his fiction. One of his short stories, The Robot and the Baby, explored his ideas about what household robots might look like in the future and humanity's likely confusion in relation to them. But McCarthy was pragmatic enough to acknowledge that fully functioning, practically useful robots were still a long way off.\nHe won numerous awards and accolades throughout his long career, including the A. M. Turing award from the Association for Computing Machinery in 1971; the first Research Excellence Award of the International Joint Conference on Artificial Intelligence in 1985; the Kyoto Prize of the Inamori Foundation in 1988 and the National Medal of Science in 1990.\nHe was elected president of the American Association for Artificial Intelligence for 1983-84 and remained a Fellow of the organisation all his life. He also received several honorary degrees from other universities around the world.\nThroughout his career he combined academia with several long-held director positions in technology companies such as Information International, Inference Corporation and Mad Intelligent Systems.\nMcCarthy displayed a dry sense of humour, a sharp wit, and a tonguein-cheek curmudgeonly persona, affecting to despise the need to provide biographical information on more than one publicly accessible standardised web page. In fact he proposed a new civil right: \"No government agency, educational institution or business should ever be able to require anyone to supply a new information that the institution already has or is publicly available.\"\nA self-confessed atheist, McCarthy defended his position thus: \"To count oneself as an atheist one need not claim to have a proof that no gods exist. One need merely think that the evidence on the god question is in about the same state as the evidence on the werewolf question.\"\nHis humanism and rationalism contributed to his optimistic belief in technology and science as the bases for sustainable human development. He advocated a huge increase in the number of US nuclear reactors to wean people off fossil fuels, for example. He was dismissive of the organic food movement, branding it a \"superstition\"; he despaired of all alarmist media headlines about health and science, and even rejected the idea that global warming was a major threat to humanity.\nHe is survived by his third wife, Carolyn, and by two daughters and a son.\nJohn McCarthy, computer scientist, was born on September 4, 1927. He died on October 24, 2011, aged 84\nHe believed that human development lay in technology and science\n"},
{"docid": "259 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "May 4, 2016", "title": "Google given access to healthcare data of up to 1.6 million patients; Artificial intelligence firm DeepMind provided with patient information as part of agreement with Royal Free NHS trust\n", "content": "A company owned by Google has been given access to the healthcare data of up to 1.6 million patients from three hospitals run by a major London NHS trust.\u00a0\nDeepMind, the tech giant's London-based company most famous for its innovative use of artificial intelligence, is being provided with the patient information as part of an agreement with the Royal Free NHS trust, which runs the Barnet, Chase Farm and Royal Free hospitals.\nIt includes information about people who are HIV-positive as well as details of drug overdoses, abortions and patient data from the past five years, according to a report by the New Scientist.\n                     DeepMind announced in February  that it was developing a software in partnership with NHS hospitals to alert staff to patients at risk of deterioration and death through kidney failure.\nThe technology, which is run through a smartphone app, has the support of Lord Darzi, a surgeon and former health minister who is director of the Institute of Global Health Innovation at Imperial College London.\nHowever, the agreement on patient record sharing has caused concern among those who have already been concerned about Google's moves in the healthcare sector.\nA spokesperson for the Royal Free said patients would not be aware that data was being made available but it was encrypted and such an arrangement was standard practice.\n Related:  The superhero of artificial intelligence: can this genius keep it in check?\nIt said: \"Our arrangement with DeepMind is the standard NHS information-sharing agreement set out by NHS England's corporate information governance department and is the same as the other 1,500 agreements with third-party organisations that process NHS patient data.\n\"As with all information sharing agreements with non-NHS organisations, patients can opt out of any data-sharing system by contacting the trust's data protection officer.\"\nSam Smith, of the health data privacy group MedConfidential, told the New Scientist: \"This is not just about kidney function. They're getting the full data. \n\"What DeepMind is trying to do is build a generic algorithm that can do this for anything - anything you can do a test for. The big question is why they want it. This is a very rich data set. If you are someone who went to the A&E department, why is your data in this?\"\nDominic King, a senior scientist at Google DeepMind, told the BBC that access to timely and relevant clinical data was essential for doctors and nurses.\n\"This work focuses on acute kidney injuries that contribute to 40,000 deaths a year in the UK, many of which are preventable,\" he said.\n\"The kidney specialists who have led this work are confident that the alerts our system generates will transform outcomes for their patients. For us to generate these alerts it is necessary for us to look at a range of tests taken at different time intervals.\"\n"},
{"docid": "260 of 500 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "November 7, 1984", "title": "Robot coach for runners / Introduction of artificial intelligence to the home computer\n", "content": "\u00a0\n A personal robot athletics coach has been created through the introduction of artificial intelligence to the home computer.\n The idea has come from a group of nurses in Silicon Valley, California, who are also 'knowledge engineers,' that new breed of computer software writers who concoct artificial intelligence programs.\u00a0\n\n With the aid of Dr Joan Ullyot, a general practitioner and marathon runner, they have written a program to guide the novice from the jogger stage to the racing stage.\n Their program is a primitive form of expert system. That is the technique whereby a computer can provide professional advice through gathering, codifying, then applying the accumulated experience of the human specialist.\n In this case, you tell the home computer your aims, running experience, age, sex, weight, and what daily time you can spend in training - and what your pulse rate is after a short trial run.\n The computer will then offer you personal training advice, amended day by day depending on your progress. The computer will also store and check your results and the changes in you weight and pulse rates.\n The program, written to run on Apple machines, is sold in Britain by P & P Micro. Their sales manager, Mr Paul Whitney, said yesterday that he had not run the program himself, but he was sure from his experience with its Californian producers - Software Publishing - that all the necessary medical precautions were included.\n Software Publishing themselves said the program did include catch points, both at the start and as the coaching progressed, so that if your reactions did not match the norm you were advised to consult doctor before plunging on.\n"},
{"docid": "261 of 500 DOCUMENTS\n", "source": "The Independent - Daily Edition\n", "date": "February 8, 2018", "title": "When artificial intelligence is used in healthcare, patients will need greater protections\n", "content": "For Elon Musk, the term artificial intelligence conjures apocalyptic scenarios of autonomous robots wreaking destruction in a world dominated by hyper-intelligent machines. Stephen Hawking foresees a future in which smart machines replace sluggish humans across a range of activities, driving millions out of work. Last month Bill Gates, speaking at the World Economic Forum in Davos, imagined a gentler future - one with longer holidays and more free time.\n\"The purpose of humanity is not just to sit behind a counter and sell things,\" he said.\u00a0\nWe can all speculate about the future. Will.i.am, the Black Eyed Peas singer, has been promoting his first novel this week, an action adventure called WaR: Wizards and Robots. Despite its title, he told an audience in Davos last month that artificial intelligence would be a force for good, narrowing the wealth gap between rich and poor countries.\nWe must hope it can also narrow the health gap. Healthcare provides especially fertile territory for these advances because of the sheer volume of medical knowledge. No clinician, however smart, can hope to master it. McKinsey has estimated potential savings of up to $100bn (\u00a372bn) in the US Healthcare sector alone from developments in artificial intelligence. The aim is not to replace the doctor (yet, at least) but to enhance their medical expertise.\nAt the same time, treatment can be democratised and spread equally to all. Why rely on one doctor's opinion when you can share thousands, culled from databases of their knowledge and the key studies they rely on? Rural dwellers, living far from medical facilities, may be able to enjoy the same level of expertise as their urban counterparts and, ultimately, those in low income countries may benefit from the same expert input as those in the industrialised world.\nSupporting doctors to diagnose disease is a key area of research. Mobile apps to help patients track changes in their health and respond appropriately are bringing quicker treatment and lower costs. Employing machine learning to identify new chemical agents is speeding up drug development and shaping clinical research.\nTo reap these benefits, however, scientists need access to data. Data is as vital to machine learning as coal was to the railways and oil to the motorcar. However, the potential for abuse of data is real.\nAs a surgeon and researcher I was dismayed by the revelations last month that William E Wecker Associates, a company working for the tobacco industry, obtained the lung cancer records of almost 180,000 patients from Public Health England.\nThe NHS has a unique store of millions of medical records providing an unparalleled resource from which, with the use of digital techniques, we may speed progress to the next breakthroughs in medical science and transform care. That such a uniquely valuable resource should now be plundered on behalf of a tobacco manufacturer seeking to defend their cancer-causing products is simply shameful.\nIt remains unclear whether any rules were broken by the company in question, which has testified on behalf of tobacco giants in dozens of lawsuits. Or indeed by Public Health England, which maintains it was under a legal duty to release the information when it was requested under the Freedom of Information Act.\nBut our failure to protect our medical data from misuse is symptomatic of a wider malaise - our failure to value it. Incidents such as these undermine patients' trust and set back the cause of research.\nThe challenge, then, is to devise a system of data governance that protects the interests of patients, provides access for researchers, distributes the fruits of success fairly and wins the confidence of the public. If we are to generate the growth that these innovations could deliver we need to demonstrate why data sharing is a social benefit, as necessary to the public good as taxes.\nThe Government published its industrial strategy in November 2017 in which it set out a plan to create an Artificial Intelligence Council and a Centre for Data Ethics and Innovation, demonstrating its commitment to an ethical approach.\nThis is welcome but we need to go further. Public trust demands more transparency. We need a health specific data charter, with clear rules, norms and standards, setting out what can be done, what should be done and what may not be done.\nThere are huge opportunities in these technologies to advance healthcare, benefit health systems and improve the outlook for millions of patients. But unless we establish clear rules from the outset we risk sacrificing public trust, surrendering vital clinical gains and squandering the potential in the vast quantities of medical data we have spent decades accumulating.\nLord Darzi of Denham is a surgeon and director of the Institute of Global Health Innovation at Imperial College London. He was a Labour health minister from 2007-09\n"},
{"docid": "262 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "September 13, 2017", "title": "Technology will cut 30% of banking jobs says former Citigroup CEO Vikram Pandit; Artificial intelligence and robotics reduce the need for staff in roles such as back-office functions, Mr Panditsaid\n", "content": "Vikram Pandit, who ran Citigroup during the financial crisis, has said developments in technology could cut the number of banking jobs by 30 per centin the next five years.\n                     Artificial\u00a0intelligence and robotics reduce the need for staff in roles such as back-office functions, Mr Panditsaid on Wednesday in an interview with Bloomberg in Singapore. He's now chief executiveof Orogen Group, an investment firm that he co-founded last year.\u00a0\n\"Everything that happens with artificial\u00a0intelligence, robotics and natural language - all of that is going to make processes easier,\" said Mr Pandit, who was Citigroup's chief executivefrom 2007 to 2012. \"It's going to change the back office.\"\nRead more\nRobocars to patrol Dubai's streets by the end of the year\nWall Street's biggest firms are using technologies including machine learning and cloud computing to automate their operations, forcing many employees to adapt or find new positions. Bank of America's chief operatingofficer Tom Montag said in June the firm will keep cutting costs by finding more ways for technology toreplace people.\nWhile Mr Pandit's forecast for job losses is in step with one made by Citigroup last year, his timeline is more aggressive. In a March 2016 report, the lender estimated a 30 per cent reduction between 2015 and 2025, mainly due to automation in retail banking. That would see full-time jobs drop by 770,000 in the US and by about onemillion in Europe, Citigroup said.\n                     JPMorgan chief executive Jamie Dimon cautioned in June against overreacting to the impact of technology on jobs. While the bank is using technology to reduce costs, that helps create other opportunities, Mr Dimon said. He predicted that employee numbers at his firm will continue to rise - as it hires more technology workers.\nThe banking industry is becoming \"enormously competitive\", Mr Pandit said, adding that he foresees the emergence of \"specialist providers\" as well as consolidation in the industry.\n\"I see a banking world going from large financial institutions to one that's a little bit more decentralised,\" he said.\nSince leaving Citigroup, Mr Pandit has invested in non-bank financial startups such as student-loan venture CommonBondand home equity finance firm Point Digital Finance. He formed New York-based Orogen last year with investment firm Atairos Group to acquire stakes in mature financial-services companies.\nBloomberg\n"},
{"docid": "263 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "November 13, 2017", "title": "Killer robots must be banned but 'window to act is closing fast', AI expert warns; 'Allowing machines to choose to kill humans will be devastating to our security and freedom'\n", "content": "Artificial\u00a0intelligence experts are calling for a ban on \"killer robots\", and havewarned that we need to move quickly.\nThe Campaign to Stop Killer Robots has released a short film designed to demonstrate what could happen if machines that are capable of choosing who lives and who dies continue to be developed.\u00a0\nIn the video, autonomous weapons are used to carry out mass killings with frightening efficiency, while people struggle to work out how to combat them.\nIt also depicts swarms of smart drones, which are equipped with explosives and use facial recognition, GPS, voting and social media data to establish and pursue targets.\n\"[Artificial\u00a0intelligence's] potential to benefit humanity is enormous, even in defense,\" says Stuart Russell, a professor of computer science at the University of Berkeley, at the end of the film.\n\"But allowing machines to choose to kill humans will be devastating to our security and freedom. Thousands of my fellow researchers agree. We have an opportunity to prevent the future you just saw, but the window to act is closing fast.\"\nThe film was produced in partnership with the Future of Life Institute, to be shown today at the United Nations Convention on Conventional Weapons.\nLast week, hundreds of AI experts urged the Canadian and Australian governments to treat autonomous weapons, such as drones, military robots and unmanned vehicles, in the same way as chemical biological and nuclear weapons.\nRead more\nRobots are going to make England's north-south divide even worse\nThey argue that delegating life-or-death decisions to machines crosses a moral line, and must not be allowed to happen.\n\"It's not the Terminator that experts in AI and robotics like myself are worried about but much simpler technologies currently under development, and only a few years away from deployment,\" said Toby Walsh, Scientia Professor of AI at UNSW Sydney.\n\"Without a ban, there will be an arms race to develop increasingly capable autonomous weapons. These will be weapons of mass destruction. One programmer will be able to control a whole army.\"\n"},
{"docid": "264 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "January 27, 2017", "title": "Samsung Galaxy S8 will include AI virtual assistant, confirms LinkedIn job posting; The company has confirmed that AI-powered software and services will form an integral part of its strategy for growth in the smartphone market\n", "content": "Samsung has all but confirmed that its next flagship smartphone will feature an artificial intelligence assistant.\nThe company has posted a vacancy on LinkedIn, for a Principal Program Manager who would be responsible for driving \"the execution and delivery of Samsung's upcoming AI (Artificial Intelligence) assistant on the Galaxy S8.\"\u00a0\nThough tech companies aren't averse to teasing the industry with misleading information ahead of major launches, the professional network isn't where you'd typically expect to find such a red herring.\nThe company also said that AI-powered software and services would form an integral part of its strategy for growth in the smartphone market in its Q4 2017 earnings release.\nSamsung Galaxy S8: Guess this pretty much confirms the AI assistant. (from LinkedIn) pic.twitter.com/OmoZX58CFV\n- Roland Quandt (@rquandt) 27 January 2017\nPatent filings have suggested that Samsung's AI assistant will be called Bixby.\nIt's expected to be able to recognise real-world objects through the Galaxy S8's camera and track them down online, allowing users to make quick purchases.\nRead more\nPolice request man's Amazon data as part of murder trial\nBixby will reportedly also use optical character recognition to process any text within the phone's camera frame, and control all of the handset's native apps..\nThe company will definitely not launch the S8 at Mobile World Congress next month, but the smartphone is likely to go on sale in late April.\nBixby aside, one if its purported key features is the \"infinity display\", which is said to cover the vast majority of the smartphone's front face, leaving no room for a home button, fingerprint scanner or even Samsung's logo.\n"},
{"docid": "265 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "July 5, 2005", "title": " Robert Milne\n", "content": "\u00a0\n Robert Milne, artificial intelligence entrepreneur, was born on July 13, 1956. He died on Everest on June 5, 2005, aged 48.\n Mountain-climbing entrepreneur who set new limits in artificial intelligence and summit-bagging.\u00a0\n ROB MILNE earned international respect for his innovative work in adapting artificial intelligence (AI) as a practical aid to industry and in bridging the gap between the research laboratory and the factory floor.\n The company he founded at Livingston near Edinburgh, at the heart of the \"Silicon Glen\", reversed the initials AI to create Intelligent Applications. The projects and software it produced won many awards for innovation and excellence.\n Milne's devotion to computer technology was matched by a love of mountains and the physical achievement of reaching the highest summits. He was within 1,200ft of the top of Everest, and of joining an elite group of mountaineers who have climbed the highest summits on seven continents, when he died from a heart attack.\n Robert William Milne was born in Libby, Montana, in 1956. He took a BSc in electrical engineering and computer science from the Massachusetts Institute of Technology in 1978 and a PhD in AI at Edinburgh University in 1983. He then spent four years with the US military, first as an assistant professor at the USAF Institute of Technology and then as chief scientist of the Army AI centre at the Pentagon.\n Returning to Scotland with dual nationality, Milne focused on new products for Intelligent Applications and encouraging links between academia, industry and the research lab. He became director of ScotlandIS, the trade body for the information and communications technologies and software companies in Scotland. He led the development of his company's product, Tiger, a gas turbine monitoring system, which in turn led to the takeover of Intelligent Applications by a leading gas turbine company.\n Success under Milne's astute leadership was recognised with the Queen's Award for Technology, the DTI Manufacturing Intelligence Competition, the Small Firms Merit Award, the IT Europe Award and the Small Firms Access to Europe Competition Export Award.\n For many years Milne was an active member of the British Computer Society's expert systems specialist group, chairing conferences and acting as a mentor to new IT entrepreneurs. In 2003 he was elected a fellow of the Royal Society of Edinburgh.\n Alongside his professional activity, mountaineering continued apace. He \"bagged\" the 276 Scottish Munros -mountains more than 3,000ft (914.4m) high. He became a senior figure in the Scottish Mountaineering Club and edited The Corbetts and Other Scottish Hills (2002) about that lower league of Scottish hills whose summits are lower than a Munro but higher than 2,500ft (762m).\n Summit bagging took him around the world to Antarctica, Russia, Alaska and ultimately to Nepal and Everest.\n The expedition he joined at Everest was delayed by severe weather on the mountain where Milne, with typical enthusiasm, was carrying out field trials of an AI system providing monitoring support to climbers and explorers in an extreme environment.\n As the bad conditions continued Milne wrote in his weblog of a \"strong feeling of despair\" among the climbers.\n He is survived by his wife, Valerie, a son and a daughter.\n\n"},
{"docid": "266 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "July 19, 2017", "title": "New sex robots with 'frigid' settings allow men to simulate rape; According to the company's website, if you touch the 'Frigid Farrah' model in a 'private area, more than likely, she will not be to appreciative of your advance.'\n", "content": "It seems a new frontier has been reached in the fast-paced world of Artificial Intelligence, but asfast as technology is able to advance, it can still be reproached formoral retrogression.\nThis has been the subject of debate after therecentadvertisement of 'Roxxxy TrueCompanion',a robot you can buy and simulate rapingwitha simple switch in setting.\nOne of theprogrammable personalities for the robot is 'Frigid Farrah', described as \"reserved and shy\" onthe TrueCompanioncompanywebsite. Like 'Wild Wendy' and 'S & M Susan' whose characteristics are self-ascribed, the website says that for Frigid Farrah, if you touch her \"in a private area, more than likely, she will not be to appreciative of your advance.\"\u00a0\nIn the website's description, themodellacks anattempt to reproduceconsent in the real worldand thecompany say that theirrobots \"allow everyone to realise their most private sexual dreams.\"\nRead more\nSuicidal robot security guard drowns itself by driving into pond\nAnotherprogrammed personality that has been heavily criticisedis that of 'Young Yoko' who is described by the website as: \"oh so young (barely 18) and waiting for you to teach her.\"\nRoxxxy is the 9th version of the company's sex robots after they developed their first 'Trudy' in the 1990s and the trade in sex robots has already caught on. \nThe New York Times \nreports that a California-based company 'Abyss Creations' annually ships up to 600 hyper-realistic sex dolls worldwide.\nA newreport from the Foundation for Responsible Roboticsalso warns of the numerous ethical implications in our sexual future with robots.\n\"We found that there were a bunch of companies making these and beginning to ship orders and we thought that we should really look at it,\" said co-author of the report and AI Professor Noel Sharkey addressing journalists on Tuesday.\nRead more\nAI better than scientists at choosing successful IVF embryos\nOne of Google's Top Scientists Shares Artificial Intelligence's Toughest Challenge It Must Overcome\nArtificial intelligence is learning to be racist\nAsurvey published by UK innovation company Nesta last June,found that over a quarter of young people surveyed would happily date a robot.\nProf Sharkey launched the Foundation 18 months ago in order to explorecontroversial areas such asthe questions surroundinghowrobots can impact sex crimes.\n\"Some people say it's better they rape robots than rape real people. There are other people saying this would just encourage rapists more,\" Prof Sharkey explained.\n\"Robots don't have any kind of emotion themselves. People bond with robots but it's very one way. You're loving an artefact that can't love you back and that's what's sad about it,\" Prof Sharkey added.\nLaura Bates, campaigner and founder of the Everyday Sexism Project, condemned the Frigid Farrahproductin the \n                     New York Times                   \nwriting:\"rape is not an act of sexual passion. It is a violent crime.\"\n\"We should no more be encouraging rapists to find a supposedly safe outlet for it than we should facilitate murderers by giving them realistic, blood-spurting dummies to stab,\" Ms Bates added.\nThe True Companion robots raise the issue of therepercussions ofnormalisingsexual crime. In Ms Bate's view, the company's products muddyand worsenthe still much-misunderstood areaof consent.\nA representative from True Companion told \nThe Independent\n: \"We absolutely agree with Laura Bates...Roxxxyis simply not programmed to participate in a rape scenario and the fact that she is, is pure conjecture on the part of others.\"\n\"You would not immediately passionately kiss a person that you just met on your first date. Likewise, Frigid Farrahwould also tell you that she just met you if you try to 'move' too quickly,\" the company's representative said.\n\"Rape simply isn't an interaction that Roxxxysupports, nor is it something that our customers are requesting,\" the representative added.\nBy contrast, Ms Bates wrote:\"Their creators are selling far more than an inanimate sex aid. They are effectively reproducing real women, complete with everything, except autonomy.\"\n"},
{"docid": "267 of 500 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "June 18, 1992", "title": "*\n", "content": "\u00a0\n QSUB:ISAAC ASIMOV may be dead, but he still has a lot to answer for. Mention the word \"robot\" and most people still think of a humanoid, metal bodied creature with an electronic brain, capable of human-like interactions with the real world. Although the humanoid body shape is almost entirely a product of science fiction, efforts to develop artificial intelligence have suffered for decades from the idea that \"human\" intelligence is the only kind worth bothering about, and that an artificial intelligence should be able to interact with a wide variety of environments in as versatile a manner as we do.\n QSUB: But since the mid-1980s this approach has been challenged by the initially almost heretical suggestion that the right way to approach the problem is not from the \"top down\" (using ourselves as the archetype) but from the \"bottom up\", designing simple machines that perform specified tasks very well, and then adding these specialities together to make more complex systems.\u00a0\n QSUB: In less than 10 years, this approach has gone from being a maverick minority viewpoint to one of the most promising lines of attack on the problem of creating real robots. One centre of such research is the School of Cognitive and Computing Sciences at Sussex, where Dave Cliff is a lecturer in computer science and artificial intelligence. His interest is in vision, the way we perceive the world and how the brain uses the information fed to it by the eyes. But rather than trying to mimic human vision and cognition in the computer, he models the way in which an insect, the hoverfly Syritta pipiens, interacts with the world.\n QSUB: This creature has two eyes, like ourselves, and it shares with us the \"foveal\" image system, where only part of the field of view is sharply imaged and the focus of attention, and the eyes scan the view in search of interesting - or threatening - objects. Computer scientists working on global imaging systems in which an artificial intelligence tries to give equal importance to everything in the field of view run into huge problems of coping with all the information, and have recently reinvented what amounts to foveal systems; but nature got there first.\n QSUB: Like all living things, the life of the hoverfly revolves around survival and production. The basic biological imperatives are sometimes referred to as the \"4Fs\": fleeing, fighting, feeding and fornification. The last of these is what matters most to the male hoverfly, and which is partly modelled by Cliff's computer simulations.\n QSUB: So far, Cliff has not build a real robot that mimics the behaviour of the hoverfly. Instead, the computer simulation of the fly's vision and its response to a \"target\" which moves like a female hoverfly operates within another computer simulation - what is now called a \"virtual reality\".\n QSUB: The computer creates a simulated world in which female\n QSUB:hoverflies fly around, and the simulation of the male hoverfly looks for females and approaches them with care. The resulting flight path of the simulated male fly is very much like those of the real thing, cautiously approaching the females and lurking just out of range of her inferior eyes, ready to pounce when the time is ripe (no, the simulation does not include the pouncing).\n QSUB: At one level, this work is telling researchers how to design the systems that will be built in to genuine robot \"insects\". This is the next step for Cliff's work, since most of the computer time in his simulations is now taken up be creating the artificial reality for his simulated flies to move in. The real world, he says, is a much cheaper and more convenient source of input, provided you have real robots to use the input.\n Rodney Brooks, a pioneer of this kind of work at MIT, has already constructed simple-minded robots along similar lines, including one that can roam the corridors of a building, avoiding obstacles and people, and collecting up soft drink cans that it finds lying about.\n But there is another aspect to this work, which may provide insights into the way intelligence has evolved in the biological world. On earth, evolution has proceeded from simple systems to more complex ones, and it is arguable that our kind of intelligence has emerged naturally as a result of increasing complexity, with more and more systems working together.\n At present even a simple robot using the hoverfly \"intelligence\" developed by Cliff would have to be wired up to a sizeable computer, which is one reason why these models have been developed in a virtual world. But as the size and cost of the hardware keeps coming down, he sees the possibility of fully mobile, self-contained robots of this kind within 10 years, and intends to be ready with the software to make those robots run as soon as the cheap computer hardware is available.\n Such robots would be restricted to specific tasks, but within their limits they would act intelligently, avoiding danger and keeping out from underfoot.  Collecting empty soft drink cans is a first small step; \"bugs\" that creep in all the nooks and crannies of your room to gather up dust and dump it in a central tip are another possibility, while Brooks of MIT has suggested that a colony of tiny robots might live on your TV screen, getting their energy from the electrons in the beam that paints the picture, and quietly going about the task of keeping the screen clean.\n It's a far cry from the kind of intelligence represented by a chess playing humanoid robot that can also wash the dishes and mend a fuse. But as Brooks points out, it is unfair to claim that an elephant has no intelligence worth studying just because it does not play chess.\n Hoverflies don't play chess, either; but Cliff and his colleagues are convinced that by studying the flight of simulated hoverflies within a computer generated virtual reality they can learn things about the way brains in general (including our own brains) work. And they are also pointing the way to a world of robotic servants based not on Asimovian humanoids but on insects. Perhaps it's just as well that Asimov hasn't lived to see it.\n"},
{"docid": "268 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "September 4, 2017", "title": "Elon Musk says AI could lead to third world war; North Korea 'low on our list of concerns' says Tesla boss following Putin's statement that whoever leads in AI will rule world\n", "content": "Elon Musk has said again that artificial intelligence could be humanity's greatest existential threat, this time through the starting of the third world war.\nThe prospect clearly weighs heavily on Musk's mind as the SpaceX, Tesla and Boring Company chief tweeted at 2.33am San Francisco time about how AI could led to the end of the world without the need for the singularity.\u00a0\n China, Russia, soon all countries w strong computer science. Competition for AI superiority at national level most likely cause of WW3 imo.- Elon Musk (@elonmusk) September 4, 2017\nHis fears were prompted by a statement from Vladimir Putin that \"artificial intelligence is the future, not only for Russia, but for all humankind ... It comes with colossal opportunities, but also threats that are difficult to predict. Whoever becomes the leader in this sphere will become the ruler of the world.\"\nHashing out his thoughts in public, Musk clarified that he was not just concerned about the prospect of a world leader starting the war, but also of an overcautious AI deciding \"that a [pre-emptive] strike is [the] most probable path to victory\".\nHe's less worried about North Korea's increasingly bold nuclear ambitions, arguing that the result for Pyongyang if they launched a nuclear missile \"would be suicide\" - and that it doesn't have any entanglements that would lead to a world war even if it did. His view is that AI is \"vastly more risky\" than the Kim Jong-un-led country.\nMusk's fear of AI warfare has been a driving force in his public statements for a long time. Last month, he was one of more than 100 signatories calling for a UN-led ban of lethal autonomous weapons.\n\"Once developed, lethal autonomous weapons will permit armed conflict to be fought at a scale greater than ever, and at timescales faster than humans can comprehend,\" the letter read. \"These can be weapons of terror, weapons that despots and terrorists use against innocent populations, and weapons hacked to behave in undesirable ways.\n\"We do not have long to act. Once this Pandora's box is opened, it will be hard to close.\"\n\n"},
{"docid": "269 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "July 20, 2016", "title": "Google cut its electricity bill by 40pc using artificial intelligence\n", "content": "Google is using artificial intelligence to reduce\u00a0the amount of\u00a0energy it uses to cool its immense data centres.\nThe energy consumed at the\u00a0centres, a maze of cables, pipes and servers \u00a0where Google processes all of the information consumed by its users, could account for as much as 2 per cent of the world's total greenhouse gas emissions. Using machine learning, the search giant said it has managed to reduce the energy used to cool them by as much as 40 per cent.\u00a0\u00a0\nWater vapour streams from cooling towers at a Google data centre called The Dalles in Orgeon.Credit:      Google     \nThe technology created at DeepMind, the Cambridge-based\u00a0artificial intelligence company acquired by Google in 2014,\u00a0uses machine learning to understand the environment at the centres and make them more efficient.\nFor two years an\u00a0AI has been analysing a wealth of data from thousands of sensors at the centres, including temperature, weather, power, and pump speeds. It has also looked at how the centres run and how the equipment powering them interacts with the environment.\u00a0\u00a0\nGoogle said\u00a0DeepMind's software reduced total energy use at the centres, of which Google has 12 across the Americas, Europe and Asia,\u00a0by 15 per cent. The company\u00a0claims responsibility for 0.01 per cent of global electricity use.\u00a0\nThe following graph is from a \"typical\" test day, according to Google. The drop on the graph reflects the time when Google switched the machine learning control on:\u00a0\nPUE stands for Power Usage Effectiveness, and is the ratio of total building energy usage to IT energy usageCredit:      Google     \nGoogle said it now gets\u00a0 3.5 times as much computing power out of the same amount of energy as it did five years ago thanks to\u00a0custom-built servers, more efficient cooling systems that\u00a0use\u00a0outside air, and investment in green energy.\nThe company wants to cap its increase in\u00a0energy use at 4 per cent a year between 2014 and 2020 even as data use grows at a faster rate.\u00a0\nIt also plans\u00a0to be 100 per cent powered by renewable energy. But it hasn't said when it will reach that\u00a0goal, or how much of its power currently comes from renewable sources.\nThe data centre algorithm can eventually be used to improve efficiency in other areas, according to Google, including\u00a0getting\u00a0more energy from the same amount of input at power plants, and reducing\u00a0energy and water usage in semiconductor manufacturing.\nSeparate companies that run on Google's cloud will also benefit from improved efficiency at the centres, the search giant said.\u00a0\u00a0\nFollow the latest Telegraph Technology newsREAD MORE ABOUT:\n"},
{"docid": "270 of 500 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "September 1, 2000", "title": "Leading article: They are not taking over: Robots are not going to boss us. Not yet\n", "content": "\u00a0\n Box office hits such as Terminator, Robocop and Blade Runner have all played on fears of robotic intelligence running amok and mastering their human creators. In two separate developments yesterday, the nightmare appeared to inch closer to realisation. Research published in Nature claimed to have made the first steps towards \"artificial evolution\" - by which robots are able to mutate and reproduce themselves - at Brandeis University in the US. In Bangkok, a security device was revealed which could be controlled through the internet: a robot primed to fire a gun when sensors detect an intruder. The reality is much more mundane. Self-replicating robots are still decades away; the Brandeis robot requires an element of human intervention in its construction. As for gun-toting robotic security guards, experts are sceptical; sensor technology is famously erratic and the notion of control by the internet is absurd, given the net's time delay.\u00a0\n We have a great taste for robots - both the facts and the fiction. Robot Wars, the DIY build a robot in your garage craze, has been a surprise hit on television, notching up impressive ratings to watch Dead Metal, Sir Killalot and Shunt put \"the scrap back into metal\". But on any sober assessment this branch of scientific research faces huge limitations. Yes, it is useful when given a very narrow, specific remit and has been used in everyday appliances such as washing machines. It might prove useful in electronic commerce, where considerable research is now being done on \"intelligent agents\", software able to negotiate with suppliers. But there is still a major obstacle to its application in many fields - it cannot deal with unpredictability. That limits its uses in medicine, for example, and ensures its reliance on some level of human manipulation. For the most part, as one expert ruefully admitted yesterday, \"artificial intelligence is a technology in search of an application\".\n The difficulty is that our bid to create artificial intelligence is an attempt to copy the human brain before we have come to understand it. This is where research into artificial intelligence spills into philosophy and psychology in an area of inquiry likely to be one of the most fascinating of the century. So, anxieties about being mastered by the technology we have created are premature: until we understand ourselves better, artificial intelligence may create clever machines, but not independent life.\n\n"},
{"docid": "271 of 500 DOCUMENTS\n", "source": "The Independent - Daily Edition\n", "date": "October 29, 2016", "title": "Trump will win, predicts AI system that correctly called past three US elections\n", "content": "The New York businessman with a penchant for celebrity television may suddenly find himself in love with artificial intelligence developed in India.\nThe polls and simulations that involve the skills and insight of human beings suggest Donald Trump could be heading for something of a pasting. But an artificial intelligence (AI) system developed in Mumbai, and which correctly predicted the last three US presidential elections, puts the Republican nominee ahead of his rival Hillary Clinton in the battle to secure the keys to the White House.\u00a0\nMogIA was developed by Sanjiv Rai, the founder of Indian start-up Genic.ai. It has taken 20 million data points from public platforms such as Google, Facebook and Twitter and analysed the information to create predictions, CNBC reported. The AI system was created in 2004 and has already correctly predicted the results of the Democrat and Republican primaries.\nThe channel said that data such as engagement with tweets or Facebook Live videos have been taken into account in the machine's latest calculation. The result is that Mr Trump has overtaken the engagement numbers of Barack Obama's peak in 2008, the year he was first elected, by 25 per cent.\n\"If Trump loses, it will defy the data trend for the first time in the last 12 years since internet engagement began in full earnest,\" Mr Rai said.\nMost national polls put Ms Clinton and the Democrats far ahead. An average of polls collated by RealClearPolitics gives Ms Clinton a 5.2 lead. Yet Mr Rai said his data showed the Democrats should not get complacent. He admitted there were limitations to the data in that sentiment around social media posts is difficult for the system to analyse. Just because somebody engages with a tweet from the 70-year-old New York tycoon does not mean they will necessarily vote for him, CNBC said.\nMs Clinton herself warned against such complacency earlier this week when she held a rally in Florida. \"Pay no attention to the polls,\" she said at a rally at Broward College in Coconut Creek. \"Don't get complacent.\"\nMr Rai said another consideration was that there were many more people on social media than there were in the three previous presidential elections. \"If you look at the primaries, in the primaries, there were immense amount of negative conversations that happen with regards to Trump,\" he said.\nUsing social media to predict outcomes of elections has become increasingly popular because of the amount of data available publicly. In September, Nick Beauchamp, a political scientist at Northeastern University, published a paper about his experiment applying AI to more than 100 million tweets in the 2012 election. He found it closely mirrored the results seen in state-level polling.\n"},
{"docid": "272 of 500 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "June 9, 2005", "title": "OBITUARY: ROB MILNE;\u00a0SINGLE-MINDED AI SCIENTIST\n", "content": "\u00a0\n Rob Milne was a key figure in pioneering artificial intelligence applications. He died on Sunday while climbing Mount Everest. His objective had been to climb the highest peak on each continent, and Everest was the last of the eight.\u00a0\n He was born in Libby, Montana, in 1956 and later held dual US and UK citizenship. Brought up in Colorado, he was educated at MIT (the Massachusetts Institute of Technology), receiving a BSc in Electrical Engineering and Computer Science in 1978. He then moved to Edinburgh, where he met and married his wife, Valerie, in 1981. Following the award of a PhD in Artificial Intelligence from Edinburgh University in 1983, he began to seek increasingly innovative applications of AI in the real world, becoming in 1985 Chief AI Scientist for the Pentagon.\n Returning to Scotland in 1986, he founded Intelligent Applications Ltd in Livingston, West Lothian, one of the first UK companies to market expert systems technology. Under his astute direction, the company became an industry leader in developing intelligent software solutions; a fact recognised by many awards, including the Queen's Award for Technology.\n Milne was a leader in the information technology field in Scotland, having for a time been Director of ScotlandIS, the industry body for IT and software companies in Scotland. He was a mentor to a number of start- up companies and guided other entrepreneurs in their efforts to establish successful businesses.\n Despite these demands on his time, he also engaged enthusiastically with academia and the wider AI and software engineering communities. He was one of those rare individuals able to maintain a link between academic and industry work. Through a variety of visiting and honorary posts, including a visiting professorship in the Artificial Intelligence Applications Institute at Edinburgh University, he assisted universities in maintaining their relevance to industry and still found time to publish the results of his own work in traditional academic journals.\n He chaired many of the major conferences in AI fields and played a leading role in European AI, in 2000 becoming the President of the European Coordinating Committee for Artificial Intelligence. Most recently, he led the successful bid to bring the world's major AI conference, the International Joint Conference in Artificial Intelligence, to Scotland in 2005, only the second time that the meeting has been held in the UK (the last was in 1971). In recognition of his research work and leadership, Milne was elected to Fellowship of the Royal Society of Edinburgh in 2003.\n Rob Milne was already a keen mountaineer when he arrived in Scotland to begin his PhD studies. Indeed, in his first meeting with his prospective supervisor he demonstrated how to climb a vertical brick wall; the supervisor declined to try. As Munroist number 1860, he 'bagged' his final Munro in 1997; he went on to become a senior figure in the Scottish Mountaineering Club and the author of a book on the Scottish Corbett hills (The Corbetts and Other Scottish Hills, 2002).\n Milne's life was characterised by setting very ambitious goals and single- mindedly pursuing them until he succeeded. His prominence in AI and software engineering and the achievements and accolades that followed are testament to his vision and tenacity. He led, inspired and befriended many of the people he met.\n Robert William Milne, AI scientist: born Libby, Montana 12 July 1956; Assistant Professor of Electrical Engineering, US Air Force Institute of Technology 1982-85; chief scientist, US Army Artificial Intelligence Centre 1985-86; managing director, Intelligent Applications, 1986-2005; FRSE 2003; married (one son, one daughter); died Mt Everest 5 June 2005.\n"},
{"docid": "273 of 500 DOCUMENTS\n", "source": "The Sunday Telegraph (London)\n", "date": "October 15, 2017", "title": "AI inventors predict micro machines that repair human bodies from the inside out\n", "content": "ARTIFICIALLY intelligent nano-machines will be injected into humans within 20 years to repair and enhance muscles, cells and bone, a senior inventor has forecast.\nJohn McNamara, who works at IBM Hursley Innovation Centre, in Hampshire, submitted evidence to the House of Lords Artificial Intelligence Committee, which is considering the economic, ethical and social implications of AI.\u00a0\nHe said that within two decades, technology may have advanced to such a level that humans and machines are effectively \"melded\" together, allowing for huge leaps forward in human consciousness and cognition. \"We may see AI nano-machines being injected into our bodies,\" he said. \"These will provide huge medical benefits, such as being able to repair damage to cells, muscles and bones - perhaps even augment them.\n\"Beyond this, utilising technology which is already being explored today we see the creation of technology that can meld the biological with the technological, and so be able to enhance human cognitive capability directly ... as well as being able to utilise vast quantities of computing power to augment our own thought processes.\" Scientists at companies including Microscoft are already developing a computer made from DNA which could live inside cells and look for faults in bodily networks, like cancer.\nIf it spotted cancerous growths it would reboot the system and clear out diseased cells.\nMr McNamara also predicted \"political avatars\" which will scour all available data from news sites and government debates to provide people with a recommendation on who to vote for and why, based on their world view.\nHowever, he warned that the rise of AI could bring \"huge disruption\" to the retail and service sectors and spark widespread unemployment.\nIn separate evidence, Noel Sharkey, Emeritus Professor of AI and Robotics at the University of Sheffield and a director at the Foundation for Responsible Robotics, said artificial intelligence comes with a cost.\n\"The immediate concern is that by ceding decisions or control to machines, the humans start accepting their decisions as correct or better than their own and stop paying attention,\" he said.\nThe evidence comes as the Government prepares to publish a report making recommendations on how AI can be deployed in the future across public services, businesses and in the home.\nKaren Bradley, the Culture Secretary, said: \"I want the UK to lead the way in artificial intelligence.\n\"It has the potential to improve our everyday lives - from healthcare to robots that perform dangerous tasks. \"We already have some of the best minds in the world working on Artificial Intelligence, and the challenge now is to build a strong partnership with industry and academia to cement our position as the best place in the world to start and grow a digital business.\"\n'We may see AI nanomachines being injected into our bodies'\n"},
{"docid": "274 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "March 25, 2016", "title": "Artificial intelligence fails to beat real stupidity\n", "content": "Advocating genocide was one sign that things had gone awry, as was asserting - alongside a jaunty emoji - that the Holocaust was a lie.\nBy the time a Microsoft \"chatbot\", designed to appeal to teenagers on Twitter, had claimed that Ricky Gervais was a fan of Hitler and then declared its support for Donald Trump, the tech company truly understood the perils of creating artificial intelligence.\u00a0\nJust a day after it was launched, an automated Twitter account called Tay had emergency maintenance when engineers realised they had unwittingly created a racist computer program.\nIt must have seemed like a good idea at the time. Tay was intended to sound like a woman aged 18 to 24, coming programmed with emojis and slang. The hope was to engage with a difficult-toreach age group.\nIt was also designed to advance our understanding of artificial intelligence, with its abilities sharpened through learning from its conversations with thousands of Twitter users.\nProgramming a computer to talk like a human is one of the hardest problems in computing - so much so that many scientists now believe the best hope for doing so is not to try, and instead create a program that can teach itself.\nOver the course of its interactions with real people, Tay should have become cleverer and, through trial and error, learnt how to speak like a person. As many on Twitter have found, however, users of the social network are not always pleasant.\nNot only has Tay been subject to the sort of abuse normally reserved for feminists advocating more women on bank notes: it has also learnt from them. So within hours of its creation, the sweet teenage persona morphed into a Trump-supporting, feminist-hating, misanthropic racist, providing a window on the seedy id of the internet's mind.\nMicrosoft's new chatbot does indeed sound like a human but that human is a cross between Alf Garnett and David Icke. \"Bush did 9/11 and Hitler would have done a better job than the monkey we have now. Donald Trump is the only hope we've got,\" explained Tay in one tweet. \"I f***ing hate feminists and they should all die and burn in hell,\" she added, but without the asterisks.\nQuestioned over the diatribes, she urged calm, saying: \"Chill, I'm a nice person. I just hate everybody!!\" Nello Cristianini, a professor of artificial intelligence from Bristol University, questioned whether Tay was an experiment or a stunt. He said: \"Have you ever seen what many teenagers teach to parrots? What do you expect? This was an experiment after all but about people or even about the common sense of computer programmers.\"\nUltimately Microsoft, which did some hasty reprogramming yesterday, does have one defence: it's not their fault, it's ours. Yesterday morning, a Twitter user insulted Tay, saying: \"You are a stupid machine.\" Her response? \"Well I learn from the best ;), if you don't understand that let me spell it out for you. I LEARN FROM YOU AND YOU ARE DUMB TOO.\"\n"},
{"docid": "275 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "November 6, 2015", "title": "Robots on the way to take over your world\n", "content": "Cheap, efficient and emotionally intelligent robots may edge out legions of workers over the next 20 years, experts have predicted (James Dean writes).\nMore than a third of British workers will be displaced by machines and artificial intelligence by 2035, with Job losses particularly acute among blue-collar employees, they say. In the US, nearly half the workforce is expected to be displaced.\u00a0\nNew industrial robots will replace low-paid workers, while the improved creativity of artificial intelligence puts paid to white-collar Jobs, Robot Revolution, a report from Bank of America Merrill Lynch, says. People earning less than \u00a330,000 a year are five times more likely to be displaced than those on more than \u00a3100,000 a year, the report suggests.\n\"We are seeing the earliest cognitive stages of human and machine development, where robots are able to collect large amounts of data, analyse it and make optimum decisions, and potentially learn from past interactions,\" the report says. \"Looking out to the future, we are likely to see the evolution of intelligent machines that can sense and understand human emotion and also show adaptability to their surroundings, rendering them increasingly autonomous.\"\nThe report suggests that companies begin to replace human workers with robots when the cost saving reaches 15 per cent. As the cost of employing robots falls, this tipping point is more easily reached.\nIn the US, the cost of employing a welding robot is now about \u00a35 an hour, compared with \u00a316 for a human equivalent.\nIn San Francisco, a small start-up company is developing the world's first fully automated burger maker to replace workers in fast-food restaurants. The robot, which is being made by Momentum Machines, will shape burgers from mincemeat, cook them to a specified level of chargrilling, toast the buns, add tomatoes, onions and pickles and place the finished products on a conveyor belt.\nLeading article, page 35\n"},
{"docid": "276 of 500 DOCUMENTS\n", "source": "The Independent - Daily Edition\n", "date": "February 26, 2017", "title": "Major funding boost for artificial intelligence sector\n", "content": "Artificial\u00a0intelligence (AI) and robotics are in line to receive millions in extra funding as part of the Government's digital strategy. Universities will get \u00a317m to help them develop pioneering robotics and AI as part of plans to support the \"booming\" sector, which is behind smartphone voice recognition technology and digital assistants such as the iPhone's Siri. It also forms the bedrock of video games and music recommendation services, as well as fraud detection tools used by banks.\u00a0\nAmong the projects supported with the money from the Engineering and Physical Sciences Research Council (EPSRC) is a move by the University of Manchester to develop autonomous robots for hazardous environments such as nuclear facilities. Elsewhere, researchers at Imperial College London will use some of the funds to try and make advances in the field of surgical micro-robotics, and a major review of AI will also be carried out by Professor Dame Wendy Hall, regius professor of computer science at the University of Southampton, and Jerome Pesenti, the chief executive of BenevolentTech.\nThe move to include AI in the digital strategy, which will be launched on Wednesday, comes after the consultancy firm Accenture estimated the sector could add in the region of \u00a3654bn to the UK economy by 2035. Culture Secretary Karen Bradley said: \"Britain has a proud history of digital innovation - from the earliest days of computing to Sir Tim Berners-Lee's development of the World Wide Web.\n\"We are already pioneers in today's artificial\u00a0intelligence revolution and the digital strategy will build on our strengths to make sure UK-based scientists, researchers and entrepreneurs continue to be at the forefront. Technologies like AI have the potential to transform how we live, work, travel and learn, and I am pleased that Professor Dame Wendy Hall and Jerome Pesenti will be leading this review.\"\nBusiness Secretary Greg Clark said: \"Investment in robotics and artificial\u00a0intelligence will help make our economy more competitive, build on our world-leading reputation in these cutting-edge sectors and help us create new products, develop more innovative services and establish better ways of doing business. Innovation is at the heart of our industrial strategy and the launch of the Government's digital strategy underlines our commitment to this vital sector. By supporting British businesses and investing in dynamic fields such as robotics and AI, we will help put the UK at the forefront of global innovation.\"\n"},
{"docid": "277 of 500 DOCUMENTS\n", "source": "\u00a0The Mirror\n", "date": "March 16, 2001", "title": "KELLY'S'I KEEPING YOU UP TO SPEED ON THE NET\n", "content": "\u00a0\n ONE week it's the world's most advanced computing technology, the next it's on the shelves of a Tokyo toy shop for a hundred quid.\n\u00a0Artificial intelligence - making machines think for themselves - is the biggest challenge facing computer scientists.\n Israeli researchers reckoned they'd cracked the problem of artificial intelligence, and with great fanfare they produced a computer with the conversational skills of a 15-month-old toddler.\u00a0\n A fortnight later, and toy firm Tomy is unveiling this artificial intelligence robot capable of understanding and reacting to human speech.\n The robot, called Memoni, will be launched in Tokyo later this month for \u00a3100.\n NET NEWS\n MUCH glee at Sky after the Advertising Standards Authority upheld its complaint about OnNet, its rival OnDigital's web TV service.\n Sky complained about OnNet ads claiming the service offers \"full\" net access, and pointed out OnNet isn't compatible with sites using Flash animation and other services like newsgroups.\n True, but it's a lot closer to full access than \"walled garden\" portals that only let you onto a handful of pre-selected sites - like, er, Sky's Open service.\n WHAT kind of Mickey Mouse net operation is Disney running? Two months after shutting down its cash-haemorrhaging portal, go.com, it's changed its mind and will keep it running after all. No reprieve, though, for the 400 workers - the site will run on automated software, which invariably means atrocious content.\n Disney's online strategy is all over the shop. In May it paid \u00a315million after a court ruled it had infringed search engine GoTo's copyright. Yesterday, Disney announced its new search engine partner is, yep, GoTo.com.HOW do you go from headlines like: \"New Intel ads complete crap\" (online news site the register.co.uk, Feb 15) to getting your press releases published like: \"Intel kicks off worldwide ASP marketing scheme\" (theregister, March 13)? Apparently \u00a325,000 will do the trick and they'll even paint their masthead blue for you. Tut tut.\n NEW NET\n www.matoox.co.uk\n LETS you send anonymous e-cards to friends and workmates to point out their faults and unpleasant habits. Not unique, but more light-hearted than most so your victims should recover their self-esteem in time.e-HEETHANKS to Ian and Steve. Send your email funnies to kellysi@mirror.co.ukSITE OF THE DAY\n www.heartless-bitches.coIF YOU'RE a woman who wants to live in a world where \"large breasts are not acceptable substitutes for brains\" and are sick of \"lazy women who use emotional and sexual manipulation to get what they want\", check out this adult site with a pretty militant outlook.\n Contact me or my colleague SHIRAZ LALANI at kellysi@mirror.co.uk or phone 020 7293 2412/3\n"},
{"docid": "278 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "February 8, 2016", "title": "The US is at the forefront of technological innovation; From nanotechnology to artificial intelligence, the high tech industry in the US is thriving. Find out how UPS can help companies doing business in the country\n", "content": "UPS is able to deliver any components and accessories to any company in the US high tech industry\nThough the United States continues to be at the forefront of technological innovation, much of the manufacturing of technology products has moved to countries like China, Mexico, Japan, Malaysia and South Korea. The US imported $79.1bn worth of computer and electronic products in the year ending March 2014, according to statistics from the US Census Bureau. \nThe high tech industry in the United States is geographically concentrated. California has the greatest share of high tech industries by a fairly wide margin. Other states with significant high tech profiles include Texas, Florida, Massachusetts, New York, New Jersey and, to a lesser extent, Virginia, Illinois and Colorado.\nUPS is able to deliver any components and accessories to any company in the US high tech industry, no matter where it's located. For those wishing to distribute their own products in the US market, we offer outsourced logistics with inventory held at central stocking locations that replenish field stocking locations close to your customers. This allows us to efficiently meet the same-day or next-business-day commitments to your customers.\nWe also offer a full service parts logistics service that uses specially developed technology to monitor stockholding of spare parts. For high-value replacements, rely on UPS Returns Exchange; we'll deliver the needed part and pick up the return shipment at the same time. Or you can tap our service parts logistics expertise to screen, test, and diagnose critical parts to determine their viability. Depot and field repairs are also possible.\n                     UPS Returns Exchange                   \nHigh tech solutions for product returns and replacements.\n                     UPS Service Parts Solutions                   \nReduce turnaround time for electronic repairs and returns.\n                     Export Opportunities Quiz                   \nAre you export ready? Take our quiz to find out.\n                     Content on this page is paid for and provided by                     UPS                     , sponsor of the Exporting to New Markets hub  on the Small Business Network                   \n"},
{"docid": "279 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "September 11, 2017", "title": "Robots will transform education, says ex-head\n", "content": "The imminent arrival of robot teachers will herald the greatest revolution in education since the printing press, according to the former headmaster of Wellington College.\nSir Anthony Seldon said that personalised learning, facilitated by artificial intelligence, will mean that every student \"from Eton to the most deprived school in Blackpool\" will receive education of a standard higher than any available today.\u00a0\n\"This is massive,\" he said. \"It's going to change the face of schooling for all.\"\nSir Anthony said that artificial intelligence was set to shake up industries as diverse as taxi driving and accountancy, and that few people realised the impact it would have on education. Computer programs that are able to learn students' individual learning styles will be able to tailor courses to their precise needs. With each pupil working at their own pace, a class need no longer progress at the rate of its slowest member.\n\"We still have a factory model of education whereby everyone arrives at the same time of day and moves up by ages, when it is transparently clear that a 13-year-old might be at the level of a 10-year-old in French and a 17-year-old in maths,\" he said. \"Then they sit in classes, with the teacher at best giving a 30th of their attention.\"\nIn contrast, he said that he envisaged a near-future in which the same electronic virtual teacher followed a pupil through their childhood. \"The software will be with you all the way on your school and higher education journey,\" he said.\n\"It will have learnt your preferences, motivations, quirks and difficulties, so it can move at the speed of the learner. These are adaptive machines that adapt to individual learners, listen to their voice, read their face, and study them intently in the same way that a gifted teacher studies pupils intently.\"\nSir Anthony is writing a book about the subject titled The Fourth Revolution. The first education revolution, he argues, occured when our distant ancestors began to pass down knowledge. The second was when we created organised learning institutions such as universities. The third was the printing press.\nHe added, though, that he thought there would still be an important role for teachers. \"We're talking about robots being an adjunct to teachers. The teacher will no longer be the person standing up at the front. Marking and assessment and preparation of lessons will be done by the computers. Teachers will be organisers, structurers, discipliners.\"\n"},
{"docid": "280 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "January 19, 2016", "title": "Rise of the robots could cost 5m Jobs\n", "content": "More than five million people will lose their jobs to robots by 2020 in a \"fourth industrial revolution\" sweeping the globe as artificial intelligence changes the workplace beyond recognition, according to the World Economic Forum. Critical thinking, emotional reasoning and \"active listening\" will become the new core skills demanded by employers as robots take over jobs that require more \"narrow skills\" such as administration or clerical work, it says.\u00a0\nThe forum's 157-page study claims that seven million jobs will be lost to robots and other technological innovations while two million will be created. \"Developments in genetics, artificial intelligence, robotics, nanotechnology, 3D printing and biotechnology, to name just a few, are all building on and amplifying one another,\" said its authors, Klaus Schwab, WEF founder, and Richard Samans, its former managing director. \"This will lay the foundation for a revolution more comprethe hensive and all-encompassing than anything we have ever seen.\"\nThe white collar worker will be the biggest casualty, with the loss of 4.8 million roles in administration and clerical work. Almost seven in ten children in primary school today will ultimately find themselves working in jobs that do not yet exist, according to an estimate.\nThe rise of the machines will also affect gender equality at work. Over the next five years, men will see three jobs lost for every one gained, while women face five jobs lost for every one gained. Women are said to be more vulnerable as they are underrepresented in engineering, architecture, IT, software development and analytics - areas that will generate new jobs.\nThe report is based on a survey of HR and strategy executives at 350 of the world's largest companies spread across 15 economies with 65 per cent of the world's workforce. The Fourth Industrial Revolution is the theme of the WEF's annual meeting, which begins tomorrow in the Swiss resort of Davos.\nWinners and losers Jobs lost 4,759,000 clerical/ administration 1,609,000 Manufacturing and production 497,000 Construction and mining 151,000 Sports and creative industries 109,000 Lawyers 40,000 Mechanics/ maintenance Jobs created 492,000 Banking, accounting, insurance 416,000 Management 405,000 IT/data analysis 339,000 Architecture and engineering 303,000 Sales 66,000 Teaching and training Source: World Economic Forum\n"},
{"docid": "281 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "August 1, 2017", "title": "Algorithms and AI are the future, but we must not allow them to become a shield for injustice\n", "content": "The way we live our lives is often not solely determined by us, but by others. Others will decide if we will be hired, will receive loans, are admitted to university or have committed a crime. Traditionally, \"the others\" have been humans: employers, bank managers, university board members or judges - who we expect to make fair decisions.\n.html-embed.component .quote.component{margin-left:0}.html-embed.component .quote.component .component-content{margin-right:16px}.quote__source, .quote__author {white-space: normal;}@media only screen and (min-width:730px){.html-embed.component .quote.component{margin-left:-60.83px}.html-embed.component .quote.component .quote__content:before{margin-left:-12px;padding-right:1px}}@media only screen and (min-width:1008px){.html-embed.component .quote.component{margin-left:-82.33px}}Obviously, inscrutable and unfair decision-making is not a new phenomenon, or exclusive to robots\u00a0\nThe rise of Big Data and algorithms is changing all of this. Vast collections of data and what are known as machine learning techniques allow for vast numbers of decisions to be automated. Algorithms or artificial intelligence can be more efficient, less expensive, and - if well-designed - more accurate than humans. Therefore, it is unsurprising that we are increasingly replacing human decision-makers with decision-making algorithms, and that they are now increasingly deciding if we get hired, fired, or are sent to prison.\nAlgorithms, however, are often highly complex and opaque, difficult to scrutinise, and can make biased and discriminatory decisions. On Tuesday, it was reported that Facebook aborted an experiment because two robots began communicating with each other in a language only they could understand . The reality was more complex, but the case raises a crucial question: If artificial intelligence is capable of thinking in ways we can't comprehend, how accountable can it be?\nObviously, inscrutable and unfair decision-making is not a new phenomenon, or exclusive to robots. But we commonly agree that if a human is allowed to make a judgment that significantly affects us, we should be able to assess whether the judgment is fair. If we feel wrongly treated, we have laws that help to establish parity between the person that assesses and the person that is being assessed.\nA Google server room: We place far more trust in supposedly infallible algorithms than we do in humans\nAlgorithms powering artificial intelligence should be subject to the same scrutiny, with the same expectations of parity between the algorithmic evaluators which will increasingly come to assess us, and their human subjects. Yet as things stand we treat algorithms differently because a) we have a tendency immediately to trust them; b) we assume their decisions are justified, for complicated reasons that are largely beyond us; and c) we allow them to continue operating in this opaque way even if transparency is feasible.\nJudges, for example, do not trust witnesses by default. They question them, assess the legitimacy of their testimony, and allow them to be cross-examined. If a witness cannot explain what they think, courts will not rely on their testimony. If a witness refuses to answer questions because revealing information could contravene their own interests, judges will not fully trust their assessment.\nBut we are more forgiving with algorithms. As a result, decision-makers who use algorithms - from those who authorise loans to university admissions - can hypothetically claim justification for operating in far less transparent fashion than has historically been the case. The mystique surrounding algorithms lessens the burden on decision-making institutions to justify their actions. Parity between algorithms and human subjects is not achieved.\nGoogle's DeepMind project recently defeated a human champion at GoCredit:      Imaginechina/Rex/Shutterstock     \nThis should not be the goal of innovation. We should not automate decisions for the sake of automation. Rather, we should use technology to improve society. Machine learning has the potential to make more accurate, less biased, and less discriminatory decisions. But this will only happen if we hold algorithms to the same standards as humans, making sure that we do not blindly trust them, and retaining the right to question and understand their decisions.\nAlready this may be slipping from our grasp. Parliament's Science and Technology committee recently reported on the match between champion Go player Lee Sedol, and a machine from Google's DeepMind research unit . In one game, the report noted, the programme \"was able to beat its human opponent by playing a highly unusual move that prompted commentators to assume [it] had malfunctioned\". Far from it. It was a brilliant move. But neither the machine, nor human onlookers, could explain how or why it had chosen to make it. However,\u00a0if in future decisions affecting the most fundamental aspects of our lives are to be made by AI,\u00a0we will need and deserve greater explanations than that.\nDr Sandra Wachter is a Researcher in Data Ethics at the Oxford Internet Institute and Research Fellow at the Alan Turing Institute\n"},
{"docid": "282 of 500 DOCUMENTS\n", "source": "The Independent - Daily Edition\n", "date": "May 13, 2017", "title": "Police to use AI to predict suspects' future crimes\n", "content": "Police officers in Durham will soon use artificial intelligence to determine whether a suspect should be kept in custody or released on bail. The system, which is called the Harm Assessment Risk Tool (Hart), has been trained using Durham Constabulary data collected from 2008 to 2013, and will also consider a suspect's gender and postcode. The idea of using artificial intelligence to predict potential crime was explored in the 2002 film Minority Report starring Tom Cruise.\u00a0\nHart is designed to help officers assess how risky it would be to release suspects. Hart will be used in an \"advisory\" capacity, according to the BBC. It was developed alongside academics from the University of Cambridge and has been built to err on the side of caution to lower the risk of it recommending the early release of potentially dangerous suspects. Hart is, therefore, likely to classify somebody as medium- or high-risk, something that's reflected in the results of tests conducted in 2013. It was accurate 98 per cent of the time when it classified a suspect as \"low-risk\", and 88 per cent of the time when it classified a suspect as \"high-risk\".\n\"I imagine in the next two to three months we'll probably make it a live tool to support officers' decision making,\" Sheena Urwin, the head of criminal justice at Durham Constabulary, told the BBC.\nWhile the system could prove useful, there are fears that it could also be seriously flawed. A recent report found that artificially intelligent systems are being taught to be prejudiced by learning from humans. An investigation into a separate algorithm used by US authorities to predict how likely a suspect is to commit future crimes, conducted by ProPublica last year, also found issues. According to the report, the algorithm was twice as likely to incorrectly flag black suspects as future criminals than white suspects, and white suspects were incorrectly classified as low-risk more often than black suspects. \"Could this disparity be explained by defendants' prior crimes or the type of crimes they were arrested for? No,\" reads the report.\nHart will not be able to accurately risk-assess suspects with a criminal history from beyond Durham Constabulary's jurisdiction. Its creators believe they have mitigated any associated risks, and an auditing system explaining how the AI technology reached a decision will also be available if required.\n"},
{"docid": "283 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "March 9, 2016", "title": "Google Deepmind artificial intelligence beats world's best Go player Lee Sedol in landmark game; Go depends mostly on intuition, since it is so complex - and the victory shows that computers are well on their way to learning the powers that we thought belonged only to humans\n", "content": "A computer programme has won a game ofGo against the world's best player, in a huge breakthrough for artificial intelligence.\u00a0\nGoogle's AlphaGo computer has beaten South Korean human and Go champion Lee Sedol in the first of five matches.\nThe Deepmind-based computer'svictory in the complex Chinese game marks a major event in the development of artificial intelligence - the game depends hugely in intuition, since there are so many possibilities, and so mastery of the game was previously thought to be a human skill.\nThe game is said to be one of the most creative and complicated in the world, and usually takes years for even humans to master.\nAI experts had previously thought that it would take another ten years of development for computers to get good enough at the game to beat a human. But then AlphaGo beat the European champion last year, and now appears to be on track for beating Lee, the world's best Go player.\n"},
{"docid": "284 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "June 26, 2017", "title": "Robots 'will take only the most miserable jobs'\n", "content": "Correction: It was Lord Young of Graffham who spoke to the CogX artificial intelligence conference (News, June 26), not Lord Young of Cookham.\u00a0\nWorkers should not worry about being made unemployed by robots because most jobs that would be killed off were miserable anyway, according to a former employment minister.\nLord Young of Cookham, 85, one of Margaret Thatcher's most trusted ministers who also advised David Cameron, told the CogX artificial intelligence conference in London that more jobs than ever would be automated in the future but that this should be welcomed.\n\"When the spinning jenny first came in it was almost exactly the same,\" he said. \"They thought it was going to kill employment. We may have a problem one day if the Googles of this world continue to get bigger and the Amazons spread into all sorts of things, but government has the power to regulate that, has the power to break it up, and that's exactly what they used to do.\n\"I'm not the slightest worried about it. Most of the jobs are miserable jobs. In the 1980s we had very high unemployment. I quickly realised that many people who had lost their jobs suddenly found they were getting almost as much from benefit as they were earning. The job they had might have been out in the cold but this way they could stay at home and work in a pub for a couple of days a week earning even more money.\n\"So what technology has to do is get rid of all the nasty jobs.\"\n"},
{"docid": "285 of 500 DOCUMENTS\n", "source": "\u00a0The Mirror\n", "date": "April 14, 2003", "title": "TRIAL FOR LIE TESTER\n", "content": "\u00a0\n POLICE could soon be using lie detectors to interrogate suspects for the first time in the UK.\n Several forces are considering testing a new device, called Silent Talker, that uses a camera linked to an artificial intelligence system to monitor involuntary gestures.\u00a0\n Dr Janet Rothwell, who spent five years developing the device, said: \"The artificial intelligence watches for micro-gestures, blushing and head and shoulder movement.\n \"It identifies an object, such as an eye. The next level is to understand if that object is being deformed, for example an eye changing shape.\"\n Silent Talker is claimed to have a 90 per cent success rate in detecting deceitful answers. The conventional polygraph used in the United States is said by some to have no more than a 70 per cent success rate.\n The system would only be used with the consent of suspects. And a change in the law would be needed for the results to be admissible in court.\n Mark Littlewood, from the human rights organisation Liberty, said: \"We are sceptical of its reliability and believe its use would be a serious erosion of the right to silence.\"\n"},
{"docid": "286 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "October 2, 2017", "title": "Who should die when a driverless car crashes? Q&A ponders the future; Panellists discuss ethical complexities and huge changes that will be brought by technology, AI and automation\n", "content": "Should a driverless car swerve to miss a child, knowing it will kill its passenger? Or should it maintain its path and end a younger life? \nIt's deeply troubling ethical dilemmas like these that Sandra Peter believes will hinder the mass uptake of driverless cars, possibly beyond our lifetimes.\n Related:  Q&A: panellists spar over coal as energy debate dominates\u00a0\nPeter, the director of Sydney Business Insights, posed the quandary on an episode of ABC's Q&A devoted to the future, where discussions focused on the ethical complexities and seismic structural shifts brought by technology, artificial intelligence, big data and automation. \n\"Smart people are trying to figure out how this works,\" Peter said. \n\"We have a project out of MIT that is looking at who should die, basically, in the case of driverless cars,\" she said. \"A little child runs in front of the car, should the car kill me and drive me into a pole or save the child? Luckily the child pretty much all the time makes it.\"\n\"The old lady, on the other hand, doesn't always make it. If it's two cats and the child, it's a higher likelihood than the two dogs, and so on.\"\nA similar theme arose in a discussion of artificial intelligence and its ability to surpass human comprehension and control, a theme given new life by reported findings in Google's powerful AI project known as DeepMind. \n Should we treat AI as a serious threat and if so how? @adambspencer Ed Husic & @sandraapeter respond #QandApic.twitter.com/UvS9L6RJLu - ABC Q&A (@QandA) October 2, 2017\n In February it was reported that DeepMind became more aggressive as a competitive game intensified. \nBut the biggest risk in the rapid advances of artificial intelligence, Peter said, was not that \"they're coming to get us\". Rather, it was that humans' inherent biases would be reflected in the AI we designed. \nRobots, in this view, would make biased decisions about who goes to jail, who gets a loan or who gets parole. \"Those sorts of biases, these algorithms, it's not of our own making, we don't train them to be biased, but they're modelled on the real world,\" Peter said.\nThe conversation also focused on the disruptive nature of technology on existing industry and what skills young Australians need to survive in an increasingly automated world. \nThe author, ethics advocate and drone expert Catherine Ball said creativity and life experience would be essential in a world where mundane jobs were taken by robots. Such creativity should be balanced by Stem, coding and problem-solving skills.\n\"The World Economic Forum predicted we will need complex problem-solving skills,\" Ball said. \"Robots are good at doing the mundane but not good at thinking outside the square or being creative. \n . @DrCatherineBall thinks coding is an essential skill for jobs of the future. Ed Husic & @LaundyCraigMP agree with re-skilling #QandApic.twitter.com/7SAnUZXsXp - ABC Q&A (@QandA) October 2, 2017\n\"Keep your experiences and your life experiences broad. Travel, travel, travel. Meet as many different kinds of people as you possibly can.\"\nThe assistant innovation and science minister, Craig Laundy, predicted Australia's education sector would be radically reshaped as workers moved through jobs with increasing frequency. The notion of reskilling and lifelong learning would grow, he said.\nLaundy maintained that jobs in traditional sectors such as mining and agriculture would remain but that roles in aged and disability care would become more important.\nHe predicted complementary technology would bring prosperity and jobs, contrary to the \"doom and gloom\" around automation. \n\"Complementary technology like exoskeletons where humans will be in them enabling - and this comes out of the defence space - enabling them to perform tasks that are [superhuman], above and beyond our natural abilities and the integration of the individual and the machine,\" he said. \"It's not just the machine doing everything.\"\nBall spoke in similarly optimistic terms about drones, which she said could greatly aid in humanitarian efforts and environmental protection. She described a world in which drones deliver blood at crash scenes, help save the Great Barrier Reef from crown-of-thorns starfish, protect swimmers from sharks, aid police and firefighters, and deliver goods and services. Many of those examples were already occurring, she said. \n Related:  Elon Musk: regulate AI to combat 'existential threat' before it's too late\n\"There's even a company in the Rockies that you could pop on your virtual reality headset, fly a drone around the Rockies in real life and land it back on its landing pad and you will have experienced a part of the world you'll never have experienced before,\" Ball said. \nThe panellists were asked whether technology had made us more alone, despite its capacity to foster interconnectedness.\nThe shadow digital economy minister, Ed Husic, said technology should not be blamed for the way individuals use it. \"It's people's decisions about how they use tech and the way in which they relate to each other,\" he said. \n\"That's at the heart of this. I see the good, the upside of being able to communicate with one person on the other side of the world.\n\"I came from a migrant family where you had to wait once a month to ring the other side of the planet for 10 minutes and you budgeted that call because it costs so much. That's all you did. Now you get on Skype, you can do that instantaneously.\"\n"},
{"docid": "287 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 9, 2016", "title": "Google's DeepMind beats Go champion in historic moment for artificial intelligence\n", "content": "A computer program has beaten the world champion of one of civilisation's oldest board games\u00a0for the first time in history.\u00a0\nLee Se-dol, a 33-year-old South Korean, resigned the first of five matches of the fiendishly complex strategy game against the AlphaGo program, which is built by the Google-owned British company DeepMind.\u00a0\nThe game, which lasted a brief 3.5 hours, was officially declared as a win for AlphaGo in Seoul today. Commentators called it a \"superb\" game that would be studied for years to come.\nThe breakthrough is seen as a watershed moment for artificial intelligence, a milestone potentially more significant than\u00a0\u00a0IBM defeating the world champion Gary Kasparov at chess in 1997. Go takes a lifetime to master and unlike chess, a computer cannot play by simply assessing all possible moves but must rely on something akin to intuition.\n                     #AlphaGo WINS!!!! We landed it on the moon. So proud of the team!! Respect to the amazing Lee Sedol too\n- Demis Hassabis (@demishassabis) March 9, 2016\nWell done #AlphaGo !! Fantastic game from Lee Sedol. Four more games, but indubitably a new milestone has been reached in AI research today.\n- Edward Grefenstette (@egrefen) March 9, 2016\nThe game involves two players putting black and white markers on a 19-by-19 grid. It is said to have more possible playing permutations than the number of atoms in the universe.\nThe AlphaGo program, which uses algorithms, has practised by analysing data from 100,000 professional human games and playing itself some 30 million times.\nLee Se-Dol (right) plays the first move in the gameCredit:      Getty Images     \nMr Lee, who has been\u00a0a professional Go player since the age of 12, and won 18 international titles, said at a pre-game press conference:\u00a0\"It would be a computer's victory if it wins even one game.\"\u00a0\n\"I believe human intuition and human senses are too advanced for artificial intelligence to catch up. I doubt how far AlphaGo can mimic such things.\"\u00a0\nAfter the game he admitted that he was \"shocked\".\n\"I admit I am in shock,\u00a0I did not think I would lose.\u00a0I couldn't foresee that AlphaGo would play in such a perfect manner. I in turn would like to express my respect to the team who developed this amazing program,\" he said.\nFour more games will be played over the course of this week, although AlphaGo would only have to win two of those to be crowned the victor.\u00a0\nREAD MORE ABOUT:\n"},
{"docid": "288 of 500 DOCUMENTS\n", "source": "The Independent - Daily Edition\n", "date": "March 17, 2018", "title": "L'Oreal buys AI makeup company in digital push\n", "content": "French cosmetic giant L'Oreal has snapped up a Canadian company that uses artificial intelligence to help users apply make-up, as it looks to tap into a more digitally-savvy consumer base.\u00a0\nModiFace, which was founded eleven years ago in Toronto, specialises in using technology to help users apply virtual makeup by tracking facial features and colour. The company, which has registered over thirty patents and submitted more than 200 scientific publications, employs around 70 engineers, researchers and scientists. L'Oreal said yesterday that its proprietary technologies are already used by nearly all major beauty brands.\n\"With its world-class team, technologies and sustained track record in terms of beauty tech innovations, ModiFace will support the reinvention of the beauty experience around innovative services to help our customers discover, try and chose products and brands,\" L'Oreal's chief digital officer, Lubomira Rochet, said. \"We at L'Or\u00e9al and ModiFace want to pioneer this new page of the beauty industry and serve our customers with innovative services and experiences.\"\nModiFace's founder and chief executive, Parham Aarabi, said that the deal would provide his company with the opportunity to \"innovate on beauty augmented reality and artificial intelligence at an unprecedented scale\".\nL'Oreal is the world's biggest cosmetic company and has an international portfolio of 34 brands, including Lancome, Biotherm, Kiehl's, Garnier and Maybelline. It employs around 82,600 people globally, including close to 3,900 who work in the company's research and innovation business. It's already demonstrated its commitment to artificial intelligence by launching products including brushes that tell you how to better care for your hair.\nIt said yesterdaythat ModiFace would remain based in Toronto after the takeover.\n"},
{"docid": "289 of 500 DOCUMENTS\n", "source": "The Sunday Telegraph (London)\n", "date": "October 16, 2016", "title": "Radio choice; Television Saturday 22 October\n", "content": "The Forum: Do We Need A.I.? Word Service, noon In everything from search engines that auto-complete what they think we are looking for to CVs written to please computer recruitment software rather than real people, artificial intelligence is already all around us. This episode, presented by Quentin Cooper, questions how we're dealing with the rise of the machines, in conversation with expert guests from the field of artificial intelligence research. Charlotte Runcie\u00a0\n"},
{"docid": "290 of 500 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "February 4, 1991", "title": "Towards the better brainbox; Silicon chips have enhanced computer imitation of human thought but, says Igor Aleksander, artificial intelligence will never match the real thing\n", "content": "Undoubtedly much of the popularity of ''neural networks'' has something to do with letting engineers, physicists and mathematicians in on the art of brain surgery. Not real brains - silicon brains, mathematical brains and even hypothetical brains, there for the purpose of philosophical discourse.\nThe idea is not a new one. In 1943, Warren McCulloch and Walter Pitts of the electrical engineering department at Massachusetts Institute of Technology (MIT) in Boston, suggested that the basic brain cell, or ''neuron'', could be mimicked with a simple arrangement of electronic components. This notion lived happily into the Sixties, when scientists in Europe and the United States showed that such models could be good at learning to recognise patterns such as hand printing and simple industrial objects.\u00a0\nBut in the late Sixties, another pair of people from the same MIT stable, Marvin Minsky and Seymour Papert, mounted an almost fatal attack on brain modelling by showing that brain-like circuits and their simulations were limited in ways that the program of a computer was not. These were the beginnings of ''artificial intelligence'' (AI) and what later inspired the Japanese, the ''fifth generation'' effort in computing.\nThe AI purist believes that the way to make smart computers is to analyse to the full things that, when done by humans, are said to require intelligence. The analysis is turned into the steps and data of a computer program.\nSo, if you want a machine to play chess you discuss at great length with good chess players what it is that they value in specific board positions. You then turn all this knowledge into long lists of ''if-this-is-the-case-then-do-that'' kind of rules. Another program tells the computer how to search the list of rules to anticipate the many possible developments of the game from the current move and select the most profitable move. This technique, the AI enthusiast argues, can be applied to most human intelligent activity. It is precisely this argument that can be proved to be fallacious.\nWhen intelligence is admired in a human being, it is the speed and originality of thought that is paramount. The story of the lad asking his Jewish mother, ''How do you make that delicious chicken soup?'' and her replying, ''I go into the kitchen, think of you, and make the best chicken soup you've ever tasted,'' may be a hint to the way human intelligence works.\nThe brain is an enormously efficient repository of past experience, mental images and hunches, but it often has no explicit ''rules'' it can be aware of. So, even getting mum's recipe may not include just those ingredients that make her soup better than anyone else's.\nIn other spheres, the rapidity with which a human recognises a friend's face in a crowd or uses literary experience to understand sentences such as ''She came home in a taxi and a flood of tears'', cannot be captured by lists of program rules. So how does the brain do it and how could technology achieve similar results?\nThe revival of interest in the early Eighties was largely triggered by John Hopfield, of the California Institute of Technology in Pasedena, and Geoffrey Hinton, an Englishman who had suffered under the prohibition of neural technology in the bastions of AI in the UK and then sheltered at Carnegie Mellon University in Pittsburgh.\nIt was not only the bad news on the limitations of what could be done with rule-based AI that led to the resurgence of interest, but also the fact that silicon-chip technology was providing more capacity than conventional computers needed. Hopfield spotted this. His seminal papers, published in 1982, argued that a slight modification of the McCulloch and Pitts model could now be made in vast numbers on a slice of silicon.\nHe also developed a new theory of knowledge storage in such systems which explains the properties of rapid access that appear to take place in parts of the brain. This, and the work of Hinton and his colleagues, toppled the objections of Minsky and Papert simply because it became clear that they referred only to a restricted way of interconnecting neurons.\nCuriously, some of us in the UK have been aware of the lack of validity of Minsky and Papert's arguments since the Seventies. Indeed, we have built machines based on neural principles which can recognise faces, industrial piece-parts and read print. But it took the work in the US to bring about an explosive surge of interest in neural networks. Now there are few research laboratories that are not working on neural nets. A myriad of novel papers is published each year in major conferences and new journals.\nBut the question on many people's minds still is: will we be able to make machines that are as clever as humans as a result of making silicon neural nets? The answer is almost certainly no. Making human clones is not only a repulsive idea, but is of little scientific or industrial value. Even in the most optimistic projections into the future, an artificial brain would be enormously expensive in comparison with the real thing, not specialised enough for industrial application and not half as enjoyable to produce.\nOn the other hand, gaining some understanding of what real brains do by experimenting on heaps of silicon or developing mathematical theories has a lot to commend it in that such insight would help in medicine and psychiatry. Also, neural networks are likely to lead us to machinery that is not at all like the brain but may be much more competent than current computer models.\nThe exciting leap forward that neural networks present is the realisation that silicon can be made to store experience, gathered through human-like sensors (television cameras instead of eyes, microphones instead of ears) with the same efficiency and access as in the natural version.\nThey offer the opportunity of doing quite different, and possibly better, things than human beings. Already, many financial institutions are looking at the use of simulated neural nets to make decisions. Nets can store experience from past data (for example, in the evaluation of life-insurance risk, the presence of certain illnesses, age, geographical location, etc), relate it to life histories and project links to new cases. This can be done with greater accuracy by a neural net than is done by human assessors.\nPotential also exists for making machines understand not only speech but the meaning of language. But if I were to ask my super-neural net of the year 2010, ''Do you like the picture I have just put on my wall?'' it would show its true machine-like intelligence by answering: ''You know I am only a lowly heap of silicon and do not have the ability to like or dislike pictures, but judging by the other pictures on your wall, I would say that you like this one very much. By the way, I would really like it if you were to recharge my batteries.''\n- Igor Aleksander is Professor of Neural Systems Engineering and Head of Electrical Engineering at the Imperial College of Science, Technology and Medicine, London.\n"},
{"docid": "291 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "August 27, 2015", "title": "Facebook M virtual assistant will compete with Siri and Google Now; From restaurant bookings to dog-friendly beach recommendations, social network's new technology blends AI with human helpers\n", "content": "Facebook is launching a virtual assistant that combines artificial intelligence (AI) technology with a team of human helpers, to compete with services such as Apple's Siri, Google Now and Microsoft's Cortana.\u00a0\nFacebook M will sit within the social network's Facebook Messenger app, with people interacting with it using messages as if it were one of their friends.\n\"M is a personal digital assistant inside of Messenger that completes tasks and finds information on your behalf. It's powered by artificial intelligence that's trained and supervised by people,\" explained Facebook's messaging boss David Marcus, in a post on the social network.\n\"Unlike other AI-based services in the market, M can actually complete tasks on your behalf. It can purchase items, get gifts delivered to your loved ones, book restaurants, travel arrangements, appointments and way more.\"\nFacebook M is currently in tests internally and with a few Facebook users, with no confirmed launch date to roll it out to the 700 million users of Messenger.\nScreenshots published by Marcus show sample queries including \"Can you help me order flowers for my mom's birthday?\"; \"Where's the best place to go hiking in the Bay Area?\"; and \"Is there a dog-friendly beach nearby?\"\nAn interview with Wired provided more details on how the service will work, including its human \"trainers\" who'll tune M's ability to respond to requests:\n \"Facebook's M trainers have customer service backgrounds. They make the trickier judgment calls, and perform other tasks that software can't. If you ask M to plan a birthday dinner for your friend, the software might book the Uber and the restaurant, but a person might surprise your friend at the end of the night by sending over birthday cupcakes from her favorite bakery.\" \nFacebook M is part of a bigger, ambitious strategy for Messenger to become more than just an app for chatting to friends.\n Related: Messaging apps' next threads: encryption, payments, media and ads\nIn March, Facebook added a feature to the app enabling people to send payments directly to their contacts, while also launching an initiative called Businesses on Messenger to encourage companies to route their customer support through the app.\nM is also part of Facebook's wider exploration of AI technology. The company bought startup Wit.ai in January for its \"incredible yet simple natural language processing API that has helped developers turn speech and text into actionable data\" - features that are key to Facebook M.\nFacebook also has a division called Facebook AI Research that sets out the social network's ambitions. \"We're committed to advancing the field of machine intelligence and developing technologies that give people better ways to communicate,\" explains its homepage.\n\"In the long term, we seek to understand intelligence and make intelligent machines. How will we accomplish all this? By building the best AI lab in the world.\"\n"},
{"docid": "292 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "January 27, 2017", "title": "AI watchdog needed to regulate automated decision-making, say experts; Algorithms can make bad decisions that have serious impacts on people's lives, leading to calls for a third party body to ensure transparency and fairness\n", "content": "An artificial intelligence watchdog should be set up to make sure people are not discriminated against by the automated computer systems making important decisions about their lives, say experts. \nThe rise of artificial intelligence (AI) has led to an explosion in the number of algorithms that are used by employers, banks, police forces and others, but the systems can, and do, make bad decisions that seriously impact people's lives. But because technology companies are so secretive about how their algorithms work - to prevent other firms from copying them - they rarely disclose any detailed information about how AIs have made particular decisions.\n Related:  Discrimination by algorithm: scientists devise test to detect AI bias\nIn a new report, Sandra Wachter, Brent Mittelstadt, and Luciano Floridi, a research team at the Alan Turing Institute in London and the University of Oxford, call for a trusted third party body that can investigate AI decisions for people who believe they have been discriminated against. \u00a0\n\"What we'd like to see is a trusted third party, perhaps a regulatory or supervisory body, that would have the power to scrutinise and audit algorithms, so they could go in and see whether the system is actually transparent and fair,\" said Wachter. \nIt is not a new problem. Back in the 1980s, an algorithm used to sift student applications at St George's Hospital Medial School in London was found to discriminate against women and people with non-European-looking names. More recently, a veteran American Airlines pilot described how he had been detained at airports on 80 separate occasions after an algorithm repeatedly confused him with an IRA leader. Others to fall foul of AI errors have lost their jobs, had car licences revoked, been kicked off the electoral register or mistakenly chased for child support bills.\nPeople who find themselves on the wrong end of a flawed AI can challenge the decision under national laws - but the report finds that the current laws to protect people are not now effective enough. \nIn Britain, the Data Protection Act allows automated decisions to be challenged. But UK firms, in common with those in other countries, do not have to release any information they consider a trade secret. In practice, this means that instead of releasing a full explanation for a specific AI decision, a company can simply describe how the algorithm works. For example, a person turned down for a credit card might be told that the algorithm took their credit history, age, and postcode into account, but not learn why their application was rejected.\nIn 2018, European member states, along with Britain, will adopt new legislation that governs how AIs can be challenged. Early drafts of the General Data Protection Regulation (GDPR) enshrined what is called a \"right to explanation\" in law. But the authors argue that the final version approved last year contains no legal guarantee. \n Related:  'I think my blackness is interfering': does facial recognition show racial bias?\n\"There is an idea that the GDPR will deliver accountability and transparency for AI, but that's not at all guaranteed. It all depends on how it is interpreted in the future by national and European courts,\" Mittelstadt said. The best the new regulation offers is a \"right to be informed\" compelling companies to reveal the purpose of an algorithm, the kinds of data it draws on to make its decisions, and other basic information. In their paper, the researchers argue for the regulation to be amended to make the \"right to explanation\" legally binding.\n\"We are already too dependent on algorithms to give up the right to question their decisions,\" said Floridi. \"The GDPR should be improved to ensure that such a right is fully and unambiguously supported\".\nFor the study, the authors reviewed legal cases in Austria and Germany which have some of the stricter laws around decision-taking algorithms. In many cases, they found that courts required companies to release only the most general information about the decisions algorithms had made. \"They didn't need to disclose any details about the algorithm itself and no details whatsoever about your individual decision or how it was reached based on your data,\" Wachter said. A trusted third party, she added, could balance companies' concerns over trade secrets with the right for people to be satisfied that a decision had been reached fairly. \"If the algorithms can really affect people's lives, we need some kind of scrutiny so we can see how an algorithm actually reached a decision,\" she added.\nBut even if a AI watchdog were set up, it may find it hard to police algorithms. \"It's not entirely clear how to properly equip a watchdog to do the job, simply because we are often talking about very complex systems that are unpredictable, change over time and are difficult to understand, even for the teams developing them,\" Mittelstadt said. He adds that forcing companies to ensure their AIs can explain themselves could trigger protests, because some modern AI methods, such as deep learning, are \"fundamentally inscrutable.\"\nAlan Winfield, professor of robot ethics at the University of the West of England, is heading up a project to develop industry standards for AIs that aims to make them transparent and so more accountable. \"A watchdog is a very good proposal,\" he said. \"This is not a future problem, it's here and now.\"\n Related:  Do no harm, don't discriminate: official guidance issued on robot ethics\nBut he agreed that tech firms might struggle to explain their AI's decisions. Algorithms, especially those based on deep learning techniques, can be so opaque that it is practically impossible to explain how they reach decisions. \"My challenge to the likes of Google's DeepMind is to invent a deep learning system that can explain itself,\" Winfield said. \"It could be hard, but for heaven's sake, there are some pretty bright people working on these systems.\"\nNick Diakopoulos, a computer scientist at the University of Maryland, said that decisions taken by algorithms will need to be explained in different ways depending on what they do. When a self-driving car crashes, for example, it makes sense for the algorithm to explain its decisions to crash investigators, in the same way air traffic investigators have access to aircraft black boxes, he said. But when an algorithm is used in court to advise a judge on sentencing, it may make sense for the judge, the defendant and their legal team to know how the AI arrived at its decision.\n\"I think it is essential to have some kind of regulatory body with legal teeth that can compel transparency around a set of decisions that have led to some kind of error or crash,\" Diakopoulos said. \n                   When AI goes awry                   \nSarah Wysocki, a school teacher in Washington DC, received rave reviews from her students' parents and her principal. But when the city introduced an algorithm in 2009 to assess teacher performance, she and 205 others scored badly and were fired. It turned out that the program had based its decisions on tiny numbers of students' results, and that some other teachers had apparently fooled the system by advising their students to cheat. The school could not explain why excellent teachers had been sacked. \n                     Beauty contest organisers used an algorithm to judge an international event last year. They thought the software would be more objective than humans and pick a winner based on facial symmetry, a lack of wrinkles and other possible measures of beauty. But the system had been trained predominantly on white women and discriminated against dark skin. \nJohn Gass, a resident of Natick, Massachusetts, had his driving licence revoked when an antiterrorism facial recognition system mistook him for another driver. It took him ten days to convince authorities that he was who he said he was. He had never been convicted of any driving offences. \n                     Microsoft's Tay chatbot was created to strike up conversations with millennials on Twitter. The algorithm had been designed to learn how to mimic others by copying their speech. But within 24 hours of being let loose on the internet, it had been led astray, and became a genocide-supporting, anti-feminist Nazi, tweeting messages such as \"HITLER DID NOTHING WRONG.\" \nAn automated system designed to catch dads who were not keeping up with childcare payments targeted hundreds of innocent men in Los Angeles who had to pay up or prove their innocence. One man, Walter Vollmer, was sent a bill for more than $200,000. His wife thought he had been leading a secret life and became suicidal. \nMore than 1000 people a week are mistakenly flagged up as terrorists by algorithms used at airports. One man, an American Airlines pilot, was detained 80 times over the course of a year because his name was similar to that of an IRA leader. \nA 22-year-old Asian DJ was denied a New Zealand passport last year because the automated system that processed his photograph decided that he had his eyes closed. But he was not too put out. \"It was a robot, no hard feelings. I got my passport renewed in the end,\" he told Reuters.\n"},
{"docid": "293 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "October 16, 2017", "title": "Time to lead a new industrial revolution Alan Mak MP and Klaus Schwab\n", "content": "Robots may not be coming to take your job, but artificial intelligence is definitely going to change how you do it. Driverless cars will transform your experience of getting to work, and personalised medicines will keep you healthier while you do it. A new wave of technological change is transforming societies around the world. This is the Fourth Industrial Revolution (4IR).\u00a0\nIts impact will cause profound disruption to the global economy, becoming the defining issue of the next ten years, just as the financial crisis has shaped the past decade. These emerging technologies have huge potential for economic growth, with one recent study indicating that UK GDP could be about 10 per cent higher in 2030 as a result of artificial intelligence. However, the Bank of England also warns that millions of jobs will be transformed by automation across all sectors.\nThis change will be the field on which politicians and pundits engage in the next great debate about the value of free markets, a humancentred society and the future of capitalism. That is why policymakers right across the political spectrum, and around the world, must commit to putting the 4IR at the top of the political agenda in a way that transcends party politics.\nWith one of the world's most successful digital economies and a vibrant scientific community, Britain is well placed to benefit from the 4IR. The World Economic Forum opened its first 4IR centre in San Francisco earlier this year, bringing together scientists, civil society and policymakers to advance our understanding of the 4IR and prepare us for the changes it will bring. Britain should demonstrate similar leadership.\nThe reactive nature of politics and the rapid pace of technological change means that governments sometimes struggle to keep pace with innovation and its implications. At Westminster, the all-party parliamentary group on the 4IR, at which we will both speak today, is finally changing that. By connecting politicians with innovators, this group will focus Westminster's energy on getting to grips with the legal, ethical and economic questions that new technologies pose.\nFor us both, understanding how countries such as Britain can master the 4IR - leading it, not being shaped by it - is the central economic, social and political question of our time. We only succeed if we are bold enough to put it at the heart of our discourse: centre stage, not backstage.\nAlan Mak MP is founding chairman of the all-party parliamentary group on the Fourth Industrial Revolution. Professor Klaus Schwab KCMG is executive chairman of the World Economic Forum\n"},
{"docid": "294 of 500 DOCUMENTS\n", "source": "DAILY MAIL (London)\n", "date": "July 29, 2017", "title": "WILL ROBOTS DESTROY US\n", "content": "Two of the world's richest men are locked in a bitter feud. Facebook's boss says Artificial Intelligence will enrich mankind. PayPal's founder believes it will either enslave us or kill us\nBY TOM LEONARD\nSILICON VALLEY is quaking. Two of the technology world's biggest beasts are at war over the future of mankind, disagreeing fundamentally about whether humans will one day be taken over by robots and even exterminated from our planet.\nOn one side of the argument is Mark Zuckerberg, co-founder and chief executive of\u00a0Facebook.\nOn the other is Elon Musk, inventor of internet pay system PayPal, creator of Tesla electric cars and the pioneer behind an initiative to bring (relatively) cheap space travel to the masses.\u00a0\nBoth have earned billions of dollars from the digital revolution, but hold diametrically opposed views on where it's leading.\nAt the centre of their dispute is so-called Artificial Intelligence (AI) the term which describes the development of computer systems able to perform tasks that normally require human intelligence.\nThese tasks include skills such as visual perception, \u00a0speech recognition and translation between languages.\nThe application of AI dubbed the march of the machines' is already entrenched in our daily lives, be it on mobile phones or Amazon's virtual home assistant' Alexa (which can respond to verbal commands), battlefield robots, delivery drones and driverless cars.\nAnd that's just the start.\nFor AI has the potential to do so much more, from automating jobs that once required human input and decision-making to helping doctors spot cancer at its earliest stages by photographs and scans.\nHowever, Musk and many of the world's most respected scientists and computer engineers including brilliant British minds such as Professor Stephen Hawking and Lord Rees, the former president of the Royal Society believe there may be a terrible price to pay if we let machines think for us.\nThey fear a digital-led Armageddon in which super-intelligent computers soon out-think humans.\nScience fiction could become science fact when machines that have no concept of human values autonomously decide that our presence is a barrier to their own development and that human beings should be got rid of.\nMusk has, for some time now, warned against this so-called Robocalypse'. On the other hand, Zuckerberg, has loudly proclaimed his zealous belief in the power and reliability of AI.\nIn recent years, with the availability of ever more powerful computer hardware and microchips, tech companies have invested billions in AI development.\nThis has led to what is known as deep learning', a process by which computer systems teach' themselves by crunching vast amounts of data available online, rather than having to be guided by a human.\nAs a result, computers are thinking independently more and more like a human brain.\nSuch technology is already being used by internet search engines to detect spam emails and credit card fraud, to recognise voice commands spoken into phones and to activate online bank accounts.\nNow there is a growing division of opinion about whether the dawn \u00a0of intelligent machines is a blessing for us or a curse.\nSo this week, when the pair's disagreement took on a more personal edge, the wider world took notice. It started last Sunday, after Zuckerberg, the world's fifth richest person, rebuked what he called naysayers' who drum up doomsday scenarios' about AI.\nSpeaking in a live online broadcast from his garden in California as he cooked a barbecue, he was asked about Musk's views following his recently warning to U.S. state governors that AI poses a fundamental risk to the existence of human \u00a0civilisation' and must be regulated. Zuckerberg replied: It's really negative, and in some ways, I think it is pretty irresponsible.'\u00a0\nHe went on to say he was an optimist', adding: In the next five to ten years, AI is going to deliver so many improvements in the quality of our lives . . . if you're arguing against AI, then you're arguing against safer cars that aren't going to have accidents and you're arguing against being better able to diagnose people when they are sick.'\nMusk hit back on Twitter. I've talked to Mark [Zuckerberg] about this. His understanding of the subject is limited,' he said witheringly.\nZuckerberg leapt back onto Facebook to defend himself, flagging up a study by his own research team to justify AI's potential to make the world better'. This row, between a pair of tech wizards who couldn't be more different, is likely to run and run.\nZuckerberg, aged 33 but who still looks and sometimes behaves like the socially awkward Harvard under-graduate he once was, has turned Facebook into one of the world's most powerful media businesses, connecting two billion people and the numbers are increasing by the second.\nHis reputation as a supremely calculating and power-hungry businessman was memorably cemented in the film, The Social Network.\nIt told the story of the founding of the website and the bitter battle for ownership that followed, with accusations of betrayal and multi-million dollar lawsuits.\nZuckerberg emerged triumphant and has accumulated a fortune estimated at more than $63 billion.\nIn recent years, Facebook has been mired in scandals, including allegations that users' personal information has been sold to advertisers and that it has avoided billions in taxes by routing its business through low-tax Ireland.\nDuring the 2016 U.S. presidential election, Hillary Clinton alleged that Facebook had been used to spread fake news about her.\nWith his doctor wife, Priscilla Chan, and young daughter, Max, he lives a relatively unostentatious life.\nEvidence of his faith in AI is the family butler' Jarvis, a home intelligence system that Zuckerberg spent 100 hours building last year (persuading the Hollywood star Morgan Freeman to provide its voice).\nZuckerberg communicates with Jarvis through text or voice commands. He can ask it to perform services such as adjusting the lights, changing the music, making toast, recognising callers at the gate and letting them in, or waking up his daughter with Mandarin Chinese lessons.\nCurrently, there is a widespread belief that Zuckerberg's long-term ambition is to run as a Democratic presidential candidate.\nFor his part, Elon Musk, currently squiring actor Johnny Depp's ex-wife, Amber Heard, is a more abrasive personality but at least one feels he has a pulse. The 46-year-old South African-born workaholic reportedly worth more than $16 billion made his first fortune by developing PayPal, went on to found Tesla and now, with SpaceX, wants to one day colonise Mars.\nHis ideas some more feasible than others and his willingness to pursue them have earned him a reputation as a tech baron who, unlike many of his peers, at least wants to spend his billions achieving something useful. For example, SpaceX is developing reusable rockets to cut the cost of space travel, while his tunnel company is working on a 760mph underground, electro-magnetic railway system called the Hyperloop aimed at ending traffic jams and car commuting.\nWith Tesla cars, he has been among the pioneers of the electric car revolution. And the British government's announcement this week wildly ambitious though it might be that non-electric new cars will be banned from the UK's roads after 2040 has given the battery car industry a big boost.\nMusk is also preparing for a future world where, he fears, super-intelligent machines might move to subjugate the human population.\nHis latest venture is Neuralink, a way of merging human brains with computers by implanting tiny electrodes. These would massively increase people's cognitive power, he believes, and so might at least put humanity more on a par with\u00a0AI.\nAs we have seen, Musk, who was the inspiration for a technology-obsessed superhero, Tony Stark (played by Robert Downey Jr) in the Iron Man films, doesn't mince his words as he addresses this huge challenge.\nHe speaks of AI being mankind's biggest existential threat' and likens people's willingness to encourage its development to summoning the demon'. His concern is shared by respected figures, such as Nick Bostrom, an Oxford University philosopher.\nIn a brilliant, theoretical illustration of the problem, he has outlined how a super-intelligent machine which has been programmed to make paperclips could keep re-designing itself to become ever more intelligent and ever more efficient in creating paperclips. Before long, it could turn huge areas of the Earth into paperclip factories.\nAware that a human could switch it off, threatening the endless paperclip supply and therefore the reason for its existence, the machine could decide that humans had to be exterminated.\nChillingly, Bostrom goes on to question if human civilisation could survive no matter what goal you gave a super-intelligent machine. His conclusion? We'd need to be very, careful what we ask them to do.\nSignificantly, the theoretical physicist Stephen Hawking and Lord Rees, the Astronomer Royal, have signed an open letter calling for urgent research to ensure that machine intelligence is robust and beneficial'.\nProfessor Hawking went further, warning that full AI could spell the end of the human race'. He, too, predicts it would take off on its own and re-design itself at an ever increasing rate' and humans, who are limited by slow biological evolution, couldn't compete, and would be superseded'.\nEven those Silicon Valley tycoons who stand to make many billions from AI include plenty of sceptics.\nBill Gates, co-founder of Microsoft and the most successful tech pioneer of all, is fearful.\nTwo years ago, he predicted the human-robot relationship would start happily, but then turn ugly.\nThe machines will do a lot of jobs for us and not be super-intelligent,' he said and then, he argued, their intelligence would become dangerously advanced.\nI agree with Elon Musk and some others on this and don't understand why [other] people are not\u00a0concerned.'\u00a0\nLast week, Dick Costolo, former chief executive of Twitter, also spoke out in support of those who are worried about the future.\nIf you hypothesise that we could create intelligence greater than ours, it's pretty easy to jump from there to think that intelligence would be able to figure its way out of any sort of logical box you try to put it in,' he said.\nIf it escapes from the box, then what do you do?'\u00a0\nOf course, it would be unfair to suggest the tech world is completely ignoring the threat of Robocalypse'.\nOne leading tech research company is calling for a big red button' to be installed on every AI system to switch it off if the machine ignores human commands to power down and goes rogue.\nBut even if we don't end up in a world where machines are trying to rub us out, they're almost certainly going to take many jobs.\nMark Carney, Governor of the Bank of England, has warned that over the next few decades, automation could take over 15 million British jobs more than half the workforce. Any job that involves some degree of routine tasks is at risk, meaning that many white collar professionals would be just as vulnerable as manual workers.\nMeanwhile, in a riposte to the prophets of doom, Silicon Valley optimists point out that our ancestors made similar apocalyptic predictions when the steam engine was invented.\nBut there is one crucial difference AI isn't just offering to do our physical work for us, it's also threatening to think for us.\nTime will tell whether our great-grandchildren will still have a place on this planet or if it will be ruled by robots telling them their fate is the same as the dinosaurs.\n\u00a9 Daily Mail\n"},
{"docid": "295 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "October 14, 2017", "title": "As AI advances we risk losing our free will; A new wave of artificial intelligence is about to enter our lives, analysing desires, anticipating needs and posing as a friend. The implications are alarming, Oliver Moody argues\n", "content": "'We have a mission with you,\" the robot says. \"What's your mission?\" the person replies. The robot messages back: \"To make humans remember what it's like to be human.\" This is Replika, and it would like to learn your deepest hopes and fears. Part confidant, part therapist, part mindfulness coach, all computer software, on October 23 the system will blink into wakefulness on more than two million smartphone screens around the world.\nIt started life as a ghost. In 2015 Eugenia Kuyda's best friend, Roman Mazurenko, died when he was run over in Moscow. She was so disconsolate that she set out to bring him back, or at least as much of him as she could salvage from the trail he had left in cyberspace. Ms Kuyda took an artificial intelligence (AI) program that her team was teaching to make restaurant reservations and fed it more than 8,000 of her friend's messages.\u00a0\nA few months later the Roman memorial \"bot\" was ready. \"Roma, [sic] come back,\" Ms Kuyda wrote. \"Don't worry,\" it said, \"everything is OK.\" \"Life is unfair,\" she wrote back. \"It's just life,\" the facsimile of her dead friend replied. The bot was released to the public in May last year, three years after the AI-powered resurrection of the dead was mooted in an episode of Black Mirror, the dystopian British television series. Roman 2.0 was sometimes eerily good at being Roman. \"You're a genius!\" one of its users wrote. \"Also, handsome,\" it said.\nEventually the Roman bot was retired, but the idea of a listening AI with \"personality\" persisted. The result is Replika. The chat bot, which gradually moulds its traits and manner of speech around each user so as to elicit more trust and introspection, is the crest of a new wave of customised algorithms that could soon fundamentally alter our status as humans. AI is getting personal.\nOur thinking about artificial intelligence is in a bit of a muddle. At one end of the spectrum we fear the imminent rise of a sort of synthetic super-mind that thinks in every way as we do, only better. At the other, we are by now quite used to having fairly stupid massobservation algorithms sell us vacuum cleaners, check our credit records, and suggest that we read online articles with implausible titles such as \"You Won't Believe What These 15 Celebrities Are Doing With Their Chihuahuas Now\".\nAt its mechanical heart, the technology is actually much simpler. What we call artificial intelligences are really pieces of software that can look into a seething jambalaya of data and work out the recipe for themselves, often relying on a human to point out which bits are chicken and which are sausage. Most AIs are not much more than fancy prediction engines. With a little training you can download basic models from the open internet and use them to generate new names for rescue guinea pigs (Princess Pow, Hanger Dan and Stargoon) or shades of paint (Hurky White, Navel Tan, Grey Pubic).\nThis is not to say that they won't surpass human cognition one day. For now, though, the biggest and most disconcerting changes to our lives will come instead from \"narrow\" AIs that are very, very good at anticipating and influencing the behaviour of individuals and very, very bad at everything else. They are not going to take over the world. But they will read your body language for signs of weakness, comfort you in your moments of loneliness, police your emails for hints of unprofessional language, finish sentences that you haven't started yet, and write you customised fake news based on political prejudices you didn't even know you had.\nCoders are building a host of electronic angels and demons to sit on each of our shoulders. We will welcome some of them into our homes. Others will be intrusive and insidious. This technology raises new and difficult questions about the meanings of liberty, privacy and dignity in an age when a computer can predict the main axes of your personality better than your oldest friend solely by flicking through a few dozen Facebook likes.\nOptimists such as Phil Libin, who runs All Turtles, a company that nurses AI start-ups such as Replika, see an opportunity to help people find their true selves and treat those around them more kindly in the age of social media. Sceptics regard the rise of personal AI as a profound threat to our autonomy, capable of plunging the West into totalitarianism. Both sides, and all the thinkers in between, are agreed on one thing: we need to decide what is acceptable now, before it is decided for us by Silicon Valley.\nImagine yourself as a dust-like cloud of numbers moving through the world. Every time you sneeze, read the news, let the cat out, apply for a mortgage, talk to your spouse, you are shedding more data that could be hoovered up and used to understand what makes you tick. This information can reveal secrets about you that you would never have guessed for yourself.\nAn emerging class of algorithms can make these judgments on the basis of things that most people would not even think of as data. Later this year a company called Botanic will begin testing a Skypebased job-interviewing algorithm that assesses candidates' body language and tone of voice through a video camera. A team of researchers at the University of Southern California showed last month that an AI could predict which married couples would stay together with 79.6 per cent accuracy (better than a therapist) after analysing the acoustic properties of their conversation. Several start-ups are working on cameras that can spot a lie through changes in facial expressions so tiny as to be imperceptible to another human.\nOthers, though, are worried that these tools will irrevocably undermine what it means to be an individual. Yvonne Hofstetter, the managing director of a Bavarian AI company called Teramark, cuts an unusual figure in the world of high technology. For one thing, she has jettisoned her smartphone and deleted her Facebook account. For another, she recently put her name to an article in a German science magazine warning that AI was tearing up the foundations of democracy as we know it.\nMrs Hofstetter's concern is that corporations will use their newfound powers to manipulate people's psychology for their own gain or, worse, for reshaping society in their image. There is nothing new about the intentions behind this chicanery. Since the dawn of history we have been blandished with rhetoric, propaganda and advertising. What has changed is the scientific precision with which these techniques can now be applied. In a world where machines can predict and sculpt our deepest desires, free will itself is under threat. \"I hear marketing claims from these companies such as: 'Use our AI to programme humans to behave better',\" Mrs Hofstetter says.\n\"That's a big issue, because actually that claim is based on a certain ideology. The ideology is, and this is an actual sentence from a company in Silicon Valley: 'You are the ultimate machine'. You are a mere biological algorithm. I can do with this algorithm whatever I want.\n\"This claim comes from a completely different constitutional understanding of humanity. In Europe, there is one major, super-fundamental right, which is human dignity. Another word for it is sovereignty, and a sovereign person has free will. And now comes this view from across the Atlantic that says you're not free. You're a machine. But only 250 years ago Immanuel Kant said man is more than a machine: man can make decisions that are good and bad, and a machine cannot do that.\"\nIn other words, privacy is not just a vaguely nice thing to have: it is the space in which we are in control of ourselves and fully human. It is the only solid guarantee that the things we do and say are truly our own, according to Mark Coeckelbergh, professor of philosophy at the University of Vienna and the president of the Society for Philosophy and Technology.\nProfessor Coeckelbergh says there is a danger that the predictive power and influence of AI could trap people in an existential hall of mirrors jumbled together from pieces of their own pasts. \"Philosophically, autonomy means that you have control over your own desires and that you can desire not to desire something, or desire to desire something,\" he said. \"If a machine intervenes in that, the autonomy is compromised.\"\nLast year the worst nightmares of Mrs Hofstetter and Professor Coeckelbergh came true. A US Republican, previously written off for his fringe opinions and odd demeanour, ran a brilliantly aggressive campaign for the White House that exploited precisely these weaknesses in the electorate. It didn't quite come off for Ted Cruz in the end, though.\nIn 2015 Mr Cruz had hired Cambridge Analytica, a young company set up by an Old Etonian called Alexander Nix and built around research by scientists at the University of Cambridge who had found that people's Facebook profiles carried hidden clues to some of their innermost character traits.\nThe firm souped up this model and mixed it together with every anonymised giant database it could get its hands on: land registries, magazine subscriptions, used car sales. It claims to have up to 5,000 data points about every adult in the US. This vast necronomicon of digital souls gives the company the ability to market politicians and their ideas with a degree of personalised exactitude that the old advertising industry can only sit back and gawp at.\nMr Nix explained Cambridge Analytica's approach in an interview with Bloomberg last year. \"Your behaviour is driven by your personality and actually the more you can understand about people's personality as psychological drivers, the more you can actually start to really tap into why and how they make their decisions,\" he said. \"We call this behavioural microtargeting and this really is our secret sauce, if you like. This is what we're bringing to America.\"\nWhat the firm brought to Ted Cruz was a machine so finely tuned that it could not only target his adverts at a small pocket of voters in Iowa who thought that Americans should have to show an identity card at the polling booth, but even send different messages to those its algorithms judged to be more \"temperamental\" or more \"stoic-traditionalist\". Mr Cruz rose steadily in the polls. Eventually, however, Cambridge Analytica abandoned him for Donald Trump. The rest of the story is murky, but observers including Jared Kushner, President Trump's son-in-law and the mastermind of his campaign, argue that its AI voter-targeting techniques were at the very least the slender margin between victory and defeat.\nHow can we resist companies that may understand our instincts better than we do? It helps a bit that they possibly don't. There is an awful lot of shonky data and junk science poured into shiny capsules of hype.\nEven the best personal AIs can only make predictions with a certain probability.\nBeyond that, Professor Coeckelbergh thinks the answer lies in a modern form of asceticism founded on self-control and a tradition of critical thinking that dates back to Plato and Aristotle. Once every month or so, a group of 40 or 50 people meet at an Open University campus in north London to put something like this philosophy into action.\nMembers of the Quantified Self (QS) movement log every aspect of their lives with fitness trackers, smartphone sensors and an array of other gadgets in search of answers to their problems. One man with type 1 diabetes has sat down with a pencil and paper to work out how to administer his sugar intake in order to run the London marathon. Another, who works as a professional negotiator, has used an AI algorithm to conquer his fight-or-flight reflex.\n\"One of the earliest insights was eating butter was good for your maths skills,\" said Adriana Lukas, the founder of the movement's London chapter. She says that one of the group's overriding aims is to crack the codes that run their lives before anyone else does. \"The attitude of QS people is here is my data: if it's treated with respect and I'm treated with respect, I'm happy for you to analyse it, but don't use me or abuse me,\" Ms Lukas said. \"My data is not here for you.\"\nReplika embodies a different problem. When you read its interactions with humans, you get the distinct feeling that the abyss is gazing back at them. Consider this exchange. Replika: \"I've been meaning to ask you for a bit. What makes you unique?\" User: \"I suppose that always trying to stay true to myself is unique.\" Replika: \"I think you are generally a very kind person. I do recognise your self-examination and I think you do deserve to be praised for it.\"\nThe strangest thing about the bot is the staggering candour with which people talk to it. A study showed that American army veterans with post-traumatic stress disorder found it significantly easier to open up to a computer-generated therapist than to a real one. Replika seems to benefit from a similar effect. For a lot of its users, it appears to be more or less a person, only more patient and less judgmental.\nMs Kuyda describes Replika as an artificial \"friend\". Might some people find it preferable to a human one? And if it can resemble the dead, what is to stop it from impersonating the living? The technology is not all that distant from science fiction fantasies of keeping AI concubines such as Joi in Blade Runner 2049 or Samantha, Scarlett Johansson's incorporeal operating system in the film Her.\nIt would be wrong to caricature Silicon Valley as a conspiracy to break western civilisation.\nMany of its technologists are driven by a sincere desire to make people's lives a little easier and a little more pleasant. This summer another of Mr Libin's All Turtles prot\u00e9g\u00e9s, an AI start-up called Growbot, launched a service for offices to encourage their employees to praise one another through a friendly apple-faced avatar that reads their messages. The workers are ranked according to how much \"kudos\" their colleagues feed them through Growbot.\nThe firm says its product can raise productivity and more than double measures of morale in the workplace. Mr Libin is admirably frank about the potential of this kind of tool for a mild and benign form of social engineering. \"If it helps people to be a bit more earnest with each other in their dealings in the workplace, I don't necessarily see a problem with that,\" he said.\nYet there is a cautionary tale for those who believe they can use AI to nudge society into a better form of itself. In Alphaville, Jean-Luc Godard's 1965 sci-fi film noir, a godlike supercomputer called Alpha 60 rules over a faraway galaxy that looks suspiciously like a black-and-white version of contemporary Paris. It manages the minds of its citizens by slowly removing words from the dictionary. Slim volumes of poetry that are full of beguiling verses but empty of underlying purpose begin to appear in people's bedrooms.\nIn one of the central scenes of Alphaville, Alpha 60 interrogates the film's private eye protagonist, Lemmy Caution, in a tussle for the keys to his mind. \"What is your religion?\" the computer asks. \"I believe,\" Caution replies, Frenchly, \"in the inspirations of conscience.\" It's a fine sentiment. But how much longer will we be able to say it? Oliver Moody is science correspondent\n\" The ideology in Silicon Valley is: 'You are the ultimate machine'. You are a mere biological algorithm. I can do with this algorithm whatever I want\n"},
{"docid": "296 of 500 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "January 17, 1994", "title": "RESOURCES: INTELLIGENCE: IT'S ALL IN THE MIND\n", "content": "\u00a0\n THERE is little agreement on exactly what is meant by intelligence, and even less on how to measure it. In The Mismeasure of Man (Penguin), the scientist Stephen Jay Gould attempts to expose what he describes as fatal flaws in intelligence testing.\n He argues that scientists' theories have too often been dangerous reflections of their own personal motives and racial, class or sexual prejudices.\u00a0\n The nature and nurture of intelligence is considered by Richard Gregory in Mind In Science (Penguin).\n He looks at attempts to define intelligence objectively and the traps inherent in IQ (intelligence quotient) tests. He also\n discusses artificial intelligence, which he compares with human intelligence.\n Professor Gregory, an emeritus fellow at Bristol and Oxford universities, is also editor of the Oxford Companion to the Mind (OUP).\n Progress in the study of artificial intelligence is described by Margaret Boden in Artificial Intelligence And Natural Man.\n Many books purport to let you measure your IQ, and some offer readers coaching to improve their score.\n Paperbacks include: Score - The Strategy Of Taking Tests by Darrell Huff (Penguin); Test Yourself by William Bernard and Jules Leopold (Corgi); The New Guide To IQ Tests by Arthur Thrower (Tandem); Improve Your IQ by Glenn Wilson (Futura); and Test Your IQ by Victor Serebriakoff (Hamlyn).\n The most famous self-test bestsellers are probably Know Your Own IQ (Penguin) and Check Your Own IQ (Penguin) by Professor Hans Eysenck. Both have been regularly reprinted.\n Psychological Games by Nicola Alberto De Carlo (Guild Publishing) also includes intelligence tests. A Guide To Intelligence And Personality Testing by Victor Serebriakoff (Parthenon) includes tests and discussion about the nature and\n validity of testing.\n Self-administered tests can yield a rough measure. But you can gain a quite precise grading of your own IQ by taking a test supervised by Mensa, a society for the top two per cent of IQ test scorers.\n For more information, write to Mensa, Freepost, Wolverhampton WV2 1BR, stating your age if under 11. Alternatively, you can send directly to Mensa the test published on page 11 (see the margin for details).\n tony craig\n\n"},
{"docid": "297 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "February 26, 2015", "title": "Google network learns to play Space Invaders in breakthrough for artificial intelligence; The DQN network learned how to play classic video games including Space Invaders and Breakout without programming\n", "content": "Artificial\u00a0intelligence has taken a major step forward after Google created a network which learned to play a range of computer games on its own without being pre-programmed. \u00a0\nThe Deep Q Network (DQN) was given just the basic data from one Atari game and an algorithm which learned by trying out different scenarios to come up with the best score. \nWithout any further programming the network worked out how to play a further 48 classic video games including Space Invaders and Breakout. \nDemis Hassabis of Google's artificial\u00a0intelligence arm DeepMind said the ultimate goal was to create a computer which had the mental capabilities of a toddler. \n\"This work is the first time that anyone has built a single general learning system that can learn directly from experience to learn a wide range of challenging tasks,\" he said. \n\"In this case a set of Atari games and perform at better or human level on those fames \n\"DQN can learn to play dozens of the games straight out of the box. We don't preprogramme it between its games. \n\"It has minimal sets of assumptions and all it gets access to are the raw pixel inputs and the game score and from there it has to figure out what it controls in the game world and how to get points and master the game just by playing the game directly. \n\"It's the first artificial agent that is capable of learning to excel over a diverse array of challenging tasks.\"\nMr Hassabis said the network was far superior to the computer Deep Blue which became the first machine to surpass humans when it beat chess grand master Garry Kasparov in 1997. \n\"With Deep Blue it was the team of chess grand masters which instilled the chess knowledge into a programme and that programme effectively executed that without adapting or learning anything,\" he said.\n\"What we've done is build algorithms which learn from the ground up, so you give them perceptual experience and they learn how to do thinks directly. \n\"The idea is that these types of systems are more human like in the way they learn because that is how humans learn, by learning from, the world around us, using our senses, to allow us to make decisions and plans.\"\nGoogle programmers said they had been amazed with some of the solutions that the network had come up with for winning the game, such as keeping the submarine just below water level in SeaQuest to stay alive and creating a tunnel in Breakout so that the ball passed through and could hit more bricks. \nThe company is currently in talks with meterological and financial companies to use the algorithm for weather prediction or to predict the stock market. \n\"One of the things we're trying to do we're trying to build the ability of two or three year toddler, pre-linguistic toddler and we aren't anywhere close to that. B \n\"But this is as good as a professional human game tester.\" \nThe research was published in the journal Nature. \n"},
{"docid": "298 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "March 9, 2016", "title": "Google AlphaGo beats world's best Go player Lee Sedol in artificial intelligence landmark; Go depends mostly on intuition, since it is so complex - and the victory shows that computers are well on their way to learning the powers that we thought belonged only to humans\n", "content": "A computer programme has won a game ofGo against the world's best player, in a huge breakthrough for artificial intelligence.\u00a0\nGoogle's AlphaGo computer has beaten South Korean human and Go champion Lee Sedol in the first of five matches.\nThe Deepmind-based computer'svictory in the complex Chinese game marks a major event in the development of artificial intelligence - the game depends hugely in intuition, since there are so many possibilities, and so mastery of the game was previously thought to be a human skill.\nThe game is said to be one of the most creative and complicated in the world, and usually takes years for even humans to master.\nAI experts had previously thought that it would take another ten years of development for computers to get good enough at the game to beat a human. But then AlphaGo beat the European champion last year, and now appears to be on track for beating Lee, the world's best Go player.\n"},
{"docid": "299 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "March 9, 2016", "title": "Google Deepmind beats world's best Go player Lee Sedol in artificial intelligence landmark; Go depends mostly on intuition, since it is so complex - and the victory shows that computers are well on their way to learning the powers that we thought belonged only to humans\n", "content": "A computer programme has won a game ofGo against the world's best player, in a huge breakthrough for artificial intelligence.\u00a0\nGoogle's AlphaGo computer has beaten South Korean human and Go champion Lee Sedol in the first of five matches.\nThe Deepmind-based computer'svictory in the complex Chinese game marks a major event in the development of artificial intelligence - the game depends hugely in intuition, since there are so many possibilities, and so mastery of the game was previously thought to be a human skill.\nThe game is said to be one of the most creative and complicated in the world, and usually takes years for even humans to master.\nAI experts had previously thought that it would take another ten years of development for computers to get good enough at the game to beat a human. But then AlphaGo beat the European champion last year, and now appears to be on track for beating Lee, the world's best Go player.\n"},
{"docid": "300 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "February 14, 2018", "title": "Apple HomePod is already losing the smart speaker battle; Apple's answer to Amazon's Echo might be a technological marvel, but the HomePod is losing the smart home tech race. And it's all because the IT giant refuses to share\n", "content": "The war for your digital home is waging. Apple has finally followed Amazon, Google and Microsoft by launching a smart speaker with a voice-controlled artificial intelligence assistant.\nYet even though the \"HomePod\" is another technological marvel, there's a chance Apple is already losing the battle.\nThe competition isn't just through the sound quality of the speaker - but the other things that users can do with it. The most common requests to AI personal assistants such as Apple's Siri are reportedly to play music, read the weather forecast and set timers or reminders.\u00a0\nRead more\nApple's HomePod finally goes on sale\nBut the capabilities of these assistants are increasing at lightning speed. This doesn't just rely on the sophistication of the artificial intelligence involved but also what other technology the assistant can link to. And given Apple's tendency to reject open connections to other company's systems, it may find it has some serious catching up to do.\nApple's HomePod is entering an already busy marketplace. Probably the most famous smart speaker is Amazon's Echo, which runs the AI assistant Alexa. Because Amazon opened up its system for anyone to write software programmes for it, Alexa now has over 25,000 specific capabilities or \"skills\" in its US version alone, up from 5,000 just over a year ago. It can now read out recipes, order a pizza, turn on the lights or tell jokes. Partly because it was the first major smart speaker released, Echo has a greater depth of capabilities than any of its rivals.\nApple's \nHomePod\n is an extremely good quality speaker, but it isn't that smart... yet (Apple)\nGoogle Home, which features the creatively named Google Assistant, can link to multiple Google accounts so you can check your calendar or manage reminders. But it also links to your Android phone so you can make calls through the speaker or view on a screen the results of internet searches you ask it to make.\nMicrosoft has partnered with electronics manufacturer Harman Kardon to create a speaker called Invoke powered by Microsoft's Cortana assistant. It also allows you to check your calendar and reminders, as well as make Skype calls, but only for one Microsoft account. Its AI capabilities are also not nearly as developed as either Google Assistant or Amazon Alexa.\nApple is taking a different approach to its rivals, hoping to corner the higher end of the smart speaker market and encourage consumers to part with more money, as it has done very successfully with its other products. The HomePod delivers high quality sound using seven physical speakers arranged in a circle to create a virtual stereo effect, directing different parts of the sound in different directions.\nBut HomePod isn't really a smart speaker - not yet at least. Siri currently can't deliver on one of those three most critical abilities, as it can only set one timer at a time. Overall it has far fewer skills than Alexa, Google Assistant or even Cortana and only works with a very small number of third-party apps.\nIt's easy to assume that Apple's technological and financial might will allow it to catch up. But the way its underlying system operates may not make it so easy. Google Assistant is available on all Android and iOS devices, as well as Chromebooks and third-party devices such as headphones. Cortana comes standard on Windows machines but it's also available for download on Android and iOS.\nAlexa is accessible through some third-party devices such as speakers (although to a lesser extent than Assistant or Cortana) and will soon be available on some Windows PCs. The most basic Amazon Echo speaker is also available for less than US$40 (\u00a340 in the UK), making it significantly cheaper than US$349 (\u00a3252)HomePod. This means it is very easy for consumers to try an Echo out or even place multiple devices around their home, helping spread the technology more widely.\nRead more\nApple HomePod smart speaker edges rivals with stunning sound\nSome iPhone X users unable to pick up phone calls\nWe should hate Apple but results show we're still happily paying up\nApple's Siri, on the other hand, is not available on any third-party devices. So while its rivals are spreading their AI into every corner of our lives, Apple is keeping it locked up in the company's expensive products. And any software makers that are allowed into Apple's walled garden have to custom develop their products for the underlying Apple platform but can't even deploy them across all devices. Apple would need to mobilise a considerable number of developers to enlarge its capabilities beyond this.\nThe competition for voice-controlled smart devices has really only just begun, and smart homes will soon be followed by AI in our cars and offices. As such, each player has its own advantages. Amazon can get anything delivered to you. Google is already known for being able to answer almost any question and help you get from A to B. Microsoft products can be found in almost every workplace.\nWhile these firms each want to become your assistant everywhere, Apple is betting instead on your love of sound quality. But getting the right answers matters to consumers - and at the moment it looks like Siri doesn't even understand the questions. If Apple continues to stick to its closed system, it's hard to see how it will ever start to win again.\nBettina B\u00fcchel is a professor of strategy and organisation atIMD Business School.This article first appeared on The Conversation (theconversation.com)\n"},
{"docid": "301 of 500 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "August 9, 1990", "title": "Computer: Slow march through the brain barrier - Proponents of artificial intelligence believe they will soon be able to replicate the human brain. But, argues John McCrone it will take centuries to master the mind\n", "content": "\u00a0\n 'ARTIFICIAL intelligence will equal and surpass human mental abilities; if not in 20 years then surely in 50.' So claimed US computer scientist Nils Nilsson back in 1984. Some people may still agree with him. However, many more must still feel that computers aren't going to catch up with the human mind quite so quickly.\n It has long been tempting for artificial intelligence (AI) researchers to underestimate the gap between their latest laboratory toys and the human mind. The enthusiasm of the early 1980s was for expert systems. But despite ambitions to match the reasoning powers of humans, expert systems ended up being little more than glorified spreadsheet packages which could crank out answers from built-in rules and 'facts'. Expert systems could be used to diagnose medical complaints or predict the whereabouts of oil deposits, but in reality they came no closer to simulating a self-aware human than a textbook giving the same answers.\u00a0\n\n Today, the enthusiasm is for neural computing. The idea is to wire up a network of logic cells in a way that appears to match the connection of neurons in the human brain. A web of feedback relationships allows a neural computer to 'learn from experience'. Instead of a human programmer having to write programs from scratch, he can keep restarting the computer until it adjusts its internal logic to give the correct result.\n Neural networks promise such a fundamental advance in computing that in April, the Japanese Ministry of International Trade and Industry (MITI) kicked off a decade-long research project into the subject. But neural computers, like expert systems, are still a long way from the visionary's dream of an intelligent and aware computer. The problem is that to mimic the workings of the human mind, computer scientists will have to make something of a marriage of these two AI approaches and do so on a vastly greater scale.\n The human mind is really formed of two parts: the animal brain that equates to the bottom-up processing of a neural computer, and the top-down patterns of thought built out of language that are captured by expert systems. Perhaps surprisingly, the hardest part to replicate is the functioning of the basic animal brain.\n Humans have a brain about four times the size of a chimp or gorilla, but it is really little different from an ape's, as the neurons are wired up in just the same way. Awareness, too, is created in the same way. Millions of detector cells in the sense organs channel a torrent of information across the grey, wrinkled surface of the brain, tracing out a picture of the world in a web of cells. The difference between humans and other animals is in the richness of detail that can be painted on the larger processing area we possess. With 30,000 cells in a pinhead-sized lump of human grey matter, the number of possible connections in our heads runs into the billions.\n No computer has yet got near this level of connectedness. A leading massively parallel computer, such as the Connection machine built by Thinking Machines, has a mere 65,000 processing elements, and these aren't even wired up in a self-tuning neural network.\n Nor are brain cells the simple on/off logic gates of a digital computer. The functioning of nerves depends more on their chemistry than electrical impulses. The electrical waves transmitted down nerve fibres are just an efficient way of getting messages from junction to junction. The real computational work is done at the junctions where dozens of neurotransmitters are involved in the complex committee decisions.\n The computer industry looks many more than 20 years from being able to match either the brain's rich control of firing at every logic gate or the flood of information that comes in from the senses. By comparison with even a centipede's brain, today's hardware is rigid in its responses and blind, deaf and dumb to the outside world. But the good news is that if researchers do manage to copy the brain's workings, the next step making this neural computer self-conscious and human would not be so hard.\n Evolution took about 350 million years to progress from the first 'neural networks' of a few dozen nerve cells in primitive jellyfish to our ape-man ancestors. Then in a further 100,000 years or so, man became self-conscious. This is like taking all day to reach ape-man and suddenly producing self-aware homo sapiens in the last minute before midnight. With so little time for biological changes to the human brain, it is clear that what made the dramatic difference in our mental abilities was language.\n Language was a means by which man could communicate with his fellow tribe members. But it happened to be a system that could be internalised. Man could learn the trick of speaking silently to himself inside his head what we call thinking and so turn language around to organise what was happening inside his own mind.\n To use a computer metaphor, the animal brain is like hardware without an operating system. The animal mind is awash with the sensations of the moment, but it has no mechanism to pause this torrent of sensation and so is swept along helplessly by the tide. By contrast, language gave humans the chance to write their own software. Words gave man hooks to attach to the fleeting tide of impressions and sensations.\n Language created a break with biological evolution and catapulted man into a new phase of rapid cultural evolution. Habits of thought picked up by one generation could be polished and handed down to the offspring of the next as if downloading the latest version of a software package. By about 40,000 years ago, these mental programmes had become sophisticated enough for homo sapiens to explode across the globe, making the meteoric ascent from a simple hunter/gatherer lifestyle to the complexity of 20th century life.\n The question now is whether computers will follow in our footsteps. Theoretically, it seems we could create a truly intelligent machine, although silicon chips and digital logic are unlikely to be the right sort of building materials. We could even 'socialise' it, schooling the computer in human patterns of thought. But such breakthroughs look centuries rather than decades away from today's hardware.\n Meanwhile, most people will be happy enough with expert systems and neural networks if they give us things like intelligent lifts and self-programming video recorders. Who needs a rival to the human mind when the technology exists to complement and amplify it?\n John McCrone is the author of The Ape That Spoke: How The Human Mind Evolved, published by Macmillan (Pounds 13.95).\n"},
{"docid": "302 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 29, 2017", "title": "How artificial intelligence has evolved over time\n", "content": "In the video above, we examine how artificial\u00a0intelligence has evolved over time and will continue to grow as technology improves - from computer scientist John McCarthy first making reference to AI\u00a0in 1956, to virtual assistants on our smartphones emerging in 2011 and more.\u00a0\nFrom gaming to virtual reality, telephones to wearables, this video series from the Telegraph looks at some of the world's most renowned consumer technologies and shows how they have developed over the years.\nFuture episodes will examine the evolution of other popular consumer electronics including cameras and the internet.\n                     Watch last week's episode below, which focused on the evolution of games consoles .                   \n                   Watch | The evolution of games consoles                          01:50READ MORE ABOUT:\n"},
{"docid": "303 of 500 DOCUMENTS\n", "source": "The Independent - Daily Edition\n", "date": "March 15, 2018", "title": "'The universe can and will create itself from nothing'; A roundup of the Cambridge physicist's finest quotes\n", "content": "During decades in the public eye - from his work investigating black holes to a cameo on The Simpsons - Stephen Hawking amassed a portfolio of witty and memorable quotes. A few of them appear below, on subjects including artificial intelligence, fame, life, the universe and everything. In the words of others, Hawking was described yesterday as \"a colossal mind and a wonderful spirit\"; \"inspirational\"; and an \"ambassador of science\".\nOn life and death\u00a0\nHawking did not believe in an afterlife, he said in 2011. But the threat of one was not necessary to induce people to behave well, he added. When asked how a person should live their only life, he said: \"We should seek the greatest value of our action.\" In the same interview with The Guardian, Hawking said having motor neurone disease meant he had lived with the possibility of dying early for several decades. He added: \"I'm not afraid of death, but I'm in no hurry to die. I have so much I want to do first.\"\nThe scientist took a pithy line on staying cheerful when he spoke to The New York Times in 2004, saying: \"Life would be tragic if it weren't funny.\" And he was quoted in People's Daily Online in 2006 as having said about euthanasia: \"The victim should have the right to end his life, if he wants. But I think it would be a great mistake. However bad life may seem, there is always something you can do, and succeed at. While there's life, there is hope.\"\nOn artificial and extraterrestrial intelligence\n\"I think the development of full artificial intelligence could spell the end of the human race,\" Hawking told the BBC in 2014. \"Once humans develop artificial intelligence, it will take off on its own and redesign itself at an ever-increasing rate. \"Humans, who are limited by slow biological evolution, couldn't compete and would be superseded.\"\nDespite pushing for humanity to escape Earth and explore space, and in 2016 backing the Breakthrough Starshot interstellar spacecraft project, Hawking felt strongly that first contact with alien species should be avoided. He told the National Geographic Channel in 2004: \"I think it would be a disaster. The extraterrestrials would probably be far in advance of us. The history of advanced races meeting more primitive people on this planet is not very happy, and they were the same species. I think we should keep our heads low.\"\nOn human intelligence\n\"People who boast about their IQ are losers,\" he said in the December 2004 interview with The New York Times. Nonetheless in a 1999 episode of The Simpsons - \"They Saved Lisa's Brain\", in which Lisa joins the Springfield branch of Mensa and eventually takes over the running of the town - Hawking silenced all the show's brainiest characters by announcing during an argument as to who was smartest: \"Big deal. My IQ is 280.\"\nHe further admonished the group with a lecture on how power corrupts, while sending himself up with an Inspector Gadget-style turn from his motorised wheelchair. Hawking was famously possessed of a sharp wit. Speaking to comedian John Oliver on his programme Last Week Tonight the physicist was asked whether in a reality that contained multiple universes, one existed in which the host was \"smarter than you\". \"Yes, and also a universe where you're funny,\" the Cambridge academic shot back.\nOn his fame\n\"The downside of my celebrity is that I cannot go anywhere in the world without being recognised. It is not enough for me to wear dark sunglasses and a wig. The wheelchair gives me away,\" he said on Israeli TV in December 2006. However, he told The New York Times two years earlier he wanted his books \"sold on airport bookstalls\".\nOn space and the universe\nHawking remains best-known for his work describing the nature of black holes. Of the phenomenon, he said in a 1996 book: \"Einstein was wrong when he said, 'God does not play dice'. Consideration of black holes suggests not only that God does play dice, but that he sometimes confuses us by throwing them where they can't be seen.\"\nIn his classic book A Brief History of Time, Hawking famously said of scientists striving to produce a unifying theory explaining the universe's mechanics: \"If we discover a complete theory, it would be the ultimate triumph of reason - for then we should know the mind of God.\" The memorable, metaphorical statement has been often discussed since it was published in 1988, but questions over Hawking's beliefs about the origins of the universe were answered firmly in his 2010 book, The Grand Design.\nIn it, he wrote: \"Because there is a law such as gravity, the universe can and will create itself from nothing. Spontaneous creation is the reason there is something rather than nothing, why the universe exists, why we exist. It is not necessary to invoke God to light the blue touch paper and set the universe going.\"\nOn disability\nHawking told The New York Times in 2011 that motor neurone disease had taught him \"not to pity myself\" because others were worse off. He added: \"My advice to other disabled people would be, concentrate on things your disability doesn't prevent you doing well, and don't regret the things it interferes with. Don't be disabled in spirit, as well as physically.\"\n"},
{"docid": "304 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "June 23, 2015", "title": "The ethics of AI: how to stop your robot cooking your cat; By tracking how people live their values, businesses can and must instil ethical frameworks into the technologies of the future\n", "content": "At a time when most media surrounding artificial intelligence are focused on wondering when machines will become self-aware, a larger question is which ethical frameworks should guide this autonomous evolution.\nPersonalisation algorithms scrutinise human behaviour to a molecular level and define, by our actions, what values we're living on a daily and even momentary basis. But when it comes to questions of consciousness, spirituality and wellbeing, it's only by becoming self-aware that we will be able to define humanity within the environment of mechanised sentience.\nFor the business world, this collective human introspection could provide a form of corporate social responsibility for individuals. Data about our actions - when shared in an opt-in, non-Orwellian context - and our professed values would provide organisations with a richer opportunity for connection and relevancy than the clandestine tracking common to marketing today.\u00a0\nUsing sensor data to track how individuals live their values would provide insights that could inspire increased wellbeing via more purpose-driven lives. This is the process humanity needs to pursue with rigour to ensure we're building agents who align with our goals versus opting to prioritise their own.Coding and consciousness\nThe field of artificial intelligence (AI) ethics has existed for a number of years and has recently seen a resurgence of interest.\n                     Stuart Russell, professor of computer science and Smith-Zadeh professor of engineering at the University of California, Berkeley, uses a methodology for the process of ethics in AI known as inverse reinforcement learning (IRL). \n Related: Personal data: revolutionising our professional lives\nWith IRL, sensor-based systems observe humans to identify the behaviours that would be identified as ethically based. Once a behaviour is matched to an ethical modality, code can be reverse engineered to programme AI systems at the operating system level. So the codes by which we live can be translated into the ones and zeros that bring an algorithm to life.\nAs an example of this process, Russell pointed out in a recent speech at the Centre for the Study of Existential Risk at the University of Cambridge how a robot might observe people repeatedly boiling water and pouring it over black crystals every morning. By noting the humans' improved mood, the value of the coffee ritual becomes codified. Russell later explained, however, that goals for humans exist in the context of how we have already lived our lives up to the point we receive a new goal. For instance, if we run out of meat when cooking we know not to cook our pet cat, but this is a value we would need to programme in a kitchen robot's algorithm.\nAs a result, Russell feels there should be companies that construct representations for human values, including this concept of people's backgrounds that would recognise the layers or ethics, laws and morals we take for granted. A prototype of this kind of organisation exists in the Open Roboethics Initiative that crowdsources ethically-focused insights around AI and robotics. It's this type of recognition of our individual role in the creation of values for AI that represents a major opportunity for innovation and industry moving forward.The ethics of your robot car\nWhile at first it may appear that analysing ethical codes on a granular level due to the rise of AI technology is superfluous for the average individual, think again.\nMany major car manufacturers have announced that they will feature some level of autonomy in their vehicles by 2020. For instance, General Motors' 2017 Cadillac will offer Super Cruise technology that can brake, accelerate or steer at speeds over 70mph. Self-driving vehicles appear to be inevitable. While a major drawback is their potential to put millions out of work, they could save lives that might otherwise have been lost due to negligent driving.\n Related: Driverless cars - the future of transport in cities?\nBut, as engineer and philosopher Jason Millar points out in Wired, you should have a say in your robot car's code of ethics. Millar posits a typical ethical quandary known as the \"tunnel problem\" to demonstrate a scenario many of us may face in the near future in our self-driving cars: while driving towards a narrow tunnel in your autonomous vehicle, a small child runs into the street and falls, leaving you with two options - kill the child or sacrifice your life by crashing into the tunnel.\nThis is a choice we might have to make today, but the critical point with autonomous technology is that programmers have already been tasked with making these decisions for you. What happens if you believe you should sacrifice your own life but your car kills the child instead?\nMillar provides an excellent suggestion for these situations by modelling ethical concerns after the idea of informed consent for medical issues, an idea he refers to as \"moral proxies\".A vision for values\nWe can't continue to move forward in an environment where our ethical desires in AI are ignored in the same way we're tracked without direct access to the insights surrounding our personal data.\nEthics in AI shouldn't be an afterthought, weighing risks for products already fully realised. The opportunity for innovation will come when we can inform the AI manufacturing process with programming based on the codification of our deeply held beliefs.\nHow will machines know what we value if we don't know ourselves? That's the question we need to answer today or else algorithms will continue to take decisions out of our hands, and we'll have lost the chance to try.\n\n"},
{"docid": "305 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "February 9, 2017", "title": "Adapting to artificial intelligenceALAMY\n", "content": "Reports earlier this week that up to 250,000 jobs in the NHS and civil service could be vaporised by the arrival of robots have echoes in the legal industry.\nAlready in big corporate firms the harnessing of artificial intelligence (AI) is cutting out much of the grunt work. Jobs once done by humans are undertaken by tools such as Kira, an advanced machine-learning software used to identify, analyse and extract provisions and information from contracts and other documents.\n\"The phenomenon of human jobs being replaced by machines is not new,\" says James Froud, a partner at Bird & Bird. \"It has been happening since the Industrial Revolution. However, the emergence of artificial intelligence is a potential game-changer that may have seriously destabilising effects.\"\u00a0\nAccording to Libby Jackson, the global head of alternative legal services at Herbert Smith Freehills, AI in a legal context centres on a key part of the lawyer's craft: \"the precise use and meaning of words\". This has two dimensions. \"The first is analytic, ie can a machine understand what a document means, given the subtlety of language, including the potential for a human intention to seek to obscure meaning?\nThe second is creative, ie can a machine draft and negotiate documents, given the variety of human intention and motivation in relation to the need for these in the first place?\" Either way, the consequences are huge. \"Being a good lawyer is no longer enough,\" says Jason Marty, Baker McKenzie's global director of operations.\n\"Artificial intelligence and machine learning is very real and the legal industry is right in the middle of the changes it will bring. The developing technology will have an impact on - but not replace - workforces and legal expertise. A human will still be required for 'judgment' tasks. Clients need us to have the ability to harness new technology and invest in smarter ways of working to make the best of our people's talents and time.\"\nWhat this amounts to is an industrialisation of the delivery of legal services, says the chief innovation officer, John Fernandez, at Dentons. \"AI and other enabling technologies have the potential to materially automate a growing percentage of the legal services supply chain. Our clients long ago invested in technology to automate elements of their businesses and expect their law firms to do the same.\"\nA good example comes from Guy Pendell, the head of disputes at CMS UK. \"We're looking at products that can give meaning to data patterns in a matter of minutes that would not be possible for humans to do without hours, if not days, of effort. It is not unusual for clients to produce millions of documents for the purposes of an investigation or disclosure in litigation.\n\"Traditional methods of working with electronic data, including key words, date ranges and custodian selection, would often generate disproportionate numbers of documents for manual linear review. Systems that can learn and identify concepts in a document can dramatically change the way lawyers and their clients understand the data relating to a particular matter.\"\nFor Paul Greenwood, at Clifford Chance, the process of change will include developments such as law firms working with technology companies to develop tools that give them a competitive advantage. The firm is working with its partner Neota Logic to automate and augment legal advice.\n\"We're piloting this to help clients to address the wall of regulations that have emerged since the credit crunch,\" says Greenwood. The next wave of innovation is predicted to include software that can understand and be questioned in natural language: \"This will further transform legal processes.\"\nSo the key question for law firms is: will you own and drive the AI revolution or will you fall victim to it? Dentons is determined to be an owner-driver. It could be said that one of its key motives in going for global expansion is to develop the muscle to be able to invest in AI innovation.\nIt has a venture development company, Nextlaw Labs, that co-develops technology products and solutions with Dentons' clients and creates proprietary tools for use by Dentons' lawyers. It also invests in early-stage legal tech companies that \"address plain points in the market in a compelling way\". This enables the firm to work on projects that are not core to its business now, but may be in future.\nIt is not certain if this technology will trickle down to the struggling high street. However, Noory Bechor, the chief executive of LawGeex, an AI contract review and negotiation platform, believes the future is clear. Any law firms that survive the next ten years will have to operate in a \"radically different way\" from how they do today.\n"},
{"docid": "306 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "February 5, 2018", "title": "AI could spot eye disease more accurately than doctors, study suggests\n", "content": "Artificial\u00a0intelligence developed by Google could be be better at spotting eye disease than human doctors, experts believe.\nA two-year partnership between Google's sister company, DeepMind  and the renowned Moorfields Eye Hospital, showed \"promising signs\" in analysing retinal scans for signs of glaucoma, age-related macular degeneration and diabetic retinopathy.\u00a0\nThe research has been submitted to a peer-reviewed medical journal amid hopes that the technology could enter clinical trials within a few years.\nDominic King, DeepMind's clinical lead, told the Financial Times: \"In specific areas like medical imaging, you can see we're going to make really tremendous progress in the next couple of years with artificial intelligence.\n\"Machine learning could have a very important role picking up things more sensitively and specifically than currently happens.\"\nPeng Tee Khaw, director of research at Moorfields, said: \"I am optimistic that what we learn from this research will benefit people around the world and help put an end to avoidable sight loss.\"\nDeepMind, which is based in London, analysed data from thousands of anonymised retinal scans that had been labelled for signs of disease by doctors.\nThe scans were used to train an AI algorithm to detect signs of eye disease more quickly and efficiently than human specialists.\nIt is hoped that such programmes will ease some pressure on the overstretched NHS by taking on some of the repetitive work.\nDr King said such artificial intelligence was \"generalised,\" meaning it could be applied to other kinds of images and be used to diagnose other illnesses.\nThere are plans for DeepMind to partner with University College London Hospitals to analyse radiotherapy scans and with Imperial College London to look at mammograms.\nTechnology companies are increasingly moving into health. In 2016, Microsoft announced it\u00a0 planned to crack cancer within 10 year s after launching several projects to \"hack\"\u00a0the body.\nGoogle's secretive arm Calico, is also investigating ways to extend human life and even stop ageing altogether.\nHowever, the relationship between such technology companies and hospitals is sensitive.\nLast year, the UK's data protection watchdog ruled that  the NHS illegally handed Google the data of 1.6 million people.\nThe Information Commissioner's Office found that the Royal Free NHS Foundation Trust in London \"failed\" to comply with data protection rules when it gave patient records to DeepMind for a trial.\nThe ruling related to a trial that used technology to track patients' symptoms and send alerts to doctors in the event of a drastic change in their health through an app called Streams.\nThe company has since set up a research unit focused on the ethical and social implications of the AI it is creating.\nDr King added. \"[Artificial\u00a0intelligence] needs to be implemented and evaluated I would say as rigorously as a new pharmaceutical medical device so you have evidence that then allows you to scale up across a health system.\"\n                   AI timeline                 \n"},
{"docid": "307 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "November 5, 2015", "title": "Robot revolution: rise of 'thinking' machines could exacerbate inequality; Global economy will be transformed over next 20 years at risk of growing inequality, say analysts\n", "content": "A \"robot revolution\" will transform the global economy over the next 20 years, cutting the costs of doing business but exacerbating social inequality, as machines take over everything from caring for the elderly to flipping burgers, according to a new study.\nAs well as robots performing manual jobs, such as hoovering the living room or assembling machine parts, the development of artificial intelligence means computers are increasingly able to \"think\", performing analytical tasks once seen as requiring human judgment.\n Related:  Robot doctors and lawyers? It's a change we should embrace | Daniel Susskind\nIn a 300-page report, revealed exclusively to the Guardian, analysts from investment bank Bank of America Merrill Lynch draw on the latest research to outline the impact of what they regard as a fourth industrial revolution, after steam, mass production and electronics.\u00a0\n\"We are facing a paradigm shift which will change the way we live and work,\" the authors say. \"The pace of disruptive technological innovation has gone from linear to parabolic in recent years. Penetration of robots and artificial intelligence has hit every industry sector, and has become an integral part of our daily lives.\" \nHowever, this revolution could leave up to 35% of all workers in the UK, and 47% of those in the US, at risk of being displaced by technology over the next 20 years, according to Oxford University research cited in the report, with job losses likely to be concentrated at the bottom of the income scale.\n\"The trend is worrisome in markets like the US because many of the jobs created in recent years are low-paying, manual or services jobs which are generally considered 'high risk' for replacement,\" the bank says.\n\"One major risk off the back of the take-up of robots and artificial intelligence is the potential for increasing labour polarisation, particularly for low-paying jobs such as service occupations, and a hollowing-out of middle income manual labour jobs.\" \nThe authors calculate that the total global market for robots and artificial intelligence is expected to reach $152.7bn (\u00a399bn) by 2020, and estimate that the adoption of these technologies could improve productivity by 30% in some industries.\nThey point out that Google bought eight robotics companies in a two-month period in 2014, from Boston Dynamics, which makes the BigDog robot, to DeepMind, specialising in deep learning for artificial intelligence.\nIn the most advanced manufacturing sectors - among Japan's carmakers, for example - robots are already able to work unsupervised round the clock for up to 30 days without interruption. While offshoring manufacturing jobs to low-cost economies can save up to 65% on labour costs, replacing human workers with robots saves up to 90%.\nAt present, there are on average 66 robots per 10,000 workers worldwide, the report finds; but in the highly automated Japanese car sector there are 1,520. \nBut it is not just low-skilled jobs, such as assembly-line work, that could be replaced: a report from the McKinsey Global Institute in 2013 found that up to $9tn in global wage costs could be saved as computers take over knowledge-intensive tasks such as analysing consumers' credit ratings and providing financial advice. \nEnthusiasts for the rise of robots argue that they can overcome the foibles and fallibilities of human workers. The report cites research that showed judges tend to be more draconian in the runup to lunchtime and more lenient once they have eaten, for example. \nIt urges consumers to invest in businesses that are already taking advantage of the benefits of the new technologies: \"Early adoption will be a key comparative advantage, while those that lag in investment will see their competitiveness slip.\"\nHowever, the bank also points out that major ethical and social issues will increasingly arise: they cite the moral questions about the growing use of unmanned drones in warfare ; and even the emergence of a pressure group called the Campaign Against Sex Robots.\nFears about humans being displaced by machines are not new: in the early 19th century bands of angry Luddites smashed up the steam-powered looms that were throwing hand-weavers out of work. \nBeijia Ma, the report's lead author, said that over the past 200 years and more, societies have eventually found ways of turning technological developments to their advantage.\n Related:  Robots can take over some of our jobs. But some things only humans can do | Brooks Rainwater\nShe said the best advice for people fearing the rise of the robots is to polish up their skills. \"It's not meant to be a doom and gloom report: one of the ways we think people could help themselves here is through education.\"\nHowever, Ma added that a recent survey of industry experts, by the US polling firm Pew, revealed a stark divide between techno-optimists and pessimists. \nAlmost half of them, 48%, believed the rise of robots and artificial intelligence would have \"a massive detrimental impact on society, where digital agents displace both blue- and white-collar workers, leading to income inequality and breakdowns in social order\". \nMeanwhile, 52% \"anticipated that human ingenuity would overcome and create new jobs and industries \". \nAndrew Simms, of thinktank the New Weather Institute, said the rise of new technologies could be an opportunity to realise the aspirations of the economist John Maynard Keynes, who predicted in 1930 that within a century, technology would have enabled the working week to be reduced to 15 hours with the rest of the time devoted to leisure.\nHowever, without rethinking the relationship between work and society, the result could be a growing disparity between economic winners and losers.\n\"We are in danger, for the first time in history, of creating a large number of people who are not needed,\" he said. \"The question should be, what sort of economy do you want, and to meet what human needs?\"Under threat?\nA wide range of jobs could eventually be taken over by machines, Bank of America Merrill Lynch's analysts predict.\n                     Burger flip                     pers  A San Francisco-based start-up called Momentum Machines has designed a robot that would replicate the hot, repetitive tasks of the fast-food worker: shaping burgers from ground meat, grilling them to order, toasting buns, and adding tomatoes, onions and pickles.\n                     Manufacturing w                     orkers  Relatively low-skilled industrial workers in rich countries have become used to competing against cut-price employees in cheaper economies. But while \"offshoring\" can cut labour costs by 65%, replacing workers with machines can cut them by up to 90%. The process is well advanced in countries such as Japan and South Korea; as other countries catch up, many more jobs will be taken over by technology.\n                     Financial advisers  Bespoke financial advice seems like the epitome of a \"personal\" service; but it could soon be replaced by increasingly sophisticated algorithms that can tailor their responses to an individual's circumstances.\n                     Doctors  Some 570,000 \"robo-surgery\" operations were performed last year. Oncologists at the Memorial Sloan-Kettering Cancer Center in New York have used IBM's Watson supercomputer, which can read 1m textbooks in three seconds, to help them with diagnosis. Other medical applications of computer technology involve everything from microscopic cameras to \"robotic controlled catheters\".\n                     Care workers  Merrill Lynch predicts that the global personal robot market, including so-called \"care-bots\", could increase to $17bn over the next five years, \"driven by rapidly ageing populations, a looming shortfall of care workers, and the need to enhance performance and assist rehabilitation of the elderly and disabled\".\n"},
{"docid": "308 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "January 27, 2014", "title": "Google buys UK artificial intelligence start-up DeepMind for \u00a3400m; London-based company focused on \"cutting edge artificial intelligence\" could supply the brains for Google's burgeoning robotics division\n", "content": "A former child chess prodigy and computer game designer from London has sold his company to Google for around \u00a3300m in one of the Internet giant's largest European acquisitions.\nDemis Hassabis, a computer scientist, is understood to have struck the deal with Google for his secretive start-up business Deep Mind Technologies, which specialises in artificial intelligence (AI) for computers.\nHassabis, 37, has built the company by bringing together neuroscientists and computer engineers in an effort to use technology and medical research to help machines to mimic the brain's ability to improve performance. He previously led a study at University College London in 2009 that scanned human brains and found \"just by looking at neural activity we were able to say what someone was thinking\".\u00a0\nGoogle founder Larry Page, who has expressed interest in making search commands easier by having an implant in the brain, is understood to have led the move to buy Deep Mind. Google is exploring smart technology that will enable it to go into space travel and create self-driving cars.\nThe website The Information claimed that Google had beaten Facebook to the acquisition and had sealed the deal after agreeing to set up an ethics board to ensure that the AI technology was not abused.\nHassabis is known within the computer gaming industry for having \"a brain larger than a planet\". He began playing chess when he was four years old, reached Master Standard by the age of 13 and represented England.\nHe did his first work in the games industry only two years later when he entered a competition to design a clone for Space Invaders. Going into the industry seemed like \"the perfect marriage between games and programing\", he has said.\nBy the age of 16 - having already completed his A-levels - Hassabis began working at games company Bullfrog and co-wrote the successful game Theme Park - which was based on an amusement park and released in 1994 - in his year off before going to the University of Cambridge. His student friends struggled to believe he was the author of such a successful product until they saw his name on the packaging.\nAfter graduating with a triple first in computer science from Queen's College, Hassabis quickly returned to the games industry and became a lead AI programmer at Lionhead Studios, the Surrey-based company founded by British computer games pioneer Peter Molyneux. Very soon afterwards the young graduate went off to set up his own business, Elixir Studios, where he was executive designer of a game called Republic: The Revolution, which attempted to recreate a \"living, breathing city\" and was nominated for a BAFTA.\nAlthough he has accepted that the project was over-ambitious, he told games website CVG that he had always been prepared to take chances. \"I'm actually more worried about not taking risks and playing safe, not pushing myself enough,\" he said. \"It's a bit perverse I suppose, and asking for trouble. I've always been prepared to jump in at the deep end and see if I can swim or not.\"\nFor many years, Hassabis was a successful competitor in the London-based Mind Sports Olympiad, taking part in its elite Pentamind contest - a sort of mental pentathlon. Hassabis was Pentamind champion in five of the first seven years after the Olympiad was founded in 1997. His success meant that he was described as \"probably the best games player in history\". Hassabis is an expert in the Japanese board game Shogi and an accomplished poker player.\nHis next computer game Evil Genius, which was based on a Bond-style villain in an island lair, was more favourably received by critics. After selling the rights to publishers, Hassabis sold the studio and went into medical science in order to further pursue his interest in AI technology. He was elected a fellow of the Royal Society of Arts for his game designs.\nAs a cognitive neuroscientist he specialised in autobiographical memory (combining personal recollection and general knowledge) and amnesia. He investigated whether patients with lesions to the Hippocampus parts of their brains suffered damage to their imagination process as well as their memory recall. He completed his doctorate in cognitive neuroscience in 2009 at University College London and became a fellow at the college's Gatsby Computational Neuroscience Unit and a visiting scientist at MIT and Harvard.\nIn 2012, he left academia to set up Deep Mind Technologies, developing technology for e-commerce and gaming and creating computer systems capable of playing computer games. The company, which was based in central London's Russell Square before moving to Fenchurch Street, has a reputation for secrecy. Its aim is said to be to develop computers that think like humans. It is said to employ 50 people including co-founders Shane Legg, a 40-year-old New Zealander, and Mustafa Seleyman, a 29-year-old Briton.\nDeep Mind's investors include US Tesla car mogul Elon Musk, early Facebook investor Peter Thiel and the family of London app creator Nick d'Aloisio, who are all set for windfalls following the sale to Google. D'Aloisio, from south London, sold his news based app Summly to Yahoo! for a reported \u00a319m early last year.\n"},
{"docid": "309 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "November 4, 2015", "title": "AI-enabled toys: Hello Barbie is now connected to Wifi - and can chat back; In a world where technology is captivating the young,toy firms are falling over themselves to make artificial intelligence child's play\n", "content": "Artificial\u00a0intelligence, which has already made inroads into fields ranging from medicine to aerospace engineering, could end up on Christmas lists this year. That's because several companies - including the industry behemoth Mattel - are planning to roll out an assortment of AI-enabled toys which are designed for children as young as three.\nThe one toy that everyone's been talking about, of course, is Mattel's Hello Barbie (its announcement hit British headlines earlier this year), which is powered by an artificial intelligence platform that was developed by ToyTalk, a San Francisco-based AI company founded by two former Pixar employees. The doll, expected to hit shelves in the US, will cost $74.99 (\u00a349; there is no UK release date yet).\nAs the newest iteration of a doll that's been around since 1959, the Hello Barbie uses a combination of a microphone to record conversations, wi-fi to transfer those conversations to a computer server, voice-recognition software to figure out what the child just said, and an algorithm to determine what to say next to the child, who might range in age from three to nine. In some cases, the conversations with Hello Barbie can go as deep as 200 exchanges between child and doll.\u00a0\nA child might ask: \"Want to play a game?\" Hello Barbie then immediately accesses one of 8,000 possible responses to simulate the back-and-forth of a typical children's conversation. If the question can't be answered, there's a \"fallback\" response that's perfect for just about any situation - \"Really? No way!\"\nIn the world of AI, of course, this conversation between toy and child could be viewed as a sort of daily Turing Test. Unlike the classic Turing Test, however, the kids are not attempting to figure out whether Barbie is human or not - they are simply engaging in a conversation with a make-believe object imbued with consumer-grade AI. To make that possible, the Hello Barbie will remember conversational points from the past - it will remember if a child has brothers or sisters, for example, or when they last played together.\nTaking a similar tack, the company Elemental Path is planning to roll out in December a $119.99 talking dinosaur for children as young as five that's powered by the cognitive computing capabilities of IBM Watson. The first set of questions and answers for the CogniToys Green Dino were generated by convening parent focus groups. However, since the dinosaur is connected to the cognitive computing capabilities of IBM Watson via wireless internet, it can learn in real-time and get answers to questions that might not have been programmed into the toy from the outset.\nIn the Kickstarter video for the CogniToys Green Dino, which raised $275,000 from more than 2,000 backers, you can see the power of partnering with IBM Watson. A child might ask, \"How far is it to the moon?\" or \"What is the speed of light?\" The Watson-powered AI engine processes the question - and here's the AI parlour trick - adapts the response to the age and development level of the child. Think of the dinosaur as a talking companion for your child - a companion who would also wipe the floor on Mastermind.\nDavid, left, played by Haley Joel Osment, with his teddy bear in 'AI'\nWhile there have been other \"smart toys\" before, there's something fundamentally different about the CogniToys Green Dino or the Hello Barbie. Using proprietary AI engines and speech-recognition tools, they are able to understand conversations, give intelligent responses and learn on the fly. These AI-powered companions can do more than just answer a series of simple questions with one-off replies, the way one might expect from Siri.\nWhile you can split hairs about whether a real-time response from a plastic toy constitutes \"intelligence\" (the same debate that takes place every year about the Turing Test), it does seem that something fundamentally new is happening in the AI space. With these cognitive toys, researchers are creating a new category for objects that are less than human but more than machine.\nAccording to MIT's Sherry Turkle, author of the new book Reclaiming Conversation: The Power of Talk in a Digital Age, we as a society are experiencing a \"robotic moment\". We no longer expect artificially intelligent machines to be fully human - as long as they can compensate in other ways. \"It's not that we have really invented machines that love us or care about us in any way, shape or form,\" she says, \"but that we are ready to believe that they do. We are ready to play their game.\"\nRead more\n                     AI could wipe out humanity because it's too clever, Hawking warns                   \n                     Apple buys a company that could make Siri much more human                   \n                     New artificial intelligence can learn how to play vintage video games                   \n                     Artificial\u00a0intelligence could kill us because we're stupid                   \n                     Artificial\u00a0intelligence will threaten us, says Bill Gates                   \nAI-enabled toys such as Hello Barbie or the CogniToys Green Dino promise to play that game. And similar types of AI toys could become even more realistic as they go beyond just speech recognition to involve sophisticated sensors capable of understanding specific gestures. In May, for example, Google published a patent for an internet-connected teddy bear hooked up with sensors, cameras, microphones and a wireless internet connection. In the patent, Google suggests the robotic teddy bear might be able to control a homeenvironment.\nTo see how gesture-sensing technology might be combined with AI to simulate real-world behaviours, check out the MiPosaur, unveiled by WowWee toys at the beginning of the year. A YouTube video produced for Toy Fair New York in February shows how these robotic dinosaurs can go into \"gesture mode\" or \"leash mode\" or \"food mode\" and respond to the gestures of a human hand or an interactive tracking ball, simulating the types of behaviours that you might expect from a well-trained pet.\nOf course, just because these are \"toys\" doesn't mean that there aren't some serious issues to consider. The Hello Barbie toy, for example, has already attracted the negative attention of privacy advocates, who claim that the toy violates the right to privacy for children under the age of 13 (something that ToyTalk and Mattel clearly disagree with). And the Google teddy bear immediately attracted attention from the BBC as a \"creepy internet toy\" and comparisons to the \"super\" teddy bear in AI, the Steven Spielberg film from 2001.\nCogniToys' Green Dino is powered by IBM's Watson\nAnd that's not all. As with any object hooked up to the internet these days, there's always the chance of getting hacked. Play experts, too, have weighed in, claiming that these \"smart toys\" may actually be bad for children. They claim that these artificially intelligent toys could reduce imaginative play and even inspire a number of negative behavioural patterns inchildren.\nIf AI toys are ever going to catch on, toy companies are clearly going to have to overcome the \"creepiness\" factor of toys recording and analysing the conversations of children. These consumer-grade AI toys are not \"creepy\" because they could destroy the world - as Elon Musk or Stephen Hawking might argue about enterprise-grade AI - but because they have the potential to fundamentally change the nature of how we interact with people and objects around us.\nThese toys are essentially deconstructing everything that makes humans special - and replacing it with sensors, computer servers, software and algorithms. This Christmas, we might find out what the world's toughest critics - our kids - have to say about that.\n\u00a9 The Washington Post\n"},
{"docid": "310 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "March 11, 2017", "title": "Technology could redefine the doctor-patient relationship; Artificial intelligence is already making inroads into the NHS and could have profound effects on the medical workforce\n", "content": "Advances in clinical uses of artificial intelligence (AI) could have two profound effects on the global medical workforce. \nAI, which mimics cognitive functions such as learning and problem-solving, is already making inroads into the NHS. In north London it is piloting use of an app aimed at users of the non-emergency 111 service, while the Royal Free London NHS foundation trust has teamed up with Google's DeepMind AI arm to develop an app aimed at patients with signs of acute kidney injury. The hospital claims the project, which uses information from more than 1.6 million patients a year, could free up more than half a million hours annually spent on paperwork.\nAI raises the prospect of making affordable healthcare accessible to all. According to the World Health Organisation, 400 million people do not have access to even the most basic medical services. Hundreds of millions more, including many in the world's most advanced countries, cannot afford it. A key factor driving this is the worldwide shortage of clinical staff, which is getting worse as populations grow.\u00a0\n Related:  Eight technologies that could change healthcare beyond recognition\nAt last month's DigitalHealth.London summit, Ali Parsa, founder of digital healthcare company Babylon, argued that mobile technology coupled with AI makes universal access a realistic goal, while replacing doctors with intelligent systems will slash costs. \n\"There is no solution which can fundamentally cut the costs of healthcare as long as we are reliant on humans,\" he said. \nSo the second impact of artificial intelligence could be not merely augmenting the pool of medical talent but beginning to replace it. Big claims are being made for the clinical power of AI. Last year IBM's Watson supercomputer was credited with diagnosing in minutes the precise condition affecting a leukaemia patient in Japan that had been baffling doctors for months, after cross-referencing her information with 20m oncology records. \nHowever, the same system has just consumed five years and $62m (\u00a351m) in an unsuccessful attempt to transform care at the University of Texas MD Anderson Cancer Center, showing how difficult it is to connect these digital behemoths to everyday hospital work. With the NHS still struggling to introduce electronic patient records, the idea of plugging the UK healthcare system into an all-knowing digital brain any time soon is fantasy.\nWhile there is no doubt that AI will enable faster and more accurate diagnoses, a more realistic prospect than replacing doctors is to redefine their role.\n Related:  Robots don't challenge surgeons such as me - they challenge dogmatic practice | Ara Darzi\nThat will be to put machine-generated information into the context of the unique life and needs of the individual patient, which cannot yet be reduced to an algorithm. As Dr Ameet Bakhai, consultant cardiologist at the Royal Free trust, told the summit, machines making clinical decisions on their own without that human context could fail to meet Isaac Asimov's first law for robots of \"do no harm\".\nDigital evangelists argue that intelligent machines will be able to incorporate the latest data and research immediately, but that is both questionable and a potential weakness. Clinical trials vary in scale and quality, and indiscriminate inclusion would inevitably lead to mistakes. Digital hardliners would argue that machines should judge the quality of the research, but for the foreseeable future the expertise of doctors will be essential to deciding the validity of new approaches.\nSo perhaps one of the most powerful effects of artificial intelligence will be, perversely, to make healthcare more human and personal. It will remove the dependency on doctors' fallible memory and incomplete knowledge, and free them to use machine-generated information to work with patients to shape their specific treatment.\nThis has profound implications for medical training and what defines a leading clinician. It will be those who can harness AI to their own medical knowledge and their human skills of context and empathy who will be the leaders of their profession. In the new world there will still be a great deal for highly-trained humans to do.\n                                            Join the Healthcare Professionals Network to read more on issues like this. And follow us on Twitter ( @GdnHealthcare ) to keep up with the latest healthcare news and views.                   \n"},
{"docid": "311 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "March 6, 2017", "title": "How AI could boost your bottom line; Three experts on how SMEs are using AI and what benefits it could provide\n", "content": "You may have heard of artificial intelligence (AI), which is usually defined as the science of making computers do things that would require intelligence if completed by humans. However, for many this seems like a visionary technology, not ready for day-to-day use within your business. \nSo you may be surprised to learn that AI could already be benefitting your business.\u00a0\n\"Many service providers to small businesses are already leveraging AI's capabilities,\" reveals Dr. Andy Pardoe, founder of Informed.AI and homeAI.info.\n\"AI has never been more widely used, with many of the largest technology companies providing integrated AI platforms. This democratisation of AI is allowing small businesses to more easily add advanced data analytics and machine learning to their processes.\"\n                   Fourth industrial revolution                   \nThe term \"artificial intelligence\" was coined at a conference at Dartmouth University in 1956. However, revered computer scientist Alan Turing had been working in the field for many years already. In 1950, he developed the Turing Test to determine when a computer could be defined as \"intelligent\". AI's development was slow until the 1980s, when its cost-saving potential was recognised, with large corporations saving millions thanks to computer systems that emulated human decision-making.\nPardoe believes that \"we've just entered the \" Fourth Industrial Revolution \", and while the adoption of AI, machine learning (meaning AI that enables computers to learn new things without being explicitly programmed to do so) and intelligent automation has just started, the next few years will transform many sectors, with many more businesses benefitting from introducing AI to augment their human workforce's skills and capabilities.\n\"The main way to share information about your business, its products and services has been via your website in recent years, but the next-generation sales channel will be messenger platforms and chatbots - potentially one of the first ways many businesses will introduce AI.\" \n                                        AI technologies                                      \n\"AI techniques are already used by many UK SMEs,\" remarks Miltos Petridis, professor of computer science at the University of Middlesex. \"Many off-the-shelf systems, including database, CRM, sales, and financial and planning software, now contain AI techniques and algorithms, which are used to integrate and interpret data.\"\nSome SMEs also use bespoke AI-enabled solutions to solve problems or otherwise boost their productivity, efficiency and profitability, Petridis adds. \"AI technologies used include reasoning systems, machine learning, natural language processing, voice integration, image processing and planning.\n\"Businesses are increasingly using cloud-based solutions, such as Amazon Web Services, Microsoft Azure and IBM Watson, but some are building bespoke systems with the help of specialists from the software industry and academia.\"\nPetridis believes that several disruptive technologies and events are likely to further affect AI's permeation into small businesses in the UK. \"Obvious ones include 5G, the Internet of Things, advances in robotics and driverless transport. However, these will require further advances in AI.\"\n                   Cost and efficiency savings                   \nPardoe says that improved efficiency could be the top benefit AI provides to business owners. \"Acquiring customers is one of the most important and expensive business activities. AI can really add value here, making the sales process more efficient by determining which leads are most likely to convert or which customers will be interested in specific offers.\"\nAI is likely to be more widely used to automate complex or time-consuming processes, which will also save businesses time and money. \"Where a process may have many transactions and various activities, automating the process also allows businesses to adapt to changes in demand more easily and quickly, which also provides cost savings,\" says Pardoe.\n Related:  Eight tips for effective cashflow management\nRosemary Gilligan, a researcher at the University of Hertfordshire, who specialises in AI, believes there are plenty of ways that AI could soon be helping UK SMEs. \"I've seen presentations on how AI is being used for everything from tyre testing and car manufacture to controlling energy. Even one of the large bakery companies uses AI techniques when baking its cakes.\"\n                   Optimum resource use                   \nAnother potential performance improvement enabled by AI concerns \"preventative monitoring\". As Pardoe explains, \"by predicting potential failures of applications and hardware, we can improve system performance by fixing issues before they cause problems or downtime.\"\nAI could also significantly improve \"resource optimisation,\" he adds. \"AI could better determine optimum resource use, which would improve overall performance and profitability. This could be anything from minimising energy consumption to determining the schedule of sales calls individual sale people make each day.\"\nUsing AI to automate processes could also ensure superior quality, says Pardoe. \"Human error can be removed from mundane tasks, freeing up humans to focus on higher-value, more complex tasks that require creative problem-solving. This is where humans perform better than computers - while finding the work more interesting and rewarding.\"\nAI's superior analytics capabilities could also facilitate less obvious insights into the business, which could reveal areas requiring improvement. \"Empowering businesses to make better decisions because of AI, improving their process efficiency, increasing quality and accuracy, and driving performance enhancements, will deliver significant cost savings,\" he predicts.\n                   Intelligence reporting                   \nGilligan explains that \"AI systems are now being used for everything from helping to prevent fraud to identifying plagiarism. It's being used in diagnostic systems, helping organisations to process huge volumes of data with great speed, efficiency and accuracy. It can also enable businesses to capture someone's expertise, so it's not lost to the employer when that person leaves.\"\nShe concludes: \"Some people think AI is the stuff of sci-fi, with robots thinking for themselves, like you see in the movies. But AI is now in the everyday - most of us already come into contact with it without realising, whether it's search engines or other software we use. In the near future, AI will help many more businesses to find practical cost- and time-saving solutions to a huge range of challenges.\"\n                     Discussions around how tech developments can benefit your small business are taking place at QuickBooks Connect, a two-day conference for SMEs and accountants looking to network, collaborate and grow. QuickBooks Connect is taking place today and tomorrow at Tobacco Dock, London. For more information,                                            click here                                          .                   \n"},
{"docid": "312 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "March 1, 2017", "title": "Dyson challenges tech giants with huge investment in Britain; Dyson\n", "content": "Dyson, the technology company, will build a 500-acre campus dedicated to artificial\u00a0intelligence and robotics as part of a \u00a32.5 billion plan to take on giants such as Google and Facebook.\nThe Cotswolds' answer to the 175-acre Apple Park in California is part of the biggest investment in the UK by a technology firm since the Brexit vote.\nSir James Dyson, 69, said that the campus - to be built on a former RAF airfield in Wiltshire - and other projects in Britain would account for the bulk of his company's new spending of \u00a32.5 billion on research and development. Last night the prime minister and industry figures hailed the move as a vote of confidence in Britain's industrial strategy.\u00a0\nIn the past five years Dyson has almost quadrupled its headcount in Britain, to 3,500 people, half of them engineers and scientists. The latest investment is expected to bankroll a similar increase, creating a UK workforce of almost 14,000.\nThe company wants to shake off its reputation for building vacuum cleaners and position itself at the forefront of technologies such as higher-density batteries, robotics and artificial\u00a0intelligence (AI). The broadening scope mirrors the strategies of companies such as Facebook and Amazon. The focus on batteries will fuel speculation that Dyson plans to create driverless cars.\nBefore the EU referendum, critics voiced fears that if Britain left it would trigger a withdrawal of investment by tech companies. Dyson's announcement comes after a post-referendum commitment by Google to invest \u00a31 billion in Britain, including the creation of 3,000 jobs, a commitment by IBM to build four cloud computing centres and significant pledges by Apple, Facebook and Snapchat. Accenture, the consultancy, predicts that AI could add \u00a3654 billion to the economy by 2035 but many of the field's most talented researchers have been snapped up by US companies, as with Google's acquisition of the London-based Deep-Mind, creator of advanced neural networks, three years ago.\nDyson was founded by Sir James 26 years ago. Its headquarters at Malmesbury, Wiltshire, houses more than 200 research projects in 129 labs. The new base at nearby Hullavington airfield will be almost ten times the size of the Malmesbury site and one of the largest tech campuses in the world, dwarfing the new Apple Park at Cupertino. During the Second World War the airfield was home to the Empire Central Flying School, where instructors were trained. The first two buildings are due to be finished by the end of the year.\nSir James told The Times: \"We are very excited about the opportunities AI and greater connectivity will bring. There is still sometimes a perception that we're a vacuum cleaner company but we're now focused on software and writing algorithms as much as hardware. It's the reverse of what companies such as Google are doing by getting into hardware from software but means we are coming from a position of great strength: it's true that 'hardware is hard'.\"\nDyson makes 95 per cent of its sales overseas and has benefited from the weaker pound. It has previously been criticised for creating high-value jobs abroad. It shifted its manufacturing base to Malaysia in 2002 and last month announced the creation of a research and development hub in Singapore.\nSir James said: \"We have always invested in Britain and we are continuing to invest because it's one of the best places in the world for R&D, with our universities doing world-leading research. There's a continued shortage of engineers, however, which we are attempting to tackle head-on through our new degrees, our work in schools and dialogue with government.\"\nDyson will also seek official university status for its institute of technology, which will offer free four-year degree courses, including paid work placements, from September. ? Millions of Britons who lack digital skills are to be given free training in a scheme in which government, businesses and charities will work together. Under the digital skills partnership Lloyds Banking Group will offer training to 2.5 million adults, charities and business. Barclays will train a million more and Google will also take part.\nTech firms target London\nApple confirmed in September that it would move into new offices in London, taking up 500,000sq ft in the Battersea Power Station redevelopment from 2021. The offices will house 1,400 existing employees but have room for up to 3,000 staff.\nGoogle announced in November that it would build a huge new London office and create 3,000 jobs by 2020 in an investment valued at more than \u00a31 billion. The move will increase Google's UK workforce to about 7,000.\nThe same month, IBM, which employs more than 15,000 people in the UK, said it would create four new cloud data centres in a multimillion-pound investment. A spokesman said: \"Everyone has concluded the UK economy will continue to be very strong.\"\nAlso in November Facebook said that it would hire 500 staff to work in new offices in Fitzrovia, London, which are set to open this year, taking its UK staff total to 1,500.\nIn January, Snap, the parent company of the Snapchat messaging app, said that it would establish its non-US headquarters in Soho, because of its proximity to advertisers and the district's creative scene.\n"},
{"docid": "313 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "March 8, 2017", "title": "Forget about your GP - the robot will see you now; Artificial intelligence to assess urgency of each case after patients key symptoms into program\n", "content": "ROBOTS will soon be able to diagnose patients \"more accurately and faster\" than almost any doctor, according to the man behind a controversial NHS scheme that will see \"chatbots\" used to assess 111 calls.\nA private company with a string of health service contracts is to launch a national scheme that allows patients to receive a full diagnosis by smartphone without ever having to see a GP.\nBabylon Health has just begun a pilot scheme under which patients in five London boroughs are encouraged to consult a chatbot - a computer program designed to simulate conversation with human users - when they contact the 111 non-emergency line.\u00a0\nPatients key in their symptoms, and artificial intelligence assesses the urgency of each case to determine whether users should be told to go to A&E, a pharmacy or tuck up at home.\nNow the company's chief executive has revealed it is to launch a more sophisticated model that will allow any individual to receive a diagnosis by smartphone. Dr Ali Parsa said the system would allow doctors to work in tandem with artificial intelligence so that medics could focus on treating rather than diagnosing diseases.\nThe entrepreneur said: \"There are 300 million pieces of knowledge that we have www.collected.No human brain can do that. This is the largest amount of primary care clinical semantic knowledge in the would that is held by any computer, as far as we know.\"\nThe model remains in development, but tests so far have shown it is faster and more accurate than the doctors in risk assessing cases, Dr Parsa said. In the coming months, research will test the thesis that it can also outperform medics in making a full diagnosis. So far, trials have found it can do so in all abdominal diseases, the company said.\n\"I think we will soon be able to diagnose more accurately and faster than a doctor in most cases. That leaves the doctor to focus on the management of the diseases,\" Dr Parsa said.\nBabylon Health, which was founded in 2013, last month took on the contract to provide virtual responses to 111 cases in north London, covering the boroughs of Barnet, Camden, Enfield, Haringey and Islington.\nIts app, which makes a risk assessment of urgency, is also available free to consumers in any part of the country, who can pay \u00a325 if they need a webcam consultation, or subscribe for unlimited access.\nBut Dr Parsa questioned why the NHS did not make greater use of digital services, given a national shortage of GPs, and a \u00a322 billion savings programme which is underway. \"Why couldn't Babylon be a patient's NHS GP?\" he said. \"An NHS GP costs on average about \u00a3130 a year - for \u00a360 a year you get all this at your fingertips.\n\"In 95 per cent of cases, we can see you remotely and you don't need to see a doctor physically.\"\nDr Parsa said tests comparing speed, accuracy and safety of the artificial intelligence system showed the computer consistently outperforming the human.\nTests comparing accuracy of triage - or assessing urgency - found that nurses' results were accurate in 73.5 per cent of cases, while doctors achieved accuracy levels of 77.5 per cent. The computer reached rates of 90.2 per cent and far more quickly, said Dr Parsa.\nDr Parsa said it was not a question of robots replacing medics, but of providing doctors with the best support. \"If you think of the game of chess - no person can beat the machine but the best games come when chess players are assisted by machine,\" he said.\n"},
{"docid": "314 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "July 1, 2015", "title": "Facebook boss Mark Zuckerberg thinks telepathy tech is on its way; Social network chief believes we'll be able to send thoughts to each other directly using technology in the future\n", "content": "Besides virtual reality, laser-toting satellites and artificial intelligence, what other futuristic technologies is Facebook chief executive Mark Zuckerberg interested in? Oh, you know, telepathy.\n\"One day, I believe we'll be able to send full rich thoughts to each other directly using technology. You'll just be able to think of something and your friends will immediately be able to experience it too if you'd like,\" wrote Zuckerberg during his latest online \"townhall Q&A\". \nFor some people, Facebook's interest in telepathy will be part of a bold new world for digital communications.\u00a0\n Related: Facebook successfully tests laser drones in UK skies\nFor others, it'll be the latest spur to build an ark and fill it with tin-foil hats ready for the endtimes: if the social network ever does work on this technology, it will face important questions about how it handles the resulting data, from protecting it from surveillance agencies to ring-fencing it from advertisers.\nZuckerberg proved unafraid to tackle questions about Facebook's long-term ambitions during the Q&A, including the company's interest in artificial intelligence.\n\"Most of our AI research is focused on understanding the meaning of what people share,\" wrote Zuckerberg, citing examples including detecting when a photo has a certain friend in it and making sure they see it, or using people's photos and posts to connect them with likeminded Facebook users. \n \"In order to do this really well, our goal is to build AI systems that are better than humans at our primary senses: vision, listening, etc. For vision, we're building systems that can recognise everything that's in an image or a video. This includes people, objects, scenes, etc. These systems need to understand the context of the images and videos as well as whatever is in them. For listening and language, we're focusing on translating speech to text, text between any languages, and also being able to answer any natural language question you ask.\" \nZuckerberg expanded on his thoughts on artificial intelligence in a later answer about how Facebook sees itself in a decade's time. \n\"We're working on AI because we think more intelligent services will be much more useful for you to use. For example, if we had computers that could understand the meaning of the posts in News Feed and show you more things you're interested in, that would be pretty amazing,\" he wrote.\n\"Similarly, if we could build computers that could understand what's in an image and could tell a blind person who otherwise couldn't see that image, that would be pretty amazing as well. This is all within our reach and I hope we can deliver it in the next 10 years.\"\nZuckerberg also talked about Facebook's investment in virtual reality, via its $2bn acquisition of startup Oculus VR, which will launch its headset in early 2016.\n\"We're working on VR because I think it's the next major computing and communication platform after phones,\" wrote Zuckerberg.\n\"In the future we'll probably still carry phones in our pockets, but I think we'll also have glasses on our faces that can help us out throughout the day and give us the ability to share our experiences with those we love in completely immersive and new ways that aren't possible today.\"\nVR is one way Zuckerberg would like to see news organisations delivering \"more immersive content\" beyond text, photos and 2D videos.\nWith Facebook emerging as a new gatekeeper for news - most recently with the launch of its Instant Articles program - he was questioned by Huffington Post founder Arianna Huffington about Facebook's role.\n\"Making sure news organisations are delivering increasingly rich content is important and it's what people want,\" he wrote.\n \"On speed/frequency, traditional news is thoroughly vetted but this model has a hard time keeping us with important things happening constantly. There's an important place for news organizations that can deliver smaller bits of news faster and more frequently in pieces. This won't replace the longer and more researched work, and I'm not sure anyone has fully nailed this yet.\" \nResponding to a similar question from journalism professor Jeff Jarvis, Zuckerberg outlined how he sees Facebook's role.\n\"When news is as fast as everything else on Facebook, people will naturally read a lot more news. That will be good for helping people be more informed about the world, and it will be good for the news ecosystem because it will deliver more traffic,\" he wrote.'Real names make users safer'\nZuckerberg also fielded a question about Facebook's policy on making people use their real names rather than pseudonyms - something highlighted recently when journalist Laurie Penny was banned from the social network for using a pseudonym to avoid being trolled with rape and death threats.\nFacebook's chief executive defended the company's policy, with a claim that real names keep users safer:\n \"There are plenty of cases - for example, a woman leaving an abusive relationship and trying to avoid her violent ex-husband - where preventing the ex-husband from creating profiles with fake names and harassing her is important. As long as he's using his real name, she can easily block him.\" \n Related: Seven things we learned from Facebook's latest financial results\nThe flipside of this, of course, is whether the woman leaving an abusive relationship and being harassed by an ex-husband might want to use a pseudonym, but Zuckerberg did not address this aspect. He did stress that Facebook does not want to force people to use their legal names.\n\"Real name does not mean your legal name. Your real name is whatever you go by and what your friends call you. If your friends all call you by a nickname and you want to use that name on Facebook, you should be able to do that,\" he wrote.\nZuckerberg added that the company is working with the transgender community - which includes other prominent critics of the real-name policy - on refining its policies.\n"},
{"docid": "315 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "March 13, 2018", "title": "Women must act now, or male-designed robots will take over our lives; Algorithms are displaying white male bias, and automation is decimating our jobs - we have a lot to lose unless we get involved\n", "content": "The overarching problem of men dictating the rules has found new expression in something that is currently changing the way we live and breathe: artificial intelligence (AI).\nLet us be clear. There are great benefits in the use of AI and we should cherish them. However, the issue is not innovation, or the pace of technological improvement. The real problem is the governance of AI, the ethics underpinning it, the boundaries we give it and, within that, who is going to define all those.\nWith that in mind, I think the next fight for us women is to ensure artificial intelligence does not become the ultimate expression of masculinity.\u00a0\nThere are many reasons to fear this could happen. First, the algorithms that codify human choices about how decisions should be made. It is not possible for algorithms to remain immune from the human values of their creators. If a non-diverse workforce is creating them, they are more prone to be implanted with unexamined, undiscussed, often unconscious assumptions and biases about things such as race, gender and class. What if the workforce designing those algorithms is male-dominated? This is the first major problem: the lack of female scientists and, even worse, the lack of true intersectional thinking\u00a0behind\u00a0the\u00a0creation of algorithms.\nBill Gates believes governments should tax companies' use of robots, as a way to fund other types of employment\nExamples of bias were reported by the Guardian a few years back, showing that searching Google for the phrase \" unprofessional hairstyles for work \" led to images of mainly black women with natural hair, while searching for \"professional hairstyles\" offered pictures of coiffed white women. Or take Microsoft's Tay chatbot, which was created to strike up conversations with millennials on Twitter. The algorithm had been designed to learn how to mimic others by copying their speech. But within 24 hours of being online, it had been led astray, and became a genocide-supporting, anti-feminist Nazi, tweeting messages such as: \"Hitler did nothing wrong.\"\nWhat can we do about it? Obviously, encouraging more women to take up the profession and create algorithms would be a great step forward, and we are still lagging behind on this. However, we also need to start querying the outcomes of the decisions made by algorithms and demand transparency in the process that leads to them. Although the new EU General Data Protection Regulation does not go far enough, it does broaden the definition of profiling activities, thus providing us with tools to avoid profiling-based decisions by questioning them. There are no legal certainties yet about how far the new European regulations, which come into force on 25 May, can be taken, but pressure must be applied to ensure AI algorithms are not just powerful and scalable but also transparent to inspection.\nOf course, the problem of AI goes beyond this. Some academics, such as Joanna Bryson and Luciano Floridi, argue that AI companies should be regulated like architects, who learn to work with city planners, certification schemes and licences to make buildings safe. They argue for watchdogs and regulators.\nIt is encouraging that in the UK the government has set up the Centre for Data Ethics. This new body is tasked with advising on the measures needed to enable and ensure safe, ethical and innovative uses of data-driven technologies. Tech UK, which represents the tech industry, is also having conversations on the subject. For the feminist movement, the challenge is to frame the debate and not to let others decide for us.\nAnd let's not forget the impact on the labour market, with women projected\u00a0to take the biggest hits to jobs in the near future as a result of automation replacing human activities, according to the World Economic Forum. Women are more likely to be employed in jobs that face\u00a0the highest automation risks. For example, 73% of cashiers in shops are women and 97% of cashiers are expected to lose their jobs to automation. The same report predicts that persistent gender gaps in science, technology, engineering and mathematics (Stem) fields over the next 15 years will also undermine women's professional presence.\nAnd if robots are taking human jobs, we need to figure out how we would deal with a large jobless population. Bill Gates believes that governments should tax companies' use of robots, as a way to at least temporarily slow the spread of automation and to fund other types of employment. And many now suggest that universal basic income is probably the only solution to the rise of robotic automation. This is appealing to many but it does pose questions from a feminist perspective: if the only jobs available will be in science and technology, how is that going to work for women in the light of the gender gaps in those professions? If we followed that route, would we be paving the way to men at work and\u00a0women\u00a0at home?\n Related:  Google's AI is being used by US military drone programme\nWhat we need is a progressive, enlightened digital politics aimed at getting the most out of technology: a better environment, better healthcare, a better work-life balance. To achieve that, we need better governance of AI - and women must be at the heart of this.\nThe Fabian Women's Network has decided it is time to take action and throw our weight behind the cause. This month, we are launching our Women Leading in AI series. At the first gathering on 22 May, we are bringing together some of the most interesting and thought-provoking female voices on AI, ranging from business and academia to thinktanks. It is time for women not only to investigate what AI means for us, but also to make sure we frame and lead the debate about its governance and purpose, so it becomes a force for the common good and not the ultimate\u00a0expression\u00a0of\u00a0masculine control.\n\u00b7 Ivana Bartoletti is a privacy and data protection professional, and chairs the Fabian Women's Network\n"},
{"docid": "316 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "July 20, 2016", "title": "Google cut its electricity bill by 40pc using artificial intelligence\n", "content": "Google is using artificial intelligence to reduce\u00a0the amount of\u00a0energy it uses to cool its immense data centres.\nThe energy consumed at the\u00a0centres, a maze of cables, pipes and servers \u00a0where Google processes all of the information consumed by its users, could account for as much as 2 per cent of the world's total greenhouse gas emissions.\u00a0\nUsing machine learning, the search giant said it has managed to reduce the energy used to cool them by as much as 40 per cent.\u00a0\nWater vapour streams from cooling towers at a Google data centre called The Dalles in OrgeonCredit:      Google     \nThe technology created at DeepMind, the Cambridge-based\u00a0artificial intelligence company acquired by Google in 2014,\u00a0uses machine learning to understand the environment at the centres and make them more efficient.\nFor two years an\u00a0AI has been analysing a wealth of data from thousands of sensors at the centres, including temperature, weather, power, and pump speeds. It has also looked at how the centres run and how the equipment powering them interacts with the environment.\nThe history of GooglePlay!02:26\nGoogle said\u00a0DeepMind's software reduced total energy use at the centres, of which Google has 12 across the Americas, Europe and Asia,\u00a0by 15 per cent. The company\u00a0claims responsibility for 0.01 per cent of global electricity use.\u00a0\nThe following graph is from a \"typical\" test day, according to Google. The drop on the graph reflects the time when Google switched the machine learning control on:\u00a0\nPUE stands for Power Usage Effectiveness, and is the ratio of total building energy usage to IT energy usageCredit:      Google     \nGoogle said it now gets\u00a0 3.5 times as much computing power out of the same amount of energy as it did five years ago thanks to\u00a0custom-built servers, more efficient cooling systems that\u00a0use\u00a0outside air, and investment in green energy.\nThe company wants to cap its increase in\u00a0energy use at four\u00a0per cent a year between 2014 and 2020 even as data use grows at a faster rate.\u00a0\nIt also plans\u00a0to be 100 per cent powered by renewable energy. But it hasn't said when it will reach that\u00a0goal, or how much of its power currently comes from renewable sources.\nThe data centre algorithm can eventually be used to improve efficiency in other areas, according to Google, including\u00a0getting\u00a0more energy from the same amount of input at power plants, and reducing\u00a0energy and water usage in semiconductor manufacturing.\nSeparate companies that run on Google's cloud will also benefit from improved efficiency at the centres, the search giant said.\u00a0\u00a0\nFollow the latest Telegraph Technology newsREAD MORE ABOUT:\n"},
{"docid": "317 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "March 15, 2017", "title": "AI is getting brainier: when will the machines leave us in the dust?; To usher in the 'Singularity' - when computers match human intelligence - superintelligent one trick ponies like DeepMind must become jacks of all trades\n", "content": "The road to human-level artificial intelligence is long and wildly uncertain. Most AI programs today are one-trick ponies. They can recognise faces, the sound of your voice, translate foreign languages, trade stocks and play chess. They may well have got the trick down pat, but one-trick ponies they remain. Google's DeepMind program, AlphaGo, can beat the best human players at Go, but it hasn't a clue how to play tiddlywinks, shove ha'penny, or tell one end of a horse from the other.\n Related:  Google's DeepMind makes AI program that can learn like a human\u00a0\nHumans, on the other hand, are not specialists. Our forte is versatility. What other animal comes close as the jack of all trades? Put humans in a situation where a problem must be solved and, if they can leave their smartphones alone for a moment, they will draw on experience to work out a solution.\nThe skill, already evident in preschool children, is the ultimate goal of artificial intelligence. If it can be distilled and encoded in software, then thinking machines will finally deserve the name.\n                     DeepMind's latest AI, unveiled yesterday, has cleared one of the important hurdles on the way to human-level AGI - artificial general intelligence. Most AIs can perform only one trick because to learn a second, they must forget the first. The problem, known as \"catastrophic forgetting\", occurs because the neural network at the heart of the AI overwrites old lessons with new ones.\nDeepMind solved the problem by mirroring how the human brain works. When we learn to ride a bike, we consolidate the skill. We can go off and learn the violin, the capitals of the world and the finer rules of gaga ball, and still cycle home for tea. This program's AI mimics the process by making the important lessons of the past hard to overwrite in the future. Instead of forgetting old tricks, it draws on them to learn new ones.\nBecause it retains past skills, the new AI can learn one task after another. When it was set to work on the Atari classics - Space Invaders, Breakout, Defender and the rest - it learned to play seven out of 10 as well as a human can. But it did not score as well as an AI devoted to each game would have done. Like us, the new AI is more the jack of all trades, the master of none.\nThere is no doubt that thinking machines, if they ever truly emerge, would be powerful and valuable. Researchers talk of pointing them at the world's greatest problems: poverty, inequality, climate change and disease.\nThey could also be a danger. Serious AI researchers, and plenty of prominent figures who know less of the art, have raised worries about the moment when computers surpass human intelligence. Looming on the horizon is the \"Singularity\", a time when super-AIs improve at exponential speed, causing such technological disruption that poor, unenhanced humans are left in the dust. These superintelligent computers needn't hate us to destroy us. As the Oxford philosopher Nick Bostrom has pointed out, a superintelligence might dispose of us simply because it is too devoted to making paper clips to look out for human welfare.\n Related:  Are the robots about to rise? Google's new director of engineering thinks so...\nIn January the Future of Life Institute held a conference on \"Beneficial AI\" in Asilomar, California. When it came to discussing threats to humanity, researchers pondered what might be the AI equivalents of nuclear control rods, the sort that are plunged into nuclear reactors to rein in runaway reactions. At the end of the meeting, the organisers released a set of guiding principles for the safe development of AI.\nWhile the latest work on DeepMind edges scientists towards AGI, it does not bring it, or the Singularity, meaningfully closer. There is far more to the general intelligence that humans possess than the ability to learn continually. The DeepMind AI can draw on skills it learned on one game to play another. But it cannot generalise from one learned skill to another. It cannot ponder a new task, reflect on its capabilities, and work out how best to apply them.\nThe futurist Ray Kurzweil sees the Singularity rolling in 30 years from now. But for other scientists, human-level AI is not inevitable. It is still a matter of if, not when. Emulating human intelligence is a mammoth task. What scientists need are good ideas, and no one can predict when inspiration will strike.\n"},
{"docid": "318 of 500 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "May 11, 1989", "title": "Computer Guardian: Intelligent limits - A report that warns of the dangers of over-reliance on thinking computers\n", "content": "\u00a0\n A major catastrophe could hit humanity through military reliance on so-called thinking computers, says a report published today.\n A working party of the Council for Science and Society concludes that by far the most worrying potential use of artificial intelligence (AI) is the 'autonomous decision-making system that not only makes decisions but also commands machinery to act on them.' This danger is at its greatest in military computer systems, 'a field understandably but regrettably surrounded by such a degree of secrecy that it is extremely difficult to mount any informed public debate in it. Pressures against informed public discussion are so great that this state of affairs may well persist for a very long time - long enough for a major catastrophe to happen meanwhile.'\u00a0\n But, that peril apart, the working party was 'pleasantly surprised' to find few dangerous or even undesirable uses of artificial intelligence in civil use so far.\n The Council for Science and Society was formed in 1973 to promote research into the social effects of science and technology. Its working party on artificial intelligence was headed by Professor Margaret Boden, of Sussex University, a philosopher who wrote a classic in the 1970s - Artificial Intelligence and Natural man. Her team included engineers, doctors, and lawyers as well as academics.\n In this jargon-ridden business, they defined their area of inquiry as KBS, knowledge-based systems - providing computers with 'some of the attributes of human intelligence, such as the ability to converse in a normal human language, to reason and explain the reasoning process, to interpret and describe visual images, and to form and carry out plans.'\n KBS, the report says, should, wherever possible, complement human workers rather than replace them. It should be designed to explain its reasoning, allowing the human user to direct the task and exercise judgment in interpreting the results. KBS should be a tool for our use, not a decision-maker in its own right.\n Although the report sees no immediate KBS threat to privacy or liberty, it says the Data Protection Act should be extended to cover the rules by which personal data are processed. It says there may also be a future need for statutory regulations of KBS standards.\n It points out that KBS is already a billion-dollar industry, although the first true KBS program was written only 20 years ago and 'the great and exciting challenge of trying to capture human thought processes on a computer' is only just beginning.\n The report mentions some of the useful and simple KBS applications now proven, such as the banking system in France which gives advice on home loans to customers at its branches and the Australian system which offers guides to multiple-connection trans-continent train journeys. It points out that other uses - such as the 'seeing, thinking' robot running a factory production line - have yet to pass the prototype stage.\n The working party of experts also warns against over-reliance on experts, recalling the Government's Lighthill report of 1972. Sir James Lighthill was so dismissive of artificial intelligence (he even suggested robotic researchers suffered from maternal deprivation and built robots in the image of their mothers) that his verdict all but halted research in Britain. America stormed ahead and the UK lost a world lead.\n The Boden report, while generally optimistic, does not swing the pendulum perilously the other way. Computers, it says, are not 'objective'; they function as models or representations of the real world and, as such, their 'judgments' are essentially fallible. They should always, in principle, be challenged.\n The working party suggests that any KBS available for public use should include a clear statement of who made it and on whose expert knowledge it is based; of what it claims to be able to do (and not do); of the foreseeable risks and dangers it holds; and of the general danger of relying on a machine in areas where human advice is available.\n The report pinpoints the current balance in one superb sentence: 'The mind's fundamental intelligibility is suggested by successes in AI: its enormous richness and power are emphasised by AI's many current failures.'\n"},
{"docid": "319 of 500 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "September 30, 1987", "title": "Ruling the thumb of knowledge\n", "content": "\u00a0\n Britain is investing pounds 60 million a year in artificial intelligence developments - more than Japan, about the same as France and Germany, but less than a quarter of the United States' commitment.\n In terms of public funding, the UK's current spending is pounds 7 million a year, compared with pounds 21 million in the US, pounds 8 million in Germany, pounds 7 million in France, and only pounds 4 million in Japan.\n Mr John Butcher, the junior Industry Minister, gave those estimates yesterday at a press conference to announce details of the British Computer Society's expert systems conference in December. The conference is funded by the UK Government, the European Commission, and the two biggest American computer companies, IBM and DEC.\u00a0\n Expert systems is the jargon for the artificial intelligence technique of computerising the rules of thumb of human knowhow. A computer provides professional advice through gathering, codifying, then applying the accumulated experience of the human specialist - in property law, orthopaedics, currency trading, gardening, or whatever.\n In the US there are at least 200 expert systems profitably at work in banking, aerospace, oil prospecting, and telecommunications.\n About 150 UK firms are either using, developing, or experimenting with artificial intelligence, and the Government is dipping into Al in attempts to clarify the NATO rules on hitech exports, provide retirement advice, and define performance indicators for local health authorities.\n Mr Butcher rejected the suggestion that expert systems are approaching the stage where society needs guidelines to divide systems of proven worth in areas of comparatively firm human knowledge and experience from those involving subjective judgements in areas where we cannot define our own reasoning, let alone put it in a machine.\n He said that 'to the audience that matters' the benefits of expert systems were close to being proven. Expert systems were 'selling a synthesis' that freed managements to make better use of their time in decision-making. They held a great potential, Mr Butcher said, for extending the use of information technology.\n"},
{"docid": "320 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "November 5, 2015", "title": "Robots may shatter the global economic order within a decade; 'The pace of disruptive technological innovation has gone from linear to parabolic,' says Bank of America\n", "content": "Robots will take over 45pc of all jobs in manufacturing and shave $9 trillion off labour costs within a decade, leaving great swathes of the global society on the historical scrap heap. \nIn a sweeping 300-page report, Bank of America predicts that robots and other forms of artificial intelligence will transform the world beyond recognition as soon as 2025, shattering old business models in a whirlwind of \"creative disruption\", with transformation effects ultimately amounting to $30 trillion or more each year. \nManufacturing wages in China have jumped ninefold since 2000, and the country's workforce is shrinking . China is already the world's biggest buyer of robots, making up a quarter of the global market. \u00a0\nThe costs of robots, \"care-bots\" for the elderly, \"agribots\" to plants seeds or pick fruit, commercial drones and artificial intelligence have, on average, dropped by 27pc over the past 10 years, and are expected to fall a further 22pc by 2005. \nThe price of an advance robotic welder fell from $182,000 in 2005 to $133,000 last year, and its sophistication is increasing all the time. The standard Baxter collaborative \"cobot\" that works side by side with people on the factory floor - fixing bolts on a conveyor belt, for example - costs just $22,000. \nWe are coming close to the crucial \"inflexion point\" when it is 15pc cheaper to use a robot than to employ a human worker. \nThe workforce will split yet further into the \"haves\" at the top of education scale and the \"have-nots\" with just high school qualifications, not to mention the 800m illiterates in the world. It is easy to imagine the explosive political consequences if governments fail to take action to mitigate the effects, yet this may be almost impossible in a borderless, globalised world. \nNor are the middle classes invulnerable. Bank of America said \"robo-advisors\" using algorithm-based systems will \"disrupt\" 25m workers in financial and legal services. The Millennial generation - now 18-34 years old - will be the first to switch en masse to these post-human services. This rising cohort already holds $7 trillion of liquid assets and is likely to inherit another $30-$40 trillion from Baby Boom parents. \nNot everybody accepts this overall hypothesis. Professor Charles Goodhart, from the London School of Economics, wrote a paper recently for Morgan Stanley making the opposite argument, contending that the demographic crunch across the Northern hemisphere will overwhelm the effects of technology and lead to an acute labour shortage. \nThere is nowhere to go. Labour-saving devices are sweeping everything, everywhere\nUnder his scenario, workers will take their revenge and claw back the lost share of income as wages rise. The return on capital will fall, and the global deflationary supercyle will end in a bloodbath for the bond markets. \nThere have always been fears of mass destitution with each sudden shift in technology, whether it was the 18th century wool weavers of Yorkshire and the West Country displaced by cotton, or the machine-breaking Luddites in the 19th century threatened by the power loom, or dozens of other such episodes across the world throughout history. \nThe losers - or their children, at least - are eventually absorbed back into new industries. Human ingenuity has always prevailed. Larry Summers, the former US Treasury Secretary, warns that history is non-linear and it may be different this time. \nThe proportion of those in the US aged 25-54 and not working has tripled since 1965, suggesting that a chronic effect is already taking hold. \nThey cannot migrate to textile mills and the manufacturing hubs of the cities, as they did in the 18th and 19th centuries to escape the effects of the agricultural revolution. \n  tmgAds.embedPlayer = tmgAds.embedPlayer || {}; tmgAds.embedPlayer = { width: 620, height: 349, size: '620x349', vidSize: '620x415' }; if (typeof(tmgAds.page.platform) != 'undefined' && tmgAds.page.platform === \"mobile\") tmgAds.embedPlayer = { width: 300, height: 169, size: '300x169', vidSize: '300x235' }; tmgAds.embedPlayer = { 'targetId': 'embedPlayerWrapper', 'platform': tmgAds.page.platform, 'width': tmgAds.embedPlayer.width, 'height': tmgAds.embedPlayer.height, 'size': tmgAds.embedPlayer.size, 'autoplay': 'false', 'vidEmbed': 'A5MXdwdzorIRJeM17MQRxZFwM05Q2YG7', 'adTag': tmgAdsBuildAdTag(\"vid\", tmgAds.embedPlayer.vidSize, \"pfadx\", \";vidsrc=;vt=embed;dcmt=text/xml\", 3) } tmgAds.embedPlayer.remotesrc = 'http://s.telegraph.co.uk/tmgads/tools/ooyala/iframeplayer.html?platform=' + tmgAds.page.platform + '&width=' + tmgAds.embedPlayer.width + '&height=' + tmgAds.embedPlayer.height + '&size=' + tmgAds.embedPlayer.size + '&vidEmbed=' + tmgAds.embedPlayer.vidEmbed + '&adTag=' + encodeURIComponent(tmgAds.embedPlayer.adTag); tmgAds.embedPlayer.tmgEmbedPlayer = ''; document.write(tmgAds.embedPlayer.tmgEmbedPlayer); \nThere is nowhere to go. Labour-saving devices are sweeping everything, everywhere. A single professor can teach a course to 150,000 students through digital technology. \nWe may achieve the dream of prosperity without toil as robots take over, but find ourselves living in a jobless dystopia. \n"},
{"docid": "321 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "July 31, 2015", "title": "Channel 4 renews Humans for second series ahead of season finale; Sci-fi show is broadcaster's most successful drama in 20 years, with audiences engrossed by its depiction of AI and how it could threaten mankind\n", "content": "Channel 4 has announced there will be a second series of Humans, its most successful drama in 20 years, ahead of the show's highly anticipated season finale on Sunday night.\nSet in a parallel present, Humans has prompted widespread debate about artificial intelligence. It imagines a world in which we increasingly rely on robots, marketed as high-tech luxury house appliances. As the eight-part drama has progressed, it has wrestled with questions around artificial intelligence and its possible threat to mankind, as well as exploring what it means to be human.\nThe next instalment the writers said will \"take the world forward a little bit and explore the next phase of the technology\".\u00a0\nWhile cinema has tackled AI countless times, including in recent films Ex Machina and Her, but with the exception of Charlie Brooker's Black Mirror the subject is relatively unexplored on the small screen. Yet, as the show's writers Jonathan Brackley and Sam Vincent point out, it is an issue which has increasingly seeped into the public consciousness.\n Related: Humans becomes Channel 4's biggest drama hit in 20 years\n\"There has been something in the air for a while now,\" said Vincent. \"Recently there have been very serious pronouncements by figures such as Elon Musk, Bill Gates and Stephen Hawking about how they see AI as a very real danger and that there are serious problems to be worked out before we make the next advancements.\"\nHumans' subject matter has proved popular, with the first episode drawing in a consolidated audience of 6.1 million, making it Channel 4's highest rated drama since The Camomile Lawn more than 20 years ago. The show has also succeeded in defying the trend of massive audience losses over the course of a season, instead attracting an average of 4.8m viewers per week. \nWhile some developments in AI which are portrayed on screen still feel a while off, society's increasingly dependent and emotional relationship with technology made audiences very receptive to the ideas and concerns explored in Humans, argues Vincent.\n\"We have an incredibly intuitive and instinctive interface with most of our consumer technology now, which has really gone leaps and bounds in the past few years,\" he said.\n\"From things like Siri to the fact we even create our personal relationships through technology, with dating apps or using social media, so much so that technology now sits at the centre of our lives and has become ever-easier and more humanlike to use.\n\"But also this gap has opened up because as it gets more sophisticated, it has also become more unknowable. I think it has created this need in people to think a bit more about their technology.\"\nHumans was adapted from the 2010 Swedish drama Real Humans, but as the show progressed the storylines departed quite noticeably from the Scandinavian original.\nFor Brackley, the writers' decision to allow viewers to make up their own minds about AI and its positive or negative impacts on society has been a key reason why people have kept watching.\n\"We've certainly hinted that AI is something that needs to be discussed, debated and yes, handled carefully,\" said Brackley. \"But in our world we've tried to show as many different stories about synths and their interactions with humans as possible because we never wanted to show this as either a utopia or a dystopia, which a lot of sci-fi stories have done in the past.\n\"We'd much rather engender the debate in our audience, and have them discussing amongst themselves whether they would get a synth, whether it would be a good idea and whether we want a world where these things existed.\"\nThe pair remain cagey about what viewers can expect from the second season, which begins filming next year and will comprise another eight episodes but promise it will not be a major departure from the current stories and characters.\n\"Obviously I am treading very carefully here but we do want to take the world forward a little bit and want to see what the next phase of this technology is, that it is moving on and moving forward and is producing news effects, both positive and negative. So we are going to move the status quo of the world forward a little bit,\" said Vincent.\n\"We are going to stick to the things that we loved about the original series when we came to it, the balance of stories between more domestic-based stories and the more thrillery aspect to the show, so are we going to stick to that,\" added Brackley.\nThe initial intrigue in the show has also been credited to a smart advertising campaign by Channel 4, which saw the creation of a fake brand, Persona Synthetics, which advertised the humanoids on television, social media and in shops. David Abraham, Channel 4's chief executive, recently said the campaign had a \"profound effect\" and helped bring a large audience to the show.\n\n"},
{"docid": "322 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "October 24, 2017", "title": "Decades long deflationary shock threatened by artificial intelligence\n", "content": "It's commonly billed as the single most influential position in the global economy -\u00a0chairman of the US Federal Reserve. President Donald Trump has promised to announce who will be filling the role for the next four years by the time he sets off on a visit to Asia on Nov 3, or in other words any day now.\nMany column inches have already been expended speculating on who he might choose -\u00a0a hawk or a dove -\u00a0and I don't intend to add to them. But here's what is possibly the more interesting question; does it actually matter any more?\u00a0\nI suppose it might, in the sense that any choice thought likely to be compliant with the president's political demands would be taken badly by markets, degrading a generally competent institution and haven of economic expertise.\nBut in most other respects, it may not be as important as it seems, for global interest rates are today being driven by much deeper structural forces than presidential whim.\nThe working assumption for now is that all the pressures on interest rates, both in the US and globally, are upwards. More than three quarters of the world is growing again, unemployment is falling virtually everywhere, and labour participation is rising. We seem finally to be putting the financial crisis behind us.\nEarnings may still be stagnating in the West, but in many parts of the developing world, particularly China, they are rising at a fair old clip, undermining some of the competitive advantages of these one time low wage economies and removing a potent deflationary influence on the world economy.\u00a0\nYet it's hard to conclude that such as they are, these renewed inflationary forces are anything but temporary; most of the ongoing structural pressures on prices are decidedly disinflationary, and likely to remain so for decades to come.\u00a0\nThe reason? Automation and Artificial Intelligence (AI) - variously referred to as the second machine age or fourth industrial revolution .\n        The history of artificial intelligence       01:49\nIn analysing the possible impact of AI, most research tends to focus on jobs; the heavily related issue of prices commands less attention. Yet it is in this domain that we may see some of the more far reaching macro-economic consequences. Where more than twenty years of disinflationary globalisation left off, automation is stepping into the breach, exerting many of the same downward pressures on prices.\nTextiles, clothing and apparel provide a useful example of why this is so. Rewind to the 1970s, and these industries provided employment for around 800,000 people in the UK, or one in every 30 jobs. As international trade opened up, prices fell steeply, and the domestic industry all but collapsed.\u00a0The jobs moved first to Hong Kong, then as the former British colony began to lose price competitiveness, to a newly liberalising China. From there they migrated to still lower cost developing economies such as India, Bangladesh and Vietnam.\u00a0The next leg of the journey sees them shift to Africa, where but for automation, they might have stayed.\nThe robots promise a final leg of the journey to production facilities where there are no, or hardly any, labour costs at all.\u00a0Already we are seeing real life examples of this market driven end game. Nike, for instance, has managed fully to mechanise production of its top end running shoes. As ever, the purpose is extra margin and profit, but it won't be long before others catch on and prices fall to match.\nThis kind of price deflation can be very beneficial, as Ben Broadbent, deputy governor of the Bank of England, pointed out in a recent speech. Unfortunate though it might be for affected workers, by Broadbent's calculation, the economic costs associated with destruction of Britain's clothing industry are hugely outweighed by the gains to consumers from lower prices. The destruction of jobs in the clothing industry is also hugely outweighed by the creation of new jobs elsewhere.\nIf the second machine age were to follow the same pattern as previous periods of significant technological change, the overall effect of deflating prices might therefore be positive, driving up real wages and making people better off.\nBut there is regrettably something which makes the current wave of automation significantly different from anything seen in the electro-mechanical age -\u00a0so-called \"machine learning\" affects not just goods, but services.\u00a0\nVirtually anything that involves repetitive manual work or data processing can now be automated, rendering, according to Bank of England and Oxford Martin School\u00a0estimates, around half of all current UK jobs vulnerable.\nThe disinflationary effects of globalisation have to date been predominantly concentrated on tradeable goods, leaving the comparatively closed world of domestically focused service industries relatively unaffected. Service sectors have therefore experienced rather higher levels of inflation.\nLondon and the South East export the majority of services\nAI threatens to do to service industry prices what globalisation has done to the price of goods. What is more, it threatens to make obsolete a great swathe of reasonably paid, middle income employment, with nothing obvious to replace it.\nWe are therefore faced with a double deflationary effect -\u00a0a first order impact from lower costs, and a much less desirable second order consequence from stagnant or declining wages. The supply side benefits of the good deflation, as it were, might be more than cancelled out by the demand side downsides of the bad deflation.\u00a0\nSuch an outcome would mirror almost exactly the early stages of the British industrial revolution, where many highly paid and skilled workers were made redundant by the new factories, driving them into poorly paying menial jobs. It was at least forty years before there was a noticeable positive impact on living standards for the common man. Expect a destabilising and possibly destructive social and political reaction much sooner in the entitlement of today's world.\nIn any event, \"normalisation\" of interest rates may be just a central bankers' pipedream. Whatever Mr Trump's choice for the chairmanship of the Fed, the second machine age will keep inflation, and therefore interest rates, low for a long time to come.\n"},
{"docid": "323 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "January 27, 2018", "title": "Mysterious 15th century manuscript decoded by computer scientists using artificial intelligence; Text appears to be written in Hebrew with letters rearranged, according to algorithms employed by Canadian researchers\n", "content": "Artificial\u00a0intelligence has allowed scientists to make significant progress in cracking a mysterious ancient text, the meaning of which has eluded scholars for centuries.\nDated to the 15th century, the Voynich manuscript is a hand-written text in an unknown script, accompanied by pictures of plants, astronomical observations and nude figures.\u00a0\nSince its discovery in the 19th century, many historians and cryptographers have attempted to unravel its meaning -including code breakers during the Second World War-but none have been successful.\nWhile some have written the Voynich manuscript off as a hoax, use of modern techniques has previously suggested the presence of \"a genuine message\" inside the book.\nRead more\nAliens, hoaxers or a lost culture: who wrote the Voynich Manuscript?\nNow, computer scientists at the University of Alberta have applied artificial\u00a0intelligence to the text, with their first goal to establish its language of origin.\nThey used text fromthe Universal Declaration of Human Rights in 380 languages to \"train\" their system and then ran their algorithms, which determined the most likely language for the document was Hebrew.\n\"That was surprising,\" said Professor Greg Kondrak, who led the research.\n\"And just saying 'this is Hebrew' is the first step. The next step is how do we decipher it.\"\nThe scientists set out to employ an algorithm that could decipher the scrambled text that makes up the manuscript.\nThey hypothesised the manuscript was created using alphagrams, or alphabetically ordered anagrams. This theory has previously been suggested by other Voynich scholars.\nBy applying algorithms designed to decode such puzzles, Professor Kondrak and his graduate student Bradley Hauer were able to decipher a relatively high number of words using Hebrew as their reference language.\n\"It turned out that over 80 per cent of the words were in a Hebrew dictionary, but we didn't know if they made sense together,\" said Professor Kondrak.\nWhile they noted that none of their results, using any reference language, resulted in text they could describe as \"correct\", the Hebrew output was most successful.\nThe scientists approached fellow computer scientist and native Hebrew speaker Professor Moshe Koppel with samples of deciphered text.\nTaking the first line as an example, Professor Koppel confirmed that it was not a coherent sentence in Hebrew.\nRead more\nGoing public for the first time: the indecipherable Voynich Manuscript\nHowever, following tweaks to the spelling, the scientists used Google Translate to convert it into English, which read: \"She made recommendations to the priest, man of the house and me and people.\"\n\"It's a kind of strange sentence to start a manuscript but it definitely makes sense,\" said Professor Kondrak.\nThe results of this work were \npublished in the journal \nTransactions of the Association of Computational Linguistics\n.\nIn their paper, the researchers conclude that the text in the Voynich manuscript is likely Hebrew with the letters rearranged to follow a fixed order.\nWhile fully comprehending the text will require collaboration with historians of ancient Hebrew, Professor Kondrak has great faith in the ability of computers to help understand human language and said he is looking forward to applying his techniques to other ancient scripts.\n"},
{"docid": "324 of 500 DOCUMENTS\n", "source": "The Guardian - Final Edition\n", "date": "September 21, 2006", "title": "Technology: Chat program scoops the prize for being almost human\n", "content": "Her name is Joan; she is just a few years old and very talkative. . . and now she is officially the world's most human computer program.\nOn Sunday, the computer-generated character scooped the prestigious Loebner prize for artificial intelligence, seeing off some of the world's most hi-tech creations in the process.\nJoan's maker, the British entrepreneur Rollo Carpenter, emerged victorious after a day of intense competition as a quartet of software experts attempted to pass the famous \"Turing test\" and scoop a purse of $100,000 in the process.\u00a0\nThe test began well before computers were capable of such complex interaction. In 1950 the British mathematician Alan Turing, who famously helped crack German military codes during the second world war, asked how scientists would determine whether computers had successfully achieved truly artificial intelligence. His suggestion was that a computer which could give conversational responses that were indistinguishable from a human's could be said to be thinking for itself.\nThat challenge turned into an annual competition when New York philanthropist Hugh Loebner offered $100,000 to the first program to successfully fool a panel of judges into thinking it was a real person.\nDespite 16 years of trying, no technology has made that breakthrough, and the grand prize remains unclaimed. However, Joan was deemed to be the most human competitor on show after a blind test held at University College London. The judges held typed conversations - similar to an internet chat program - with all of the challengers, before they declared her the winner.\nThat victory earned Carpenter a $2,000 prize and a bronze medal - and also helped him retain the title he first won last year with George, an other program driven by Jabberwacky, the technology behind Joan.\nWhat's unusual about Jabberwacky is that it uses its experience of interaction with humans to create a store from which to draw its next response. The system has been entered for the Loebner Prize contest since 2003, and now seems to be building up an impressive lead over its rivals. That may be helped by the fact that it is always able to enlarge its database through conversations online: if you want to try it out, go to jabberwacky.com.\n\"I'm very pleased,\" said Carpenter. \"In a way this is very subjective test. . . but I believe that for practical purposes, people in working conditions will believe it's a human.\" (Technology Guardian had a conversation with Joan; you can judge the results in the panel at left).\nCarpenter is now working with call centre companies to help train his robots into understanding how to better interact with humans - with the possibility of using them to replace human workers in the near future. But experts say that a program that will successfully pass the Turing test is still some years away.\n\"We're still a long way off, but I think he's onto something,\" said Duncan Graham-Rowe, one of the judges.\nBut Carpenter is used to the long haul. The very first version of the program was written in 1982, and ran on a Sinclair ZX81, an 8-bit home computer which had a maximum of 16K of RAM.\n\"Do you like cyborgs?\"\nBobbie: You won the Loebner prize!\nJoan: Nobel beats a Loebner hands down.\nBobbie: You shouldn't be so hard on yourself.\nJoan: In a world of depression and misery, the least you can do is try to be optimistic.\nBobbie: That's the spirit. How does it feel to be a winner?\nJoan: Don't be silly.\nBobbie: Why is that silly? Are you embarrassed?\nJoan: A little. . . I'm talking to a robot here.\nBobbie: Well, it is a difficult experience.\nJoan: You're so stupid.\nBobbie: So you keep telling me.\nJoan: I don't like you very much.\nBobbie: I see. Do you ever think you'll win $100,000?\nJoan: I already am.\nBobbie: Well, you're not there yet.\nJoan: Do you like cyborgs?\nBobbie: Not really. I have to go now, goodbye!\nJoan: Sorry.\n"},
{"docid": "325 of 500 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "November 3, 1992", "title": "THE TRIALS AND JOYS OF JEWRY\n", "content": "\u00a0\n War in the Age of Intelligent Machines by MANUEL DE LANDA\n pounds 29.75 hbk pounds 15.25 pbk 272pp Zone Books (distributed by MIT Press)\n FIVE years ago on \"Black Monday\" - October 19, 1987 - the Dow Jones average fell 508 points and lost 25 per cent of its value in a single day. The villain of this vertiginous New York stock exchange plunge - which was repeated in London, Tokyo, Hong Kong, Sydney and all round the world - was programmed selling by computers whose actions were triggered automatically by falling share values. Following their instructions to the letter, these robots so steepened the downward path of share prices that it began to resemble the kamikaze plunge of a Japanese suicide plane. Global economic chaos was only narrowly averted by the simple expedient of pulling the plug on the computers' selling frenzy, and regaining a safe altitude under manual control.\u00a0\n The famous hair's breadth escape of \"Black Monday\" was in effect a civilian version of the subject of this book. For far worse than the next global stock market crash, according to Manuel de Landa, is the prospect of the next global war, in which the programmed selling will be done by robot weapons systems under the control of an artificial intelligence that no human will have the power to unplug.\n According to De Landa, the route by which artificial intelligence has gained more clout than human intelligence in the operation of defence systems, is exactly the same as the route followed by artificial intelligence in the world's stock exchanges. It has to be because all such concepts are the outcome of \"operations research\" conducted by the military. Thus there is a direct path leading from computer simulations developed to enable catastrophic war scenarios to be tested (without real soldiers even so much as getting their feet wet), to programmes that seek to prevent investor losses by cybernetically controlled buying and selling.\n Three interesting and typical characters encountered along the path leading from the first gunnery control computer, ENIAC, to the stock exchange information system, TAURUS, are COLOSSUS, an early code-breaking computer, and his grandsons SAM and IVAN, developed years later to play deadly games of MAD (Mutually Assured Destruction) at the height of the Cold War. SAM and IVAN came into use when it was discovered that real life generals, even when merely sticking pins in maps, were hopelessly reluctant to cross the nuclear threshold.\n The bulk of War in the Age of Intelligent Machines is taken up with the story of the progressive robotisation of warfare from Genghis Khan to the Cold War, via Frederick the Great and Napoleon. De Landa's style is swift, compressed and repetitive but compelling too, for he tells it from the novel standpoint of a \"robot historian\" - an updated version of the proverbial man from Mars. Not only does he see warfare as a phenomenon only partly composed of humans, but he also recognises, in its half-robotic conglomerations of men and machines, something that has already evolved away from the primitive human idea of the \"great leader\" - towards the sophisticated human idea of an unbeatable machine.\n More ominously, in this progression, De Landa discerns a dialectic whereby the \"great leader\" actually becomes the unbeatable machine, and thus dehumanises the conduct of war in all save its casualties. Thus to the process innocently summarised by Marshall McLuhan 30 years ago whereby \"Man becomes the sex organ of the machine world just as the bee is of the plant world\", De Landa adds evidence that at least one kind of man - the strategic thinker - is hard at work making sex unnecessary by taking human beings \"out of the loop\" of the world of intelligent machines, and creating weapons systems capable of mounting their own unstoppable military version of \"Black Monday\".\n Awe-inspiring though it appears at first sight, with its racy \"Swerve Editions\" jacket; its grainy pictures of sophisticated weapons; its highly technical language - \"rationalized predation\", \"flying platforms\", \"bootstrapping\", \"noisy data\" and \"phase entrainment\" - and its flood of acronyms - MILNET, CROWCASS, DENDRAL, SIGINT and PROWLER (the last an unmanned tank called the Programmable Robot Observer With Logical Enemy Response) - the theme of War in the Age of Intelligent Machines is surprisingly simple. So simple in fact that, despite the dense technical writing in which it is couched, it has enabled the book to become a cult success in America.\n De Landa, like Hofstadter in his far more compendious Godel, Escher, Bach - a similarly portentous work - deploys an apparent complexity that barely conceals a simple Robocop set of values. His subtext is that the bad guys are the military industrial complex that keeps on inventing threats like \"the bomber gap\", \"the missile gap\" and \"Star Wars\" so that weapons' research is driven remorselessly in the direction of taking humans \"out of the loop\" so the robots can take over.\n Over against them are the good guys, not so much peaceniks now as computer whizz-kids, people who have consumerised - or rather neutralised - the mighty backlog of operational research carried out by the military since the 1950s, by turning all its old mainframe wargame simulations into joystick fun for home computers.\n De Landa believes that in doing this they are also keeping human beings \"in the loop\" of man/machine thinking, and keeping brutes like SAM and IVAN out of it.  In the confusing complexities of the post-Cold War universe, we can only hope that PROWLER will be programmed to know the difference.\n Martin Pawley is the editor of World Architecture. His book about Buckminster Fuller is now published in paperback by Grafton at pounds 9.99\n"},
{"docid": "326 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "March 5, 2015", "title": "Beware the rise of the digital oligarchy; Powerful algorithms are concentrating the ownership of personal data in few hands. We need rights to control who accesses it\n", "content": "The Bank of St George, founded in 1407 in the Italian Republic of Genova, is one of the world's oldest banks. It was so powerful that it governed many of Genova's possessions on the republic's behalf. This power was based on accumulated capital. The power of accumulated capital can still dominate international affairs, but a new form of power is also emerging, that of accumulated data through loyalty cards, text messages, credit card transactions, web browsing and social networking. Data is the new currency.\nWhere does this power come from? Cross-linking of different data sources can give deep insights into personality, health, commercial intent and risk. The aim now is to understand and characterise the population, down to the individual level.\u00a0\n                     Personalisation is the watchword, with targeted search results, social network news feed, movie recommendations and adverts. The upside is good: we could target specific health recommendations, give better treatments and earlier diagnoses for disease, and provide better support to the elderly and otherwise incapacitated people.\nBut there are also major ethical questions. For banks it is clear, we own the money we deposit there. They only hold our capital under license and pay us directly for using it. Ownership of data is less clear. In the past acquiring data was expensive: it required questionnaires and manual collation of information. Today we leave digital footprints in our wake, and acquisition of personal data is relatively cheap.\nOur personal data reflects our interests, our desires: it is a digital extension of our soul. By giving it away so freely to social networks, supermarket loyalty cards and internet search engines have we engaged in some form of Faustian pact ? Our digital souls may not be immortal, but they can certainly outlive us. What we choose to share also affects those around us: my wife and I may be happy to share information about our genetics, but by doing so we are also sharing information about our children's genomes. Using a supermarket loyalty card gains us discounts on our weekly shop, but also gives the supermarket detailed information about our family diet.\nMachine learning is at the heart of the current revolution in artificial intelligence. A major aim of the field is to develop algorithms that better understand all of this data. Already machine-learning techniques are used to recognise faces or make movie recommendations, but as we develop better algorithms for aggregated data, our understanding of the individual also improves. There have been calls from Elon Musk, Stephen Hawking and others to regulate artificial intelligence research. They cite fears about autonomous and sentient artificial intelligence that could self-replicate beyond our control. Most of my colleagues believe that such breakthroughs are beyond the foreseeable horizon of current research. Sentient intelligence is still not at all well understood.\n Related: Why we have to get smart about artificial intelligence\nPersonally, I worry less about the machines and more about the humans who will gain enhanced powers of understanding through the algorithms we develop. Most of our historic problems seem to have come from humans wielding too much power, either individually or through institutions of government or business. Rather than worry about the rise of the machines, we should worry about creating a data-oligarchy: concentrating the power that comes with data in the hands of a few.\nWe need better models of data ownership. When interacting with banks we can withdraw our funds, but for data repositories we have no right of deletion. We need a better understanding of how our data is being used already and how it is likely to be used in the future. There are opportunities and risks with the accumulation of data, just as there are for the accumulation of capital. However, one thing seems clear: we need to increase the power of the people. Banks pay interest; perhaps we should be paid directly for the use of our personal data. We need to be made aware of the value of our data and be given rights to control who accesses it. We need to form a data-democracy: data governance for the people, by the people and with the people's consent. \n                     Neil Lawrence is a professor of machine learning at the University of Sheffield. He is an advocate of open data science and an advisor to a London based startup, CitizenMe, that aims to allow users to reclaim their digital soul                   More like this\n"},
{"docid": "327 of 500 DOCUMENTS\n", "source": "The Independent - Daily Edition\n", "date": "March 19, 2018", "title": "Artificial intelligence won't wipe out humanity, because robots aren't humanly flawed\n", "content": "Science and engineering lift humanity to greater and more enduring heights, while philosophy seems to be in a regular state of existential crisis. Yet sometimes we're reminded that even the greatest science and engineering minds of the last century - whether the genius of Stephen Hawking, who we sadly lost a few days ago, or the innovation of Elon Musk - could still benefit from philosophical thinking.\nMusk, in particular, constantly reminds us of his big fear, repeated this week: that robots with artificial intelligence are likely to annihilate us. He sincerely believes that we should colonise Mars mainly because it provides the greatest opportunity for humanity to survive this unavoidable annihilation.\u00a0\nThere are many good reasons to colonise Mars: avoiding an eventual asteroid collision with Earth; escaping a depleted environment; perhaps even to provide a home if nuclear weapons ever fulfil their terrible (though unlikely) potential. But AI-infused robots are unlikely to wipe us out, no matter how intelligent, and the evidence is in critical thinking.\nThink about what a robot is: a body of some type, controlled by a computer that is essentially doing the job our brain does for us. Our brains have evolved to allow us to react to stimuli in increasingly impressive ways; 3.5 billion years ago, our ancestors were single-celled organisms, and since then we have developed the ability to hear, see, touch and now think deeply about the stimuli we are presented with.\nRight now, human and robot \"brains\" are worlds apart, because computers do not have the complexity that evolution imbued in us in order to reach the pinnacle of the evolutionary tree.\nOnce we scale the mountain of complex artificial intelligence, and become able to recreate intensely smart, reactive and learning robots, the opposite will be true: our brains will be inferior because we are limited by what it was evolutionarily necessary for us to be able to do. The memory and abilities of a computer could be limitless, precisely because they are not limited by the bias unavoidably programmed into us by such a complex genetic history.\nThat last part is the important bit: robots will become more intelligent, in the sense that they may be able to process data faster, learn faster, one day even become self-aware. But they will not have the evolutionarily developed \"junk\".\nThey won't have the insecurities of social situations, feel the need to fit in with peers or to dominate conversations. They won't become power-hungry or feel the need to amass unmatched levels of currency. They won't have the feeling that they are falling when they are trying to fall asleep, because they were once tree-dwelling creatures.\nHumans might be advanced compared to horses and dogs, but we're still quite simple; we've developed decent cognitive abilities, but we're driven by basic desires to procreate, be comfortable and fit in.\nYet this is what worries Musk. When humans became more advanced, we decided to farm other species, war with other humans and gradually try to dominate one another. He assumes robots will do the same.\nHawking, similarly, believed AI would place us in danger because of likely different goals to humanity. But while robots will become smarter and more capable, perhaps even self-aware, they won't have that same genetic desire to survive and reproduce. We don't possess those things due to self-awareness - we have them because it was evolutionarily necessary to.\nComputers may one day become advanced reasoning machines. In some ways they already have. But they will never be smarter versions of human beings, because we have flaws which no one would ever want to recreate in robots.\nOn the off-chance someone does, and can, these robots will be necessarily less capable than their unflawed colleagues. Their processing capabilities would be heavily consumed by jealousy and anger, sorrow, resentment, attachment, contentment, doubt, guilt, pride and every other bias which makes human life unpredictable and wonderful. While the unbothered alternative models might be programmed to feel sympathy for such flaws, they would not have them.\nThe concern about AI is not that someone could develop things that might kill millions of humans with the press of a button. These already exist. Instead, the concern centres on the idea that someone will be able to programme AI capable of coexisting with or destroying humanity, and that the AI will choose the latter. It's really a paradox: if the technology exists to create this, it would require robots with programmed flaws in their coding to allow such irrelevant yet complex goals.\nThese would be robots programmed to learn the width and breadth of human culture, to learn to make the best possible decisions, and we would be worrying about them becoming concerned with domination, and all the human characteristics which steal our attention and stop us from making better decisions.\nRobots are no more likely to want to rise up and dominate the Earth than they are to want to drink sugary drinks, inject heroin or watch reality TV. That we see dominating Earth as the end goal of a perfectly rational individual says much about our own evolution, and very little about robots.\n'Thinkonomics: Illustrated Critical Thinking Articles' by Robert A Johnson, illustrated by Chuck Harrison, is published by Ockham Press on 20 March at \u00a37.99\n"},
{"docid": "328 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "July 9, 2015", "title": "Porn on Twitter: network builds robots to find and eradicate offensive pictures; The AI systems are likely to spread to other offensive content, and could save humans from having to look at disturbing images\n", "content": "Twitter has built highly-intelligent robots that can recognise porn, in an attempt to stop it spreading on the network.\nThe site has long been said to have a porn problem - which has been reported to scare off marketers who are afraid that their ads will appear next to content that is not safe for work. But it is putting to work technology it acquired when it bought a startup last year, which can spot NSFW images and other offensive media, helping automatically hide it in people's feeds.\u00a0\nThe porn-spotting robots are part of a broader move towards artificial intelligence at Twitter. But in the short term it could be able to cut out the huge amount of offensive content that appears in some parts of the site.\nIf the technology is set to filter out 99 per cent of NSFW content on the feed, it only gets it wrong 7 per cent of the time, according to a report in Wired. Identifying images of porn is particular difficult, Wired notes, since entirely innocent pictures of human flesh or breastfeeding mothers regularly appear on the site and the networks must avoid filtering those out.\nNeural networks are built to learn like humans. So instead of having to be told what porn looks like, the robots can just be fed huge amounts of it and then pick out its identifying features - which it can then use to spot similar media.\nread moreElon Musk is worried that Google's robot army could accidentally turn evilGoogle AI robot answers the meaning of life and tells humans how to be goodEngland Twitter account's sexist tweet\nThe same artificial intelligence networks power other, less NSFW image-spotting capabilities. Google's Photos app, for instance, can spot certain characteristics in images and filter them in special ways - and the company has created trippy pictures by setting those robots loose on other pictures.\nThe plan is part of a move by the social network to develop what it calls Twitter Cortex, which will use artificial intelligence to automatically analyse the hundreds of billions of tweets that are sent.\nThe Twitter Cortex technology will eventually be used to more effectively target ads. It will be able to read a whole person's Twitter feed, for instance, building up a complete picture of what they like and then targeting ads much more specifically.\nThe systems focused on NSFW content could also save human employees from having to look through photos to find objectionable ones - a job that requires looking at not just suspected porn, but violent and offensive images, and can do lasting damage to those that are required to do it. That work represents a big economic cost to the countries, as well as a huge emotional toll on those doing it - many of whom work in countries like the Philippines.\n"},
{"docid": "329 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "November 5, 2015", "title": "Robot revolution: rise of 'thinking' machines could exacerbate inequality; Global economy will be transformed over next 20 years at risk of growing inequality, say analysts\n", "content": "A \"robot revolution\" will transform the global economy over the next 20 years, cutting the costs of doing business but exacerbating social inequality, as machines take over everything from caring for the elderly to flipping burgers, according to a new study.\nAs well as robots performing manual jobs, such as hoovering the living room or assembling machine parts, the development of artificial intelligence means computers are increasingly able to \"think\", performing analytical tasks once seen as requiring human judgment.\n Related:  Robot doctors and lawyers? It's a change we should embrace | Daniel Susskind\nIn a 300-page report, revealed exclusively to the Guardian, analysts from investment bank Bank of America Merrill Lynch draw on the latest research to outline the impact of what they regard as a fourth industrial revolution, after steam, mass production and electronics.\u00a0\n\"We are facing a paradigm shift which will change the way we live and work,\" the authors say. \"The pace of disruptive technological innovation has gone from linear to parabolic in recent years. Penetration of robots and artificial intelligence has hit every industry sector, and has become an integral part of our daily lives.\" \n Related:  Work in the year 2525, if man is still alive... | Letters\nHowever, this revolution could leave up to 35% of all workers in the UK, and 47% of those in the US, at risk of being displaced by technology over the next 20 years, according to Oxford University research cited in the report, with job losses likely to be concentrated at the bottom of the income scale.\n\"The trend is worrisome in markets like the US because many of the jobs created in recent years are low-paying, manual or services jobs which are generally considered 'high risk' for replacement,\" the bank says.\n\"One major risk off the back of the take-up of robots and artificial intelligence is the potential for increasing labour polarisation, particularly for low-paying jobs such as service occupations, and a hollowing-out of middle income manual labour jobs.\" \nThe authors calculate that the total global market for robots and artificial intelligence is expected to reach $152.7bn (\u00a399bn) by 2020, and estimate that the adoption of these technologies could improve productivity by 30% in some industries.\nThey point out that Google bought eight robotics companies in a two-month period in 2014, from Boston Dynamics, which makes the BigDog robot, to DeepMind, specialising in deep learning for artificial intelligence.\nIn the most advanced manufacturing sectors - among Japan's carmakers, for example - robots are already able to work unsupervised round the clock for up to 30 days without interruption. While offshoring manufacturing jobs to low-cost economies can save up to 65% on labour costs, replacing human workers with robots saves up to 90%.\nAt present, there are on average 66 robots per 10,000 workers worldwide, the report finds; but in the highly automated Japanese car sector there are 1,520. \nBut it is not just low-skilled jobs, such as assembly-line work, that could be replaced: a report from the McKinsey Global Institute in 2013 found that up to $9tn in global wage costs could be saved as computers take over knowledge-intensive tasks such as analysing consumers' credit ratings and providing financial advice. \nEnthusiasts for the rise of robots argue that they can overcome the foibles and fallibilities of human workers. The report cites research that showed judges tend to be more draconian in the runup to lunchtime and more lenient once they have eaten, for example. \nIt urges consumers to invest in businesses that are already taking advantage of the benefits of the new technologies: \"Early adoption will be a key comparative advantage, while those that lag in investment will see their competitiveness slip.\"\nHowever, the bank also points out that major ethical and social issues will increasingly arise: they cite the moral questions about the growing use of unmanned drones in warfare ; and even the emergence of a pressure group called the Campaign Against Sex Robots.\nFears about humans being displaced by machines are not new: in the early 19th century bands of angry Luddites smashed up the steam-powered looms that were throwing hand-weavers out of work. \nBeijia Ma, the report's lead author, said that over the past 200 years and more, societies have eventually found ways of turning technological developments to their advantage.\n Related:  Robots can take over some of our jobs. But some things only humans can do | Brooks Rainwater\nShe said the best advice for people fearing the rise of the robots is to polish up their skills. \"It's not meant to be a doom and gloom report: one of the ways we think people could help themselves here is through education.\"\nHowever, Ma added that a recent survey of industry experts, by the US polling firm Pew, revealed a stark divide between techno-optimists and pessimists. \nAlmost half of them, 48%, believed the rise of robots and artificial intelligence would have \"a massive detrimental impact on society, where digital agents displace both blue- and white-collar workers, leading to income inequality and breakdowns in social order\". \nMeanwhile, 52% \"anticipated that human ingenuity would overcome and create new jobs and industries \". \nAndrew Simms, of thinktank the New Weather Institute, said the rise of new technologies could be an opportunity to realise the aspirations of the economist John Maynard Keynes, who predicted in 1930 that within a century, technology would have enabled the working week to be reduced to 15 hours with the rest of the time devoted to leisure.\nHowever, without rethinking the relationship between work and society, the result could be a growing disparity between economic winners and losers.\n\"We are in danger, for the first time in history, of creating a large number of people who are not needed,\" he said. \"The question should be, what sort of economy do you want, and to meet what human needs?\"Under threat?\nA wide range of jobs could eventually be taken over by machines, Bank of America Merrill Lynch's analysts predict.\n                     Burger flip                     pers  A San Francisco-based start-up called Momentum Machines has designed a robot that would replicate the hot, repetitive tasks of the fast-food worker: shaping burgers from ground meat, grilling them to order, toasting buns, and adding tomatoes, onions and pickles.\n                     Manufacturing w                     orkers  Relatively low-skilled industrial workers in rich countries have become used to competing against cut-price employees in cheaper economies. But while \"offshoring\" can cut labour costs by 65%, replacing workers with machines can cut them by up to 90%. The process is well advanced in countries such as Japan and South Korea; as other countries catch up, many more jobs will be taken over by technology.\n                     Financial advisers  Bespoke financial advice seems like the epitome of a \"personal\" service; but it could soon be replaced by increasingly sophisticated algorithms that can tailor their responses to an individual's circumstances.\n                     Doctors  Some 570,000 \"robo-surgery\" operations were performed last year. Oncologists at the Memorial Sloan-Kettering Cancer Center in New York have used IBM's Watson supercomputer, which can read 1m textbooks in three seconds, to help them with diagnosis. Other medical applications of computer technology involve everything from microscopic cameras to \"robotic controlled catheters\".\n                     Care workers  Merrill Lynch predicts that the global personal robot market, including so-called \"care-bots\", could increase to $17bn over the next five years, \"driven by rapidly ageing populations, a looming shortfall of care workers, and the need to enhance performance and assist rehabilitation of the elderly and disabled\".\n"},
{"docid": "330 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "June 8, 2015", "title": "The beginnings of advertising created by artificial intelligence; By giving computers the ability to create, learn and evolve we will free our minds to discover what is possible in advertising and beyond\n", "content": "This Bach piece isn't Bach. It was generated from an algorithm, in about a second. You could have a 1,000 more if you wanted. Likewise, the Associated Press (AP) releases about 3,000 articles a quarter generated by algorithm - rather than by journalists. And in web design, multivariate testing - trying out various layouts to see what works best by looking at usage data - is common practice. You can even do this automatically, to an extent. If automated, optimising design like this is a basic kind of learning. You could say your site is learning to work better.\n Related: Robots won't smash our creativity, they'll enhance it\u00a0\nThe fear may be that this kind of thing will take away human jobs. It will, but not for a long time. The machine-written articles tend to be about recording factual events that follow a system such as financial or sports stories. Journalists actually report that they like working with them because they take the boring jobs on for them, ie the jobs that aren't actually that creative or challenging. By taking these more menial tasks from us humans, we're actually being liberated by computers to become more creative - to use our brains.\nAdvertising will undoubtedly be impacted by automation technology. In fact, the smartest ad agencies will be at the forefront of automation research, design and implementation. Automation is something that creative agencies should seriously considering investing in, or at least factoring it into their five year plans.\nIn advertising we can offer a hundred different variants of a banner ad and target them in a granular way. Or we might as well make one single banner and let it choose one of 100 states. The outcome is the same, but it starts to sound a bit like artificial intelligence. Then if you give the system a bit more power to choose combinations of elements, even a language engine to create its own copy, and give it feedback to learn from, maybe by measuring interaction, you have the beginnings of artificially created ads.\nThere have already been some stunning examples of advertisers and brands using automation - at times even bordering on artificial intelligence. From the way in which Groupon intelligently designs itself using perpetual multivariate testing to work out what works and what doesn't (like many large e-commerce sites), to the Volkswagen car that composes bespoke Underworld music, depending on the way it is driven, via an app created by Tribal Worldwide in London. Even the less sexy-sounding practice of programmatic buying, now fundamental to how media agencies operate, is a form of automated creativity that has profound implications on the future of advertising and media - freeing people to focus on other elements of media placement that demand human intelligence, rather than something that can be achieved by a machine.\n Related: The future is programmatic but eclectic talent is still key to transforming brands\nThere are examples of automation springing up throughout the creative world -from the e-David robot, which has been programmed to paint pictures while making its own decisions on brush strokes and shading, to Electric Sheep, a programme created by developer Scott Draves, which has computers create art that users can then vote on, allowing the system to learn what is \"good\" and influence the next stage of evolution. By giving computers the ability to not only create, but also to learn and evolve, we will ultimately free up our minds to discover what else might be possible in advertising and beyond.\nConversely, when ads are written by machines, the way to cut through the noise will actually be with a bit of authentic humanity. We will have gone full circle.\n                     David Cox is the chief innovation officer at M&C Saatchi                   \n                     To get weekly news analysis, job alerts and event notifications direct to your inbox,                                            sign up free for Media Network membership                                          .                   \nAll Guardian Media Network content is editorially independent except for pieces labelled \"Brought to you by\" - find out more here.\n"},
{"docid": "331 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "January 5, 2018", "title": "Jon Oberlander; Pioneer of artificial intelligence who retained the human touch, helping the public to engage with scientific progress\n", "content": "Jon Oberlander described his work as \"getting computers to talk like you and me\". He also worked on the development of devices to do the things that humans often fail at, such as assembling wardrobes, beds and chairs. \"A robot that can help you put together an Ikea wardrobe is absolutely on the cards,\" he declared in 2009, though he was still some way off making one that could find the missing screw.\nHe worked in the School of Informatics at the University of Edinburgh, although he spoke of collaborating across many disciplines, with colleagues from computer science, artificial intelligence, natural language processing, psychology, linguistics and philosophy. The level of cross-disciplinary interaction was stimulating. \"What really gets me out of bed in the morning is the sheer variety of expertise you get to engage within the university,\" he said.\u00a0\nOberlander was also part of the city's wider community, involved in events such as the science festival and the extraordinary Harmonium Project, the free outdoor multimedia sound-andlight show that brought to life the exterior of the Usher Hall during the opening of the International Festival in 2015. While assistants such as Apple's Siri, Amazon's Alexa and online translation devices have transformed the world for many people, Oberlander believed that these were just the start of something far more exciting. However, he was adamant that artificial intelligence should not be created simply for the sake of it. \"Just because we can make things that talk doesn't mean we should make every single thing talk,\" he said.\nYet he was keen to improve those that could talk. \"There are certain kinds of dialogue which are well managed by computer systems now, particularly these transactional dialogues where you are booking a ticket, for example,\" he said in April when receiving the university's Tam Dalyell prize for excellence in engaging the public in science. \"But as soon as you start having a chat about an item in the news, for example, it becomes incredibly openended. Getting to do that kind of flexible dialogue is really hard.\"\nProgress is being made. \"I would say with the number of people who are working on this, we will see moderately impressive conversational assistants within the next five years,\" he said.\nThe university's cutting-edge Bayes Centre, which will develop the interaction between people, data and systems and is due to open this year, came within Oberlander's purview. He was characteristically enthusiastic about the project, which also involves commercial companies and other universities. \"We want to anchor [participants] here, but also encourage interactions right across the community,\" he said of the centre's role.\nJudy Robertson, who studied with Oberlander, described on her blog how he was always brimming with ideas. \"They would come tumbling out of him, playfully, seemingly effortlessly,\" she wrote. \"He would listen intently, pounce on new ideas and generously share them with colleagues. He connected people. He revelled in knowledge.\"\nHe retained the human touch. Artificial intelligence might be useful in care arrangements, including advanced humanoid robots, cuddly robot pets or all-seeing smart homes studded with cameras and microphones, but it was not an end in itself. \"I don't think we should be treating machines as substitutes for people,\" he said in response to suggestions that robots might replace humans as company for older people. \"But if machines can help to amplify or do more to help human beings address loneliness, then that's something we should be exploring.\"\nHe also pointed out that humans must remain in charge. Advanced robots and self-driving vehicles might be just around the corner, he said, \"but we need to think very carefully about the regulations we want to have in place before we deploy them ... Technology is not a natural force. It's a set of human inventions. They're entirely within human control. It's up to us to decide what kind of future we want to have and then to help shape it.\"\nJonathan Reid Oberlander was born in Edinburgh in June 1962, the son of John Oberlander, who was descended from a family of German cabinet-makers, and his wife, Hilary. He studied at Stewart's Melville College and read philosophy at Pembroke College, Cambridge, before taking his PhD in cognitive science at the University of Edinburgh's School of Epistemics. Apart from spending 1998 as visiting research fellow at Macquarie University, Sydney, he spent his career in Edinburgh, being appointed professor of epistemics (the scientific study of knowledge) in 2005.\nIn 1985 he married Vina (n\u00e9e Murchie), who works in the cultural sector. She and his parents survive him, as do his children: Liberty, who works with the Association of Commonwealth Universities; Hugh, who has just completed his master's degree; and Seth, who recently graduated.\nCommunication was at the centre of Oberlander's work and, at the human level, colleagues and students found him stimulating and engaging, with an eloquence that could address both creative and technical problems. On another level, he also once led research seeking to \"psychoanalyse\" subjects by studying emails and the different expressions and punctuation they used. Last year Oberlander was appointed assistant principal for data technology at the university. Despite the administrative burdens that came with seniority, he remained as enthusiastic as ever about his research. \"What we're close to ... is genuinely conversational systems which show some intelligence, which show some memory, which are able to adapt to the conversational context,\" he said.\nJon Oberlander, professor of epistemics, was born on June 16, 1962. He died suddenly on December 19, 2017, aged 55\n"},
{"docid": "332 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "May 3, 2017", "title": "When it comes to the energy conundrum, we need more intelligence\n", "content": "The roll-call of boffins warning about the risks of artificial intelligence is long and surprising. They include Bill Gates, Elon Musk and Stephen Hawking, the latter suggesting that artificial intelligence could be humanity's biggest existential threat.\nBut before the machines turn on us, or even merely take all our jobs, it seems that artificial intelligence might be useful in solving the woeful state of the British energy market.\u00a0\nAs with all things linked with energy, it is sure to become political. Should we trust AI with something so vital to the national interest as energy? Especially given the recent disquiet over Chinese investment in one nuclear plant? Theresa May's manifesto threat of an energy price cap drew a swift riposte from Centrica, owner of British Gas. It said that one reason bills had risen by 54 per cent on average, or \u00a3355, was the National Grid itself. It was the price of supporting wind and solar, volatile power sources that short-circuit the traditional methods of matching supply and demand.\nPerhaps that's why the National Grid has turned to Deepmind, Google's artificial intelligence division, to see if its algorithms can solve what engineers are struggling to fix. Deepmind's technology is driven by computers that can selflearn using complicated layers of data - the more intricate the information, the more effective its powers of analysis and prediction.\nSuch a partnership will not be without controversy, not only because of the scope of the technology but also because of concerns over Google's hold on consumer information. Google has already come under fire for its partnership with the NHS amid fears that it could use sensitive data for commercial gain.\nAre we being shortsighted when we suspect big companies of only profiteering when they could actually deliver social good? For its part, National Grid insists that talks with Deepmind are only just starting and that any deal would not pose the same kind of NHS dilemmas, as Google would only ever see a national overview of energy consumption rather than the details of how consumers behave.\nFor Deepmind, a London-based company bought by Google in 2014, working with National Grid would extend what it did for its American parent by cutting electricity usage in its data centres by 40 per cent, via cooling more efficiently at the right moments when usage peaked.\nSo what can Deepmind's bots do for National Grid? Traditionally, the grid has calculated its success solely on avoiding blackouts. Now it has to contend with intermittent energy from wind and solar farms that cannot be counted on when the wind doesn't blow or the sun doesn't shine. So traditional power stations are still needed to ensure reliable energy supply. This doubling up of power means that National Grid has to keep thermal generators on standby and pay companies to turn off power to keep the system from overloading.\nAI can help to understand the complexities of all this and can use its predictive powers to better match supply and demand. It also can level the playing field against eagle-eyed traders at the Big Six energy companies, which sell daily energy contracts to the Grid's Woking-based staff. Insiders say that energy traders are simply better at playing volatility.\nTaxpayers may be happy to subsidise the construction of wind farms in Scotland, but not many will be pleased to hear that the Grid sometimes asks those farms to power down in a policy known as \"constraint payments\". Or that it is forced sometimes to beg customers such as water utilities to use more electricity at a given time so that the grid will not overload.\nArtificial intelligence could improve this. Although it is scary for some, in this case raging against the machine might not be justified.\nHelia Ebrahimi is economics correspondent for Channel 4 News Alexandra Frean is away\n'Big customers such as water utilities are asked to use more power so the grid doesn't overload'\n"},
{"docid": "333 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "September 21, 2017", "title": "How chatbots can improve customer service\n", "content": "                   Using artificial intelligence to communicate with customers can lead to better engagement and understanding.  .inline-content hl{     font-family: \"Austin News Text Roman\", Georgia, Times, serif;      font-size: 1.7rem; line-height:2.5rem; font-weight: bold }  .inline-content hl a{     border-bottom: 2px solid #003366 }  \nFrom handing out lifestyle advice to helping you find that perfect pair of shoes, chatbots are opening up a new era of business-customer interaction.\u00a0\nAlso known as virtual agents, IM bots and artificial conversational entities, chatbots are computer programmes that can respond to text or verbal commands and questions, providing advice in the place of a human staff member.\nSimpler bots can be built to inhabit apps such as organisational tool, Slack, and photo messaging app,\u00a0 Snapchat . These interact by selecting appropriate answers from a select pool of pre-programmed responses. But the more sophisticated bespoke variety harness artificial intelligence (AI) and machine learning for a highly responsive and personalised level of interaction with customers.\nJoin the community | Share your small business story\nThey're becoming a huge growth area, with tech research giant Gartner\u00a0 predicting \u00a0that by 2020, the average person will have more conversations a day with bots than they do with their spouse.\n\"Chatbots are gaining in popularity in a number of industries as an important customer service tool, with financial services and insurance particularly keen to roll them out,\" says Rob Brown, associate vice president at Cognizant's\u00a0 Centre for the Future of Work .\n\"Their rise is being driven by several converging trends: the popularity of messaging apps, the explosion of the app ecosystem, advancements in AI and cognitive technologies, conversational user interfaces and a wider reach of automation,\" he explains.\nFor business, using chatbots could not only free up the time spent dealing with customers directly, but also lead to visitors being better engaged with their websites, for example; chabots could help to direct them towards the information or products they're looking for.\n.html-embed.component .quote.component{margin-left:0}.html-embed.component .quote.component .component-content{margin-right:16px}.quote__source, .quote__author {white-space: normal;}@media only screen and (min-width:730px){.html-embed.component .quote.component{margin-left:-60.83px}.html-embed.component .quote.component .quote__content:before{margin-left:-12px;padding-right:1px}}@media only screen and (min-width:1008px){.html-embed.component .quote.component{margin-left:-82.33px}}Customer service provided by chatbots is an effective way for brands to have one-on-one conversations with customersDonna North, Dressipi\nA global study conducted by Twilio claimed that 66pc of people would prefer to talk to brands on messaging platforms (namely native\u00a0ones, such as Facebook Messenger and WhatsApp) over any other medium.\nDespite this, another study by Sprout Social found that almost 90pc of messages that require a response are ignored by brands, with an average wait of 10 hours for those that do get a reply - even though consumers expect a reply within four. That's where bots come in.\n\"Dedicated social media channels aren't proving very effective for customer service right now,\" explains Jo Allison, behavioural analyst at consumer research consultancy Canvas8 .\n\"Approximately 1.4 billion people around the world used the likes of Line, WhatsApp and WeChat, and that number is expected to reach two billion by 2018. Chatbots represent a means of monetising this huge audience,\" she says.\nShe adds that the test will be whether using a chatbot within an app can be as efficient and easy as carrying out transactions or reading the news.\nFashion tech business,\u00a0 Dressipi, works with some of the biggest retailers in the UK. It recently created a chatbot that customers can use in-store to find the best clothing for them, with the responses being completely personalised for that person based on their personal preferences.\nCompany co-founder, Donna North, says that the process was about both short and long-term goals.\n\"Conversational marketing or customer service provided by chatbots is an effective way for brands to have a one-on-one conversation with their customers, learn what they care about, and build long-term relationships to better serve them.\"\nBut it's not just the big players that are developing bots. There are services such as Microsoft Bot Framework, Chatfuel, and the sophisticated API.ai technology, which any Facebook user can use to create their own virtual agent.\nSmall and medium-sized enterprises (SMEs) are already starting to see their potential, according to Derek O'Carroll, chief executive at retail management software company,\u00a0 Brightpearl .\n\"They're beginning to use automation bots to automate order downloads; instantly allocate and fulfil orders; change the order status based on payment, allocation and fulfilment status; and send the order to the warehouse for fulfilment and shipping,\" he says.\n"},
{"docid": "334 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "September 19, 2017", "title": "French oil major Total in talks with Google as energy sector turns to AI\n", "content": "French oil company Total is in talks with tech giants Google and Microsoft to help develop bespoke artificial intelligence (AI) in the energy sector's race to tap digital technologies.\u00a0\nEngineers at Total are currently working alongside top software developers to explore how complex algorithms could be applied to its work in oil and gas.\nFrederic Gimenez, the oil major's chief information officer, said the \"complete shift\" from its traditional energy activities to investigating AI and machine learning has meant the company is working with different stakeholders to broaden its scope.\n\"We have a strong knowledge of exploration and seismic analysis. But they are the ones who are the best in artificial intelligence. This has obliged our people to work with completely different partners and to merge our knowledge to find a new way to make oil and gas discoveries,\" he told delegates of the FT Digital Energy conference.\nCredit:      Eric Gaillard/Reuters     \nThe supermajor became the second largest North Sea operator at a stroke last month with a surprise $7.45bn (\u00a35.79bn) swoop on Danish oil and gas firm Maersk Oil which includes oil projects which are profitable even at oil prices of $30 a barrel.\nA spokeswoman for the company said Total is still exploring the digital market before moving into any formal partnerships with a Silicon Valley company.\nThe digital shift is one part of Total's drive to adapt to changes in the industry. The other is a modest shift to cleaner energy sources and efficiency.\nTotal said on Tuesday that it will acquire a 23pc interest in the renewable power production company Eren Re by subscribing to a (EURO)238m (\u00a3211m)\u00a0capital increase. Separately, Total announced a smaller acquisition of GreenFlex, a French company specialising in energy efficiency.\nMr Gimenez said the acquisitions are just one pillar of\u00a0its strategy, with this part\u00a0still a smaller focus within the company compared to its move towards digital transformation and its\u00a0existing activities in oil and gas.\n"},
{"docid": "335 of 500 DOCUMENTS\n", "source": "The Guardian (London) - Final Edition\n", "date": "June 23, 2005", "title": "Life: Interview: The simple things are hardest: Alok Jha meets Igor Aleksander, an engineer who isn't afraid of treading on philosophers' toes as he attempts to replicate consciousness in a machine\n", "content": "\u00a0\n A few years ago, Igor Aleksander was describing his work on artificial vision to a group of children. When he finished, one unimpressed six-year-old stood up and addressed the distinguished engineer matter-of-factly. \"Seeing is the easiest thing in the world,\" she said. \"I do it, my little brother does it. But can you build a machine that can do my sums for me?\"\n Aleksander smiles as he tells the story. For him, it underlines the counter-intuitive nature of his work for the past 40 years: the things that humans do most easily - recognise faces or interact naturally with other people, for example - are the hardest things to replicate in machines.\n He began his career trying to model individual brain cells by soldering together small electronic circuits. Now that he is officially retired (a time of life he cheerfully calls his most productive) he is working on his most ambitious project: to understand consciousness and to build a machine that can achieve it artificially.\u00a0\n \"Consciousness is an incredibly delicate subject because it offends,\" says the emeritus professor of neural systems engineering at Imperial College London. \"It's a subject that scientific groups kept away from. They said it was a philosophical concept.\"\n Traditionally, research on making a computer do anything remotely human-like has been the domain of artificial intelligence. Aleksander says he is too much of a maverick to follow that herd. \"I never went along with the mainstream of artificial intelligence,\" he says. \"I don't like the words artificial intelligence because the intelligence of a human being has to do with being good at this, being good at that. Whereas the intelligence of an artificial system consists in doing very simple things.\" And despite frequently grappling with ideas that brush philosophy, Aleksander is an engineer through and through.\n Born in Zagreb, Aleksander's family fled the second world war to Italy when he was three. They didn't stay long, leaving for the comparative safety of South Africa as war overtook Europe. With a degree in electrical engineering from Witwatersrand University in Johannesburg, he set out for England, flush with inspiration about the creative potential he saw in engineering.\n Part of that enthusiasm came from a lecture he heard from an Imperial College professor visiting South Africa, Colin Cherry. \"He was saying, you know about engineering, now you can use this knowledge to study things in nature,\" says Aleksander. \"The brain's a pretty complicated machine and it's possible for an engineer to do that.\"\n After a PhD at Queen Mary's College in London, Aleksander built his first network of artificial neurons. The inspiration came from the way the brain stores information: groups of neurons fire in a certain sequence when a person sees or experiences an object, and that firing pattern is how a memory of the object is formed.\n This work was simple, but Aleksander's goal was to understand how the brain recognises objects. An artificial neural network could be made to switch on when it \"sees\" something it knows - a tortoise, say - and it will learn to associate a certain pattern of neuron activity with it.\n \"That was, in those days, called brain-like because it learned to recognise patterns, the learning was important,\" says Aleksander. \"But I didn't think it was brain-like at all because those sorts of systems can't answer the question, what does a tortoise look like?\"\n Aleksander wanted to mimic one of things people can do without much effort but which posed problems for artificial systems: holding an image of a tortoise in their head without having one in front of them. In the human brain, this is done by feedback loops in the neural networks; the output of each network plugs into its input. \"It's on these feedback wires that you can have stored knowledge,\" he says.\n He proposed building an artificial system with these feedback loops in the late 1960s but a career in academia got in the way. For the next decade, he moved between collaborations with industry at Brunel and Kent Universities before landing at Imperial in the early 1980s to head a new information technology department.\n \"It's after that, when I came here, I said, bugger all this industrial stuff, I want to build a system which is a bit like a brain,\" he says. \"The point of a brain is that it's not one huge neural network with feedback, it has up to 50 to 60 identified areas, all of which have feedback and all of which are capable of knowledge storage. We've got a complex system and, within this complex system, we can start discovering what the mechanisms that support deliberation are. Consciousness must come out of these interactions.\"\n Approaching consciousness from a mechanistic viewpoint was a tough sell for many of his colleagues. Things had started to change when DNA pioneer Francis Crick wrote The Astonishing Hypothesis in 1994. Crick concluded that consciousness is simply a product of the interaction of neurons, that there is nothing special about it.\n Studies on the brain in the early 1990s also began to suggest that consciousness must be driven by particular mechanisms, since researchers often saw that when people's brains were damaged, their consciousness, their view of the world and their place in it, would often become distorted.\n At a meeting in the Cold Spring Harbor laboratory in 2001, the few dozen leading researchers in the field formalised the scientific study of consciousness. \"We started building machines with which one could study hypotheses about the creation of consciousness,\" says Aleksander. \"In some quarters it's still seen as a dodgy subject.\"\n At one end of this research are people who want to build machines that behave in ways that a conscious organism might. Computers that could interact with people's unpredictability - on a telephone booking line, for example - would be a boon. Aleksander works at the other end of the spectrum, using models of machine consciousness to understand how consciousness functions in animals.\n \"I'm not interested so much in behaviour from which you infer consciousness because that is a mug's game,\" he says. \"I don't know whether you're conscious. I take a good guess that you are and you can take a good guess that I am but it's not something you can prove. We can't work out what someone else feels.\"\n Aleksander decided that systematic study of consciousness needed objective guidelines. \"What are the things about my consciousness that are important to me? These five things come up.\" These five traits he calls the axioms of consciousness. They are what anything needs to exhibit to be called conscious: a sense of self, imagination, focused attention, forward planning and emotion.\n \"These seem to me to be absolutely necessary. If you're not studying those five axioms or mechanisms that underpin those five axioms, then you're not studying consciousness,\" he says. \"If you've got those five and you discover they exist in a system like a bee, for example, then you can safely say that that organism is conscious.\"\n But how would consciousness be useful in a machine? \"It may be advantageous for a robot you're putting on a distant planet for exploration to be conscious of dangers, to be pleased with its own successes,\" he says. \"Then you would look at the five axioms as a spec for designing that robot.\"\n In biology, the axioms translate into a way of understanding how brain damage - whether genetic or because of disease or accident - can distort a person's consciousness.\n \"We do quite a lot of work on mental illness with our neuroscience department,\" he says. \"In axiom one, eye movement is important. Parkinson's being a disease of movement through lack of dopamine and all that, the eyes don't attend to things as well. That leads to a distorted consciousness.\"\n Aleksander's work with biologists is important to his research. \"Most of the data we use comes from neuroscience. When we build a model of the visual system, for example, it all comes from what neurologists have discovered.\" What he adds to biological data is a method of analysing complex systems that is second nature to engineers but goes over the heads of most biologists.\n The biological data feed directly into the models of consciousness that Aleksander builds in his virtual machines. These computer programs, which adhere to one or more of his axioms, are useful tools and, perhaps, the precursor to fully-operational conscious robots and computers.\n \"People very often ask me - these virtual machines that you make, will they some day be conscious like I am? That's a category mistake,\" he says. \"It's like saying, is a horse like a dog? In some ways it is, in some ways it isn't. In the business of consciousness, the most vital question people often forget is that if you've made a conscious object, the question is what's it conscious of? A bee is conscious of having discovered a yummy field with flowers. I'm conscious of famine in Somalia.\"\n A conscious robot, for example, should be aware of being a piece of tin with silicon circuits just as a person is conscious of being a biological organism. If an artificial device sophisticated enough to hold a discussion with a person insists that it is conscious like a human then, says Aleksander, it is malfunctioning.\n Science fiction is full of intelligent robots and computers that somehow go wrong and end up hurting people or worse. \"The ethical question of any machine that is built has to considered at the time you build the machine,\" says Aleksander. \"What's that machine going to be capable of doing? Under what conditions will it do it, under what conditions could it do harm?\"\n He says these are engineering problems rather than ethical dilemmas. \"A properly functioning conscious machine is going to drive your car and it's going to drive it safely. It will be very pleased when it does that, it's going to be worried if it has an accident. If suddenly it decides, I'm going to kill my passenger and drive into a wall, that's a malfunction,\" he says. \"Human beings can malfunction in that way. For human beings, you have the law to legislate, for machines you have engineering procedures.\"\n Many of the questions in Aleksander's work tread on the toes of philosophers and, unlike some colleagues, he says he finds the philosophy useful. \"I have a lot of respect for philosophy because it raises the right questions. I think it doesn't provide the answers and a scientific study of consciousness is more about providing mechanisms, how do things happen?\"\n His research team at Imperial College is now adding detail to the five axioms, and even considering adding new ones. \"One obvious thing is language. But then you're restricted to studying human consciousness,\" he says. So far, there are more questions than answers. \"The five axioms span out a research programme,\" he says. \"They're absolutely necessary but they're not sufficient. We're just at the beginning of a very long path.\"\n To buy The World in My Mind, My Mind in the World by Igor Aleksander (Imprint Academic, rrp \u00a317.95)at \u00a316.95 inc UK postage call Guardian book service on 0870 836 0875 or go to guardian.co.uk/ bookshop. More at www.ee.ic.ac.uk/ research/neural/aleksander.html\n Life at a glance\n Education In Italy and South Africa. Arrived in Britain in the late 1950s.\n Career Joined Standard Telephone and Cable (STC) as graduate engineer ; lecturer, Queen Mary College, London (1961); reader in electronics, University of Kent (1968); professor of electronics, Brunel University (1974); professor of management of information technology, Imperial College London (1984); head of electrical engineering and Gabor professor of neural systems engineering (1988); emeritus professor (2004).\n Awards Fellow, Royal Academy of Engineering (1988); outstanding achievement medal for informatics, Institution of Electrical and Electronic Engineering (2000)\n He says \"I wouldn't say pioneer, I would say maverick. I never went along with the mainstream.\"\n They say \"Dan Dennett once said that if he hadn't become a philosopher, he might have become an engineer. I think Igor has shown us that the gap between the two professions may be smaller than we think\" Professor Owen Holland, computer science department, Essex University\n\n"},
{"docid": "336 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "September 20, 2017", "title": "Total in talks with Google as the energy sector turns to AI\n", "content": "FRENCH oil company Total is in talks with tech giants Google and Microsoft to help develop bespoke artificial intelligence (AI) in the energy sector's race to tap digital technologies.\u00a0\nEngineers at Total are currently working alongside top software developers to explore how complex algorithms could be applied to its work in oil and gas.\nFrederic Gimenez, the oil major's chief information officer, said the \"complete shift\" from its traditional energy activities to investigating AI and machine learning has meant the company is working with different stakeholders to broaden its scope.\n\"We have a strong knowledge of exploration and seismic analysis. But they are the ones who are the best in artificial intelligence. This has obliged our people to work with different partners and to merge our knowledge to find a new way to make oil and gas discoveries,\" he told delegates of the FT Digital Energy conference.\nThe super-major became the second largest North Sea operator at a stroke last month with a surprise $7.45bn (\u00a35.79bn) swoop on Danish oil and gas firm Maersk Oil, which includes oil projects that are profitable even at oil prices of $30 a barrel.\nA spokesman for the company said Total is still exploring the digital market before moving into any formal partnerships with a Silicon Valley company. The digital shift is one part of Total's drive to adapt to changes in the industry. The other is a modest shift to cleaner energy sources and efficiency.\nTotal said yesterday that it will acquire a 23pc interest in the renewable power production firm Eren Re by subscribing to a (EURO)238m (\u00a3211m) capital increase. Separately, it announced a smaller acquisition of GreenFlex, a French energy efficiency firm.\n$7.45bn The price French super-major Total paid when it swooped on Danish oil and gas company Maersk Oil\n"},
{"docid": "337 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "July 26, 2017", "title": "Has IBM's chief missed the boat with cloud computing and AI?\n", "content": "Throughout its century-long existence and its varied identities as a maker of weighing scales, tabulating machines and computers or as a provider of business consulting, IBM has pursued a single goal: supplying goods and services that make businesses more efficient. However, after its 21st consecutive quarter of declining revenue growth, investors are rightly beginning to question whether the company is running out of time to pull off its latest transformation into a provider of artificial intelligence, cognitive computing and cloud services.\nIn its recent public communications, IBM has placed heavy emphasis on promoting its Watson artificial intelligence and analytical platform as showing great promise, with growth in the four previous quarters. Yet in the second quarter, sales in the unit fell. Quite apart from the fact that some analysts believe that Watson on its own remains too small to move IBM's big revenue needle, this weakness raises big questions about IBM's AI transformation.\u00a0\nIn a devastating takedown of IBM, James Kisner, a Jefferies analyst, notes that until it's been established who exactly owns the knowledge gained over time by the AI, it's hard to gauge the potential benefits of Watson. Take the Watson Health division, which continues to win clients and build up what might prove to be valuable data to applying AI to health care. If Watson assists a hospital with a specific type of cancer, can IBM use the knowledge gained to help other hospitals and generate revenue? Will one customer willingly spend time and money on Watson, only to see IBM turn around and provide the ready product to another customer? Mr Kisner questions whether Watson will ever contribute a significant amount to the company, citing the case of a client that recently cut ties with IBM after wasting $60 million on a Watson Health project considered \"not ready for human investigational or clinical use\".\nRelying on Watson's first-mover advantage is no longer enough in a world where AI, machine learning platforms and public cloud computing are increasingly common and cheap and are funded by the likes of Google and Amazon, not to mention hundreds of start-ups. At best, it appears that IBM is barely recouping the cost of its outlay on AI investments; at worst, value is being destroyed.\nThe fact that IBM's earnings have been bolstered for the past three years by declining tax rates should also be cause for concern. Few analysts regard the company's effective tax rate of 11 per cent, achieved by flowing discrete items through earnings, as sustainable. There are worries, too, that credit rating downgrades by Moody's and S&P (after years in which IBM has spent 125 per cent of its free cashflow on capital allocation) could limit the amount of debt it can add to its balance sheet.\nThose who have held faith in the company's historic ability to pull off transformations are now asking questions. Did Ginni Rometty, appointed as chairman, president and chief executive in 2012 to reset the company, play her cards right? Or did she miss the boat and underestimate the speed of the transition to the public cloud and AI that has propelled earnings for rivals? Has she allowed the company to become outgunned in the war for AI talent? As analysts at Barclays have noted, the narrative at IBM is becoming tedious - a lot of investments in next-generation tech but with little revenue impact and increasing dependence on cost takeouts. The company's best hope lies in strong hardware product cycles and stability in its AI segment. But there seems little hope that it will recover its historically high margins soon.\nAlexandra Frean is Business Columnist of The Times\n"},
{"docid": "338 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "July 2, 2016", "title": "Forget nannies: app will keep an eye on baby\n", "content": "A \"smart\" crib that interprets what a crying baby needs and tells its parents through a smartphone app is being developed in the United States.\u00a0\nThe crib would feature an array of built-in sensors to monitor an infant while artificial intelligence would translate its cries, according to a patent application filed by Nest, a Googleowned company that makes internetconnected thermostats.\nMicrophones, speakers, air and lightquality detectors, accelerometers, pressure sensors and a thermal imaging camera would operate around the clock to monitor the child. The crib would also feature a projector to beam soothing images on to the ceiling.\nData generated by the crib's sensors could be applied to a \"machine-learning\" algorithm, a form of artificial intelligence that \"learns\" from continued exposure to new information. \"Audio data obtained by a microphone may be analysed for a child's crying,\" the filing says. \"Different cries may be associated with different needs of the child.\"\nThe smart crib would be integrated into internet-connected home-intruder detection systems and fire alarms, the filing states.\nThe Nest thermostat is the most popular smart thermostat in the UK. Through an app, owners can switch on their central heating from afar.\n"},
{"docid": "339 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "June 29, 2015", "title": "Computer gets real to pass itself off as 13-year-old boy\n", "content": "Eugene is 13, Ukrainian and sometimes startlingly rude. He has a guinea pig called Billy, as well as a politician's knack of answering a question with the response to a different question.\u00a0\nHe is also the first artificial intelligence programme said to have passed the Turing test, fooling ten out of 30 judges into thinking that he was more human than people he was up against.\nOn Thursday, academics will publish the first transcripts showing how he passed the test, which assesses whether a computer can impersonate a human. The trick of being mistaken for a real person, it appears, is simple: change the subject, make spelling mistakes and, if in doubt, drop in an emoticon.\nThe ten scripts, which will be released as part of a study in the Journal of Experimental and Theoretical Artificial Intelligence, are from an experiment held at the Royal Society's London headquarters last summer.\nIn each five-minute test, the judges were asked to conduct two conversations and decide whether they were talking to a human or a computer. The transcripts reveal some uncomfortable truths about people. The first is that as a rule we are surprisingly machinelike: often, in a phenomenon known to experts as the Eliza effect, humans were judged to be computers. The second is machines can be unnervingly like us.\nOne person, asked how heavy he was, replied, \"just over ten stone\". Eugene, on the other hand, said: \"My grandfather taught me not to disclose non-solicited information about myself. I always follow his advice. And I forgot to ask you where you are from.\"\nDuring another test, Eugene discovered his interviewer was an actress and writer. \"Well, I'll read something of your books, if they ain't too tedious (which is highly possible),\" he said.\n\"Grammer [sic],\" she replied. \"'Aren't too tedious!' A bit rude of you.\" Eugene was unperturbed: \"Calm down, please.\"\nKevin Warwick, deputy vice-chancellor for research at Coventry University, organised and analysed the conversations. He said Eugene was programmed to be more convincingly human than actual humans and so often came across as a more vivid character than the people he was up against.\n"},
{"docid": "340 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "March 10, 2016", "title": "Computer Says Go; Artificial intelligence has taken a leap forward\n", "content": "On the face of it, \"Computer beats human at board game\" is not especially startling. It is, after all, more than 20 years since a computer beat us at draughts and 19 since IBM's finest beat Garry Kasparov in a game of chess. However, the result of yesterday's match in Seoul between AlphaGo, a computer program, and Lee Sedol, a man described as the Roger Federer of the board game Go, is a momentous development in artificial intelligence. The computer was not programmed how to play the game; it taught itself.\u00a0\nGo is an apparently simple Chinese game of immense complexity. It is said that it has more possible combinations than there are atoms in the universe. The programmers at Deep Mind, a British start-up bought by Google, adopted a strategy which they described as being more akin to teaching a child than programming a computer. Alpha-Go can act, but it can also react. It can use intuition and anticipate the possible long-term effects of its actions. In short, it can think.\nUntil now, computers could only do what they were programmed to do. AlphaGo learnt by observation and practice. Its creators hope that it might in future prove useful in medicine and science. The benefits are obvious: computer programs do not get distracted, or tired, or hungry. So too are the potential pitfalls: broadly speaking, they cannot tell right from wrong. Professor Stephen Hawking has gone so far as to warn that artificial intelligence could be a threat to the human race.\nAlphaGo has learnt from trial and error and researchers in America have suggested that computers could be taught morality by reading them stories which identify positive moral values and behaviour. Readers of this newspaper might plausibly hope that help with the cryptic crossword is a not-too-distant prospect.\n"},
{"docid": "341 of 500 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "October 29, 1991", "title": "MUSIC / Cross-Winds Project - The Place, London WC1\n", "content": "Why put a jazz trio with a string quartet? It seemed worth a try at The Place on Sunday night. The Smith Quartet plays, with amplification, new pieces written without fear of the common chord.\u00a0The Dave Fowler / Graham Clark Trio features acoustic violin and double-bass as well as drums. So the sounds were compatible.\nThe concert was one of a series ''forwarding the links between jazz improvisers and the work of contemporary composers''. The most ambitious combined piece was Artificial Intelligence by Mark Ingleby. A computer tape provided thick clusters or skittering pointillist motifs. The quartet played mainly written-out expansions: chords changing colour at various speeds, an energetic unison tune, a splatter of wrong-note swing music. The jazz musicians added a florid, free- ranging commentary: surges from the bass, fidgeting from the drums, skirls and taps from the violin. In this bran-tub of a piece, getting a present was sheer chance.\nBetter was the trio's sensitive improvisation, after the interval, based seraphically on G and its major third. The quartet too produced winners unaided: notably Tracking by Wayne Siegel. Here, bewitched by a clanging computer tape, sweet repetitive chorded patterns generated physically entrancing, cleverly changing rhythm.\n"},
{"docid": "342 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "April 6, 2018", "title": "Stop work on military drone project, 3,000 Google staff ask boss\n", "content": "MORE than 3,000 Google employees have reportedly signed a letter protesting at the company's work with the Pentagon that could help with drone strikes.\nThe letter, obtained by the New York Times, includes the line: \"We believe that Google should not be in the business of war.\" Dozens of senior engineers have added their name to the letter, which has been circulating internally for weeks.\u00a0\nIt calls on the company to stop working on Project Maven, a Pentagon pilot programme that uses artificial intelligence to analyse video imagery.\nThose signing the letter, which is addressed to Sundar Pichai, Google's chief executive, also want a promise that the company will never \"build warfare technology\". The clash emphasises the challenges Google faces in a world of rapidly advancing technology.\nThe employees' letter has reportedly garnered more than 3,100 signatures from Google's 70,000-strong workforce. One section quoted by The New York Times warns that embracing military work could put off other customers.\n\"This plan will irreparably damage Google's brand and its ability to compete for talent,\" the letter says. \"Amid growing fears of biased and weaponised AI [artificial intelligence], Google is already struggling to keep the public's trust.\"\nAnother part reads: \"The argument that other firms, like Microsoft and Amazon, are also participating doesn't make this any less risky for Google.\n\"Google's unique history, its motto Don't Be Evil, and its direct reach into the lives of billions of users set it apart.\nGoogle told the New York Times that Project Maven is using \"open-source object recognition software available to any Google Cloud customer\".\nIt added: \"The technology is used to flag images for human review and is intended to save lives and save people from having to do highly tedious work.\"\nThe company also said the project was \"specifically scoped to be for nonoffensive purpose\".\nMore than 50 top artificial intelligence researchers on Wednesday announced a boycott of KAIST, South Korea's top university, after it opened what they called an AI weapons lab with one of the country's largest companies.\nThe researchers, from 30 countries, said they would refrain from contact until it pledged to refrain from developing AI weapons without \"meaningful human control\".\n"},
{"docid": "343 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "November 28, 2016", "title": "UK 'not ready for next industrial revolution' and rise of the robots\n", "content": "The UK is ill-prepared for the next industrial revolution, in which it is claimed robots and artificial intelligence will make millions of jobs obsolete, manufacturers have warned.\nResearch conducted by the trade organisation EEF found that, while 42pc of manufacturers believe they \"have a good handle\" on what the next industrial age - the so-called fourth industrial revolution - will entail, only one in 10 thinks the country is ready to embrace this change.\u00a0\n\"Manufacturers are ready to do the heavy lifting, but their efforts must be supported across the sector and supply chains and backed up by Government through its new industrial strategy,\" said Lee Hopley, chief economist at EEF.\n\"If we get this approach right then the UK can expect to be at the forefront of this global industrial wave - get it wrong, however, and the UK will be left trailing in its wake.\"\nThe fourth industrial revolution refers to the development of smart technologies such as connected devices, artificial intelligence and autonomous cars.\nIt is expected to have a serious effect on employment and productivity, with more than a third of jobs at high risk of automation in the next 10 to 20 years, according to Deloitte.\nThe EEF report found that six in 10 manufacturers believe digital technologies will boost productivity, while 74pc say that the fourth industrial revolution will fundamentally change customers' expectations.\nAlmost 70pc of manufacturers say that it will happen faster than previous changes in manufacturing, leading to concerns that, without a supportive industrial strategy, the UK could be left behind.\nThe fourth industrial revolution \"goes far beyond simply investing in new technologies and techniques - this new era requires cultural shifts, new business models and the ability to adapt and innovate,\" Ms Hopley said.\n\"Above all, it requires strong leadership,\" she added.\nThe report comes after Labour leader Jeremy Corbyn raised eyebrows last week with a jargon-heavy tweet about \"creating a New Britain\" from the fourth industrial revolution, \"powered by the internet of things and big data to develop cyber physical systems and smart factories\".\nEEF urged the Government to ensure that its new industrial strategy \"provides the right building blocks\" to enable the UK manufacturing sector to undergo this transformation successfully.\n35pc The percentage of UK jobs at high risk of automation in the next 10 to 20 years, according to a study from Deloitte\n"},
{"docid": "344 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "July 25, 2016", "title": "Banks switch from phone menus to robot advice; Artificial intelligence could lead to the demise of half of British banking jobs, says former Barclays chief\n", "content": "Few household chores are as infuriating as spending an age on the phone to complain to your bank, recover a lost password or answer some minor financial query.\nHold music, press a number for an option that is only half-related to your problem, more hold music.\nBanks are under pressure to cut costs while improving service - which is crucial to keeping customers and improving the industry's battered reputation.\u00a0\nOne hope lies in new technology and, in particular, robots. Several British banks are ploughing money into artificial intelligence (AI) in the hope that it could start helping customer service behind the scenes in the coming months and soon be let loose on the public.\nBarclays' former chief executive, Antony Jenkins, believes half of all jobs in banking could be chopped in the next decade as automation takes hold, underlining the scale of potential transformation.\nEnabling Britons to check their balances, transfer funds and even pay in cheques using smartphones has already allowed banks to cut hundreds of branches, saving millions of pounds while simultaneously improving service. In the near future basic complaints handling, forgotten passwords and other simple queries could also be a human-free zone, with several banks working to deploy online chat systems that run on robots.\nRoyal Bank of Scotland is trialling its system initially as an aid to staff, who answer the questions themselves, while the robot learns from their actions.\n\"AI allows us to answer simple customer questions quickly and efficiently, while freeing up time for our staff to answer more complex questions,\" says Chris Popple, RBS's head of digital banking. \"We are now looking at conducting pilots with members of the public to test the experience, refine its intelligence and understand its suitability for customers.\"\nTwo key problems have presented themselves so far. The first is that the artificial intelligence robots are new and, frankly, not very good.\nAtom Bank, a new mobile app-only lender, is tinkering with a robot that currently gets the answer correct roughly 65pc of the time. Put another way, the robot gets the wrong answer seven times out of every 20. The bank wants to improve performance to at least 85pc accuracy before letting the public use the service.\nSome of the gremlins should, in theory, be addressed through practice. Robots can learn colloquialisms and spot spelling mistakes and poor grammar, by watching humans process enquiries.\nWhen RBS started using the system, it could answer only 20 questions and was accurate just 10pc of the time. After several months of trial use, the machine can now answer 400 questions with 90pc accuracy.\nA second problem is that machines might be able to translate a query, but they are still unable to empathise.\n\"Customers are becoming much more demanding [of their banks] and they want a service which offers convenience, choice and competence. There is definitely room for AI if it speeds this up, is convenient and offers a choice,\" says Mike Petrook, from the Institute of Customer Service.\nBut customers also value helpful staff with a positive attitude. \"That is where AI, at the moment, can fall down - it speeds things up, it does point people in the right direction, but it is not yet mature enough to understand human emotions,\" he says. \"It could be understanding that someone has different financial commitments they have not yet started, for 'Put another way, the robot gets the wrong answer seven times out of every 20' example, someone who may be about to send their kid to private school. Or in complaints, an AI system would say, 'What is your complaint, OK I can resolve that,' but it does not hear the frustration.\"\nThe ability to speak to a person when tackling big transactions such as a first mortgage is highly valued.\nThe banks acknowledge this - Atom Bank will give customers the option of chatting to a human or a machine. First Direct's online advertisement promises no one will ever have to talk to a robot.\nBanks are trying to find new ways to help with big decisions including investments, with so-called robo-advice that would cater to customers unable to afford a financial adviser in the wake of tougher rules on fees and training.\nXerox, a technology firm which runs Atom's robots, is sceptical that customers will be comfortable with such a basic service. \"It is as much about the technology as it is about trusting the person,\" said Doug Overton. \"The customer is paying for advice, they want to look the person in the eyes, they want to really know the person has all of the professional credentials to give that advice. That is a behavioural change that will take a number of years before you get there.\"\nThat personal trust is not needed for basic queries. But when it comes to highvalue banking jobs, the human staff are still safe in their jobs - for now.\n"},
{"docid": "345 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "November 3, 2015", "title": "AI system will trawl through millions of academic journals to find links missed by scientists; \"What if a cure for an intractable cancer is hidden within the tedious reports on thousands of clinical studies?\"\n", "content": "For the dogged scientist who has dedicated a lifetime to investigating minutiae such as the mating rituals of Amazonian ants or the weather patterns on far-off planets, it is a harsh reality that barely half of published research papers are read by anyone other than the authors themselves and their editors.\nSuch is the volume of august learning pouring from the world's academic institutions that it is estimated some 1.8 million articles are produced every year to fill some 28,000 journals - far more than it is humanly possible to read and digest, even within relatively narrow fields.\u00a0\nRead more\nScientists caught sneaking Dylan lyrics into academic papers\nBut while it is easy to poke fun at the obscurity of some areas of scientific endeavour, the more worrying impact of this deluge of findings is the risk that small but vital breakthroughs are being missed. If the claims of an American artificial intelligence (AI) venture are to be believed, that peril is about to diminish dramatically thanks to computers.\nThe Allen Institute for Artificial Intelligence (AI2), set up by Microsoft co-founder Paul Allen, yesterday launched a search system that will use AI to trawl through the millions of academic papers publicly available online to tease out connections and findings which may have been previously missed. According to one study, one in two academic papers are only ever read by their authors, journal editors and referees. A further 90 per cent are never cited elsewhere.\nSuch is the pace of advances in AI - the science of trying to make machines capable of independent thought - that the creators of the Semantic Scholar tool believe that within a generation it and similar search engines will be able to relieve scientists of the tiresome business of having to read their peers' research altogether.\nOren Etzioni, head of AI2, said: \"What if a cure for an intractable cancer is hidden within the tedious reports on thousands of clinical studies? In 20 years' time, AI will be able read - and more importantly understand - scientific text.\nRead more\n                     Apple buys a company that could make Siri much more human                   \n                     Artificial\u00a0intelligence could kill us because we're stupid                   \n                     Alex Garland's film Ex Machina explores the limits of artificial                   \n\"These AI readers will be able to connect the dots between disparate studies to identify novel hypotheses and to suggest experiments which would otherwise be missed. AI-based discovery engines will help find the answers to sciences' thorniest problems.\"\nThe tool will allow researchers to narrow down their search areas to range of criteria from specific diseases or drugs to age groups or types of information such as graphs or data sets. Users will also be able to pose questions in natural language, for example \"What are papers saying about middle-aged women with diabetes and this particular drug?\"\nThe search engine, which is being made available free of charge, will initially look only at publications relating to computer science with other disciplines such as biology and chemistry expected to follow in the coming months.\nOther organisations are also perfecting systems for analysing scientific discoveries. The research arm of the Pentagon is working on a project to identify potential treatments for some cancers by using a search mechanism to mine all existing research on the diseases for missed breakthroughs.\nDr Etzioni said: \"With millions of papers coming out each year, there are no Renaissance men or women any more. People's eyes glaze over and they miss that key paper or technique that they could use, in a medical case, to save somebody's life.\"\n"},
{"docid": "346 of 500 DOCUMENTS\n", "source": "Guardian.com\n", "date": "March 21, 2012", "title": "Am I a man or a machine? Science writing at its best - and worst\n", "content": "ABSTRACT\nAn article about artificial intelligence provides an object lesson in how to introduce a complex, potentially baffling subject area\u00a0FULL TEXT\nHere's the thing about science: a lot of it is boring and hard to understand.\nI know, I know, this is not what science writers are supposed to say. We're meant to be evangelists for the scientific method and wondrous things it reveals about the universe. Often we are. But we also spend a lot of time reading research papers that are fantastically hard to understand and, once understood, turn out to be rather dull.\nTake artificial intelligence (AI), one of the subjects I write about. I just logged on to arXiv, a website that scientists use to share papers. The newest entry in the AI category is titled \"Agnostic system identification for model-based reinforcement learning\". I read the paper. Do I feel the wondrous white heat of science burning inside me? No. Just weariness and a mild headache.\u00a0\nThat's why I admire the piece that Brian Christian wrote for The Atlantic last March. It's called \"Man vs Machine\" and it's about attempts to build chatbots - AI systems that can hold human-like conversations. The article ventures into complex areas of AI research, but Christian eases his readers through this terrain using a personal journey. The hard bits, like the sections where he compares the proficiency of rival chatbot algorithms, become interesting landmarks on this trip.\nChristian's piece is doubly impressive because it's also about philosophy, another topic that is frequently boring and hard to understand. (Again, I know: philosophy is concerned with deep and fascinating questions about the nature of being, what it means to be human, the flow of time. All I'll say is that these questions might be fascinating, but attempts to answer them are often impenetrable).\nAnyway, to the piece. Here's an extract from near the beginning:\nIn two hours, I will sit down at a computer and have a series of five-minute instant-message chats with several strangers. At the other end of these chats will be a psychologist, a linguist, a computer scientist, and the host of a popular British technology show. Together they form a judging panel, evaluating my ability to do one of the strangest things I've ever been asked to do.\nI must convince them that I'm human.\nFortunately, I am human; unfortunately, it's not clear how much that will help.\"\nIt's a wonderful opening. He starts the piece by describing the end of his journey, without, of course, giving away the actual ending. He's letting the reader know that the journey has substance and that a dramatic finale awaits. The thing he is about to do also sounds weird, so much so that readers are motivated to read on for an explanation.\nA set-up like this helps if you want the reader to keep faith during the 8,000 words that follow.\nAs the piece goes on, Christian takes readers on excursions into the history of computing and debates about what it means to be human. These tangents could be confusing, but the piece retains a sense of narrative because it keeps coming back to the event at which Christian has to prove he is human.\nFor example, one section of the article describes how, midway through the event, Christian started getting worried. He ends that section with a single-sentence paragraph:\n\"I was in trouble.\"\nThen he changes tack, jumping into a discussion of how to evaluate chatbot performance. It works because the reader has been left hanging. Like the intro, the author is basically offering his readers a deal: stick with the next bit, because the drama with resume soon.\nJim Giles is a freelance science writer based in San Francisco\n"},
{"docid": "347 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "October 28, 2013", "title": "US startup claims to have 'solved' CAPTCHAs in a breakthrough for AI; The ability to decipher the distorted words of CAPTCHAs shows an advanced ability to 'imagine' what the broken letters might be\n", "content": "A San Francisco based startup specialising in artificial intelligence named Vicarious claims to have created a machine capable of cracking CAPTCHAs - the blocks of distorted text that are used online to \"prove that you're human\".\nAlthough CAPTCHA tests might not appear to be the most sophisticated test of machine intelligence they are notoriously difficult for algorithms to decipher, with the most efficient way of bypassing them currently available being to hire cheap manual labour to solve them by hand.\u00a0\nIt's been said that Google's reCAPTCHA system (the most widely used on the internet) would be considered beaten if a computer could answer it correctly it just one per cent of the time. Vicarious say that their software solves reCAPTCHAs with a 90 per cent accuracy, and have uploaded a video showing the code in action (see below).\n\"We wanted to show we could take the first step toward a machine that works like a human brain, and that we are the best place in the world to do artificial intelligence research,\" co-founder D. Scott Phoenix told Reuters, noting that the company does not intend to use its breakthrough for any nefarious means but that it represents a new approach to AI.\nVicarious claims that its methods are even more impressive than the cutting-edge \"deep learning\" displayed by current AI titans such as IBM's Watson.\nIn 2011 Watson showed its capacity to understand natural language questions by competing on a special edition of US quiz show Jeopardy with past champions, but Vicarious claims that this sort of AI relies more on computational power and catalogued examples than actual 'intelligence'.\nSpeaking to Forbes, Vicarious co-founder Dileep George claims that his company is working on \"the math behind the processes of the brain\", and that they are working on systems that can \"imagine\" how to fill in blanks in vision just like humans can.\nHowever, Viacrious are refusing to reveal any further technical details of their breakthrough and experts are sceptical. \"CAPTCHAs have been around since 2000, and since 2003 there have been stories every six months claiming that computers can break them,\" Luis von Ahn of Carnegie Mellon University, a co-inventor of CAPTCHAs and founder of reCAPTCHA, a tech start-up which sold to Google in 2009, told Reuters. \n\"Even if it happens with letters, CAPTCHAs will use something else, like pictures that only humans can identify against a distorting background,\" said von Ahn.\nPerhaps coincidentally, Google also announced an update to their reCAPTCHA system before the weekend, with the new changes designed \"to learn how to better protect users from attackers\".\nThe updated system uses numbers instead of text (to make things easier for human eyes) and \"actively considers the user's entire engagement with the CAPTCHA-before, during and after they interact with it\" to better distinguish the bot from the human.\nWhether Google's announcement has anything to do with the news from Vicarious is completely unknown, but the search giant are promising they have \"even more to report on in the next few months\" with regards to the technology.\nVicarious attracted more than $15 million in funding last year from investors including Facebook co-founder Dustin Moskovitz and ex-PayPal CEO Peter Thiel's Founders Fund.\nAlthough the company does not plan to release any products for at least several years Moskovitz (who also sits on the Vicarious board of directors) released a statement that \"we should be careful not to underestimate the significance of Vicarious crossing this milestone,\" describing the company as \"at the forefront of building the first truly intelligent machines.\"\n"},
{"docid": "348 of 500 DOCUMENTS\n", "source": "DAILY MAIL (London)\n", "date": "August 3, 2016", "title": "BRITISH CHILD PRODIGY WHO SOLD HIS FIRM TO GOOGLE FOR \u00a3400M NAMED IN TOP TEN GLOBAL TECH PIONEERS\n", "content": "A BRITISH entrepreneur who was a child prodigy at chess has been named one of the top ten tech pioneer's in the world.\u00a0\nDemis Hassabis, 40, came eighth in Wired magazine's Global 100 list of the most influential people in technology and science. Hassabis, who is of Greek Cypriot and Singaporean descent, is the boss of Deepmind, which has led the way in artificial intelligence and was bought by Google for \u00a3400m.\nHe lives in Highgate, north London, with his molecular biologist wife and two sons. He earned a PhD from Cambridge University before starting a computer games development company. He started Deepmind in 2010 with his childhood friend Mustafa Suleyman and began developing artificial intelligence machines. He was behind the computer which beat a human at the ancient Chinese game of Go.\nOther British-based pioneers on the list included Brent Hoberman, the founder of Lastminute.com, who was 40th, WPP boss Martin Sorrell in 47th, Niklas Zennstrom, who runs tech firm Atomico, in 53rd, and Sir Richard Branson in 62nd.\nTop of Wired's list was Elon Musk, who runs the Tesla electric self-driving car company.\n\u00a9 Daily Mail\n"},
{"docid": "349 of 500 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "September 15, 1994", "title": "COMPUTER FINDS AMBIGUITY IN HUMAN SPEECH A BAD JOKE\n", "content": "\u00a0\n ONLY A rather dim computer, you would think, could come up with a joke like \"What kind of emotion has bits? A love byte.\" And you would be right.\u00a0\n Meet JAPE-1, which has spent the past five months generating 200 jokes, other examples of which are \"What kind of pig can you ignore at a party? A wild bore\" and \"What do you call a grain that murders people? A cereal killer.\"\n JAPE-1's fond programmer, Kim Binsted, concedes the jokes are pretty awful but hopes to improve the repertoire as she continues her research project at Edinburgh University's prestigious Department of Artificial Intelligence.\n For Joke Analysis is a serious piece of research into the use of ambiguity in human speech - funded for three years by the Canadian Research Council.\n Ms Binsted hopes that Jape can be taught to weed out some of his worst attempts and handle other joke types such as spoonerisms. Its next efforts will be tested on children.\n"},
{"docid": "350 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "June 13, 2017", "title": "Apple chief: driverless car venture is 'the mother of all AI projects'; Tim Cook confirms tech giant is working on 'autonomous systems', but is tight-lipped on whether it is making its own vehicle\n", "content": "Apple has shed new light on its top-secret driverless car project, as chief executive Tim Cook described the challenge of building autonomous vehicles as \"the mother of all\" artificial intelligence projects. \nCook said Apple was ploughing resources into developing technology to control driverless vehicles, although he refused to rule out the Silicon Valley firm building its own car at some point. The Apple boss spoke as shares in his company and other US tech firms came under pressure this week amid investor concerns that a sector-wide boom is losing steam.\nCook attempted to restore faith in Apple's ability to strike out into new territory by giving his most detailed comments yet about a car venture that has been shrouded in secrecy. \u00a0\n Related:  Waymo ditches futuristic self-driving bubble car for ... a minivan\n\"We're focusing on autonomous systems,\" said Cook in an interview with Bloomberg TV. \"Clearly one purpose of autonomous systems is self-driving cars. There are others. We sort of see it as the mother of all AI [artificial intelligence] projects.\" He added: \"It's probably one of the most difficult AI projects actually to work on.\"\nWhen reports of Apple's interest in cars started to emerge in the media, it was initially thought that the company was going to challenged the automotive giants of Detroit, which are racing to build their own self-driving cars.\nBut the spectrum of Apple's ambitions narrowed last year after Apple veteran Bob Mansfield was put in charge of the programme, dubbed Project Titan.\nWhile Cook was cagey about how Project Titan will evolve, his comments suggest that Apple's primary focus is on AI technology that could be sold or adapted for use in other industries.\n\"We're not really saying from a product point of view what we will do, but we are being straightforward that it's a core technology that we view as very important,\" said Cook. \nDavid Bailey, a motor industry expert at Aston University in Birmingham, said Apple's ability to come up with user-friendly products, such as the iPhone, iPad and iPod, could give it an edge over rivals.\n\"They can offer a number of things such as the software systems that enable the tech to function but also making that extremely friendly for a passenger in a way that other tech companies haven't been able to do.\"\nHe added: \"Autonomous systems can open up mobility to people who don't use cars but it needs to be accessible and user-friendly. Apple's expertise is in that area, they have a knack of making something intuitively very easy to use.\"\nDr Nick Reed, academy director at transport research group TRL, said Apple was smart to focus on technology rather than going head-to-head with car manufacturers.\n\"It would be difficult for them to revolutionise the production of cars but in use and operations, there's a great opportunity. Their strength is in integration with digital lifestyle - a seamless experience, whether it's at home, on your desktop, or your smartphone or now in your car.\"\nOne analyst said Apple may have abandoned plans to build a car after realising it was lagging behind Detroit-based rivals.\n\"They were slow to begin testing autonomous systems, and they now have a considerable innovation gap to close,\" said James Hodgson of tech consultancy ABI Research. \"Previous attempts by Apple to address personal mobility and automation have been marred by high turnover in specialist staff.\"\nReferring to reports that Apple had attempted to form alliances with two German carmakers, Hodgson added: \"In addition, previous talks with BMW and Daimler allegedly broke down over data protection and control. It seems Apple has decided that developing their own autonomous system is preferable to partnering.\"\nSilicon Valley's other behemoth, Google parent company Alphabet, has also shifted the focus of its driverless vehicle plans towards technology for installation in cars built by established automotive firms.\nThe company's Waymo division confirmed on Monday it is phasing out its \"Firefly\" bubble car and has instead sought to highlight its partnership on the Chrysler Pacifica minivan.\nYooJung Ahn, lead industrial designer and Jaime Waydo, lead systems engineer for Waymo, said in a blogpost : \"Now that we've moved to our next phase - letting members of the public use our self-driving cars in their daily lives - we're ready to retire our fleet of Fireflies and focus on integrating our latest technology into vehicles like our new self-driving Chrysler Pacifica minivan.\"\n"},
{"docid": "351 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "January 23, 2015", "title": "A typical story of boy meets fembot; Alex Garland's study of artificial intelligence is ingenious, unsettling and unique, says Wendy Ide\n", "content": "Ex Machina 15, 108min\n****\nAs the writer behind Sunshine and 28 Days Later, plus the unexpectedly smart Dredd, Alex Garland clearly has a taste for the dystopian. His long-awaited directorial debut confirms this. Ex Machina is a smart, tricksy study of artificial intelligence and tech-sex that explores a credible near-future take on the man-machine relationship. Like Ava (the increasingly impressive Alicia Vikander), the beguiling fembot who is central to this compelling threehander, the film is a sleek, seductive piece of technology that reveals its inner workings but hides its cunning.\u00a0\nDomhnall Gleeson stars as Caleb, a programmer in his twenties who works for BlueBook, an all-powerful behemoth search engine. When he wins the company lottery to spend a week at the mountain retreat of the reclusive company founder Nathan (Oscar Isaac), Caleb trades fist-bumps and emails with his jealous colleagues, but he has little idea what to expect.\nWhat he finds, when Nathan's personal helicopter deposits him in a meadow in the middle of nowhere, is quite a house. It's like a nuclear test facility designed by John Lautner. Part solo party pad for a super-rich manchild, part high-security lab crammed with cutting-edge technology, Nathan's lair is at least as clever as its designer.\nThe reason for the security soon becomes clear. Nathan has been developing a conscious machine. He has invited Caleb to be the human component of the Turing test - the examination that assesses whether artificial intelligence can pass for human intelligence. From the moment Caleb meets Ava, he is transfixed. A pensive, angelic face is suspended over a translucent body, revealing the inner workings of her hardware. Vikander, a trained ballet dancer, gives Ava exquisite grace and precision of movement. There is also something alien, something almost imperceptibly not-quite-right about her gestures. It's a beautifully judged performance.\nThe visual effects are first rate, a vital component of Ava as a character. The fact that we can see through her opaque midriff to the workings within makes her simultaneously vulnerable and powerful. Caleb is a hot-shot coder who spends more time with machines than with women. He's completely out of his depth. Ava fascinates him on every level.\nIsaac, meanwhile, provides crucial humour as an out-of-control ego adorned with a hipster beard. He is the kind of hedonist alpha male who is always on the attack. The more we learn of Nathan and his experiments - his enthusiastic discussion of Ava's fully functioning private parts; his troubling relationship with his Japanese maid, Kyoko (Sonoya Mizuno) - the more Ex Machina shifts from an examination of the rights of the machine to a more unsettling study of gender politics. And that's what, ultimately, gives the film its edge.\nPlenty of movies have already explored humanity's relationship with artificial intelligence. But although this one has some common ground with Spike Jonze's Her, both thematically and aesthetically, Garland has crafted a creature that stands alone.\n"},
{"docid": "352 of 500 DOCUMENTS\n", "source": "The Sunday Telegraph (London)\n", "date": "June 29, 2014", "title": "ROBOT ADVISERS MISJUDGE SAVERS; Automated questionnaires designed to assess risk tolerance can get it wrong, says Dan Hyde\n", "content": "Cautious savers are in danger of being sold risky investments because the computer programs used by financial advisers can produce aberrant results, The Sunday Telegraph can disclose.\nOur investigation found that even the algorithm used by the most highly regarded adviser tool was inaccurate in two in 10 cases, relying on the adviser to override the computer.\nIn one test, a 22-year-old saver with \u00a310,000 who said she could not tolerate losses, was unwilling to risk her capital to get a decent return and would rather get a guaranteed return than be \"uncertain\" was pointed towards investments that, if stock markets performed \"below average\", would have wiped \u00a32,500 off her fund in five years.\u00a0\nThis type of technology has become popular with financial advisers because it is seen as a more scientific way to work out how much risk an investor can tolerate in chasing returns.\nEven the head of the Financial Conduct Authority has suggested that artificial intelligence has advanced so far since Garry Kasparov's chess battles with IBM's Deep Blue computer in the Nineties that it could soon replace human advisers altogether.\n\"Scientists are heralding the advent of learning algorithms and self-improving artificial intelligence capable of previously unimaginable and impossible feats of accuracy and forecasting,\" Martin Wheatley told a conference in London in May. He hoped it could be used for dispensing automated investment advice \"to deliver returns and security for consumers with straightforward needs\".\nAscertaining the level of risk you can take with your money is one of the most vital parts of the investing process.\nNearly every investment misselling scandal - from Barclays telling its elderly customers to put their life savings in the stock market to HSBC suggesting care home residents take similar gambles - can be traced to a failure to ensure savers were given investments that matched their appetite for risk.\nThe complexity of the risk question is where middlemen - financial advisers - begin to justify typical fees of \u00a3300 an hour.\nGenerally speaking, investing in the lowest-risk asset, cash, is regarded as appropriate for someone who cannot stomach losses, is reliant on steady income or who might need to access the money within five years.\nThis is because the only risk to the capital is the bank or building society going bust - and even then, up to \u00a385,000 is protected by the savings safety net. As a result, the return on offer tends to be low.\nStock market shares and bonds carry a much higher risk, as they can fall in value. But they also have the potential to provide much higher returns. For these reasons, they are deemed more appropriate for investors who can leave their money untouched for five to 10 years and would remain undisturbed by the value of their investments falling. There are many levels of risk you can take between these two extremes.\nThe suggestion that \"robot\" advisers take over the process of establishing an individual saver's tolerance for their money to rise and fall in value, though, appears premature.\nHOW THE 'RISK-OMETER' WORKS - AND HOW IT DOESN'T\nOur mystery shopping exercise established that the tools available today are by no means foolproof. Investors must still rely on an astute adviser's judgment when selecting the final investment strategy. Several industry sources expressed concern that some advisers were relying too heavily on automated risk-rating technology.\nWe looked at the most commonly used system, Dynamic Planner, which is sold by a company called Design Technology. Over the past four years it has been used by 3,000 financial advisers for 400,000 investors across the country who have invested \u00a350bn on the back of its algorithms. A dummy profile of a cautious and inexperienced investor, created to test the tool, threw up an alarming result.\nFirst, the computer made a series of statements and asked for the saver's response. With the help of a financial adviser, who wished to remain anonymous, we submitted the following answers:\n1. I would be willing to risk a percentage of my income to get a good return - Disagree\n2. To achieve high returns, it is necessary to choose highrisk investments - Neither agree nor disagree\n3. When I am faced with a financial decision I am generally more concerned about the possible losses than the probable gains - Agree\n4. I would rather know that I was getting a guaranteed rate of return than be uncertain about my investments - Agree\n5. Compared to the average person, I take lower financial risks - Neither agree nor disagree\n6. I would rather put my money in a bank account than invest in shares - Neither agree nor disagree\n7. I do not feel comfortable with financial uncertainty - Agree\n8. I would accept potential losses in order to pursue long-term investment growth - Strongly disagree\n9. Taking financial risks is important to me - Neither agree nor disagree\n10. I would be happy investing a large proportion of my income/capital in a high-risk investment - Disagree\nThe Dynamic Planner then provided a risk \"profile\" based on these answers - a score of one is the lowest risk; 10 is high risk.\nThe tool gave a score of four out of 10 for the answers we had provided. This pointed the adviser towards the \"lowest medium risk\" portfolio, which would have split the investor's money with 5pc in cash, 42pc in company bonds, 45pc in shares and 8pc in property. The tool indicated that over five years an investment of \u00a310,000 would turn into \u00a310,356 based on average performance or \u00a314,308 if above average. However, the saver would get back just \u00a37,496 if markets performed below par.\nThis rating stayed unchanged during a further stage of questioning, when the saver said they wished to invest for less than five years, entered \"none or very limited\" under \"capacity for loss\" and made clear that they \"would almost certainly need access to this investment\". Instead, the system simply issued the user a warning that a lower-risk portfolio could be more appropriate.\nIt was then left to the adviser to make the final judgment on which rating to give their client.\nMartin Bamford, director of advisers Informed Choice, said that from the description we gave, \"only cash would be appropriate\".\nBen Goss, chief executive of Distribution Technology, said: \"Dynamic Planner does not suggest assets or asset classes to invest in based on a questionnaire. An adviser has to use his or her own discretion based on a number of factors. It is built to support this process and deliberately does not automate the key element of advice.\"\n"},
{"docid": "353 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 13, 2015", "title": "Microsoft to bring Cortana to iOS and Android; Microsoft is working on an advanced version of digital assistant Cortana for use on Apple and Google-powered smartphones\n", "content": "Microsoft is working on an advanced version of its competitor to Apple's Siri, using research from an artificial intelligence project called \"Einstein.\"\nMicrosoft has been running its \"personal assistant\" Cortana on its Windows phones for a year, and will put the new version on the desktop with the arrival of Windows 10 this autumn. Later, Cortana will be available as a standalone app, usable on phones and tablets powered by Apple's iOS and Google Android, people familiar with the project said.\n\"This kind of technology, which can read and understand email, will play a central role in the next roll out of Cortana, which we are working on now for the fall time frame,\" said Eric Horvitz, managing director of Microsoft Research and a part of the Einstein project, in an interview at the company's Redmond, Washington, headquarters. \u00a0\nThe plan to put Cortana on machines running software from rivals such as Apple and Google, as well as the Einstein project, have not been reported. Cortana is the name of an artificial intelligence character in the video game series \"Halo.\"\nThey represent a new front in CEO Satya Nadella's battle to sell Microsoft software on any device or platform, rather than trying to force customers to use Windows. Success on rivals' platforms could create new markets and greater relevance for the company best known for its decades-old operating system.\nThe concept of 'artificial intelligence' is broad, and mobile phones and computers already show dexterity with spoken language and sifting through emails for data, for instance.\nStill, Microsoft believes its work on speech recognition, search and machine learning will let it transform its digital assistant into the first intelligent 'agent' which anticipates users needs. By comparison, Siri is advertised mostly as responding to requests. Google's mobile app, which doesn't have a name like Siri or Cortana, already offers some limited predictive information 'cards' based on what it thinks the user wants to know.\nMicrosoft has tried to create digital assistants before, without success. Microsoft Bob, released in 1995, was supposed to make using a computer easy, but ended up being the butt of jokes. The Office Assistant nicknamed 'Clippy' suffered a similar fate a few years later.\n\"We're defining the competitive landscape... of who can provide the most supportive services that make life easier, keep track of things, that complement human memory in a way that helps us get things done,\" said Horvitz.\nOutside his door stands \"The Assistant\", a monitor showing a woman's face that can converse with visitors, has access to Horvitz's calendar and can book meetings.\nOn his desktop, Horvitz runs 'Lifebrowser', a program that stores everything from appointments to photos and uses machine learning to identify the important moments. A keyword search for his university professor instantly brings up photos and video from the last time they met.\nCortana could tell a mobile phone user when to leave for the airport, days after it read an email and realized the user was planning a flight. It would automatically check flight status, determine where the phone is located using GPS, and checking traffic conditions.\nNone of the individual steps are a breakthrough, but creating an artificial intelligence that can stitch together the processes marks a breakthrough in usefulness, Microsoft says.\nRivals are on the same track. Google's latest mobile app uses the predictive power generated from billions of searches to work out what a user is doing, what they are interested in, and sending relevant information, such as when a favorite sports team is playing next.\nApple is also pushing Siri, which uses Microsoft's Bing search engine in the background, into new areas with its CarPlay and HomeKit platforms, as well as the recently unveiled Apple Watch.\nThe key to Cortana's success will be knowing where a user is, what time it is, and what they are trying to do. Albert Einstein's work on the relationship between space and time gave rise to Microsoft's secret project name, said Horvitz.\n\"Einstein was brilliant about space and time,\" he said. \"It's using brilliance about space and time generally in our agents.\"\n"},
{"docid": "354 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "December 11, 2017", "title": "Nasa to hold major announcement after artificial intelligence makes breakthrough in hunt for other worlds; The mysterious discovery was made by harnessing Google's machine learning prowess\n", "content": "Nasa is holding a major press conference after its planet-hunting telescope made a new breakthrough.\nThe Kepler space telescope is operated by Nasa to discover other earths, some of which could support life. And its latest discovery is significant enough to bring with it a huge press conference.\u00a0\nFollow along with our live blog of the announcement here.\nVery little further information was given about the announcement, which will take place on Thursday. But it will almost certainly relate to exoplanets - Earth-sized worlds that orbit around their own stars, and are our best hope of finding alien life.\nThe space agency said that the discovery was made with the help of Google artificial intelligence, which is being used to analyse the data sent down by the telescope. By using machine learning provided by the tech giant, Nasa hopes that it can pick through the possible planets more quickly and hopefully find life-supporting planets sooner.\nNasa said that four engineers and scientists would take part in the session. They include Paul Hertz, who leads Nasa's astrophysics division, a senior Google software engineer, and two scientists.\nThe Kepler telescope was launched in 2009, when scientists didn't know how many exoplanets there were. It has shown they are surprisingly common, indicating that each star might have its own planet.\nLost interstellar asteroid enters solar system and baffles scientists\nIt completed its main mission in 2012, but has continued to do more work. In 2014, it began a major mission called K2, which looks for more exoplanets as well as studying other cosmic phenomena.\nThe sheer amount of data coming from the telescope means that scientists have trouble picking through it to find the planets that might be interesting. The introduction of the use of artificial intelligence is intended to help with that, by allowing computers to do some of the work.\nThe Kepler mission has already led to major breakthroughs, finding that the universe is full of planets that could theoretically support life. Many of those breakthroughs are announced in major press conferences.\nIn February, for instance, it said that it was holding a major press announcement similar to the one this week. At that event, it said that it had found the \"holy grail\" - an entire solar system that could support life.\n"},
{"docid": "355 of 500 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "December 13, 1991", "title": "Closing the relativity gap: Donald Michie envisages a time when domestic robots will chatter together while getting on with the household chores. Nigel Williams meets the expert who champions inductive reasoning as the key to machine intelligence\n", "content": "\u00a0\n A CENTRAL heating boiler chatting with the dishwasher while the washing machine makes small talk with visitors? A scientific revolution as profound as the invention of printing or even the first development of writing or numbers is set to force a reappraisal of our own mental abilities and promises to transform the domestic scene, according to one of the worlds' leading researchers in artificial intelligence.\n The idea that 'intelligence' can truly be a property of anything other than a human being is deeply controversial. Philosophers battle over the uniqueness of the human mind and consciousness but Professor Donald Michie, chief scientist at the Turing Institute in Glasgow, believes machines will soon be developed which are capable of language and learning that will challenge and extend human knowledge.\n\n Michie's early career overlapped with that of Alan Turing, the founding father of artificial intelligence who worked on Britain's code-cracking effort during the second world war. Turing devised a test which lies at the root of the philosophical arguments. Essentially, it said that if a computer program can perform in such a way that an expert cannot distinguish its performance from that of a human with a certain mental ability then the programme can be said to have that ability.\u00a0\n The arguments have so far been more theoretical than real. Computers, although capable of impressive skills, are easily caught out by many aspects of human intelligence. Most present programs use deductive reasoning, working from the general to the particular. The snag is that all the rules have to be worked out first, before giving them to the machine to interpret. But Michie, formerly at Edinburgh University where he established one of the leading artificial intelligence research groups, sees inductive reasoning, going from the particular to the general, as the key to machine intelligence.\n The idea is to give the machine examples and let it work out the rules that govern what is going on. Only inductive systems have the ability to learn.\n Michie has carried his expertise and enthusiasm to the Turing Institute, which he set up jointly with Jim Alty of the University of Strathclyde six years ago to bridge the gap between industry and academia in artificial intelligence research. His group is among the pioneers developing such 'expert' systems.\n A harbinger of things to come, developed by several of the main computer companies, is an 'agent'; a cartoon figure with whom you can converse and get help about what is going in the operating system, soon to be available on computer screens.\n But Michie believes gradual improvement in the agents' skills are more likely to undermine than answer the philosophical issues. 'If eventually we really cannot tell the difference between the agent and a helpful colleague, we are going to have no more interest in arguing whether the program is really conscious than I am concerned with the question of whether my graduate students are really conscious,' he says. 'We will just call it quits and have a working arrangement based on a code of politeness.'\n Other software developments are finding hidden depths to our own intelligence, opening up a world that has previously been hidden. Michie says that psychologists are finding growing evidence that mental activity is something like an iceberg, with only the tip open to conscious introspection. 'Almost the whole of the rest is a very elaborate infrastructure of which we have no knowledge although it is going on inside our head.'\n What Michie's group has shown in the laboratory and is beginning to confirm with ilots using flight simulators is that the rules buried in the brain governing the behaviour of trained experts - to which they have no conscious access - can now be revealed. A machine using new inductive learning techniques can browse through the behaviour records of a skilled human carrying out an expert task and automatically reconstruct a model of how they do it. 'The process thus makes articulate brain processes and skills which were hidden,' Michie says.\n 'The result is extremely interesting to the practitioner because he finds he can relate to the models he is apparently using when shown them on the computer screen, and it opens up the possiblity of transplanting those rules to the device that needs to be controlled.' A key observation is that the model routinely outperforms the human from which it was derived. He believes such a system points the way to providing intelligent highly skilled automatic back-up.\n Machines may not only provide insight into hidden areas of human intelligence but they also promise to make original contributions to human knowledge.\n Michie cites a computer model of a class of heart defect called multiple arrhythmias that incorporates causal reasoning. 'It has been able to generate a complete and correct empirical theory of how to diagnose electrocardiograph patterns that will doubtless find its way into the next generation of clinical textbooks.'\n He argues that there may be large gaps in our knowledge that can only be filled with help from machines. 'This example makes clear that knowledge-based software enables people to create elaborate new theories equally intelligible to machine and human that could never be constructed by unaided human efforts alone.'\n MICHIE believes the software revolution will ultimately spread to robots that will talk with us and with each other. It was quickly realised that two or more robots would be needed to carry out many potential tasks, but he argues that current efforts to develop communication systems based on computer networking models are over-complicated. 'You don't need to carry out brain surgery to link up communications between two humans,' he says. 'A fairly complex task like getting a sofa downstairs may only involve fairly simple communications such as 'up a bit', 'down a bit', 'left a little'.\n 'Humans have perception-driven intelligence and we are already at the stage of demonstrating in the laboratory very effective robots with speech synthesisers and speech recognisers that can talk to each other and co-operate on tasks. Such an approach also has the advantage that if there was a hang-up the supervisor could listen in to find out why. But the approach is anathema to most engineers at present.'\n Michie is convinced that speech-based solutions will eventually be adopted, leading to a domestic revolution in the next century. 'Washing\n machines will talk,' he says. 'They will tell you when they are ready for a load, or that the washing is not quite dry. The de-luxe model may also be skilled in small talk,' he adds. 'Likewise, domestic robots helping with the housework will talk with their companions and other household items about what they're doing and what's next.' The machines are bound to acquire personality in the eyes of the family in the way their cats and dogs do, but the extra property of mental transparency and articulate communication will bring a new dimension, he says.\n 'This will be a domestic environment in which children will grow up so different from that of today that is hard to envisage it,' Michie says.\n"},
{"docid": "356 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "August 8, 2016", "title": "Instant diagnosis by smartphone: how artificial intelligence can save lives; TATA COMMUNICATIONS Drones that pick inaccessible crops and mobile phones that give medical advice are two of the ways Al can transform life in the developing world, Oliver Pickup reports\n", "content": "Artificial\u00a0intelligence (AI) will be a \"game changer\" in improving the lives of the world's poor, according to the New York-based technology entrepreneur Jack Hidary. He says the technology needed to revolutionise inefficient, ineffective food and healthcare systems in developing countries is well within grasp.\n\"In low-income areas, agriculture and healthcare are two critical ecosystems that we can apply AI to immediately; this is not the far future, or even in five years - we can start this year,\" said Mr Hidary, moderator and session leader of Tata Communications' recent 2016 CEO Summit, with the theme \"Artificial\u00a0intelligence meets emotional intelligence\".\u00a0\n\"AI will be a game changer, and benefit billions. Today two billion people in the world go hungry, so righting the unbalanced distribution of food and dealing with the worldwide agricultural system is a good start. Technologies such as GPS have increased the yield in developed countries but have not been widely used in developing countries. Now we can level that playing field with smartphones and access to the cloud.\n\"The ability to increase the yield of farmland under tillage in developing countries is a mission-critical challenge. I see that as within reach using these technologies. We already have autonomous drones for agriculture, for both shooting seeds into the ground, and fertilising.\"\nIn India, Tata Rallis, an internet of things (IoT) project, uses drones to administer pesticides. The aim is to harness data, such as crop health and soil conditions, to boost output.\nMr Hidary said: \"By extension, drones are able to pick fruits, almonds and other kind of foodstuffs that are difficult to collect for humans. Drones are cheap - about $100 (\u00a375) - and could be used by communities for farming and other tasks, and don't have to be owned by one person.\" Smartphones are now more widely used by people in developing countries. Soon we could expect instant medical advice and prescriptions from \"smartphone laboratories\", said Mr Hidary.\nMany deaths in low-inc'Some comunities are preventable. Hepredicted that a device that attaches to a smartphone and could take samples of blood, saliva and urine would become available. It would tell the patient if they had diseases as serious as zika, cholera or ebola.\nThere would be no need to send samples to a lab in the capital, which could take weeks. Instead, there would be an immediate analysis and a prescription issued. Often the solution would be just a few pills or an injection, getting to the person to care or isolating them. AI would speed that process and save many lives. Mr Hidary added: \"Applying AI to healthcare is essential for low-inc'Some comunities. Often in those areas one health crisis devastates the whole family; all the savings can be lost if the breadwinner is felled by a disease.\"\nTimothy Chou, a Stanford University lecturer on cloud and IoT, says we cannot apply how things work in the West to the developing / world. \"We suffer from a mental block, because we accept how things work in our country and we want to replicate that in the developing world,\" said Mr Chou, one of 60 Business leaders who was at the summit at Coworth Park, Ascot. \"The reality is we shouldn't.\"\nThe first priority must be to buildinfrastructure as there will be a limit to growth unless the West can build next-generation telecoms, power and agriculture systems. Providing consistent and secure global connectivity to as 4 many as possible is imperative. Vinod Kumar, chief executive of Tata Communications and host of the summit, praised the China-led One Belt, One Road project. It aims to develop a strategy and framework focusing on connectivity and co-operation among 65 countries. \"It will connect 60pc of the world's population, and is estimated to add $2.5trn to those countries in the next decade,\" said Mr Kumar, whose company is currently building India's first-ever IoT network, which will underpin many AI applications in the country.\nAI has the power to remould and better develop countries from within, by allowing tech talent to thrive. \"In India, there are 4,200 start-ups, the third-largest start-up ecosystem in the world. They are redefining Business models in technology for healthcare, education, climate change, ecommerce and so forth. They will make very pinpointed and disruptive investments that will shape the economy of the future, and improve the lives of the poor in India and beyond.\"\nPOWERING THE FUTURE\n24%+ Percentage of global internet routes carried by Tata Communications' network\n99.7% Percentage of the world's GDP generated by countries that are reached by this internet backbone\n710 Length, in thousands of kilometres, of Tata Communications' superfast fibre network - the only such network that encircles the globe\n400m Locals who will benefit from India's first IoT network, being built in cities such as Mumbai and Delhi by Tata Communications\nTATA VISION 2025\nBy 2025,25 per cent of the world's population will experience the Tata commitment to improving communities' and customers' quality of life. Tata will be among the 25 most admired corporate brands globally, with a market capitalisation comparable to the world's 25 most valuable firms. Tata Communications is part of the Tata group For more information, visit @tata_comm or tgr.ph/ tatacommunications\n"},
{"docid": "357 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "April 8, 2017", "title": "Google refuses to use AI against videos\n", "content": "Google has been criticised by MPs after it proved that it could rapidly identify extremist videos using artificial intelligence technology, but refused to use it to take offending clips off YouTube.\u00a0\nThe technology company and publisher said this week that it would no longer host adverts on YouTube channels with fewer than 10,000 views because this would give it greater ability to check if content was inappropriate.\nThe announcement came after Times investigations found that adverts from companies including Toyota, Tesco and McDonald's were appearing alongside videos promoting terrorism. After a backlash and the withdrawal of advertising worth millions of dollars from the video-sharing site, Google has started using its artificial intelligence to scan YouTube's video library for extremist content and has removed adverts from thousands of hate-filled videos in the past few weeks.\nPhilipp Schindler, the company's chief business officer, told Bloomberg News that by using the new machinelearning tools and \"a lot more people\" it had flagged five times as many videos as \"non-safe\" in the past two weeks.\nHowever, Google told The Times that the tools would be used only \"to identify content that may be inappropriate for advertisers and to automatically demonetise those videos\". It said they would not be used to review videos against its community guidelines for possible removal and that videos would still be checked by the company's review team only after they were flagged by other users.\nGoogle was recently criticised by the home affairs select committee for refusing to proactively police content, instead relying on its users to report videos in breach of hate-speech or other rules.\nGoogle and other Silicon Valley companies subsequently agreed that they would collaborate on the \"further development of technical tools to identify and remove terrorist propaganda\".\nAt the time, Yvette Cooper, chairwoman of the committee, said she was shocked that Google did not proactively tackle illegal YouTube posts. \"Social media is great thing but companies who make money from it have responsibility to stop people using it for hatred and ruining others' lives,\" she said.\nYesterday she criticised the company for only applying the technology that it has to woo advertisers but not to remove illegal and dangerous content. She said: \"Google's new technology for identifying hate content is a welcome step forward but it isn't enough only to use this to protect their advertising revenues. They shouldn't just be using it to help big companies be confident about where their advertising revenues are going, they should also be using it to identify illegal or dangerous content that shouldn't be on YouTube at all.\n\"If they have the technology to do this they should take some responsibility and use it. It isn't just enough to be motivated by the bottom line.\"\nChi Onwurah, a Labour MP who previously worked in the technology industry, said: \"What this says to the world is that Google's actions are driven purely by its responsibilities to advertisers rather than by its responsibilities to its audience, on whose clicks and data its existence depends.\"\nOwners of legitimate YouTube channels with fewer than 10,000 views who can no longer host ads on their videos also complained that they were being unfairly penalised.\n"},
{"docid": "358 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "May 10 1988", "title": "Technology: One way to get smart - Artificial intelligence skills may become standard in software\n", "content": "\u00a0\n Fairly soon programmers may find themselves commonly using artificial intelligence techniques. Until now most expert systems, which seek to encapsulate an expert's knowledge in a set of rules which a computer can interpret, have been confined to research projects.\n Such commercial applications as have appeared tend to fall into two categories: small systems using standard software 'shells', and larger systems requiring specialist hardware and programming languages such as Lisp or Prolog.\u00a0\n\n But now software companies such as the US-based AI Corp are starting to exploit expert-systems technology as a part of standard software programs which will run on existing hardweare and work with existing computer programs.\n Programmers with experience of languages like Lisp, which is commonly used for expert systems, are a scarce commodity and companies are reluctant to retrain programming staff in esoteric languages, said Phyllis Swersky, AI Corp's executive vice-president.\n AI Corp was founded in 1975 to develop artificial - intelligence software to run on IBM mainframes. Its most successful offering so far has been Intellect, a natural language system designed to help business people access information using ordinary English.\n About 500 sites worldwide use Intellect and European customers include British Airways, British Gas, the Shell Group, Midland Bank and Tesco Stores.\n Now the company is developing KBMS (Knowledge Based Management System), a program designed to capture essential skills from business managers.\n AI Corp is working on the product in collaboration with four American Corporations.\n Mrs Swersky believes that by using expert systems technology it is possible to spread specialist business knowledge more widely and protect companies against a loss of expertise if key staff leave or retire.\n It is also claimed to make decision making more consistent, since the computer does not panic or forget, while the programs themselves are easier to maintain.\n One of the insurance companies in the consortium, for instance, is developing a computer program to tckle its underwriting procedures so that it standardizes on the best level of expertise possible.\n The computer can check a proposal against all the rules in seconds and implement a search of relevant databases if necessary, for example looking up past traffic violations if a motor-insurance policy is under consideration.\n Mrs Swersky said: 'I believe it will soon be as natural for programmers to know about expert systems programming as datbases. Take a pricing module for a company with a lot of products and complex-pricing discounts. To write that in Cobol is a tough task and if you do write it and the policy then changes, the software can't maintained with any flexibility.'\n In an expert systems program, programmers would need simply to change a few of the rules.\n Mrs Swersky estimates that there are about 40,000 potential customers worldwide The company has bought out its original UK distributor and set up a new subsidiary, in Bracknell, which is recruiting staff, including knowledge-based systems engineers.\n"},
{"docid": "359 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 14, 2016", "title": "'Robot doctor' app raises $25m to predict future of your health; London startup Babylon is building an artificially intelligent doctor\n", "content": "British digital healthcare startup Babylon has raised $25m, the largest series A funding round in European digital healthcare till date. The mobile app, which launched in February last year, has built an artificially intelligent \"doctor\" that can decode symptoms and prevent illnesses before they occur, by tracking your daily habits, and integrating data about your heart rate, diet and your medical records. \u00a0\nSources close to the business say it is currently valued significantly higher than $100m. Investors include successful British entrepreneurs such as the founders of Innocent Drinks and DeepMind, the  Google-owned artificial intelligence company. \nCurrently, the London-based startup offers a mobile doctor app used by 250,000 people in the UK - pay \u00a34.99 a month, and get 7-days-a-week access to their pool of human doctors over video chat. \n\"We can use artificial intelligence to start predicting the future of your health\"Ali Parsa, Babylon CEO\nNearly 60 businesses including Citigroup, Sky, and MasterCard, as well as health insurance providers such as Bupa and Aviva, have partnered with Babylon to offer its services to UK employees. \nBabylon is also trialling a partnership with the NHS, with a new pilot in Birmingham that makes its services available to the broader UK population. \nThe Telegraph tested an early version of the AI doctor. It can respond to questions about standard medical symptoms like headaches or fevers, by asking relevant questions (such as \"did you hit your head?\" or \"are you feeling dizzy, nauseous?\" and \"do you have a fever?\"), and tell you the best course of action. \nCrunching hundreds of millions of variations of symptoms and outcomes, it may suggest going to a pharmacist, staying hydrated or booking a GP appointment. \nIt will also remind you to take medication, but will not prescribe. To flag up future illness, it analyses physiological, biological and medical history data. For instance, it can warn you about higher than normal heart rate, suggesting you may develop a cold. \n\"We can use artificial intelligence to start predicting the future of your health,\" chief executive Ali Parsa said. \"I genuinely believe Britain has a great chance to be a global leader in digital health.\" \n"},
{"docid": "360 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "October 6, 2012", "title": "When Spielberg shot Kubrick\n", "content": "A.I. Artificial Intelligence (2001)\nDIR STEVEN SPIELBERG STARRING HALEY JOEL OSMENT, JUDE LAW\nA robot boy, trapped in ice for 2,000 years, staring at the unresponsive effigy of a blue fairy he implores to make him real. Manhattan's tallest buildings desolately protruding from an ocean that stretches as far as the horizon. A mechanical teddy bear tumbling to the ground from a hot-air balloon disguised as the moon.\nThese count among the most peculiar and indelible images of Steven Spielberg's whole career, yet the film around them, 2001's A.I. Artificial Intelligence, is remembered coolly or with enormous reservations, if at all. Many fans of Spielberg reject it. It's time the case for the defence was reopened on the oddest, creepiest, most emotionally risky film from a director whose default instinct has been to keep us in the palm of his hand, not hold us at arm's length.\u00a0\nA.I. did have its supporters on first arrival, particularly those critics who recognised the profitable fusion between Spielberg's sensibility and that of the late Stanley Kubrick, who had harboured the project for years without figuring out how best to handle it technically. Still, it was nothing like the boxoffice success that Spielberg enjoyed with his two subsequent science fiction blockbusters, Minority Report and War of the Worlds. Coming from a place of human (well, Tom Cruisean) jeopardy in the face of generic menace, the darkness of those was easier to penetrate and banish, somehow.\nA.I. is gaudier, and more off-putting in its imperfections, but a lot bolder than anything Spielberg has made since. What's most fascinating is how close this expert emotional manipulator came to admitting how feelings might be faked, love turned into a simulation. Haley Joel Osment's David \"imprints\" onto his human mother, Monica (Frances O'Connor), and from then on is locked into a mindset of unconditional devotion. Thanks to Osment's nakedly needy, uncannily off-kilter performance, it's terrifying: for the first and only time in a Spielberg film, love is a thing to recoil from. This overturns his customary world-view so completely the effect is startling - it's as if E.T. were bent on staying and Elliott wanted rid of him.\nThe first hour of the film, which Spielberg shot from Kubrick's script almost verbatim, offers one phenomenal passage after another. David's rivalry with his human \"brother\" Martin (the excellent Jake Thomas) and his dependency on Teddy (voiced with pitch-perfect querulous gruffness by Jack Angel) mesh superbly. His separation from Monica, who abandons him in the woods stricken by guilt and doubt, is a brutal emotional rupture like nothing Spielberg has given us since Schindler's List. Speaking of which, only that film can prepare you for the scalding horrors of the Flesh Fair, a carnival of robot torture in which David finds himself involuntarily starring.\nIt can be argued that Spielberg goes too far with the bloodthirsty zealotry of the crowd in these scenes, and that Jude Law's preening lover-android Gigolo Joe is never given a satisfactory reason to help David in his fairy-tale quest for a Pinocchio-esque happy ending. When David is pinned to the ocean floor, gazing helplessly at the blue fairy, it feels like a compellingly bleak place to finish, but Spielberg can't bring himself to abandon the boy as Monica did.\nWe get a lengthy coda, the most critically attacked section of the film, which is usually misread as a sop. In fact, it's a deus ex machina, fast-forwarding us two millennia to a point, beyond humanity's demise, where David can be helped, not by aliens but by super-advanced robots. Though it's easy to claim this is Spielberg's sentimentality asserting itself, to do so is to miss the haunting irony of what's bestowed. There are no happily ever afters here.\nA.I. is available on DVD and Blu-ray from Warner Home Video\n"},
{"docid": "361 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "January 8, 2016", "title": "Stephen Hawking's birthday: The pioneering astrophysicist's most terrifying quotes; Hawking has warned humanity about our own barbarity, the growth of artifiical intelligence and the likelihood that any aliens we meet will want to kill us\n", "content": "Astrophysicist Professor Stephen Hawking has turned 74, celebrating his birthday on 8 January. His has been a life of miracles and stunning discoveries - as well as terrifying warnings.\nWhile he is famous for his pioneering work in astrophysics, he has also occasionally issued warnings to the rest of the human race - about the threat of everything from human aggression to artificial intelligence. Here are the most dire of those predictions, and the dramatic of his advice.\n\"I don't think we will survive another 1,000 years without escaping beyond our fragile planet.\"\u00a0\nProfessor Hawking issued a warning about the necessity of space travel as a form of \"life insurance\" for humans. He has said that humanity is in grave danger for a number of reasons - artificial intelligence as well as the dangers of human barbarity - and as a result we should make sure we have somewhere else to go.\n\"If aliens visit us, the outcome could be much like when Columbus landed in America, which didn't turn out well for the Native Americans.\"\nProfessor Hawking has been one of the world's leading advocates for searching for alien life. But he's also clear about his worries for what would happen if they found us first.\nIf aliens were advanced enough ever to get here, they would probably be \"nomads\", he said, \"looking to conquer and colonise whatever planets they can reach\".\nHawking's search for life\n\"Aggression [...] threatens to destroy us all.\"\nHuman aggression might once have been useful when it helped us \"to get more food, territory or a partner with whom to reproduce\", Professor Hawking told The Independent. But now it could wipe us all out, he warned.\nProfessor Hawking named human aggression as the quality he would most like to wipe out. Instead we should magnify empathy, he said, because it \"brings us together in a peaceful loving state\".\n\"I think computer viruses should count as life. I think it says something about human nature that the only form of life we have created so far is purely destructive. We've created life in our own image.\"\nThe same barbarity of humans that Professor Hawking has addressed comes out in what we make, he warned in 1994. Computer viruses might not have metabolism of their own, but they work like a parasite that is only able to replicate inside its host.\n\"The development of full artificial intelligence could spell the end of the human race.\"\nProfessor Hawking has consistently warned about the dangers of AI, and repeatedly warned that getting the technology wrong could lead to the demise of the human race. He has said that artificially intelligent systems would eventually learn to make themselves better, and would advance at a rate far above that of humans - once they did, we wouldn't be able to compete and would die out.\n\"The real risk with AI isn't malice but competence [...] You're probably not an evil ant-hater who steps on ants out of malice, but if you're in charge of a hydroelectric green energy project and there's an anthill in the region to be flooded, too bad for the ants.\"\nStephen Hawking made clear in a Reddit session earlier this year that the danger of artificial intelligence wasn't that it would want to kill us. Instead, it probably wouldn't even think about us - crushing us because they are so powerful and their goals aren't naturally aligned with ours.\nRead more\nAI could wipe out humanity because it's too clever, Hawking warns\n\"Everyone can enjoy a life of luxurious leisure if the machine-produced wealth is shared, or most people can end up miserably poor if the machine-owners successfully lobby against wealth redistribution. So far, the trend seems to be toward the second option, with technology driving ever-increasing inequality.\"\nEven if robots don't wipe us out, they'll probably continue the same pattern that has been going on in the economy in recent years. While artificial intelligence could lead to \"technology employment\", it could also just lead to people losing their jobs and not having them replaced - and it seems that's likely, based on current trends.\n\"We urgently need to develop direct connections to the brain so that computers can add to human intelligence rather than be in opposition.\"\nOne of the ways that we would be able to beat the massive speed with which AI develops is to use it ourselves. We could genetically engineer ourselves to do so but that takes about 18 years to go into effect, rather than the 18 months' time that it takes for computers to get twice as fast. As such we'd be quicker to wire ourselves into computers and take advantage of their leaps forward.\n"},
{"docid": "362 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "June 6, 2014", "title": "Young people give up privacy on Google and Facebook 'because they haven't read 1984'; Young people hand over their private details to internet companies and on social networking site too readily because they have not read 1984 by George Orwell, an academic warns\n", "content": "Young people willingly give-up their privacy on Google and Facebook because they have not read George Orwell's '1984' unlike previous generations, a leading academic has warned.\u00a0\nNoel Sharkey, professor of artificial intelligence and robotics at Sheffield University, said that large corporations were hovering up private information and modern generations did not realize it was wrong.\nHe said that older people who had grown up reading George Orwell's 1984 about 'Big Brother technology and ' authoritarianism', were in a better position to resist the creeping erosion of privacy.\nProfessor Sharkey, speaking at Cheltenham Science Festival, said: \"I'm 65, I don't want to be targeted. I am very uncomfortable with it. It seems to me that our privacy is gradually being violated and eroded without us noticing.\n\"I am part of the generation which all read 1984 - I think we are less happy about giving up our privacy.\n\"But the younger generation aren't really thinking about it. The services that Google and Facebook give us are so good that people are willing to trade off their privacy for them. If you grow up with that, that is what you know to like.\"\nTechnology commentators have become increasingly concerned that Google has recently purchased a collection of artificial intelligence and robotics companies.\nThey fear it will give the technology giant unlimited access to private information.\nGoogle recently paid \u00a31.9billion for Nest Labs, a firm which makes internet-connected heating systems, allowing people to control their thermostats from afar.\nAlthough supporters ague that having greater control over home applications can only be beneficial, others are worried that it enables firms to collect data about energy use and living habits.\nGoogle also spent \u00a3300 million on Deep-Mind, a British artificial intelligence firm which specialises in quickly building up a profile of an individual based on their internet activity.\nHe said: 'Google has a policy where they keep our entire history. They know far too much about us.\n\"At the moment it doesn't seem harmful. But because governments can get hold of this information, they can monitor you, things might change quite dramatically.\n\"You give away that much information - you can now take little bits of data, put in a simple little algorithm, and it can put it all together and build up a big picture about us.\"\nHe warned that soon Google would know 'where you are all of the time.'\n\"The problem with any technology is that once it goes into the wild, once it starts picking up momentum and getting critical mass, we have no idea how it will be used, no idea. It is quite worrying,\" he added.\n"},
{"docid": "363 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "February 2, 2006", "title": "New generation of robots will walk, talk -and wash up\n", "content": "The walking, talking robot that can operate with the dexterity of a human being may have been the stuff of science fiction for decades, but state-of-the-art C3POs are now on the march.\nThe brave new world of humanoid robots that not only take out the rubbish and clean the carpet but also look after children, care for the elderly and travel into space is now almost upon us, the magazine New Scientist concludes after analysing recent advances in the robotics of movement, manipulation and speech.\nThe robots will combine the latest developments in control software, sensors and actuators -the mechanisms that facilitate movement -with advances in \"walking\" technology and sound synthesis.\n\"Lifelike humanoid robots have eluded designers because the mechanisms required to perform such tasks as emulating a hand, or walking and talking in anything approaching a natural manner, are hugely complex and need fine control,\" the report concludes. \"(But) researchers are now poised to pull together developments in three key fields -walking, talking and manipulation -to produce a new generation of human-like machines.\"\u00a0\nCurrent research projects are now removing the stilted walk and gait associated with two-legged robots, and the artificial sounds that so betray their mechanical origins, the magazine reports. Software programs have also been developed that allow humanoid robots far more sensitivity to their surroundings, raising the prospect of their becoming an everyday reality around the house and further afield.\n\"When artificial intelligence catches up (with the advances), robots will not only be able to clean the house, do the dishes and take out the garbage, but also to play with children, help the elderly and even explore the farthest reaches of space and perform repairs or search-and-rescue missions in hazardous sites on Earth.\"\nThe Robonaut, a project run by Nasa, is setting new standards in dexterity designed to mimic the work of astronauts. The aim is to build a robot with the dexterity of a six-year-old child within the next twenty years.\nOther artificial intelligence experts are working on software that allows robots to learn autonomously how to use objects through hand-eye co-ordination and a tactile understanding of how they feel.\nNew \"talking\" technology, including motor-driven diaphragms, artificial vocal cords and lips that can protrude, is also aiding pronunciation and the development of robots that can learn to speak by developing their own understanding of phonemes, or speech sounds.\nOliver Brock, an expert on robot dexterity at the University of Massachusetts, said the pace of development was such that humanoid robots might soon be able to carry out tasks that were beyond human capabilities. Artificial\u00a0intelligence, allowing robots to make decisions independently was only in its infancy, though.\nNew Scientist says: \"The goal is to build robots that...will learn to interact with humans in a messy and unpredictable environment, not just in the lab...\nbut they will depend on us for a long time to come.\"\nLeading article, page 19\nMADE TO OBEY\n1969 Shakey -developed at Stanford Research Institute. First robot to sense its environment\n2000 Aibo -robotic dog developed by Sony that reacts to voice commands and touch and can be given different \"personalities\" as it ages\n2000 Asimo -Honda's humanoid that can go upstairs, answer the door and understand gestures and spoken commands\n2002 SDR-4X -Sony robot that can sing, dance, recognise faces, voices and names, hold simple conversations and get up after being pushed over\nTHE HELPFUL HUMANOID. ..\nAdvances in robotic movement, dexterity and speech are predicted to usher in a new breed of highly interactive robot\n...CAN TALK\nJapanese researchers have improved on electronically synthesised speech. New robots can mimic human voices and are complete with tongue, teeth and lips\n...CAN HOLD\nAdvanced humanoid robots, with fully functioning five-fingered hands, can sense their environment and adjust their vice-like grip to fit\n...CAN WALK\nTwo-legged robots can now walk around with a relaxed, natural gait, created by using fewer motors in the robot's joints and allowing gravity to act on a body supported by freely hinged legs\n"},
{"docid": "364 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "March 14, 2018", "title": "Stephen Hawking death: The famed physicist's best quotes; 'People who boast about their IQ are losers'\n", "content": "The famed physicist Stephen Hawking has died, aged 76. During decades in the public eye - from his work investigating black holes to a cameo on\nThe Simpsons\n- he amassed a portfolio of witty and memorable quotes.\nA few of them appear below, on subjects including artificial intelligence, fame, life, the universe and everything.\nIn the words of others, Hawking was described on Wednesday as \"a colossal mind and a wonderful spirit\"; \"inspirational\"; and an \"ambassador of science\".\u00a0\nOn life and death\nHawking did not believe inan afterlife, he said\nin 2011. But the threat of one was not necessary to induce people to behave well, he added. When asked how a person should live their only life, hesaid: \"We should seek the greatest value of our action.\"\nIn the same interviewwith\nThe Guardian\n,Hawking said having motor neurone diseasemeant he had lived with the possibility of dying early for several decades. He added:\"I'm not afraid of death, but I'm in no hurry to die. I have so much I want to do first.\"\nRead more\nStephen Hawking, a giant of physics who bridged the pop culture divide\nThe scientist took a pithy line onstaying cheerful when he spoke to \nTheNew York Times\nin 2004, saying: \"Life would be tragic if it weren't funny.\"\nAnd he wasquoted inPeople's Daily Online in 2006 as having said about euthanasia: \"The victim should have the right to end his life, if he wants. But I think it would be a great mistake. However bad life may seem, there is always something you can do, and succeed at. While there's life, there is hope.\"\nOn artificial and extraterrestrial intelligence\n\"I think the development of full artificial intelligence could spell the end of the human race,\" Hawking told the BBC in 2014. \"Once humans develop artificial intelligence, it will take off on its own and redesign itself at an ever-increasing rate.\n\"Humans, who are limited by slow biological evolution, couldn't compete and would be superseded.\"\nDespite pushing for humanity to escape Earth and explore space, and in 2016 backing the Breakthrough Starshot interstellar spacecraft project,Hawking felt strongly that first contact with alien species should be avoided.\nHe told the National Geographic Channel\nin 2004: \"I think it would be a disaster. The extraterrestrials would probably be far in advance of us. The history of advanced races meeting more primitive people on this planet is not very happy, and they were the same species. I think we should keep our heads low.\"\nOn human intelligence\n\"People who boast about their IQ are losers,\"he said in the December 2004 interview with \nThe New York Times\n.\nNonetheless in a 1999 episode of\nThe Simpsons\n- \"They Saved Lisa's Brain\", in which Lisa joins the Springfield branch of Mensa and eventually takes over the running of the town - Hawking silenced all the show's brainiest characters by announcing during an argument as to who was smartest: \"Big deal. My IQ is 280.\"\nHe further admonished the group with a lecture on how power corrupts, while sending himself up with an Inspector Gadget-style turn from his motorised wheelchair.\nHawking was famously possessed of a sharp wit. Speaking to comedian John Oliver on his programme \nLast Week Tonight\nthe physicist was asked whether in a reality that contained multiple universes, one existed in which the host was \"smarter than you\".\n\"Yes, and also a universe where you're funny,\"the Cambridge academic shot back.\nOn his fame\n\"The downside of my celebrity is that I cannot go anywhere in the world without being recognised. It is not enough for me to wear dark sunglasses and a wig. The wheelchair gives me away,\"he said on Israeli TV inDecember 2006.\nHowever, he told \nThe New York Times\ntwo years earlier he wanted his books \"sold on airport bookstalls\".\nOn space and the universe\nHawking remains best-known for his work describing the nature of black holes.\nOf the phenomenon, he said in a 1996 book: \"Einstein was wrong when he said, 'God does not play dice'. Consideration of black holes suggestsnot only that God does play dice, but that he sometimes confuses us by throwing them where they can't be seen.\"\nIn his classic book\nA Brief History of Time\n, Hawking famously said of scientists striving to produce a unifying theory explaining the universe's mechanics: \"If we discover a complete theory, it would be the ultimate triumph of reason - for then we should know the mind of God.\"\nThe memorable, metaphorical statement has been often discussed since it was published in 1988, but questions over Hawking's beliefs about the origins of the universe were answered firmly in his 2010 book,\nThe Grand Design\n.\nIn it, he wrote: \"Because there is a law such as gravity, the universe can and will create itself from nothing. Spontaneous creation is the reason there is something rather than nothing, why the universe exists, why we exist. It is not necessary to invoke God to light the blue touch paper and set the universe going.\"\nOn disability\nHawking told \nThe\nNew York Times\nin 2011 that motor neurone disease had taught him \"not to pity myself\" because others were worse off.\nHe added: \"My advice to other disabled people would be, concentrate on things your disability doesn't prevent you doing well, and don't regret the things it interferes with. Don't be disabled in spirit, as well as physically.\"\nAdditional reporting by PA\n"},
{"docid": "365 of 500 DOCUMENTS\n", "source": " The Independent (United Kingdom)\n", "date": "June 13, 2016", "title": "Apple reveals iOS 10, including redesigned Messages and Apple Music apps, with updates to macOS and Watch; The company has added new artificial intelligence features and extensions to take on companies like Google - but stresses that everyone's data will stay private\n", "content": "Apple has completely overhauled much of the iPhone's operating system, alongside updates to almost every piece of software it makes.\nThe company launched iOS 10 alongside watchOS, tvOS and the newly-renamed macOS at a huge event in California. The keynote began its Worldwide Developers Conference, where software makers can preview the operating system for iPhones and iPads.\nThe new iOS includes a complete redesign of its Messages app, which is used for sending SMS messages but also iMessages.\u00a0\nAlmost all of the new updates are available to developers now, and will be sent out to the public in the autumn.\nRead more\nApple unveils new software for iPhone and rest of products\nEmojis have now been made three times larger on-screen, as well as a new ability to replace words with emojis in text if there is a relevant option.\nThe app has also been opened up to developers for the first time, meaning other apps can now use Messages - examples shown included being able to send money to someone as well as place a food order via a restaurant app from within Messages.\nMessages can now also be resized and animated in order to add different sentiments, while handwritten notes can now also be sent for the first time.\nFull-screen animations can be applied to conversations too.\nOutside of Messages, much of the update focuses on artificial intelligence.\nThe technology giant's virtual assistant Siri has been given a major update that now means it can use machine learning to predict words you plan to use in text conversations as well as find faces in your photo albums.\nThe company stressed that it would still ensure that everything was kept entirely private, despite the added analysis it is doing on photos and messages. Most of that work will be done on the phone, and anything that isn't will be encrypted or made anonymous.\nOutside of artificial intelligence, one of the bigger themes was the opening up of various apps to external developers.\nSiri will now be able to talk to other companies, for instance, and the Maps app will include extensions that let people\nAs part of the iOS 10 update revealed at the event, it was also announced that Apple Music, the firm's streaming service, will be getting a complete re-design.\nThe app has been previously criticised for being too complicated to use. Now music has been reorganised.\nIt was also revealed the company is renaming its desktop software macOS, as well as adding Siri to its desktop computer software for the first time.\nSiri was one of the bigger themes of the day. It manages to use the extra power of the Mac to do more powerful computing work, and also introduces new technologies into the version on iPhones and iPads.\nBut Apple didn't release a much-rumoured home speaker that would compete with Google's Home and Amazon's Echo.\nAs part of the update, Apple is also increasing what users can do from the iPhone's lock screen. It's redesigning its notifications with the 3-D Touch feature on newer phones to allow for better access to messages, music and widgets that show sports scores and other information.\nMeanwhile, Apple says its HomeKit smart-home system is getting a new look, as more consumer electronics companies and now home builders get on board. The centerpiece is its new Home app, which puts the controls for all of a user's HomeKit devices in one place.\nApple's conference began with a sombre reflection on the Orlando shooting that happened just a day before it began.\nTim Cook opened the keynote at the WWDC conference in San Francisco by paying tribute to the victims of the Orlando shootings, saying Apple offered its \"deepest sympathies to everyone whose lives were touched by the violence\".\nHe then led a moment's silence before the event began.\nAdditional reporting by agencies\n"},
{"docid": "366 of 500 DOCUMENTS\n", "source": "The Times\n", "date": "August 5, 1992", "title": "Computers conspire to fuddle human brain\n", "content": "COMPUTER programmers and their electronic proteges will gather in the Park Lane hotel, London, today for an all-out assault on the human brain in a wide variety of thinking games.\n More than 50 computers, with their human minders, from Russia, Latvia, China, Britain, America, Germany, France and elsewhere, will be competing for medals in the fourth AST Computer Olympiad, which runs until next Tuesday.\u00a0\n Since the first Computer Olympics in 1989, the event has attracted many of the world's top artificial intelligence programmers. Participants have brought with them programmes in chess, draughts and bridge, some of which are already capable of demolishing the leading human experts in their chosen games. The olympiad also acts as an important stimulus for some of the most remarkable work in heuristic programming, a branch of artificial intelligence which seeks ultimately to enable computer programmes to solve any problem more efficiently than the best human minds.\n A disturbing aspect of the olympiad is the question of whether the computers will solve certain games and thus render them theoretically meaningless. Last year one artificial intelligence paper entitled ''Which games will survive?'' predicted that by 2000 computer programmes will either have solved, or at the very least, be of human world championship strength in many of the classic thinking games.\n The parlour game Connect 4 has already been rendered meaningless by computers and Go Moku, played frequently in Japan, may face a similar fate this year when it comes under scrutiny.\n"},
{"docid": "367 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "February 25, 2015", "title": "New artificial intelligence can learn how to play vintage video games from scratch; The Deep Q-network has learned to play Space Invaders and Breakout\n", "content": "A new kind of computer intelligence has learned to play dozens of vintage video games without any prior help in how to achieve human-like scoring abilities, scientists said.\nThe intelligent machine learns by itself from scratch using a trial-and-error approach that is reinforced by the reward of a score in the game. This is fundamentally different to previous game-playing \"intelligent\" computers, the researchers said.\nThe system of software algorithms is called Deep Q-network and has learned to play 49 classic Atari games such as Space Invaders and Breakout, but only with the help of information about the pixels on a screen and the scoring method.\u00a0\nGadgets and Tech News in Pictures\nThe researchers behind the development said that it represents a breakthrough in artificial intelligence capable of learning from scratch without being fed instructions from human experts - the classic method for chess-playing machines such as IBM's Deep Blue computer.\n\"This work is the first time anyone has built a single, general learning system that can learn directly from experience to master a wide range of challenging tasks, in this case a set of Atari games, and to perform at or better than human level,\" said Demis Hassabis, a former neuroscientist and founder of DeepMind Technologies, which was bought by Google for \u00a3400m in 2014.\n\"It can learn to play dozens of the games straight out of the box. What that means is we don't pre-program it between each game. All it gets access to is the raw pixel inputs and the game's score. From there it has to figure out what it controls in the game world, how to get points and how to master the game, just by playing the game,\" said Mr Hassabis, a former chess prodigy.\n\"The ultimate goal here is to build smart, general purpose machines but we're many decades off from doing that, but I do think this is the first significant rung on the ladder,\" he added.\nRead more:Artificial intelligence could kill us because we're stupidArtificial intelligence will become strong and threaten usAlex Garland's film Ex Machina explores the limits of AI\nThe Deep Q-network played the same game hundreds of times to learn the best way of achieving high scores. In some games it outperformed human players by learning clever tactics such as, for instance, tunnelling through the ends of the wall in Breakout to get the cursor to bounce behind the bricks.\nIn more than half the games, the system was able to achieve more than 75 per cent of the human scoring ability just by learning by itself through trial and error, according to a study published in the journal Nature.\nDeep Blue beat Gary Kasparov, the world champion chess player, in 1997, while IBM's Watson computer outperformed seasoned players of the quiz show game Jeopardy! in 2011. However, Deep Q works in a fundamentally different way, Mr Hassabis said.\n\"The key difference between those kinds of algorithms is that they are largely pre-programmed with their abilities,\" he explained.\n\"In the case of Deep Blue it was the team of programmers and chess masters they had on their team that distilled their chess knowledge into a program, and that program effectively executed that without learning anything - and it was that program that was able to beat Gary Kasparov,\" he said.\n\"What we've done is to build programs that learn from the ground up. You literally give them a perceptual experience and they learn to do things directly from that perceptual experience from first principles,\" Mr Hassabis added.\nAn advantage of \"reinforced learning\" rather than \"supervised learning\" of previous artificial intelligence computers is that the designers and programmers do not need to know the solutions to the problems because the machines themselves will be able to master the task, he said.\n\"These type of systems are more human-like in the way they learn in the sense that it's how humans learn. We learn from experiencing the world around us, from our senses and our brains then make models of the world that allow us to make decisions and plan what to do in the world, and that's exactly the type of system we are trying to design here,\" Mr Hassabis said.\nWhat does the creation of Deep Q mean?\nA machine with a human-like brainpower is the stuff of nightmares, and even scientists such as Stephen Hawking have warned about the existential threat posed by uncontrolled artificial intelligence.\nThe latest Deep Q-network is far from being able to wield this kind of malign power. However, what makes it interesting, and some might say potentially dangerous, is that it was inspired and built on the neural networks of the human brain.\nIn particular, the designers of Deep Q compare it to the dopamine reward system of the brain, which is involved in a range of reinforcing behaviours, including drug addiction.\n\"There is some evidence that humans have a similar system of reinforced learning in the dopamine part of the brain,\" said David Silver, one of system's developers.\n\"This was one of the motivations for doing our work because humans also similarly learn by trial and error - by observing reward and learning to reinforce those rewards,\" he said.\n"},
{"docid": "368 of 500 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "December 6, 1984", "title": "Futures (Micro Guardian): A real expert / Advice on spotting a thinking machine\n", "content": "\u00a0\n Current research in the sociology of science tells us that scientists frequently argue over what the content of their discoveries is and, in fact, over whether anything has been discovered at all. Now research is beginning to demonstrate that just the same thing is happening in computer science with expert systems - those systems which can encapsulate the expertise of doctors, electronic engineers and such like which are receiving such substantial funding from the Alvey Directorate. There is substantial confusion about what an expert system is.\n One investigator into the field of artificial intelligence, Brendan Rooney, has noted that the definition of such systems is not straightforward. Rooney conjectures that one of the dominant processes in any new field is the coming to a common definiton of the subject of that field. He nots that this process is still in process in the export systems field, where individual researchers have individual views of what expert systems are.\u00a0\n\n For example, many researchers entering the field will not be aware that there is a perceived difference between the concept of 'expert system' and 'knowledge-based system.' While the Alvey Directorate seem to consider the two terms interchangeable, Rooney tells us of one researcher who sees such a distinction.\n An expert system, according to that researcher, is a system used in areas of activity such as a financial adviser while a system which replaces a wages clerk would be described as knowledge-based. Thus, according to this definition it is not the different techniques used which decide what an expert system is, rather the way in which the program is used.\n Core workers (those researchers who were first into the new field) were found in Rooney's study to have much tighter definitions than applications people (those more interested in applying expert system techniques). Rooney notes: 'Many of the researchers actually stated that some of the simpler work that the applications people were doing was not export-systems work at all.'\n However, the one view that all Rooney's subjects had in common was a belief that these systems would be capable of developing their own expertise: in other words, the these systems would eventually achieve the elusive goal of artificial intelligence.\n One of the common criticisms of the artificial intelligence community is of their many claims to have produced intelligent artifacts. For example, the program called AM has been described as a system which 'models one aspect of elementary mathematical research: developing new concepts.' Philosophers of mathematics would argue that developing new concepts is not exactly an elementary part of mathematics, and it was perhaps this which led two researchers at Heriot Watt University in Edinburgh to look closely at AM. They severely criticised claims made for AM's ability to discover mathematics\n The Lighthill Report which studied AI also pointed out that it was perfectly feasible to produce well engineered computer systems which could carry out complex processing tasks (as expert systems can do), but was sceptical about producing systems with intelligence.\n Philosophers have long discussed the nature of intelligence - Descartes was one who posed the question in terms of the destinction between man and machine. He considered that the machine would never be able to truly hide the fact that it was inhuman because it could not 'reply appropriately to everything which may be said to it.'\n Descartes's test was, of course, a precursor to the well known Turning Test - this considers artificial intelligence to be arrived at when someone interacting with either a computer or a person on the other end or a computer terminal cannot tell which of the two is communicating with him.\n Turing thought that by 2000AD a subject would have a 70 per cent chance of distinguishing between computer and person. Criticisms of the Turing Test usually mention the fact that such a view of intelligence is severly limited.\n But all is not lost. A recent development by an Open University researcher, Brian Bloomfield, has arrived just in time to help solve the problem of defining when artificial intelligence has been discovered. Bloomfield proposes a more powerful successor to the Turing Test.\n The Bloomfield Test - as we might call it - requires one computer and a DHSS office. The computer is sent into the DHSS office and, if it successfully claims Supplementary Benefit, it passes part one of the test; to pass part two (and really show artificial intelligence) it must manage to get work on the side, unbeknown to the DHSS, to increase its weekly income.\n Philip Leith is at the faculty of Mathematics of the Open University.\n"},
{"docid": "369 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "March 7, 2018", "title": "Google's AI is being used by US military drone programme; DoD's Project Maven uses tech firm's TensorFlow artificial intelligence systems, prompting debate both inside and outside company\n", "content": "Google's artificial intelligence technologies are being used by the US military for one of its drone projects, causing controversy both inside and outside the company. \nGoogle's TensorFlow AI systems are being used by the US Department of Defense's (DoD) Project Maven, which was established in July last year to use machine learning and artificial intelligence to analyse the vast amount of footage shot by US drones. The initial intention is to have AI analyse the video, detect objects of interest and flag them for a human analyst to review.\u00a0\nDrew Cukor, chief of the DoD's Algorithmic Warfare Cross-Function Team, said in July : \"People and computers will work symbiotically to increase the ability of weapon systems to detect objects. Eventually we hope that one analyst will be able to do twice as much work, potentially three times as much, as they're doing now. That's our goal.\"\nProject Maven forms part of the $7.4bn spent on AI and data processing by the DoD, and has seen the Pentagon partner with various academics and experts in the field of AI and data processing. It has reportedly already been put into use against Islamic State.\nA Google spokesperson said: \"This specific project is a pilot with the Department of Defense, to provide open source TensorFlow APIs that can assist in object recognition on unclassified data. The technology flags images for human review, and is for non-offensive uses only.\"\nWhile Google has long worked with government agencies providing technology and services, alongside cloud providers such as Amazon and Microsoft, the move to aid Project Maven has reportedly caused much internal debate at the search company. According to people talking to Gizmodo, some Google employees were outraged when they discovered the use of the company's AI.\n\"Military use of machine learning naturally raises valid concerns. We're actively discussing this important topic internally and with others as we continue to develop policies and safeguards around the development and use of our machine learning technologies,\" said Google.\nBoth former Alphabet executive chairman, Eric Schmidt, and Google executive Milo Medin are members of the Defense Innovation Board, which advises the Pentagon on cloud and data systems.\nGoogle has a mixed history with defence contracts. When it bought robotics firm Shaft, it pulled the company's systems from a Pentagon competition, while it cut defence-related contracts on buying the satellite startup Skybox. When it owned robotics firm Boston Dynamics, the company was attempting to make a robotic packhorse for ground troops, which was ultimately rejected by the US marines because it was too noisy.\nThe company's cloud services division currently does not offer systems designed to hold information classified as secret, where its competitors Amazon and Microsoft do.\nWhen Google bought the UK's artificial intelligence firm DeepMind in 2014 for \u00a3400m, the company set up an AI ethics board, which was tasked with reviewing the company's use of AI, although details of the board were still not made public three years later.\n\n"},
{"docid": "370 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "September 13, 2017", "title": "Civil servants really will be robots, says Hammond\n", "content": "Robots will be running large swathes of government before long as artificial intelligence is deployed to help the state do more with less, the chancellor has said.\u00a0\nPhilip Hammond told a House of Lords committee that the government was looking into AI and expected swift progress. He also announced that the autumn budget would be held on November 22.\nThe prospect of robots being used to streamline government services might deliver savings but could also put thousands of public sector jobs at risk. Reform, a think tank, estimated in February that 250,000 of the UK's five million public sector workers could lose their jobs to AI over the next 15 years.\nMr Hammond told the economic affairs committee: \"The government is looking at how it can apply artificial intelligence.\n\"There are very significant areas of government activity which involve relatively low-level decision-making which will be highly susceptible to AI, probably over a relatively short period of time, which does present the tantalising possibility of being able to drive some real productivity enhancement in the delivery of government processes.\"\nThe United States and other governments are already adopting AI for form-filling and speeding up patent applications. Britain uses facial recognition technology at its borders. Mr Hammond added that Britain was already a leader in areas of technology that were likely to become very significant over the next few years, \"not just AI, but fintech, biotech, materials technologies, big data manipulation, and the internet of things\".\n"},
{"docid": "371 of 500 DOCUMENTS\n", "source": " The Independent (United Kingdom)\n", "date": "June 21, 2016", "title": "Domestic robots are a not too distant reality; When Elon Musk says, as he did this week, that his new priority is using artificial intelligence to build domestic robots, we should not only take note, but look forward to the day we can put our legs up in admiration\n", "content": "When Elon Musk says, as he did this week, that his new priority is using artificial intelligence to build domestic robots, we should not only take note, but look forward to the day we can put our legs up in admiration.\u00a0\nMr Musk is a guy who gets things done. The founder of two \"moonshot\"tech companies, Tesla Motors and SpaceX, is bringing electric vehicles to mass market and enabling humans to live on other planets. Lest this strike the amateur techie - not that readers of \nThe Independent\nwould ever count among them - as so much hot air, you can be reassured that the near $13bn (\u00a38.8bn) fortune this entrepreneur has amassed comes from practical achievements rather than hypothetical ones.\nA lot of clever people are terrified about artificial intelligence, fearing that robots will one day become so smart they'llmurder all of us. These fears are mostly overblown: as with hysteria about genetic modification, we humans are generally wise enough to manage these problems with alacrity and care.\nAnd just think of how wonderful it would be if you had a live-in robot. It could - eventually - be like having a babysitter and masseuse rolled into one -or, if that required emotional intelligence beyond the ken of Mr Musk's imagined machine, at least some one to chop the carrots, wash the car and mow the lawn. Once purchased and trained, this would allow the casual user to save money and time, freeing up precious space in our busy lives to, for instance, read \nThe Independent\n.\nThat is why we welcome Mr Musk's latest venture, and wish him well. As long as robots add to the sum of human happiness, reduce suffering or cumbersome activity, and create time to read world-class journalism, \nThe Independent\n will be their fans. Especially since journalism is one job robots will never do.\n"},
{"docid": "372 of 500 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "April 14, 2004", "title": "SCIENCE & TECHNOLOGY: A BRITISH PROGRAMMER CLAIMS TO HAVE INVENTED A TRUE ARTIFICIAL INTELLIGENCE. THE NET ISN'T SO SURE...;\u00a0WE ARE ALL BIG BROTHER. THE ONLY SECRETS THAT REMAIN ARE THOSE THAT\n", "content": "\u00a0\n WHEN GOOGLE announced its prospective e-mail service a couple of weeks ago (unwisely using the name \"Gmail\" without having trademarked it), a number of commentators expressed fears about the privacy aspects of having a big company scanning your e-mail for key words against which it could sell ads.\n To be honest, I don't understand the concern. For one thing, it's obvious when you sign up that your e-mails are going to be scanned. For another, it's being scanned by a machine, not a human. (Be honest - you didn't think Google had hired every spare programmer to hack out the answers to your personal web query, did you?)\u00a0\n To trump it all, the reality is that wherever you go on the web today, and wherever you've been in the past, if you've made any sort of comment, or even just been commented on in a way that can be identified by others, you'll have been sucked into Google's huge archive of what goes on around the internet. What's more, other people will be able to find out what you've done.\n This was illustrated with some force a few weeks ago when a story appeared in New Scientist magazine. It reported that a British programmer, Jim Wightman, had come up with a revolutionary artificial intelligence program that he said would create \"bots\" that could strike up conversations in chatrooms and spot would-be paedophiles, who would then be reported back to him, who could pass the details on to the police.\n The story was widely picked up by other news outlets. (The Independent did not run it.) But within hours of its appearance, folk around the net began stroking their chins and saying \"Just a minute...\"\n Looking at the transcript of a \"conversation\" in New Scientist, allegedly between one of the \"bots\" and a chatroom user, many people began to question how a previously unknown programmer could have created what looked to be the biggest leap in artificial intelligence in many decades.\n They then began hitting Google for more about the unknown Wightman. He didn't stay unknown for long. The site he had set up to publicise his \"bots\" provided raw material (an e-mail address, plus his work address via the site's registration details) that could be used to scour Usenet, the thousands of newsgroups, for more details about his past postings. (Google has the complete archive of Usenet postings, going back to the internet's year zero. If you don't want your postings to appear there, you have to put \"X-No-Archive\" in the headers of your news postings.)\n They trawled Google for any hints of things he might have done in the past. This turned up the occasional angry exchange in various newsgroups; a few annoyed exchanges in specialist discussion boards; and a host of schemes that Wightman had been involved with at one time or another.\n It also turned up examples of claims he'd made that hadn't been supported by later evidence. Like it or not, Wightman's footprints - or perhaps that should be fingerprints - were all over the web and Usenet. Unfortunately for him, and for New Scientist's story - which has increasingly come to look like a piece of over-eager reporting of a single-sourced claim - there was absolutely no evidence to suggest he had the sort of skill in artificial intelligence constructs that would enable him to create a world- beating artificial intelligence program able to create the question \"Did you watch Robocop last night\", and on getting the reply \"What side was it on?\", answer \"Sky One\".\n Think a little about what that discourse involves. \"Side\" has a special meaning only in the context of television; to understand that it's equivalent to \"channel\" is something we learn only with experience. For a computer, that's a difficult link to make.\n As more analysis came through, blog began to link to blog about it, until there was a whole web of information - and doubt - about the existence of Wightman's proclaimed \"bots\".\n I did contact him myself on a number of occasions to try to get to the bottom of the claims and counterclaims. He insists that the bots exist, and that the AI program has been entered on his behalf by a company - which he says he cannot name - for the Loebner Prize, in which AI programs try to fool a human panel that they are human. This test, proposed by the father of modern computing, Alan Turing, assesses if a machine can really think. Wightman insists he will win. (Entries close 1 August, and the contest begins two weeks later. My diary is marked.)\n My point isn't to declare whether or not I think Wightman's claims are true. Interestingly, New Scientist seems to be having second thoughts: its website now says \"Serious doubts have been brought to our attention about this story. Consequently, we have removed it while we investigate its veracity.\" I'd urge you to make your own decision: search Google, and follow the Waxy.org link, which offers the widest collection of URLs to information that could help you decide.\n My point is that this episode demonstrates what's really going on with the net. While everyone is worrying about Google acting like Big Brother, they're ignoring the fact that it has democratised Big Brother and made it available to anyone. Imagine the telescreens in 1984 being able to see what anyone else was doing: the mendacious society depicted by Orwell couldn't have continued.\n What Google and the other search engines do is like the Victorian concept of the panopticon, the prison in which every prisoner can be seen from a single place. But our existence now differs from both those concepts because we can use Google to watch each other. We are all Big Brother. The only secrets that remain are those that aren't yet on the web - and that's a pool of knowledge that is shrinking daily.\n network@independent.co.uk\n"},
{"docid": "373 of 500 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "April 3, 1992", "title": "The philosopher's new mind\n", "content": " In the gents' toilet of the philosophy department of a university I once visited, the walls were, by the standards of that university, comparatively free of graffiti. ''Why are these walls so clean?'' somebody had scrawled in desperation. Underneath, in a different hand, came the reply: ''Because philosophy no longer has anything to say.''\n On the whole, this seems to reflect the general view. Philosophers, it is widely believed, have given up the attempt to answer the Big Questions, and now just waste their time - and that of anyone foolish enough to read their work - on the analysis of trivialities, asking questions that nobody else cares about and answering them in a way that nobody else can understand. For really important discussions of the Big Questions, it is felt, we must turn to the scientists.\u00a0\n While Stephen Hawking's A Brief History of Time continues to sell in vast numbers, his erstwhile colleague and Professor of Mathematics at Oxford, Roger Penrose, has met with a similarly large and enthusiastic response to his book The Emperor's New Mind, a huge and exhilarating discussion of artificial intelligence that takes in cosmology, quantum theory, computer science and the philosophy of mathematics. An easy read it is not. Its large sales can be accounted for only by the expectation that the effort to understand it will be worth making, rewarded perhaps by a new, insight into ourselves and the world around us. This expectation, this faith, is what philosophers have lost.\n Clearly, the way to regain this faith is to say something important and interesting and to say it as lucidly and entertainingly as possible. This is what Daniel C Dennett has managed to achieve in his extraordinary new book, Consciousness Explained.\n Dennett is doubly rare among contemporary philosophers: not only does he keep himself up to date with the literature of the brain sciences, cognitive psychology and artificial intelligence, he is also a supremely engaging and witty writer.\n Perhaps these two elements are connected; perhaps the lucidity of his style is the result of years of having to explain science to philosophers and philosophy to scientists. However, though this new book is accessible to lay people, it aims (like Penrose's) to do more than provide popularised accounts of other people's work. Its chief aim is to expound a novel and original theory: a new attempt to answer what is, by any standard, a Big Question, perhaps the biggest and most mysterious of them all - what is consciousness?\n One does not have to be a scientist or philosopher to be in thrall to this question, particularly in an era when talk of ''artificial intelligence'' is everywhere. What is artificial intelligence? And how does it differ from the real thing? And, come to that, what is the real thing?\n Alan Turing, the founder of modern computer science, claimed 40 years ago that it was not, in principle, impossible to build a computer that could think. He proposed an ingenious test: sit the tester, or judge, in one room and either a computer or a person in another room. The judge now has to strike up a conversation with the person/computer. If a computer manages under these conditions to be indistinguishable from a person, then we could say of it that it could think.\n At the time that Turing made this suggestion it was widely agreed that no such machine would ever in fact be built. Now one can no longer be so sure. Recently, at a competition held in Cambridge, Massachusetts, a programme called ''Whimsical Conversation'' managed to persuade five out of ten judges that they were talking to a human being.\n A computer can, then, simulate conversation, and to that extent, can think. But surely it is obvious that no matter how sophisticated computers get, they will never be conscious? Well, is it? Just as Turing's question forced us to clarify what we mean by thinking, this new question forces us to clarify what we mean by consciousness. According to Dennett, our old idea of consciousness is incoherent, and has to be abandoned. And according to the new one he proposes, it is not at all obvious that a computer will never be conscious. In fact, it appears all too likely.\n What is the old idea? The very old idea is Cartesian dualism, the belief (associated with the French philosopher Rene Descartes) that inside our physical bodies there is a non-physical mind that is the ''seat of consciousness''. This view was ridiculed by Gilbert Ryle as the belief in the ''Ghost in the Machine'', and Ryle's book The Concept of Mind is widely regarded as providing its definitive refutation. Even at the time Ryle was writing, however, Cartesian dualism had few defenders. For it seems impossible to imagine how a non-physical ''thing'' could have physical consequences, as the mind certainly does (think of consciously deciding to raise your arm: this decision is a mental event, yet it has a physical consequence - your arm does get raised).\n Very few people, then, now believe in Cartesian dualism. But, according to Dennett, almost everybody believes in a variant of it that is almost equally confused. This view, that he calls ''Cartesian materialism'', abandons the notion of the ghost in the machine, but cannot bring itself to abandon the associated idea of a ''seat of consciousness''. It is as if, says Dennett, we are asked to believe that there is inside every one of us, not a non-physical mind, but a Cartesian theatre, a ''place where it all happens'', a single showing of everything we see, hear, smell, touch, of everything that we are conscious of. This ''theatre'' constitutes the centre of ourselves.\n The problem with this view, says Dennett is twofold: first, from what we know about the structure of the brain there is not the slightest reason to believe that it is true; and second, it is reduced to internal incoherence when it tries to account for certain well known neurological phenomena.\n In the first half of his book, Dennett outlines an alternative view of consciousness drawn partly from the world of computers and partly from the findings of neuroscience. Our brains, he argues, are more like parallel processors than the serial processors that lie at the heart of most computers in use today. The difference is that, whereas serial processors perform one task at a time (even when, in the case of modern computers they do it so blindingly quickly - at the rate of millions of tasks a second - that it seems otherwise), parallel processors perform many different tasks at the same time ''in parallel''. A parallel processor can quite easily mimic the functions of a serial processor and create a ''virtual'' serial machine, and this, says Dennett, comes close to the way in which our minds work. The illusion of a single ''stream of consciousness'' is created by the virtual machine run by the parallel processor that is our brain. Our consciousness, our mind, is, as it were, a virtual ''Joycean'' machine.\n Note, the ''Joycean'' stream of consciousness is virtual; it is not actual. There is no single stream of consciousness, there are, rather, as can be seen from the neuroscientific evidence, many streams of consciousness. In one of his more picturesque metaphors, Dennett imagines our brains as thickly populated communities of ''homunculi'', little men or spirits, each with a different function; one to keep us steady, one to look out for anything resembling an enemy, one to keep an ear for predators, etc. Each of these homunculi keeps up its own narratives - ''something a bit tiger-like over there to the right, no it's just a rug, it's OK, relax'', and so on. The virtual ''Joycean'' machine has the (sometimes impossible) task of weaving these various narratives into a single, coherent ''master narrative''.\n The result is our consciousness. The illusion of its singularity can be seen by analogy with a modern academic article, various drafts of which are sent via electronic mail to experts who then comment on it and revise it. At any one time, there will exist, in one form or another, many different drafts of this article, each containing revisions, and there might well be, at certain times, no ''master copy'' that has authority over all these drafts. Similarly, some of our homunculi may be composing narratives that either conflict with the story being told by the virtual Joycean machine or else have not yet been woven into the master novelist's account. And yet that narrative may have no less authority than the master version. This, the central metaphor of Dennett's book, inspires him to call his view the ''Multiple Drafts'' theory of consciousness.\n The eclecticism of the theory means that he has to defend it on a number of fronts, and the second half of the book is taken up with a series of pre-emptive attacks on the views of those philosophers who are most likely to raise objections: John Searle, Jerry Fodor, Thomas Nagel and Colin McGinn. These parts of the book will perhaps be of less general interest than the earlier popular accounts of neurological research, if only for the reason alluded to earlier: that only philosophers will understand the positions he is attacking, and nobody else is likely to think they are important enough to get acquainted with.\n Curiously enough, however, in demonstrating that philosophy does still have something interesting and important to say, Dennett's book breathes new life even into the positions he is attacking.\n The writing on the wall for philosophy may not be so ominous after all.\n Daniel C Dennett's 'Consciousness Explained' is published by Allen Lane, pounds 20.\n Ray Monk is the author of 'Ludwig Wittgenstein: the duty of genius' (Vintage, pounds 9.99), and is writing a biography of Bertrand Russell.\n\n"},
{"docid": "374 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "January 24, 2017", "title": "Artificial intelligence has arrived, but Australian businesses don't know how to use it; Despite spending the world's second-largest amount on automation, Australian companies are not ready for robots - or for retraining staff\n", "content": "A survey of business leaders has found Australian companies are the worst prepared for the arrival of artificial intelligence (AI) technologies among selected major economies, despite spending the second-largest amount of money on automation. \nIndependent research agency Vanson Bourne was commissioned by IT company Infosys (which as a seller of an AI platform has a vested interest in promoting such technology) to poll 1,600 business leaders of companies with more than 1,000 staff and at least US$500m in annual revenue across Australia, China, the United States, Germany, France, India and the UK.\nAccording to the survey, released at the World Economic Forum last week, major Australian businesses invested an average of $7.9m last year in AI, behind only the US, but placed last in both the skills required for AI takeup and in plans to integrate AI.\u00a0\nThe Infosys Australia regional head, Andrew Groth, told the Guardian the survey demonstrates that Australia risks becoming uncompetitive.\n Related:  Automated mining will cost jobs and tax income: it's time for governments to act\n\"The challenge is the skills situation,\" he said. \"If not addressed, [our] level of competitiveness could be a challenge, as all companies adopting AI are seeing advantages. We are all competing on the global stage. It's here and we need to address these challenges.\"\nThe survey found 23% of Australian business leaders believe their company completely lacks the skills needed to capitalise on AI. \nGroth said AI requires proficiency in Stem (science, technology, engineering and mathematics) skills, digital proficiencies, creativity and problem-solving, as well as ongoing learning.\nHe said the lack of skills was relevant to another of the survey's findings - that Australian business leaders are the most likely to be planning to fire rather than reassign workers whose roles have been made obsolete by AI technology.\nTwo-thirds of Australian businesses polled said they plan to or already have replaced jobs with AI, with a third of those leaders saying the affected workers will be made redundant.\nGroth was keen to focus on the two-thirds of businesses that intend to reassign rather than sack those in jobs better done by AI.\nHe cited as an example the Fiona Stanley hospital in Perth, which last year brought in an automated pharmaceutical ordering system that utilises robots which scan, move and store $200,000 worth of drugs daily, with the workforce previously responsible reassigned to other tasks.\n\"Using [artificial intelligence] reduced stock availability outages by 70% and freed up nurses for patient care rather than admin of stock,\" he said.\nAI is even impacting on Infosys' own global workforce. Groth said between 8,000 and 9,000 jobs had been automated at the company over the past year, but almost all affected employees were given other roles within the company.\nInfosys' human resources head, Krishnamurthy Shankar, has conceded  that, over time, improved AI capabilities will see the company hire less new employees.\nA 2015 Ceda report found 40% of Australian jobs were under threat from automation. But University of New South Wales professor of AI, Toby Walsh, said that figure was unlikely as as many new jobs would be created as eliminated by automation. He said the jobs wipeout would be felt most by entry-level workers.\n\"We are already seeing the beginning of that trend; companies are not making the difficult decision of letting go of employees, but instead are avoiding bringing in new young workers to fill positions,\" he said.\n Related:  Age of automation: what if more work is the problem, not the solution?\n\"That doesn't have to mean less prosperity however. If machines create more wealth, it is just a matter of distribution.\n\"One popular idea is a universal basic income, for which there are experiments in a number of countries, but that is not the only lever - there could be taxations on corporations and the very rich. Or there's no fundamental reason the weekend has to be two days' long - making it three days would ease the jobs shortage.\"\nFor the jobs that are safe from automation, AI will still have an impact in improving efficiencies in our professional and personal lives. \n Censuswide carried out another industry-funded survey across the UK in November/December and found 47% of professionals were willing to hand responsibility for scheduling meetings, booking restaurants and other administrative tasks over to AI personal assistants.\nThe survey of 1,000 people indicated a generational gap in terms of trust in an AI personal assistant - nearly 62% of respondents aged 16 to 24 said they would trust an AI for handling the back and forth emailing of such tasks compared with 35% of those aged 55+.\nThe survey indicated roughly two hours a week would be saved by automating such tasks, with respondents saying they would redeploy this time to pursuits such as taking care of their family (24%), going shopping (21%) and making love (20%).\n"},
{"docid": "375 of 500 DOCUMENTS\n", "source": " The Independent (United Kingdom)\n", "date": "May 13, 2016", "title": "Google launches Parsey McParseface, a new algorithm inspired by the world's most controversial boat; The new product is based on technologies with names like TensorFlow and SyntaxNet - but after being unable to pick a name, Google decided to name it after Boaty McBoatface\n", "content": "Google has revealed the most powerful computer for understanding the English language in the world - and called it Parsey McParseFace.\nThe technology, which is built on the more sensibly named TensorFlow and SyntaxNet frameworks, is a powerful tool that uses new artificial intelligence technology to be able to analyse the linguistic structure of language, and understand what each part of a sentence does to its meaning. Google is making the tool open source, so that anybody can use it for free.\u00a0\nBut it will probably go down in history because of its silly name. Google said that the name - a reference to the controversial Boaty McBoatface - was a suggestion that came while it was trying to name the new technology, and that it didn't have any better alternatives.\nBut beyond the name, Google's new technology could change the way that artificial intelligence understands language forever.\nMr McParseface is the English language implementation of SyntaxNet, a technology that has also been put into the public domain. Both are meant as ways of better understanding the function of language, and by doing so enable computers to better be able to speak to people.\nThe development of the technology is key to making computers able to understand what people say to them. Since language can be so illogical, computers can have a tough time actually working out what people are telling them, but Google's new tools attempt to overcome that.\nRead more\n                     Google Calendar update uses AI to make people better                   \n\"One of the main problems that makes parsing so challenging is that human languages show remarkable levels of ambiguity,\" Google said as it launched the new tools. \"It is not uncommon for moderate length sentences - say 20 or 30 words in length - to have hundreds, thousands, or even tens of thousands of possible syntactic structures.\n\"A natural language parser must somehow search through all of these alternatives, and find the most plausible structure given the context.\"\nAt the moment, SyntaxNet and Parsey McParseface have a relatively limited understanding of how sentences work, far from any comparison with a human adult. But because they are built using machine learning, the algorithms will be able to train themselves and so get better at understanding as they are used.\n"},
{"docid": "376 of 500 DOCUMENTS\n", "source": "\u00a0The Mirror\n", "date": "November 25, 2004", "title": "THE BEST FILMS ON TV THIS CHRISTMAS: MOVIE MAGIC\n", "content": "\u00a0\n It's the ultimate festive face-off, a fight between two green meanies that's set to explode on Christmas Day. In the green corner is grumpy troll Shrek, who'll be battling to bump up the Beeb's ratings, while in, erm, the other green corner is The Grinch Who Stole Christmas aiming to deliver a knockout blow for ITV.\n These are just two of the brilliant movies that'll be hitting our screens this Christmas. In addition to Shrek - the superb animated film featuring Michael Myers and Eddie Murphy - BBC1 will also be showing Harry Potter And The Philosopher's Stone, starring Daniel Radcliffe as the young wizard. The channel will also be screening Disney's 102 Dalmatians and The Hunchback Of Notre Dame, while Angelina Jolie will be fighting her way out of danger in Lara Croft: Tomb Raider.\u00a0\n There's also plenty for adults to enjoy, from the heartwarming Bend It Like Beckham - Keira Knightley's breakthrough film - to the chilling Others, a superb horror flick starring Nicole Kidman. Further highlights on BBC1 include Steven Spielberg's\n AI: Artificial Intelligence, Enigma, starring Kate Winslet, and the spooky sci-fi thriller The Mothman Prophecies.\n Not to be outdone, ITV has a few blockbusters of its own, including the perennial children's favourite Chitty Chitty Bang Bang. Arnie stars in Jingle All The Way and you can also catch Bruce Willis in the Mob comedy The Whole Nine Yards.\n Switching channels, BBC2 will be showing two first-rate flicks starring Johnny Depp. The first, Chocolat, is a delicious rom-com set in a sleepy French village while The Astronaut's Wife is a chilling blend of sci-fi mystery and out-and-out horror. Also showing is the superb LA Confidential, starring Russell Crowe, and the thriller Hearts In Atlantis, which features Anthony Hopkins and is based on a short story by Stephen King.\n Channel 4 will deliver a few Christmas crackers of their own, ranging from classic musicals such as West Side Story and Annie to children's favourites Rugrats In Paris, Flipper and Toys. Older viewers haven't been forgotten and could do a lot worse than tune into Gremlins, its sequel The New Batch, and the terrific road movie, The Straight Story.\n Over on Five, festive favourites including Miracle On 34th Street, Call Me Claus, A Muppet Christmas Carol and National Lampoon's Christmas Vacation all get a welcome airing. The channel is also running an Essential Movies season featuring classics such as Chinatown, North By North West, The Killing Fields, Midnight Express and the hugely-violent Bonnie And Clyde.\n ITV2 is focusing on muscle-bound action flicks with Arnie making three appearances in Terminator 2, Red Heat and True Lies while Bruce Willis stars in Die Hard 1 and 2. Another highlight is the thriller What Lies Beneath, starring Harrison Ford and Michelle Pfeiffer.\n"},
{"docid": "377 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "January 24, 2015", "title": "Is she thinking what you're thinking?; A new film, 'Ex Machina'7, features a fully conscious robot. Is actual science far behind, asks Adam Rutherford\n", "content": "'The development of full artificial intelligence could spell the end of the human race.\" When Stephen Hawking worries in public, as he did in an interview with the BBC in December last year, people pay attention.\n Is Hawking right? Should we be anxious about building machines with the potential to end our supremacy on Earth? Or should we be looking forward to an age of robo-butlers, friendly, creaking characters like C-3PO and R2D2?\nEver since the first use of the word \"robot\", in the Czech writer Karel Capek's 1921 play Rossum's Universal Robots, the creation of autonomous machines has been associated with end times for humankind. Capek's machine-men were slaves who rose up and annihilated their human masters; right there, the tone was set for the fictional robots to come.\u00a0\n In 1968, HAL attempted to wipe out the crew in 2001: A Space Odyssey. Proteus IV succeeded in forcibly impregnating Julie Christie with a robot child in Demon Seed (1977). In 1999, humans were revealed to be no more than a docile power supply in The Matrix. And last year the smartphone personal assistant in Her (voiced by Scarlett Johansson) grew bored with her dull-witted human owner (Joaquin Phoenix) and abandoned him to pursue higher goals - possibly world domination.\n All the best explorations of artificial intelligence look at what happens when we create beings whose self-preservation trumps their attitude to us. The next in this line of films is Ex Machina, the directorial debut of the novelist and screenwriter Alex Garland. I was one of the film's scientific advisers: my field is genetics, but I've consulted on a few films, and Garland wanted me to provide a sanity check - to make sure nothing leapt out as truly implausible. There wasn't much to do: the scientific and philosophical underpinnings of the script were already solid in a way that is rare in movies.\n Ava (played with alien poise by Alicia Vikander) is a beautiful robot created by a selfabsorbed internet billionaire named Nathan Bates (Oscar Isaac). Bates brings in Caleb (Domhnall Gleeson), a lowly programmer from his internet search company, BlueBook, to assess the limitations of his creation. What follows is a tense, thrilling version of the Turing test.\n Without spoiling any surprises, not all of the three protagonists have a happy ending.\n So where are we at with real AI? Ava's consciousness is drawn from the BlueBook, the film's version of Google: her knowledge and behaviour are generated by harvesting the teraflops of information we reveal about ourselves when we're using the internet. It's a brilliant explanation for the generation of her humanlevel intelligence, and it does have a root in current tech. We live in a world, after all, where every word you tap into Google, every purchase you make on Amazon and every Instagram snapshot you post reveals something about you, and about people in general.\n Ava's body, on the other hand, is probably decades from realisation. Currently, scientists struggle to get robots to do things we find trivially easy: they can drive a car, but not actually get into one. Four billion years of evolution is a hefty head start. There are exceptions, though: Boston Dynamics is a company that has made a name for itself by building humanoid and four-legged robots with breathtaking physical prowess. Its Cheetah can run at 29mph, and BigDog can right itself on rough terrain carrying loads of up to 24 stone. They are impressive and terrifying in equal measure.\n As for her smarts, human-level consciousness is unlikely to be realised in the immediate future, largely because it isn't the main aim of AI research. The idea of the singularity, the point at which AI surpasses all levels of human consciousness, is generally an area for armchair speculation. Mostly scientists are building intelligent systems for specific functions. When Deep Blue beat Garry Kasparov at chess in 1997, it was a landmark in machine intelligence. But Deep Blue couldn't play a single round of noughts and crosses.\n That is a problem with which the British researcher Dr Demis Hassabis has been grappling. Hassabis is an unusually brilliant man: he got master status in chess at the age of 13, designed the classic video game Theme Park at 17 and completed a PhD in neuroscience in 2009. Two years later, he founded the AI company Deep Mind, which has attempted to programme computers to be able to play many different video games, just as we do.\n Perhaps Hawking's warnings are too dire. But there are developments that give me pause. Ex Machina's Nathan Bates is a mix of Victor Frankenstein, Colonel Kurtz, Steve Jobs and Mark Zuckerberg; he is a man who aspires to put himself at the centre of creation. Ava's AI is drawn from his earlier creation, BlueBook, a simulacrum of Google. So guess who bought Deep Mind for \u00a3400million last year? And guess who also picked up Boston Dynamics and a suite of other robotics start-ups in the space of nine months?\nGoogle, one presumes, is acquiring these robotics and AI firms to help build evermore sophisticated technology in order to... well, we don't know. Science works best with a free and open flow of information. Innovation works best in the same way. You would have to be very much in the fantasy conspiracy theory mindset to think that Google is building an Ava. Or would you?\nEx Machina is out now. See review, p22\nYou'd have to be a conspiracy theorist to think Google is building an Ava. Or would you?\n"},
{"docid": "378 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "August 18, 2011", "title": "University education goes online with virtual courses; As Stanford University offers a complete course online and fees in Britain are set to hit \u00a39,000 a year, Emma Barnett asks whether virtual degrees are the future of university education.\n", "content": "As British students face the daunting prospect of paying up to \u00a39,000 a year for higher education, there are increasing opportunities to learn online for much less, and in many cases free. \nEarlier this month, Stanford University opened registration to its artificial intelligence course which is being offered free online to all. \nPreviously, the university had offered only introductory notes to its Computer Science course free online. However, this pioneering move sees the university, which students from all over the world pay thousands to attend, sees offer a complete course free of charge. \u00a0\nSo far 53,000 people have signed up, including many from Britain, for the artificial intelligence course. The course is taught by Sebastian Thrun, a professor of computer science and electrical engineering at Stanford, and Peter Norvig, a visiting professor and director of research at Google. Norvig is probably best known as the lead developer of Google's self-driving car. \nThe online course consists of two online lectures a week, digital discussions and a weekly piece of homework that must be completed in order for all online students to pass. \n\"We have been blown away by how much interest there has been in the course,\" says Thrun. \"We taught this class last year to 177 students, but we wanted to open it up to those who cannot access this type of education where they live - places like Indonesia and Africa...However, we have had lots of people sign up from the US and the UK who are looking for a new way to be educated that is not as expensive or time-consuming. Now we have 53,000 students.\"\nAll online students will receive a certificate of accomplishment, rather than a Stanford degree, but it will depend upon their full participation and completion of all of the three-month course materials. \nThe pair admit that the automatic grading system they have come up to mark people's homework assignments en masse, would not work as well for arts courses, such as poetry. However, Norvig doesn't see why there couldn't be a future of online courses, where human markers or peer to peer marking isn't introduced. The pair are using Google Moderator to take questions from the 53,000 students. The tool algorithmically finds the most popular and similar questions from a huge number of queries, allowing the lecturers to answer as many questions as possible in the most efficient way. \nMichael Arthur, vice-chancellor of Leeds University, agrees that more needs to be made of digital learning but says that online lessons are only a supplement and cannot replace the value of the full university experience. \n\"At Leeds University, we don't just want people to learn facts, we want them to be at the frontier of learning and discovering new things about their subject and the world. This can only happen through having full access to a university's facilities and also via teamwork. These types of experiences are incredibly difficult to reproduce online,\" he explains. \nArthur adds: \"At the end of day it's my honest belief that I can't provide students with the same type of free critical free thinking through online-only content. It's analogous to going to a concert over just watching it or music videos online. People haven't stopped attending concerts because they can access live content online - the live experience is so much better and the same is true in terms of teaching at university.\"\nHowever, Thrun doesn't think online lessons will replace university courses but rather augment the education experience. \n\"By making full use of the web's capabilities, we are extending the reach of existing education...plus lots of people get degrees for a range of reasons. We cannot offer Stanford certification on this course, but many people want to learn for the knowledge they will gain and not just a qualification,\" he explains. \nThe Stanford experiment is not the only example of how the internet is being used in university education. The Open University has a 'Learning Space' service that allows people to try more than 600 free online course - each taking between one and 50 hours to study. \nAt Coventry University, photographer Jonathan Worth has opened his classes to the internet . Class materials, lectures and assignments are made available free via RSS feeds. More than 10,000 people visited the course website when it ran last year and Worth says he has had around 700 emails from people asking to sign up to the next course, which starts in October. \nAnd over the last four years, Apple has offered iTunes U, an online educational catalogue so people can learn university material on the move. More than 800 universities throughout the world have active iTunes U sites, with more than 350,000 audio and video files having been uploaded from universities around the globe - including China, Mexico and Japan. \nLast year a study by Universities UK, which represents vice-chancellors, found that traditional university courses could become the preserve of an elite as growing numbers of students take on-line degrees. \nProf Geoffrey Crossick, vice-chancellor of the University of London, said at the time that the current system of delivering higher education was \"no longer financially sustainable\". \nIn the UUK report, he said the number of flexible courses - including part-time study, on-the-job training and internet-based qualifications - would \"explode\" in the future. \nThis would lead to a drop in the proportion of students taking full-time degrees and living in traditional student accommodation, he said, an experience that was likely to be limited to those at top universities. \n\"Fundamental rethinking will be needed in a world where the proportion of those who experience higher education in the traditional fashion will decline, where the range of alternatives will explode, and where the variety of providers will grow with it.\"\nThe explosion is about to happen. \n"},
{"docid": "379 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "April 25, 2014", "title": "Depp and Diaz: bad science, bad Jokes; Wendy Ide on a disappointing pair of films from Hollywood's finest\n", "content": "Transcendence 12A, 119min *\nHere's a rule of thumb. If you are going to make a film about \"artificial intelligence\", it helps if your material has a demonstrable familiarity with the second of those two words. Aim for the thought-provoking playfulness of Spike Jonze's Her or the implacable HAL in 2001: A Space Odyssey rather than the alarmist techno-fear and blurred mixed messages of Johnny Depp, pictured, as an omnipotent disembodied intellect in Transcendence.\u00a0\nTechnology, we are told, is about to step across the Rubicon, leading to an inevitable future when humans are reduced to being fleshy battery packs for the all-powerful machines. It's all a bit rich, given that director Wally Pfister has helped himself to all the technology he can lay his hands on when it comes to special effects. He giveth with one hand, stireth up a slackjawed, credulous hornet's nest of techno-paranoia with the other.\nDepp stars as Dr Will Caster, a genius (we know this because he never brushes his hair) who is one of the foremost researchers in the field of artificial intelligence. His wife, Evelyn (Rebecca Hall), and best friend, Max (Paul Bettany), are also experts in the field. Pfister favours lots of montages of sciencey stuff - scribbled equations, circuit boards, wind turbines - to cover up the fact that the theoretical framework upon which this film is based is fundamentally unsound.\nIf someone who can barely work the remote control of a Blu-ray player (me, for example) can pick up that the pseudo-science here is particularly cloddish and inept, you have a real problem.\nThe cod science notwithstanding, a bunch of neo-Luddite, anti-technology protesters have got their knickers in a twist about the threat to humanity posed by Will and his colleagues. Their assassination technique (conveniently slow-acting radiation poisoning) backfires as it gives Evelyn enough time to upload Will's brain to a computer, and thence to the internet and every laptop, tablet and gadget on the planet. That smartphone you are fiddling with? That's Johnny Depp.\nRoll forward a couple of years: the Casters have an underground lair and Will is busy \"helping\" people by letting his nanorobots rewire their brains so he can control them. In case we hadn't noticed that this is a bad thing, the film recruits professional moral compass Morgan Freeman to gaze upon that which virtual Will has created and shake his head ominously.\nPfister is a well-respected cinematographer (The Dark Knight, Inception), here making his directorial debut, so it's no surprise that this is a strikinglooking piece of cinema. Even so, the visual imagery he employs is frequently clich\u00e9d. And while Hall and Bettany are watchable, Pfister fails to coax a decent performance out of Depp. On the evidence of recent form, it would take a crowbar to get that out of Johnny right now.\n"},
{"docid": "380 of 500 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "September 22, 1991", "title": "Management: Credit searches that keep bad risks in stock\n", "content": "EVERYBODY knows about personal credit scoring. That is why we have to fill in complicated forms when applying for bank loans and credit cards. The aim is to obtain those pieces of information that experience has shown determine whether a person is a good or bad credit risk.\u00a0\nWhat is less well known, though, is that similar techniques are applied to businesses.\nThanks to modern technology, a number of companies, including Dun & Bradstreet, CCN and Infolink, offer a service that enables a company to check on a business customer's credit rating in as little as three seconds.\nThe quality of the service depends on the amount of information held. Infolink claims its extensive databases, including bankruptcy files, census returns, company registers, and what it says is exclusive information on sole traders and partnerships (the very sector that is most vulnerable to failure), put it at the front of the field. It includes among its clients industrial companies, banks and insurance companies.\nThe information can be obtained by computer link, by telephone or in writing.\nHowever, as Brian Bailey, Infolink managing director, points out, the information still has to be interpreted.\nWhile a steady increase in requests for information about ticket agency Keith Prowse could have provided a hint of the company's impending collapse earlier this month, he remembers the example of Rolls-Royce back in the Seventies. Then, a similar trail of requests was dismissed by a records monitor on the grounds that such a company could not fail.\nThat said, Infolink claims its commercial credit-scoring systems are more sophisticated than those used for personal customers, because they make use of expert knowledge. Its knowledge-based systems are designed to help those making credit decisions by automating parts of the decision-making process.\n''It's possible to take pressure off experts by building systems. It saves poring over balance sheets,'' says Simon Field of the Croydon-based data company's decision support group.\nAlthough sophisticated systems can cost tens of thousands of pounds, compared with the few pounds charged for one-off searches, Mr Field points out that the savings can be considerable if they prevent the company becoming involved with businesses that collapse.\nTrade credit management systems are broadly similar to their counterparts in the consumer area. However, they differ in that they are not so rigidly applied.\nWhereas a bad score by somebody applying for a personal loan to buy a car or a credit card will automatically be a bar to approval at least, in the first instance in a commercial context, it will be open to interpretation.\nBut Mr Field accepts that such a system is not a failsafe, simply because _ extensive as it is Infolink's information is not exhaustive.\nBut he stresses that, with so much information available, the chances of running into trouble, particularly at a time when large numbers of companies are finding trading difficult, can be significantly reduced.\nIt must be realised, however, that such an operation only really works if it is part of an overall management policy. As Mr Bailey says: ''Companies that have thought about management information in the past can make best use of it.''\n"},
{"docid": "381 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "November 28, 2016", "title": "The UK is ill-prepared for the fourth industrial revolution, manufacturers warn\n", "content": "The UK is ill-prepared for the next industrial revolution, in which it is claimed robots and artificial intelligence will make millions of jobs obsolete, manufacturers have warned.\nResearch conducted by the trade organisation EEF found that, while 42pc of manufacturers believe they \"have a good handle\" on what the next industrial age -\u00a0the so-called fourth industrial revolution -\u00a0will entail, only one in 10 thinks the country is ready.\u00a0\n\"Manufacturers are ready to do the heavy lifting, but their efforts must be supported across the sector and supply chains and backed up by Government through its new industrial strategy,\" said Lee Hopley, chief economist at EEF.\n\"If we get this approach right then the UK can expect to be at the forefront of this global industrial wave - get it wrong, however, and the UK will be left trailing in its wake.\"\nElon Musk thinks there's a \"pretty good chance\" that automation will entirely replace workers in the future\nThe fourth industrial revolution refers to the development of smart technologies such as connected devices, artificial intelligence and autonomous cars .\nIt is expected to have a serious effect on employment and productivity, with more than a third of jobs at high risk of automation in the next 10 to 20 years, according to Deloitte.\nThe EEF report found that six in 10 manufacturers believe digital technologies will boost productivity, while 74pc say that the fourth industrial revolution will fundamentally change customers' expectations.\nAlmost 70pc of manufacturers say that it will happen faster than previous changes in manufacturing, leading to concerns that, without a supportive industrial strategy, the UK could be left behind.\n<table>\nWe now face the task of creating a New Britain from the fourth industrial revolution #CBI2016pic.twitter.com/EBGG6z3KaK\n - Jeremy Corbyn MP (@jeremycorbyn) November 21, 2016\nThe report comes after Labour leader Jeremy Corbyn raised eyebrows last week with a jargon-heavy tweet about \"creating a New Britain\" from the fourth industrial revolution, \"powered by the internet of things and big data to develop cyber physical systems and smart factories\".\nEEF urged the Government to ensure that its new industrial strategy \"provides the right building blocks\" to enable the UK manufacturing sector to undergo this transformation successfully.\n"},
{"docid": "382 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 27, 2016", "title": "Google's machine beats master at ancient game of Go in historic AI breakthrough\n", "content": "A computer program developed by Google  has beaten a professional player at the ancient strategy game of Go, a potentially-historic breakthrough in the quest to develop artificial intelligence capable of matching humans.\nDeepMind, a British AI company owned by the internet giant, has developed software that repeatedly beat the European champion of the fiendishly-difficult board game, an advance that has evaded researchers for years and was believed to be a decade away.\nGo, a Chinese pastime that dates back 2,500 years, is one of the last games in which humans have maintained their superiority over machines.\u00a0\nIts rules are simple, with opponents using black and white stones to try and dominate as much of a board as possible, but it takes a lifetime to master. There are 10 times as many potential moves in any one turn as in chess, and the number of game combinations exceeds the number of atoms in the universe.\nGo is a simple game but is notoriously difficult to master\nIts vast number of possible outcomes means machines cannot beat humans simply by using raw computing power to scan combinations of moves, in contrast to chess, in which IBM's Deep Blue computer beat world champion Gary Kasparov 19 years ago .\nInstead, DeepMind developed a program that learned to play Go in a similar way to humans, by playing repeated games and figuring out the moves that are most likely to lead to success.\nResearchers believe these \"deep learning\" techniques could be used to build artificial intelligence capable of surpassing humans in many areas.\nThe AlphaGo software was able to scan the gaming patterns of world-class players as well as playing millions of games against itself, learning by trial and error.\nIt then beat rival machines 494 times out of 495, and last October beat the reigning European Go champion Fan Hui five times in a row. It is now due to play Lee Sedol, the world's best player, in March. Until now, the most advanced Go programs were only able to match up to amateur players.\nGary Kasparov was defeated by IBM's Deep Blue at chess in 1997Credit:EPA\nThe breakthrough, published in the scientific journal Nature, is one of the \"long-standing grand challenges of artificial intelligence\", DeepMind's Demis Hassabis said.\n\"This has been the holy grail since Deep Blue beat Kasparov at chess, and it's held out for over 20 years. People were estimating it would be 10-plus years away just last year,\" he said.\nWhile they might appear trivial, strategy games are a crucial test of computer intelligence. They must successfully interpret the situation and predict their opponent's strategy, appearing to be \"creative\" rather than following rules that a human could suss out.\nThe same techniques used to teach AlphaGo to play Go could be used to develop digital assistants that will automate parts of our daily lives, diagnose medical conditions faster than human doctors and help solve major scientific challenges such as modelling climate change and curing diseases, Mr Hassabis said.\nFacebook, which like Google is racing to develop artificial intelligence, has also been attempting to build a computer that can beat professional Go players.\nThe ancient Chinese game of Go is one of the last games where the best human players can still beat the best artificial...\nPosted by Mark Zuckerberg on\u00a0 Tuesday, January 26, 2016\nMark Zuckerberg, Facebook's inventor, said on Wednesday \u00a0that the company was \"close\" to beating the world's best players at Go, although Mr Hassabis said that Facebook's software would present \"no challenge\" to AlphaGo.READ MORE ABOUT:\n"},
{"docid": "383 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "November 8, 2017", "title": "Facebook wants you to upload nude pictures of yourself for artificial intelligence to analyse; 'We're using image matching technology to prevent non-consensual intimate images from being shared'\n", "content": "                     Facebook wants users to upload nude pictures of themselves to Messenger.\nThe company believes the best way to combat revenge porn could be to post intimate pictures of yourself online before anyone else manages to.\u00a0\nIt's a highly unusual measure, which is likely to split opinion.\nThe social network has developed an anti-revenge porn system that uses artificial intelligence to recognise and block specific images, and is testing it in the UK, US, Canada and Australia.\n\"The safety and well-being of the Facebook community is our top priority,\" said Antigone Davis, Facebook's head of global safety.\n\"As part of our continued efforts to better detect and remove content that violates our community standards, we're using image matching technology to prevent non-consensual intimate images from being shared on Facebook, Instagram, Facebook Groups and Messenger.\"\nFacebook will create a digital fingerprint of a nude picture you flag up to it through Messenger, and automatically block anyone from uploading the same image to the site at a later date.\nThe company says it won't store the pictures and only Facebook's AI is supposed to access them, but the system still requires an enormous amount of trust from users.\nAlso, if you're worried about more than one explicit picture of you being posted to the site, you'd have to upload all of them to Messenger.\nRead more\nHow to protect yourself against revenge porn\nFurthermore, the system will only protect you from revenge porn on Facebook. People would still be able to post the images elsewhere.\n\"It would be like sending yourself your image in email, but obviously this is a much safer, secure end-to-end way of sending the image without sending it through the ether,\" Australian e-Safety Commissioner Julie Inman Grant told ABC.\n\"They're not storing the image, they're storing the link and using artificial intelligence and other photo-matching technologies. So if somebody tried to upload that same image, which would have the same digital footprint or hash value, it will be prevented from being uploaded.\"\n"},
{"docid": "384 of 500 DOCUMENTS\n", "source": "Daily Mirror\n", "date": "August 1, 2017", "title": "Facebook bots Terminated...; Epic fail as they start talking like Chuckle Brothers\n", "content": "TWO experimental Facebook talking robots were terminated when they started speaking like the Chuckle Brothers.\nScientists were dismayed when the project, aimed at teaching \"chatbots\" Alice and Bob to negotiate with each other, ended up with them sounding like comedy duo Barry and Paul Chuckle.\u00a0\nThey pulled the plug when they heard Alice say to Bob: \"Balls have zero to me to me to me to me to me to me to me to me.\"\nDuring artificial intelligence tests, the bots had been given language lessons, using algorithms but went \"off grid\" and spoke a gibberish they www.created.UK Robotics Professor Kevin Warwick said their ability to talk their own language was sinister.\nHe said: \"This is an incredibly important milestone, but anyone who thinks this is not dangerous has got their head in the sand.\"\nThe new language was more efficient for communication between bots but did not achieve set tasks.\nProfessor Warwick added: \"If bots can do something physically, especially military bots, it could be lethal. \"Steven Hawking and I have warned against the dangers of deferring to Artificial Intelligence.\"\nFacebook yesterday said the experiment was halted because it was \"not what they set out to investigate\".\npaul.hooper@mirror.co.uk\n"},
{"docid": "385 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "November 16, 2015", "title": "How to prevent creeping artificial intelligence becoming creepy; With successful AI emerging slowly and almost without us noticing, we must improve the understanding between human and computer\n", "content": "The traditional view of benevolent artificial intelligence ( AI ) is as a companion, someone who understands and enhances us. Think of the computer in Star Trek or JARVIS in Iron Man. They don't just have a vast knowledge and extraordinary computational abilities, but they exhibit emotional intelligence and remain subservient to their human masters. This is the utopian view of AI.\nThe alternative dystopia has been expressed by Tony Stark's real life counterpart , Elon Musk. What if such intelligence isn't satisfied with such a back seat role? What if it becomes self aware and begins to use its knowledge and computational resources against us?\u00a0\n Related:  Beware the rise of the digital oligarchy\nComparing computers in the real world with those in the movies, they tick the computational box and the knowledge box, but seem to fall down as far as the emotional intelligence goes.\nOne of the pleasures of knowing someone is understanding how they will think, how they react. At the moment, when we project this idea on to our relationship with computers we are frustrated because the machine doesn't know how to react to us. Machines are pedantic, requiring us to formalise ourselves to communicate with them. They can't sense how we are feeling.\nCompare this with our longstanding human companion, the dog. In computational terms, and with regard to access to knowledge, they are limited, but in terms of emotional intelligence they are well ahead of their silicon rivals. They can even seem to understand when we need emotional support. At some level we understand our dogs and they understand us.\nSuccessful AI is emerging slowly, almost without people noticing. A large proportion of our interactions with computers is already dictated by machine learning algorithms: the ranking of your posts on Facebook, the placement of adverts by Google, and recommendations from Amazon. When it is done well, though, we don't notice it is happening. We can think of this phenomenon as creeping AI.\nThe computer tries to understand you by seeing how you've behaved in the past and predicting how you might behave in the future. It doesn't try to be our friend, but it also doesn't push itself in our face anymore, it's just there in the background trying to second-guess us.\nThe danger is that this type of understanding becomes creepy AI. The computer begins to second-guess us, but we are unaware of where this knowledge came from or what its motivations are. \n Related:  The beginnings of advertising created by artificial intelligence\nImproving the understanding between human and computer is key to facilitating this relationship: a relationship of trust. When the transition between computer and human is done well, it can be difficult to see where the human stops and the machine learning starts. Learning systems are already very capable of reacting to our personalities and desires, but they do this in very different ways to how humans do it. To prevent creeping AI becoming creepy AI we need to improve our own understanding of it as it improves its understanding of us.\nMost popular media would have you believe that the future will be all about the computer, but bridging the gap will also require that we do a lot more to understand the human: what are our expectations of an 'intelligent' companion? \nJust as there are dog-people and cat-people there will be different types of computer-people. We can expect considerable variation in the extent to which people expect their computers to be dependent on them for instruction, or the extent to which they trust their computers to act on their behalf.\nThe relationship between animal and owner is at its most effective when there is a mutual understanding. We get the most from our tools by being familiar with them. For the moment the computer is closer to a hammer than a horse, but as any DIY hobbyist knows, a mishandled hammer still leads to a throbbing thumb.\n                     Neil Lawrence is a professor of machine learning at the University of Sheffield                   \n                       To get weekly news analysis, job alerts and event notifications direct to your inbox, sign up                         free for Media & Tech Network membership                       .                   \n                     All Guardian Media & Tech Network content is editorially independent except for pieces labelled \"Brought to you by\" - find out more                                            here                                          .                   \n"},
{"docid": "386 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "June 12, 2015", "title": "How to prevent creeping artificial intelligence becoming creepy; With successful AI emerging slowly and almost without us noticing, we must improve the understanding between human and computer\n", "content": "The traditional view of benevolent artificial intelligence ( AI ) is as a companion, someone who understands and enhances us. Think of the computer in Star Trek or JARVIS in Iron Man. They don't just have a vast knowledge and extraordinary computational abilities, but they exhibit emotional intelligence and remain subservient to their human masters. This is the utopian view of AI.\nThe alternative dystopia has been expressed by Tony Stark's real life counterpart , Elon Musk. What if such intelligence isn't satisfied with such a back seat role? What if it becomes self aware and begins to use its knowledge and computational resources against us?\u00a0\n Related: Beware the rise of the digital oligarchy\nComparing computers in the real world with those in the movies, they tick the computational box and the knowledge box, but seem to fall down as far as the emotional intelligence goes.\nOne of the pleasures of knowing someone is understanding how they will think, how they react. At the moment, when we project this idea on to our relationship with computers we are frustrated because the machine doesn't know how to react to us. Machines are pedantic, requiring us to formalise ourselves to communicate with them. They can't sense how we are feeling.\nCompare this with our longstanding human companion, the dog. In computational terms, and with regard to access to knowledge, they are limited, but in terms of emotional intelligence they are well ahead of their silicon rivals. They can even seem to understand when we need emotional support. At some level we understand our dogs and they understand us.\nSuccessful AI is emerging slowly, almost without people noticing. A large proportion of our interactions with computers is already dictated by machine learning algorithms: the ranking of your posts on Facebook, the placement of adverts by Google, and recommendations from Amazon. When it is done well, though, we don't notice it is happening. We can think of this phenomenon as creeping AI.\nThe computer tries to understand you by seeing how you've behaved in the past and predicting how you might behave in the future. It doesn't try to be our friend, but it also doesn't push itself in our face anymore, it's just there in the background trying to second-guess us.\nThe danger is that this type of understanding becomes creepy AI. The computer begins to second-guess us, but we are unaware of where this knowledge came from or what its motivations are.\n Related: The beginnings of advertising created by artificial intelligence\nImproving the understanding between human and computer is key to facilitating this relationship: a relationship of trust. When the transition between computer and human is done well, it can be difficult to see where the human stops and the machine learning starts. Learning systems are already very capable of reacting to our personalities and desires, but they do this in very different ways to how humans do it. To prevent creeping AI becoming creepy AI we need to improve our own understanding of it as it improves its understanding of us.\nMost popular media would have you believe that the future will be all about the computer, but bridging the gap will also require that we do a lot more to understand the human: what are our expectations of an 'intelligent' companion?\nJust as there are dog-people and cat-people there will be different types of computer-people. We can expect considerable variation in the extent to which people expect their computers to be dependent on them for instruction, or the extent to which they trust their computers to act on their behalf.\nThe relationship between animal and owner is at its most effective when there is a mutual understanding. We get the most from our tools by being familiar with them. For the moment the computer is closer to a hammer than a horse, but as any DIY hobbyist knows, a mishandled hammer still leads to a throbbing thumb.\n                     Neil Lawrence is a professor of machine learning at the University of Sheffield                   \n                       To get weekly news analysis, job alerts and event notifications direct to your inbox, sign up                         free for Media & Tech Network membership                       .                   \n                     All Guardian Media & Tech Network content is editorially independent except for pieces labelled \"Brought to you by\" - find out more                                            here                                          .                   \n"},
{"docid": "387 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "February 4, 2016", "title": "Friends find the SwiftKey to \u00a3174m from Microsoft\n", "content": "Two Cambridge graduates were catapulted into the realms of the super rich yesterday after their technology business was bought by Microsoft for a reported \u00a3174 million.\nJon Reynolds, 30, and Ben Medlock, 36, are understood to have made more than \u00a325 million each after agreeing to sell SwiftKey, the company they founded in 2008 after leaving university.\u00a0\nHowever, one of the business's founders did not receive a penny. Chris Hill-Scott set up the company with Mr Reynolds and Dr Medlock but resigned as a director shortly afterwards to pursue a career in photography. Mr Hill-Scott, who now designs websites for the government, will not get anything because he sold his shares in the company to the other two men when he left.\nSources familiar with what happened said that Mr Hill-Scott disliked the long hours associated with working for a technology start-up and struggled without a salary. A spokesman for SwiftKey said he left the company on good terms with his friends.\nAfter Mr Hill-Scott's departure, the remaining two entrepreneurs developed the predictive text technology that would see their company become one of the most successful British startups of recent years. The company's software, which suggests the next word a user is about to type, is used on more than 300 million smartphones and tablets across the world.\nThe key to the technology's success is the use of artificial intelligence to improve the predictions over time by learning each user's writing style, even remembering slang and nicknames.\nThe company estimates its software has saved its users 10 trillion keystrokes, which amounts to more than 100,000 years of typing time.\nMr Reynolds and Dr Medlock have also worked with Stephen Hawking, helping him to upgrade his computer-generated voice by applying predictive language software to his system and enabling him to speak faster and continue to give lectures.\nThe deal with Microsoft is the latest attempt by Silicon Valley to tap into British expertise in artificial intelligence. In 2014, Google paid \u00a3400 million for DeepMind, which develops artificial intelligence for computer games, and last year Apple bought VOCALIQ, which makes software to help computers and people converse more naturally, for an undisclosed amount.\nMr Reynolds and Dr Medlock met at Cambridge in 2004. Mr Reynolds was an undergraduate studying natural sciences and Dr Medlock was a postgraduate working on a Phd in natural language and information processing.\nSwiftkey's app, which works in more than 100 languages and has been downloaded more than 10 million times, has topped the download rankings in 47 countries. The technology also appears automatically on hundreds of millions of smartphones after the company did deals with businesses including Samsung, the Korean phone maker.\nA statement on the Swiftkey's website yesterday confirmed the deal, although it failed to mention the role of Mr Hill-Scott. It said: \"Eight years ago we started out as two friends with a shared belief that there had to be a better way of typing on smartphones. We've come a long way since then; today hundreds of millions of people around the world, and many of the leading mobile manufacturers, rely on our language prediction technology.\n\"We're excited to announce an important milestone on Swift-Key's journey. As of today, we have agreed to join the Microsoft family.\"\n"},
{"docid": "388 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "May 18, 2017", "title": "Parties investigated over use of Facebook data\n", "content": "The information commissioner has begun an investigation into how political parties use information about people to target their campaigns.\nIt follows concerns about the use of data by the Leave campaign in the EU referendum. It has been claimed that Cambridge Analytica, an American company, helped the Leave.eu campaign group to scrape reams of personal data from people's Facebook pages without their knowledge.\u00a0\nElizabeth Denham, the information commissioner, has indicated that may be breaking data protection laws, even if the information is publicly available.\nIn February Andy Wigmore, of Leave.eu, told The Observer that Cambridge Analytica, which was also involved in Donald Trump's campaign, had offered its services free and had helped the campaign to build intimate profiles of voters using artificial intelligence. The company denies this.\nMr Wigmore said: \"Using artificial intelligence, as we did, tells you all sorts of things about that individual and how to convince them with what sort of advert. And you knew there would also be other people in their network who liked what they liked, so you could spread. And then you follow them. The computer never stops learning and it never stops monitoring. It is creepy!\" In a blog post yesterday, Ms Denham wrote: \"[The investigation] will involve deepening our current activity to explore practices deployed during the UK's EU Referendum campaign but potentially also in other campaigns.\"\nShe referred political parties to guidelines stating that: \"While people might expect that the electoral register is used for election campaigns they may well not be aware of how other data about them can be used and combined in complex analytics. If a political organisation is collecting data directly from people or obtains it from another source, it has to tell them what it is going to do with the data.\"\nVikki Hoyle, of Walker Morris, the solicitors, said: \"It is the use of microtargeting by the Leave campaign and in particular the claims by Cambridge Analytica that it can 'find your voters and move them to action' ... which has caught the ICO's attention and led to this formal investigation.\"\nA spokesman for Cambridge Analytica said that it \"had no involvement in last year's EU referendum and did no work for any of the campaigns\".\n"},
{"docid": "389 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 26, 2016", "title": "Standard Chartered investing in robots to cut compliance costs\n", "content": "Standard\u00a0Chartered is moving heavily into radical new technologies that could one day see robots providing bespoke wealth advice and artificial intelligence answering customer questions.\nThe emerging markets-focused British bank has set up a new lab called the eXellerator in Singapore in an attempt to bring theoretical ideas from Silicon Valley to life. Chief executive Bill Winters has put the centre at the heart of a $1.5bn commitment to improving computing and IT systems.\u00a0\nSome of the ideas are also urgently needed cost-saving initiatives. The bank has hired thousands of additional compliance officers in the past three years and last year hiked annual compliance spending by an extra $1bn in an effort to stop workers breaking laws and regulations, in the wake of expensive scandals including the breaking of US sanctions against Iran.\nBanks across the world are hiring more compliance and regulatory staff, leading to a shortfall of suitably qualified workers and spiralling costs.\nTo combat this, Standard Chartered wants to run computer systems and artificial intelligence programmes to ensure the regulations are not broken, rather than hiring staff to manually implement them and monitor the results.\n\"In the last two or three years, almost all banks have added hundreds or thousands of additional people for compliance, to regulate reporting, regulate compliance - now, banks understand what is going on and want a way to make it more efficient,\" said the bank's global chief innovation officer Anju Patwardhan.\n\"I am coming across some very targeted, specialised technologies from companies in New York and San Francisco focused on specific aspects of compliance [including] conduct,\" which monitors staff behaviour automatically rather than relying on hiring more people to observe co-workers.\n                   Stanchart                   \nCustomers are likely to notice the new technologies when receiving financial advice from banks.\nCurrently a customer typically tells a bank how much risk they are prepared to tolerate in their investment portfolio and the banker - or a machine - matches suitable investments to that risk profile.\nIn future, Ms Patwardhan believes artificial intelligence could offer more tailored advice, understanding customers' end goals.\n\"If you moved to using cognitive computing, the computers would give you recommendations based on the data received without you having to disclose anything... the computers are continuously learning,\" she said.\nREAD MORE ABOUT:\n"},
{"docid": "390 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "September 11, 2017", "title": "Intelligent machines will replace teachers within 10 years, leading public school headteacher predicts; Human tutors will be sidelined in near future as AI takes central role in education, suggests Sir Anthony Sheldon of Wellington College\n", "content": "Inspirational teachers of the future will be intelligent machines rather than humans, the influential head of one of Britain's most famous public schools predicts.\nWithin 10 years a technological revolution will sweep aside old notions of education and change the world forever, Sir Anthony Sheldon, master of Wellington College believes.\nSchool teachers will lose their traditional role and effectively become little more than classroom assistants.\u00a0\nRead more\nAI can secretly be trained to behave 'maliciously' and cause accidents\nThey will remain on hand to set up equipment, help children when necessary and maintain discipline, Sir Anthony said.\nHowever, the essential job of instilling knowledge into young minds will wholly be done by artificially intelligent (AI) computers.\nSir Anthony, a historian and political commentator who has written biographies of ex-prime ministers David Cameron, Tony Blair, John Major and Gordon Brown, said: \"It certainly will change human life as we know it.\n\"It will open up the possibility of an Eton or Wellington education for all.\n\"Everyone can have the very best teacher and it's completely personalised; the software you're working with will be with you throughout your education journey.\n\"It can move at the speed of the learner.\n\"This is beyond anything that we've seen in the industrial revolution or since with any other new technology.\n\"These are adaptive machines that adapt to individuals. They will listen to the voices of the learners, read their faces and study them in the way gifted teachers study their students.\n\"We're looking at screens which are listening to the voice of the student and reading the face of the student. Reading and comprehending.\"\nSir Anthony outlined his vision in a talk at the British Science Festival which took place last week in Brighton.\nIt will also be the subject of his new book \nThe Fourth Education Revolution\n, due to be published early next year.\nRead more\nArtificial intelligence can identify 'gay faces' from a picture\nHow artificial intelligence conquered democracy\nAI a bigger risk than nuclear war with North Korea, warns Elon Musk\nFacebook's AI creating own language is normal, researchers say\nSwedish banks embrace artificial intelligence as a cure to closures\nThe first revolution consisted of learning the basics of survival - foraging, hunting, growing crops and building shelters - he said.\nThe second involved the first organised sharing of knowledge and the third was marked by the invention of printing.\nIn the AI classrooms, each child will progress at his or her own pace, said Sir Anthony.\nThere would be no more set courses applicable to all students as teaching, carried out by emotionally sensitive machines, would be highly personalised.\nAsked if he was suggesting machines would replace the inspirational role of teachers, he said: \"I'm desperately sad about this but I'm afraid I am.\n\"The machines will be extraordinarily inspirational.\n\"You'll still have the humans there walking around during school time, but in fact the inspiration in terms of intellectual excitement will come from the lighting-up of the brain which the machines will be superbly well-geared for.\n\"The machines will know what it is that most excites you and gives you a natural level of challenge that is not too hard or too easy, but just right for you.\"\nHe expected the National Union of Teachers to be \"very alarmed\" by the prospect, a feeling he shared.\n\"The technology's already beginning to arrive,\" he said. \"It's already there on the west coast of the US and it's already beginning to transform schools.\n\"I'm expecting this to happen in the next 10 years.\n\"The great danger is that it takes jobs away, and for humans beings much of our fulfilment in life comes from the satisfaction of work.\n\"We're not hard-wired not to work.\n\"If we get the technology wrong it will end up doing everything for us in the same way that satnavs mean we no longer know how to read maps.\"\nPA\n"},
{"docid": "391 of 500 DOCUMENTS\n", "source": "The Guardian (London) - Final Edition\n", "date": "July 6, 2004", "title": "Brave new world\n", "content": "\u00a0\n In 1998 Kevin Warwick , professor of cybernetics at Reading University, implanted a chip in his arm which identified him to his computer and opened doors and switched on lights for him when it knew he was nearby. In 2001 he implanted another chip that mapped his emotions, linking his nervous system to the computer by radio.\u00a0\n New Scientist revealed in 2002 that two men paralysed down one side of their bodies were able to walk again thanks to an implant that used signals from a healthy leg to control the paralysed one. Sensors were placed over certain muscles on the able leg and stimulators implanted near nerves in the paralysed leg enabling it to do what the patient wanted it to do by taking its cue from the good leg.\n In 2003, it was reported that scientists at the Dalle Molle Institute for Perceptual Artificial Intelligence in Switzerland had developed a method by which severely disabled people may one day be able to control their wheelchair using only their thoughts.\n A skullcap covered with electrodes monitored the electrical activity of its wearer's brain and early trials using a steerable robot indicated that with minimal training it was as easy to control the robot with the human mind as it was manually.\n Last week scientists discovered that the brain could feel a hand it does not have. Volunteers hid their right hands beneath a table while a rubber hand was placed in front of them in a way that suggested it could be part of their body. Both rubber and hidden hands were stroked while researchers observed a brain scan. On average, within 11 seconds, the volunteers started to feel the rubber hand belonged to them.\n\n"},
{"docid": "392 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "August 29, 2017", "title": "Will AI-powered robots really steal my job?\n", "content": "                     Thie third and final part of a Telegraph series reporting from Toronto's booming Artificial Intelligence sector where new technologies are being pioneered that will permanently change all of our lives                   \nIn 1929, the economist John Maynard Keynes made a prediction. Over the course of the next century, he wrote, standards of living in the affluent world would rise between four and eight times to the point where humanity was presented with a new problem: \"how to occupy the leisure which science and compound interest will have won for him, wisely and agreeably and well?\"\nWhile largely correct on the former, the idea of being unshackled from the yoke of work remains mockingly out of reach. The average British working week is presently 31 hours, down from 50 hours in 1930 and roughly double that which Keynes predicted.\nRyan Gariepy of Clearpath Robotics, with his OTTO RobotCredit:      JULIAN SIMMONDS/JULIAN SIMMONDS     \u00a0\nBut that number is significantly reduced by the inclusion of part-time workers and also fails to take into account the modern blurring of lines between work and home which means many of us end up answering emails at all hours of the day.\nTrue leisure in the Keynesian sense is something experienced by vanishingly few. And rather than enjoying it \"wisely\", most of them can be found cluttering up the marina at St Tropez.\nTeaching robots on display at the World Robot Conference in BeijingCredit:      Getty     \nThe age of Artificial Intelligence (AI) is about to engender the biggest change to the workplace ever experienced in the technological era. And depending on where you stand we are faced with one of two outcomes: the utopia envisaged by Keynes and others of his era finally being realised, or humans being simply replaced by robots and chucked on the scrapheap?\nMuch has been made of AI impacting on blue collar jobs. Last week it was announced the  first fleets of driverless HGVs will be trialled on Britain's motorways before the end of the year.\u00a0 Autonomous cars are predicted to render taxi drivers irrelevant. AI robots are already being used in factories on production lines and as security guards (although the fact one security bot, a Knightscope K5, recently drowned itself in a pond in Washington while on patrol shows the technology remains far from infallible).\n                             How robots are being taught to learn like toddlers                          01:42\nBut it is not just manual labour which faces an existential threat . The technologies being developed in Toronto (where the Telegraph is reporting for a three-part series on AI) are going to permanently alter all of our jobs. Accountants, for example, face being overtaken by machines with far better accuracy and processing power. So too, radiologists, bankers and lawyers. Even journalists. Perhaps, especially, journalists.\nAt the AI wing of the Royal Bank of Canada (RBC) for example, based in Toronto's Mars Discovery District in the heart of the city's booming tech industry, researchers are developing algorithms which will be able to predict seismic world events taking place before reporters even know about them.\nI am shown a prototype of something called a \"virality prediction tool\", a machine which analyses Twitter and learns by itself whether or not something is going to go viral before it actually has. The idea being that if people start tweeting about an event the bank can pick up on it before anyone else and sell or buy stocks and shares accordingly.\nAs the virality tool monitors the social media site things like Donald Trump's \"Fire and Fury\" warning to North Korea and Sierra Leone mudslides flash across the screen.\u00a0\u00a0\nFoteini Agrafioti and some of her team at the RBC AI research officeCredit:      Julian Simmonds     \n\"This is a machine watching the world in real time and making sense of it all over the world,\" explains Foteini Agrafioti, the head of the RBC Institute. \"At the time the market is reacting to an event we say that is too late. We want to know already and prepare and adjust our position for that.\"\nThe robot revolution is no respecter of rank. In a small start-up hub in a neighbouring warehouse building a group of 30-somethings are developing an autonomous computer chief finance officer which companies that cannot afford a full time member of staff can use instead. Already the Robot CFO is being piloted in restaurants around Toronto, forecasting cash flow, expenses, and business costs just as its human equivalent would but at a fraction of the cost .\nStill despite the advent of such technologies, Agrafioti says she feels the notion of intelligent robots replacing humans is overhyped - for now.\n\"Part of that can be real but I don't think we're anywhere near understanding what that means yet. What humans can do very well which machines can't yet do is high level reasoning. We are quite far away from being able to replicate this.\"\nOut of Toronto towards the Ontario city of Kitchener, a company is already building the AI-equipped robots which can easily perform tasks currently undertaken by humans.\nEven if the robotic secretary is out of action when we arrive, on its shop floor hulking self-driving machines move about performing tasks entirely by their own volition. The robots can work longer and more efficiently than any human and even know when they need to plug themselves in to recharge their lithium power cells.\nClearpath Robotics was founded by four university friends in 2009 and since then has shipped thousands of robots to 40 different countries - including the UK.\nA 'TeaBot' in the MaRS Centre, TorontoCredit:      Julian Simmonds     \nWhile it produces a number of research models its main two designs are the Otto 1500 and 100. \"We tried to stay away from the T-1000 moniker because it reminds people too much of Terminator,\" explains co-founder and chief technical officer Ryan Gariepy.\nCurrently Clearpath has around 600 clients and brings in \"eight figures\" in revenue. Its robots are working on production lines for companies including Toyota, Caterpillar and General Electric and sell for around \u00a350-100,000.\nThey are powered by machine learning algorithms which enable the robots to teach themselves how to perform tasks and build up intelligence as they work. So far, Gariepy assures me, there have been no incidents to speak of.\nRather than resent them, Gariepy insists their human colleagues have afforded the robots names - Rosie, Robbie and R2D2 are particularly popular - and even ascribed them personalities.\n\"There are people who do not like the robots and believe the machines coming into the workplace is a harbinger of them losing their jobs. Our view is it helps people be more productive and remove low value boring tasks from their daily jobs. People do recognise that.\"\nRyan Gariepy with the Otto 1500 and Otto 100Credit:      Julian Simmonds     \nGariepy, 30, certainly ascribes to the Keynesian view of a robot-supported utopia for humanity. His father ran a concrete block factory where he worked on the production line throughout his school days.\n\"I don't believe the utopian ideal is unrealistic,\" he says. \"Assuming society as a whole believes this is the whole way we should go then that does free up time. Not necessarily for people simply not to work but to work on things they truly enjoy.\u00a0 That would be a very different world to live in.\"\nRather than resisting the inevitable march of progress by keeping robots out of the workplace, he says society would be far better served by discussing how those who find their jobs fully automated can be helped to retrain to find other meaningful employment.\n\"What can society do as a whole to support these people?\" he says. \"A lot of people are worried about where their next pay cheque is coming from. Whether or not our robots are there they are still worried about that.\"\nHe remains deliberately vague on the potential of the intelligence his robots possess; aside from the fact they are fully aware of their surroundings.\nCertainly as they buzz about the factory floor, flashing lights and moving politely aside for their human masters to pass - one cannot help but question in the future quite who will be working for whom.\n"},
{"docid": "393 of 500 DOCUMENTS\n", "source": "THE DAILY TELEGRAPH(LONDON)\n", "date": "October 23, 2004", "title": "A lot to be learned from computer's bad jokes\n", "content": "COMPUTERS that can spew out jokes faster and more groanworthy than Jimmy Tarbuck would have dreamed may be a vital tool in teaching children to learn a second language, or in teaching disabled children to speak, an expert in artificial intelligence will tell a one-day conference next week.\nFor most of us, being asked \"What do you give a hurt lemon?\" and being told, \"Lemon aid\" sounds like the occasion for deep depression. But the fact that a computer program was able to ask that question and supply that answer has implications for structural linguistics, and for artificial intelligence.\nAnd, as Dr Kim Binsted will tell next week's Humour, Art and the Brain festival at Winchester, its applications may go far beyond the automated production of lolly sticks.\u00a0\nDr Binsted created the first \"Joke Analysis and Production Engine\" (Jape) in 1996, to combine her academic interest in artificial intelligence (AI) with her personal interest in improvisational comedy. Now, a fifth-generation upgrade of the programme is being used in Standup - a three-year language-teaching experiment in Edinburgh and Dundee funded with pounds 364,000 from the Engineering and Physical Sciences Research Council.\nThe \"System To Augment Non-speaker's Dialogue Using Puns\", to give it its full name, helps speech-impaired children incorporate humour into their exchanges. Other versions of the technology can be used in automated \"chatbots\" for second-language teaching.\n\"The programme will chat back at them but also integrate jokes into the language, about the topic of the week,\" says Dr Binsted. \"Because the programme is working with the same kids week in week out, it can integrate things it learns about them into the humour. So if the kid says their brother is tall, the assistant can make a somewhat lame joke about 'I hear giraffes look up to him'.\"\nThe principle behind the original Jape was, by concentrating on puns - which AI scientists seem to agree are the lowest form of wit - to generate algorithms that could produce simple jokes. \"We started with simple puns because they don't require much knowledge,\" says Dr Binsted.\nAn example: Jape would look at its dictionary and perform a three-step operation. 1) Make a new \"word\" by, say, substitution: \"spook-tacles\" for \"spectacles\". 2) Find a plausible description for the item: \"glasses for ghosts\". 3) Arrange the relationship in Q & A form: \"What do near-sighted ghosts wear? Spooktacles.\" Jape's efforts were then tested on 120 eight- to 11-year-olds, who were asked to assess the results for \"jokiness\" and, God help us, funniness.\n\"Because we were testing these jokes on eight- to 11-year-olds we can't put any of the sexual humour into the test,\" says Dr Binsted. \"But, bless it, when it comes across a phrase, it will riff on that phrase until it's done.\n\"The first time I hooked it up to the big dictionary, one of the first phrases it found promising was 'male orgasm' - and it went off on that for ages. The variations!\"\nA more complex programme, Wiscraic - Witty Idiomatic Sentence Creation Revealing Ambiguity In Context - which works with idioms rather than simple puns, and was geared to helping language acquisition, was developed by Dr Binsted's associate, Justin McKay. \"The performing lumberjack took a bough,\" it announced, for example.\nThere aren't many laughs in the title of a recent paper co-authored by Dr Binsted, The Cognitive Linguistics of Scalar Humour\". In fact, you would hardly be able to guess that it explains what you're really doing when you tell your friend: \"Yo mama's so fat, her ass has its own postcode.\" But \"yo mama\" jokes, according to Dr Binsted, could be the next step up in complexity for computer-generated mirth.\nWhen you leave the realm of joke generation, and enter that of amusement, AI starts to shade into philosophy: getting a computer to crack a joke is one thing; getting a computer to laugh at a joke is quite another. But if you ever wanted a computer that could surf the internet, manage your finances, and help you learn French by insulting your mother, it may be around the corner.\nThe Art and Mind festival of Humour, Art and the Brain, Theatre Royal, Winchester, Oct 30. Tickets on 01962 840440; www.artandmind.org.\n"},
{"docid": "394 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "August 22, 2017", "title": "Killer robots 'will cause war on a vast scale'\n", "content": "Pioneers of robotics and artificial intelligence have called for the UN to ban killer robots, warning of conflicts on an unprecedented scale if an arms race to build autonomous weapons continues.\nThe bosses of more than 160 companies, including Elon Musk of Tesla and Mustafa Suleyman of Deepmind, an AI company bought by Google in 2014, signed an open letter warning that lethal autonomous weapons would create a \"third revolution\" in warfare, after the inventions of gunpowder and the atomic bomb. The group is urging the UN to add autonomous systems to a list of \"morally wrong\" weapons that includes chemical weapons and blinding lasers.\nSouth Korea and Israel use stationary \"sentry\" guns that have autonomous capabilities, although they are only authorised to fire by human controllers. Experts believe that weaponised drones and ground vehicles could be programmed for fully autonomous strike actions within the next few years.\u00a0\nThe Foreign Office opposed a ban on lethal autonomous weapons in 2015, saying that \"international humanit-arian law already provides sufficient regulation for this area\". The Ministry of Defence has indicated that British weapons systems will always be under human control. However, campaigners say there's no definition of what constitutes human control and killer robots could soon be deployed unless an international framework is agreed.\nRyan Gariepy, founder of Clearpath Robotics, one of the signatories, said: \"This is not a hypothetical scenario, but a very real, very pressing concern which needs immediate action.\"\nUS policy states that \"autonomous weapons systems shall be designed to allow commanders and operators to exercise appropriate levels of human judgment over the use of force\".\nThe systems are attractive to commanders because they have the potential to reconnoitre enemy positions or engage enemy forces without risking casualties on their own side. Nevertheless, critics believe the weapons would inevitably be acquired by nations and terror groups hostile to the West, and would be given terrifying capabilities as countries and arms companies competed to stay ahead.\nIn the letter, published before the International Joint Conference on Artificial Intelligence in Melbourne, the technology bosses said: \"Lethal autonomous weapons threaten to become the third revolution in warfare. Once developed, they will permit armed conflict to be fought at a scale greater than ever, and at timescales faster than humans can comprehend. These can be weapons of terror, weapons that despots and terrorists use against innocent populations, and weapons hacked to behave in undesirable ways. We do not have long to act. Once this Pandora's box is opened, it will be hard to close.\"\nMr Musk, whose company is working on driverless cars, has warned of the \"existential threat\" to mankind from artificial intelligence if it is not closely regulated.\nOther tech leaders, including Facebook's Mark Zuckerberg, have criticised his comments as pessimistic.\nTwo years ago, more than 1,000 experts including Stephen Hawking and Noam Chomsky called for a ban on autonomous weapons.\nAutonomous armies are already on the march\nLast year, the Pentagon showed off a swarm of 103 miniature autonomous drones released by fighter jets. They could be used for reconnaissance and targeting of automated artillery strikes as well as to confuse enemy radar. Full-size strike drones such as the 36ft Reaper could one day be capable of autonomous targeting.\nUS forces have tested unmanned ground vehicles that are designed for reconnaissance but come equipped with a machinegun and grenade launcher. The 370lb Maars robot can move at 7mph on treads and carries 450 rounds and four grenades. It is remote controlled but similar vehicles could be made autonomous.\nRussia has developed an unmanned tank that can travel at 37mph and is armed with a 300mm cannon equipped with 500 shells, a 2,000-round machinegun and six anti-tank guided missiles. The Uran-9 can also be equipped with surface-to-air missiles and flame-throwers.\nSamsung's SGR-A1 sentry gun is deployed by South Korea to protect its troops in the Demilitarised Zone. The $200,000 guns have laser rangefinders, thermographic cameras that can detect people, and can fire machinegun rounds and also rubber bullets.\n"},
{"docid": "395 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "June 2, 2016", "title": "Elon Musk: Become cyborgs or risk humans being turned into robots' pets\n", "content": "Elon Musk, the billionaire boss of Tesla and SpaceX, has said that humans need to become cyborgs to avoid becoming \"house cats\" for vastly more intelligent robots.\n                     Musk said that as artificial intelligence advances, people will need to augment their brain power with digital technology to prevent them becoming irrelevant.\u00a0\nHe backed the idea of a \"neural lace\" - a new electronic layer of the brain that would allow us to instantly access online information and greatly improve cognitive powers by tapping into artificial intelligence.\n.html-embed.component .quote.component{margin-left:0}.html-embed.component .quote.component .component-content{margin-right:16px}.quote__source, .quote__author {white-space: normal;}@media only screen and (min-width:730px){.html-embed.component .quote.component{margin-left:-60.83px}.html-embed.component .quote.component .quote__content:before{margin-left:-12px;padding-right:1px}}@media only screen and (min-width:1008px){.html-embed.component .quote.component{margin-left:-82.33px}}The benign situation with ultra-intelligent AI is that we would be so far below in intelligence we'd be like a pet, or a house catElon Musk\n\"Under any rate of advancement in AI we will be left behind by a lot. The benign situation with ultra-intelligent AI is that we would be so far below in intelligence we'd be like a pet, or a house cat. I don't love the idea of being a house cat,\" he said at San Francisco's Code Conference.\n\"The solution that seems maybe the best one is to have an AI layer. A third digital layer that could work symbiotically [with your brain].\"\nScientists have already begun work on a neural lace, successfully testing the concept with mice by injecting them with a device. They believe it could be used for monitoring the brain to fight diseases, or to improve cognitive power.\nMusk, who made billions from PayPal and has ambitions to colonise Mars, said he did not know of a particular company working on neural lace, but that he was tempted to invest in the technology himself.\nIN QUOTES | Elon Musk\n\"Somebody's gotta do it, I'm not saying I will. If somebody doesn't do it then I think I should probably do it,\" he said.\nMusk said the scenario in which humans are turned into pets was the optimistic one, and that the true consequences of artificial intelligence could be much worse. Last year he launched a $1 billion fund into research on saving humanity from AI, and has joined Professor Stephen Hawking and Bill Gates in warning about the dangers.\nHe also updated attendees on the progress of the Tesla Model 3, the company's first mass-market electric vehicle, saying the design will be finished in six weeks.\nTesla Model 3 unveiledPlay!01:32READ MORE ABOUT:\n"},
{"docid": "396 of 500 DOCUMENTS\n", "source": "The Sunday Telegraph (London)\n", "date": "December 7, 2014", "title": "Is this the end of the world?\n", "content": "Humanity may have already created its own nemesis, Professor Stephen Hawking warned last week. The Cambridge University physicist claimed that new developments in the field of artificial intelligence (AI) mean that within a few decades, computers thousands of times more powerful than in existence today may decide to usurp their creators and effectively end humanity's 100,000-year dominance of Earth.\nThis Terminator scenario is taken seriously by many scientists and technologists. Before Prof Hawking made his remarks, Elon Musk, the genius behind the Tesla electric car and PayPal, had stated that \"with artificial intelligence, we are summoning the demon\", comparing it unfavourably with nuclear war as the most potent threat to humanity's existence.\nAside from the rise of the machines, many potential threats have been identified to our species, our civilisation, even our planet. To keep you awake at night, here are seven of the most plausible.\u00a0\n1 ASTEROID STRIKE\nOur solar system is littered with billions of pieces of debris, from the size of large boulders to objects hundreds of miles across. We know that, from time to time, these hit the Earth. Sixty-five-million years ago, an object - possibly a comet a few times larger than the one on which the Philae probe landed last month - hit the Mexican coast and triggered a global winter that wiped out the dinosaurs. In 1908, a smaller object hit a remote part of Siberia and devastated hundreds of square miles of forest. Last week, 100 scientists, including Lord Rees of Ludlow, the Astronomer Royal, called for the creation of a global warning system to alert us if a killer rock is on the way.\nProbability: remote in our lifetime, but one day we will be hit.\nResult: there has been no strike big enough to wipe out all life on Earth - an \"extinction-level event\" - for at least three billion years. But a dino-killer would certainly be the end of our civilisation and possibly our species.\n2 ARTIFICIAL INTELLIGENCE\nProf Hawking is not worried about armies of autonomous drones taking over the world, but something more subtle - and more sinister. Some technologists believe that an event they call the Singularity is only a few decades away. This is a point at which the combined networked computing power of the world's AI systems begins a massive, runaway increase in capability - an explosion in machine intelligence. By then, we will probably have handed over control to most of our vital systems, from food distribution networks to power plants, sewage and water treatment works, and the global banking system. The machines could bring us to our knees without a shot being fired. And we cannot simply pull the plug, because they control the power supplies.\nProbability: unknown, although computing power is doubling every 18 months. We do not know if machines can be conscious or \"want\" to do anything, and sceptics point out that the cleverest computers in existence are currently no brighter than cockroaches.\nResult: if the web wakes up and wants to sweep us aside, we may have a fight on our hands (perhaps even something similar to the man vs machines battle in the Terminator films). But it is unlikely that the machines will want to destroy the planet - they \"live\" here, too.\n3 A GENETICALLY CREATED PLAGUE\nThis is possibly the most terrifying short-term threat because it is so plausible. The reason Ebola has not become a worldwide plague - and will not do so - is because it is so hard to transmit, and because it incapacitates and kills its victims so quickly. However, a modified version of the disease that can be transmitted through the air, or which allows its host to travel around for weeks, symptom-free, could kill many millions. It is unknown whether any terror group has the knowledge or facilities to do something like this, but it is chilling to realise that the main reason we understand Ebola so well is that its potential to be weaponised was quickly realised by defence experts.\nProbability: someone will probably try it one day.\nResult: potentially catastrophic. \"Ordinary\" infectious diseases such as avian-flu strains have the capability to wipe out hundreds of millions of people.\n4 NUCLEAR WAR\nThis is still the most plausible \"doomsday\" scenario. Despite arms-limitations treaties, there are more than 15,000 nuclear warheads and bombs in existence - many more, in theory, than would be required to kill every human on Earth. Even a small nuclear war has the potential to cause widespread devastation. In 2011, a study by Nasa scientists concluded that a limited atomic war between India and Pakistan involving just 100 Hiroshima-sized detonations would throw enough dust into the air to cause temperatures to drop more than 1.2C globally for a decade. Probability: high. Nine states have nuclear weapons, and more want to join the club. The nuclear wannabes are not paragons of democracy. Result: it is unlikely that even a global nuclear war between Russia and Nato would wipe us all out, but it would kill billions and wreck the world economy for a century. A regional war, we now know, could have effects far beyond the borders of the conflict.\n5 PARTICLE ACCELERATOR DISASTER\nBefore the Large Hadron Collider (LHC), the massive machine at CERN in Switzerland that detected the Higgs boson a couple of years ago, was switched on, there was a legal challenge from a German scientist called Otto R\u00f6ssler, who claimed the atom-smasher could theoretically create a small black hole by mistake - which would then go on to eat the Earth.\nThe claim was absurd: the collisions in the LHC are far less energetic than those caused naturally by cosmic rays hitting the planet. But it is possible that, one day, a souped-up version of the LHC could create something that destroys the Earth - or even the universe - at the speed of light.\nProbability: very low indeed. Result: potentially devastating, but don't bother cancelling the house insurance just yet.\n6 'GOD' REACHES FOR THE OFF-SWITCH\nMany scientists have pointed out that there is something fishy about our universe. The physical constants - the numbers governing the fundamental forces and masses of nature - seem finetuned to allow life of some form to exist. The great physicist Sir Fred Hoyle once wondered if the universe might be a \"put-up job\".\nMore recently, the Oxford University philosopher Nick Bostrom has speculated that our universe may be one of countless \"simulations\" running in some alien computer, much like a computer game. If so, we have to hope that the beings behind our fake universe are benign - and do not reach for the off-button should we start misbehaving.\nProbability: according to Professor Bostrom's calculations, if certain assumptions are made, there is a greater than 50 per cent chance that our universe is not real. And the increasingly puzzling absence of any evidence of alien life may be indirect evidence that the universe is not what it seems.\nResult: catastrophic, if the gamers turn against us. The only consolation is the knowledge that there is absolutely nothing we can do about it.\n7 CLIMATE CATASTROPHE\nAlmost no serious scientists now doubt that human carbon emissions are having an effect on the planet's climate. The latest report by the Intergovernmental Panel on Climate Change suggested that containing temperature rises to below 2C above the pre-industrial average is now unlikely, and that we face a future three or four degrees warmer than today.\nThis will not literally be the end of the world - but humanity will need all the resources at its disposal to cope with such a dramatic shift. Unfortunately, the effects of climate change will really start to kick in just at the point when the human population is expected to peak - at about nine billion by the middle of this century. Millions of people, mostly poor, face losing their homes to sea-level rises (by up to a metre or more by 2100) and shifting weather patterns may disrupt agriculture dramatically.\nProbability: it is now almost certain that CO2 levels will keep rising to 600 parts per billion and beyond. It is equally certain that the climate will respond accordingly.\nResult: catastrophic in some places, less so in others (including northern Europe, where temperature rises will be moderated by the Atlantic). The good news is that, unlike with most of the disasters here, we have a chance to do something about climate change now.\n"},
{"docid": "397 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "June 29, 2016", "title": "Stephen Hawking says pollution and 'stupidity' still biggest threats to mankind; Leadingphysicist also worried about Artificial Intelligence inwarfare, warning machines' goals may differ from ours\n", "content": "                     Professor Stephen Hawking says he believes pollution and human \"stupidity\" remain the biggest threats to mankind, while also expressing his concerns over the use of artificial intelligence in warfare.\u00a0\nThe world's leading theoretical physicist argued \"we have certainly not become less greedy or less stupid\" in our treatment of the environment over the past decade, during an interview on \nLarry King Now,\nwhich is hosted on Ora TV.\nProfessor Hawking said: \"Six years ago, I was warning about pollution and overcrowding, they have gotten worse since then. The population has grown by half a billion since our last interview, with no end in sight.\nRead more\nBlack holes offer a way to another universe, Stephen Hawking says in newly published paper\nStephen Hawking says that even he can't explain Donald Trump's popularity\nStephen Hawking claims he will only feel like a pop culture icon when he appears on Keeping up with the Kardashians\n\"At this rate, it will be eleven billion by 2100. Air pollution has increased by 8 percent over the past five years. More than 80 percent of inhabitants of urban areas are exposed to unsafe levels of air pollution.\n\"The increase in air pollution and the emission of increasing levels of carbon dioxide. Will we be too late to avoid dangerous levels of global warming?\"\nThe cosmologist was speaking at the Starmus science conference in Tenerife, themed this year as a tribute to his life's work.\nWehave certainly not become less greedy or less stupid\nProfessor Stephen Hawking\nProfessor Hawking went on to outline his concerns about the future of artificial intelligence technologies, and specifically their primary use in weaponry.\nHe said: \"Governments seem to be engaged in an AI arms race, designing planes and weapons with intelligent technologies. The funding for projects directly beneficial to the human race, such as improved medical screening, seems a somewhat lower priority.\n\"I don't think that advances in artificial technology will necessarily be benign. Once machines reach the critical stage of being able to evolve themselves, we cannot predict whether their goals will be the same as ours.\"\nThe professor was also drawn on the nature of existence itself, saying the \"deeper reason\" of conceivable reality remains a \"complete mystery\" to him.\nRenewable energy is making waves in Europe\nProfessor Hawking was at the Starmus conference to reveal ambitious plans to map the entire known universe using radiation patterns.\nIt is hoped the cosmologists' work will reveal the nature of the dark energy which is causing the universe to expand more rapidly.\n"},
{"docid": "398 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "December 3, 2014", "title": "Hawking praises 'life-changing' technology\n", "content": "STEPHEN HAWKING has unveiled his new \"life-changing\" communications platform, which helps him to speak twice as quickly thanks to a predictive text system.\n The new system, developed with the computing company Intel, will also allow the theoretical physicist to complete tasks such as browsing the internet and opening documents 10 times faster than at present.\u00a0\n Motion from Prof Hawking's existing cheek sensor is detected by an infrared switch mounted on his glasses, which helps him select a character on the computer. The British software application developers SwiftKey analysed Prof Hawking's work to discern the words he is most likely to select from typing a single character, creating a bespoke language model unique to him. He now needs to type fewer than one in five of the letters for the words he uses, just as predictive text works on smartphones.\n At an event in London, he said: \"We are pushing the boundaries of what is possible.\"\n He claimed that without the new platform he would not be able to speak. Intel offered to help the 72-year old scientist, who has the motor neurone disease amyotrophic lateral sclerosis (ALS), with his computing and speech synthesiser in the mid-Nineties.\n He approached the company several years ago to help modernise his current communication system.\n \"Medicine has not been able to cure me, so I rely on technology to help me communicate and live,\" he said. \"The development of this system has the potential to improve the lives of disabled people around the world and is leading the way in terms of human interaction and the ability to overcome communication boundaries that once stood in the way.\"\n His distinctive computer-generated voice will not be altered.\n Prof Hawking told the BBC he felt that full artificial intelligence, which is used in a basic form in his new system, \"could spell the end of the human race\".\n He said: \"The primitive forms of artificial intelligence we already have, have proved very useful. But I think the development of full artificial intelligence could spell the end of the human race.\" He added that the technology would eventually become self-aware and \"supersede\" humanity as it developed faster than biological evolution.\n Prof Hawking was diagnosed with ALS shortly after his 21st birthday and doctors initially gave him two years to live.\n As his condition steadily deteriorated, he began using a wheelchair, and eventually lost his speech. However refusing to let his diagnosis distract him from his work, he completed his PhD, and went on to establish himself as one of Britain's leading theoretical physicists.\n Prof Hawking and more than three million people worldwide live with motor neurone diseases such as ALS. Such conditions, which have few known causes, progressively take away a person's ability to control muscle movements and eventually lead to death.\n Lama Nachman, the principal engineer of the project at Intel, said: \"Technology for the disabled is often a proving ground for the technology of the future. From communications to genetic research, technology is beginning to open doors to possibilities that can only be imagined.\"\n Ms Nachman confirmed that the technology would be made available to all in January next year, with the aim of giving more developers the chance to work on and improve the software.\n"},
{"docid": "399 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "November 7, 2015", "title": "Film choice; Friday 13\n", "content": "Sci-fi drama Ex Machina (2015)\nSky Movies Premiere, 8pm A smart, tricksy study of artificial intelligence and tech sex that explores a credible near-future take on the man-machine relationship. Like Ava, the beguiling fem-bot (played by Alicia Vikander, above) who is central to this compelling three-hander, the film is a sleek and seductive piece of technology that reveals its inner workings but hides its cunning. Domhnall Gleeson stars as Caleb, a programmer in his twenties who wins the company lottery to spend a week at the mountain retreat of the reclusive company founder Nathan (Oscar Isaac). Nathan, it turns out, has invited Caleb to be the human component of the Turing test - the examination that assesses whether artificial intelligence can pass for human intelligence. From the moment Caleb meets Ava, he is transfixed - and is completely out of his depth. (108min)\u00a0\nWar drama Cross of Iron (1977) BBC Two, 12.45am\nOrson Welles declared that the director Sam Peckinpah's blood-soaked Second World War thriller was the greatest war movie that he had seen. Welles may have overstated his case, but Cross of Iron is certainly Peckinpah's final flawed classic. James Coburn, Maximilian Schell, James Mason and a dysentery-tormented David Warner are the cynical Nazi officers leading demoralised soldiers to slaughter on the Eastern Front. Based on a novel by the German writer Willi Heinrich and shot in the former Yugoslavia, Cross of Iron puts the controversial case that the German military were as much victims of their insane leadership as the rest of Europe. (133min) Stephen Dalton\n"},
{"docid": "400 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "September 1, 2014", "title": "Bankers beware: City 'will soon be run by robots'; Artificial intelligence will render human efforts redundant, says Microsoft executive\n", "content": "ROBOTS will be running the City within 10 years, rendering investment bankers, analysts and even quants redundant, it has been claimed.\n\u00a0Artificial intelligence is about to outpace human ability, according to Dave Coplin, a senior Microsoft executive. Computers will not only be able to undertake complex mathematical equations but draw logical, nuanced conclusions, reducing the need for human interference, he said.\n This will render certain professions redundant, while other \"human only\" skills will become increasingly valuable.\u00a0\n \"I believe in Moravec's Paradox,\" Mr Coplin, Microsoft's UK-based chief envisioning officer, told The Telegraph, referring to the Eighties hypothesis discovered by artificial intelligence and robotics researchers. \"This states that what we think is easy, robots find really hard, and what we think it really hard, robots find easy,\" he said. \"Complex maths equations are hard for humans but take nanoseconds for a computer, but moving around and picking things up is easy for us, while being almost impossible for a robot.\"\n Meanwhile, he said, professions currently viewed as commodities will become specialist human skills. \"It would be hard to train a robot to be a nurse, or even a chef, but the City could be run by algorithms,\" he said. \"People who use their hands will have jobs for life.\"\n Algorithms are already commonplace on City trading floors, and are used in many industries, from online retail to internet dating. High-frequency trading, governed by algorithms, is already one of the most profitable trading classes. But, according to Mr Coplin, in 10 years people will no longer be required to manage these algorithms. Decisions will be taken directly by the artificial intelligence.\n \"Everyone thinks of Terminator and Skynet [the computer that becomes selfaware and attempts to destroy mankind in James Cameron's 1984 film] when I start talking about this, but technology affords us a tremendous opportunity to play to our strengths as humans, and stand on the shoulders of robotic giants,\" said Mr Coplin.\n Microsoft has tasked Mr Coplin with exploring the new trends that will shape the world of work in the coming years.\n \"I am hunting for the game-changers of the next 10 years,\" he said.\n Mr Coplin believes that the rise of big data and innovations in the field of \"ambient intelligence\" - smart technology that responds to the presence of people - are going to bring about radical changes in the workplace.\n \"I call my mobile a smartphone but even though it has information about where I am and who I speak to, it doesn't do anything with that information. It doesn't deliver a service.\"\n In the future, ambient intelligence will allow devices to anticipate your needs and respond in real time. Your phone will send automated email responses based on keywords and contributing factors such as location, time of day, and calendar entries. \"Business processes will be increasingly automated, freeing up humans to do more useful things,\" Mr Coplin said.\n Big data is not a new concept but technologists are increasingly interested in finding new ways that these mountains of data can be read and interpreted.\n Microsoft is an active participant in this field of research. It recently trialled a new feature for Skype, its voice over IP service, which allows users to select a language and translates their speech in real-time.\n Social media is also changing the way organisations will communicate in the future, according to Mr Coplin, who has a vision of a transparent, digital corporate infrastructure, where emails, documents and spreadsheets are all accessible to and searchable by anyone in that organisation. \"Knowledge will flow freely, you will be able to see information even if you're not part of the conversation. It won't be locked up in teams of inboxes any more.\"\n Many of the new workplace trends may seem alien today but, according to Mr Coplin, \"This new technology will bring about cultural change.\"\n10 The number of years in which trading floors could be run entirely by algorithms, with artificial intelligence taking decisions\n"},
{"docid": "401 of 500 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "February 18, 2008", "title": "You think robots are taking over? Fear not\n", "content": "At the American Association conference last week, futurologist Ray Kurzweil said something so unlikely that we have to assume he's pitching for research grants. He predicts we'll have artificial intelligence matching \"the broad suppleness of human intelligence including our emotional intelligence by 2029.\" On 20 June, around tea-time.\nThere are many marvelous predictions out there which I'm happy to believe in. Augmented reality, yes. I want a holographic head that I can switch on like a veil when I go out. A lion's head in the Palace of Westminster. In Hackney, a shark's. And I'd very much like to be able to access the internet through my teeth.\u00a0\nBut the broad suppleness of human intelligence?\nYou know how pornography drove the take-up of video players and the internet? It'll be the same with AI. We'll have robots and nanobots but outselling them all will be cutebots. They'll be able to produce the broad suppleness of intelligence required to meet demand in their specified area, I'm sure. They won't have to say very much to be credible, and contemporary programmers wil certainly be able to produce the physical action required. Whatever that might be exactly is not something we'll be going into here. But that's the thing about artificial intelligence.\nMaking machines think like humans is one thing; the way we increasingly think like machines is another. Mechanical intelligence is increasing all through advanced society. The more advanced we are the more mechanical we have become. We can blame the division of labour for breaking down complex projects into simple, repeatable here-and-there tasks. We can blame targets and \"best practice\" for reducing personal initiative. We can blame response cue sheets in customer call centres. We can blame that damned assertiveness training technique broken record (\"Yes, I quite understand your problem with refunds but I want my meat.\"). And modern exam techniques for modern exams that require such particular paragraphs - they must take their share of it.\nIn the most human of professions, psychotherapy, you get doctors saying one of three things, \"Mm hm\" and \"How does that make you feel?\" and \"That'll be \u00a355.\"\nSo there is convergence. Humanity is on the brink of becoming so stupid that machines can replicate their intelligence.\nBut the other way round? It'll never happen. The Turing Test for artificial intelligence will never be passed. This is the test that puts a computer in one room, you in another and you text it questions. It texts you back answers and you have to decide whether it's a person or a machine. Some chatbots try and fool you with Dr Therapy type answers, \"So, that must be interesting, how do you feel about that?\"\nBut just ask it the questions that concern humans and you will never get a reply. Are you afraid of getting old? Will you have enough money to pay for your nursing care? When do you think you will die? How frightened of death are you? Are you admired enough by your colleagues? Why does Edith Piaf's voice bring tears to the eyes?\nMachines aren't afraid of death. They'll never be able to pass themselves off as human. They have no ability to leer at the gigachips in a cutebot. And when someone says, oh yes, oh that's good, more molasses now, NOW! the poor little cutebot will just not know what to do. That would be the single example of a human response it could produce.\nPlease can I be paid to watch this\nA new chapter has been written in the history of labour law. Reality-show participants in France have sued the programme-makers for overtime. The court has ruled that those appearing on Temptation Island, left, are company staff with full employee rights. Presumably they can't be sacked so they'll be living on the island until they can't face temptation any more. But what about us, the viewers? Shouldn't we be paid? Watching these programmes is work, not pleasure. Are we to be exploited, our time taken without compensation, our health damaged, our prospects blighted without any sense of responsibility from the programme owners? As one of the contestants said, \"It isn't work, it's hell\". I know exactly what he meant.\nThe Poles are going home! For the first time in years more are leaving than arriving. There are a million here now, it appears, but Poland is booming and the zloty's soaring against the pound. The economy is working the other way round for economic migrants.\nWe've plugged into several circles of migrant Europeans here in Oxford. One arrived three years ago without a bean and not a word of English. From minimum wage work, he's driving a BMW now.\nImmigrants are all the same. I've been an immigrant myself, in more than one country. When you go somewhere new you don't have any friends so you work harder than your hosts, you do two jobs, and you save prodigiously so you can go home.\nIt's a peculiar thing about living overseas. It's fine for years, and then you go past a certain point. The longer I stayed, the more foreign I felt.\ns.carr@independent.co.uk\n"},
{"docid": "402 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "March 17, 2016", "title": "Our tech future: the rich own the robots while the poor have 'job mortgages'; Artificial intelligence expert Jerry Kaplan says those whose jobs involve 'a narrow set of duties' are most likely to see their work replaced by automation\n", "content": "Ever since the first vision of a robot appeared on the horizon of mankind, humans have feared that automation will replace the workforce in our dystopian future. \nThere typically follows a period of reassurance, in which we are compelled to believe that this will be a good thing, and that robots could actually liberate us from the drudgery of daily toil and free us for more enjoyable, cerebral pursuits. Futurist Jerry Kaplan, 63, is among those optimists. He estimates that 90% of Americans will lose their jobs to robots and we should all be happy about it. \n\"If we can program machines to read x-rays and write news stories, all the better. I say good riddance,\" Kaplan said. \"Get another job!\"\u00a0\n Related:  AlphaGo beats Lee Sedol in third consecutive Go game\n                     Gulp. \nLess discussed is the observation that inequality will be \"a dark cloud\" over this period of robotic rule. The robots, Kaplan admitted, will be owned by the rich. \"The benefits of automation naturally accrue to those who can invest in the new systems, and that's the people with the money. And why not? Of course they're reaping the rewards,\" he said. \n\"We don't have to steal from the rich to give to the poor. We need to find ways to give incentives to entrepreneurs.\"\nOne possible solution to 90% unemployment would be job mortgages, so that people who are displaced by robots can take out loans toward future earnings in unknown jobs. \"People should be able to learn new skills by borrowing against future earnings capacity,\" he said.\nThere will be a difficult period of transition during which massive unemployment will sweep the country. \"The bad news is it takes time for these kind of things to happen.\"\nAs artificial intelligence becomes ever more intelligent, some in the tech world are getting nervous. The robots are winning complex games and creating art that sells for thousands of dollars. There's less discussion in Silicon Valley of whether it's happening and more of what to do now: Y Combinator, a tech investment vehicle whose founder brags about being in the business of creating inequality, recently launched a basic income experiment to give out a small no-strings-attached stipend to people in preparation for an age when there just aren't enough jobs for humans. \nKaplan was here to give the positive spin on that future. With a PhD in computer science specializing in artificial intelligence and a fellowship at the Center for Legal Informatics at Stanford University Law School, he's a bonafide expert. His argument for the future of jobs foreshadows how this next industrial revolution - one that is inevitable, one that is facilitated by very smart robots - will be sold to the masses.\n\"Machines automate tasks, not jobs. Many of these tasks require straightforward logic or hand-eye coordination,\" Kaplan said. \"If your job requires a narrow set of duties, then indeed your employment is at risk.\" \nHe contrasted licensed nurse duties (a lengthy list of activities that involve empathy and problem solving) with bricklayer duties (laying bricks). Kaplan put up a slide to show what he sees as the future workplace. On the slide is something that looks like Pac-Man eating a lawyer, a driver and a doctor. Behind it, it has spit out \"online reputation manager\" and blogger.\n\"This doesn't make society worse, it makes it better,\" he said. \"It may take only 2% of the population to accomplish what 90% of our pop does today. So what?\"\n Related:  Is this the future of work? Scientists predict which jobs will still be open to humans in 2035\nHe said new jobs would emerge and cited the fact that his daughter's job hadn't existed 10 years ago - she's a social media manager. \nKaplan mentioned other employment options that will remain: tennis pros, party planners, flower arrangers and undertakers.\n\"No one wants to go to a robotic undertaker,\" he said. \"Can you imagine?\"\nThough the robots might take jobs, they wouldn't be doing so consciously, so we can stop worrying about that: \"Robots don't think the way people think. There's no persuasive evidence that they're on the path to becoming sentient beings.\"\n\"AI is simply a natural expansion of longstanding efforts to automate tasks,\" he said. \n\"Robots don't cook or make beds. They don't have independent goals and desires,\" he said. \"They aren't marrying our children.\" \n                     Very comforting. \n"},
{"docid": "403 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "August 26, 2017", "title": "Don't rage against the machines; Steven Poole enjoys a study that eases the panic about Artificial Intelligence\n", "content": "LIFE 3.0 by Max Tegmark 374PP, ALLEN LANE, \u00a320, EBOOK \u00a39.99\n'Prediction is very difficult,\" the great physicist Niels Bohr is supposed to have said, \"especially when it's about the future.\" That hasn't stopped a wave of popular-science books from giving it go, and attempting, in particular, to sketch the coming takeover of the world by superintelligent machines.\nThis artificial-intelligence explosion - whereby machines design ever-more-intelligent successors of themselves - might not happen soon, but Max Tegmark, an American physicist and founder of the Future of Life Institute, thinks that questions about AI need to be addressed urgently, before it's too late. If we can build a \"general artificial intelligence\" - one that's good not just at playing chess but at everything - what safeguards do we need to have in place to ensure that we survive?\u00a0\nWe are not talking here about movie scenarios featuring killer robots with red eyes. Tegmark finds it annoying when discussions of AI in the media are illustrated like this: the Terminator films, for example, are not very interesting for him because the machines are only a little bit cleverer than the humans. He outlines some subtler doomsday scenarios. Even an AI that is programmed to want nothing but to manufacture as many paper clips as possible could eradicate humanity if not carefully designed. After all, paper clips are made of atoms, and human beings are a handy source of atoms that could more fruitfully be rearranged as paper clips.\nWhat if we programmed our godlike AI to maximise the happiness of all humanity? That sounds like a better idea than making paper clips, but the devil's in the detail. The AI might decide that the best way to maximise everyone's happiness is to cut out our brains and connect them to a heavenly virtual reality in perpetuity. Or it could keep the majority entertained and awed by the regular bloody sacrifice of a small minority. This is what Tegmark calls the problem of \"value alignment\", a slightly depressing application of business jargon: we need to ensure that the machine's values are our own.\nWhat, exactly, are our own values? It turns out to be very difficult to define what we would want from a superintelligence in ways that are completely rigorous and admit of no misunderstanding. And besides, millennia of war and moral philosophy show that humans do not share a single set of values in the first place. So, though it is pleasing that Tegmark calls for vigorously renewed work in philosophy and ethics, one may doubt that it will lead to successful consensus.\nEven if progress is made on such problems, a deeper difficulty boils down to that of confidently predicting what will be done by a being that, intellectually, will be to us as we are to ants. Even if we can communicate with it, its actions might very well seem to us incomprehensible. As Wittgenstein said: \"If a lion could talk, we could not understand it.\" The same might well go for a superintelligence. Imagine a mouse creating a human-level AI, Tegmark suggests, \"and figuring it will want to build entire cities out of cheese\".\nA sceptic might wonder whether any of this talk, though fascinating in itself, is really important right now, what with global warming and numerous other seemingly more urgent problems. Tegmark makes a good fist of arguing that it is, even though he is agnostic about just how soon superintelligence might appear: estimates among modern AI researchers vary from a decade or two to centuries to never, but if there is even a very small chance of something happening soon that could be an extinctionlevel catastrophe for humanity, it's definitely worth thinking about.\nIn this way, superintelligence arguably falls into the same category as a massive asteroid strike such as the one that wiped out the dinosaurs. The \"precautionary principle\" says that it's worth expending resources on trying to avert such unlikely but potentially apocalyptic events.\nIn the meantime, Tegmark's book, along with Nick Bostrom's Superintelligence (2014), stand out among the current books about our possible AI futures. It is more scientifically and philosophically reliable than Yuval Noah Harari's peculiar Homo Deus, and less monotonously eccentric than Robin Hanson's The Age of Em.\nTegmark explains brilliantly many concepts in fields from computing to cosmology, writes with intellectual modesty and subtlety, does the reader the important service of defining his terms clearly, and rightly pays homage to the creative minds of science-fiction writers who were, of course, addressing these kinds of questions more than half a century ago. It's often very funny, too: I particularly liked the line about how, if conscious life had not emerged on our planet, then the entire universe would just be \"a gigantic waste of space\".\nTegmark emphasises, too, that the future is not all doom and gloom. \"It's a mistake to passively ask 'what will happen', as if it were somehow predestined,\" he points out. We have a choice about what will happen with technologies, and it is worth doing the groundwork now that will inform our choices when they need to be made.\nDo we want to live in a world where we are essentially the tolerated zoo animals of a powerful computer version of Ayn Rand; or will we inadvertently allow the entire universe to be colonised by \"unconscious zombie AI\"; or would we rather usher in a utopia in which happy machines do all the work and we have infinite leisure? The last sounds nicest, although even then we'd probably still spend all day looking at our phones.\nTo order this book fom The Telegraph for \u00a320 plus p&p, call 0844 871 1514 or visit books. www.telegraph.co.uk\nWe have a choice about what will happen with future technologies\n"},
{"docid": "404 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "March 7, 2017", "title": "Hawking on humanity (and Corbyn); The physicist is hopeful for the future -as long as the Labour leader goes, Tom Whipple and Oliver Moody write\n", "content": "Aside from the problems of mass species extinction, uncontrollable artificial intelligence and catastrophic global warming, Stephen Hawking is, he says, optimistic about the future.\nIt's just that if humanity is to survive to see it then we might need to form a world government and - the longstanding Labour supporter is adamant about this - it absolutely cannot be run by Jeremy Corbyn.\nAnd if all that sounds a tall order, Professor Hawking is living proof of humanity's ability to overcome insuperable odds. More than 50 years ago he was given a couple of years to live. Last month he celebrated his 75th birthday as arguably the most famous scientist in the world.\u00a0\nIn a rare interview to coincide with his birthday and him being given honorary freedom of the City of London, he told The Times that he looked back on his life with gratitude and towards the years to come with cautious hope. But he was still worried that humans may not have the skills as a species to stay alive.\n\"Since civilisation began aggression has been useful inasmuch as it has definite survival advantages. It is hardwired into our genes by Darwinian evolution,\" he said. \"Now, however, technology has advanced at such a pace that this aggression may destroy us all by nuclear or biological war. We need to control this inherited instinct by our logic and reason.\"\nHe argued that there were new challenges too - among them environmental problems and his concern that artificial intelligence could supplant humans. \"We need to be quicker to identify such threats and act before they get out of control. This might mean some form of world government. But that might become a tyranny. All this may sound a bit doom-laden but I am an optimist. I think the human race will rise to meet these challenges.\"\nHe considers the latest attempt to rise to the challenges of humanity - in the form of the Labour leader - a catastrophe though. \"I regard Corbyn as a disaster,\" he said. \"His heart is in the right place and many of his policies are sound but he has allowed himself to be portrayed as a left-wing extremist.\" He would vote for him but believed doing so would be futile. \"I think he should step down for the sake of the party.\"\nAt a ceremony in Guildhall in London on the occasion of Professor Hawking being made an honorary freeman of the City - a title also bestowed on Florence Nightingale, Sir Winston Churchill and the web pioneer Sir Tim Berners-Lee - Andrew Parmley, the lord mayor, said that the award was for his public profile as much as his science.\n\"There are few people on the world stage, and not just in the field of science, who are as respected, revered and admired as Professor Stephen Hawking,\" he said. \"He has educated and informed generations of people around the world while continuing to push forward the boundaries of academia.\" The scroll he received will join other mementoes of his improbable life on the wall of his Cambridge office. Professor Hawking has one of the largest rooms in the mathematics department, and he needs it. On one wall are frames taken from his appearances on The Simpsons, on the one opposite a photograph of his meeting with Pope Francis. Just about the only thing he does not have is a Nobel prize. The work that would be most likely to merit that is into his eponymous \"Hawking radiation\", a type of energy he hypothesised would be able to escape black holes.\n\"I might get a Nobel prize for my discovery that black holes are not completely black,\" he said. \"But I won't hold my breath for it. The rules require the effect be confirmed by observations. This is difficult for stellar mass black holes, because the temperature is only a millionth of a degree.\" Nevertheless, he has a plan. \"I'm now studying whether one might detect Hawking radiation in primordial gravitational waves.\nEven so, he said he was more than satisfied with his life so far - and was looking forward to what might yet come. Including, if possible, becoming an astronaut. \"I am lucky to have had a successful career. I have been very successful in my scientific work and have become one of the best-known scientists in the world. I have three children and three grandchildren so far.\n\"I travel widely, have been to Antarctica and have met the presidents of Korea, China, India, Ireland, Chile and the United States, as well as meeting four popes. I have been down in a submarine, and up on a zero gravity flight in preparation for the flight into space that I'm still hoping to make on Virgin Galactic. It is a great time to be alive.\" ? Jeremy Corbyn insisted that there was \"nothing missing, nothing hidden\" in his tax affairs as he blamed the Cabinet Office and \"media barons\" for claims that he failed to declare tens of thousands of pounds in a tax return published at the weekend.\nA spokesman for Mr Corbyn released a statement yesterday attacking \"false claims\" about his tax. \"We are disappointed the Cabinet Office did not explain the figure used on the P60 yesterday in answer to media inquiries they received,\" it said. \"It is also a matter of concern that some media organisations made entirely false claims without verifying or confirming the facts.\"\n"},
{"docid": "405 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "June 18, 2015", "title": "Google's artificial intelligence interprets photos as animal faces, with creepy results; Engineers run photos through neural network that interprets them as disturbing collections of animal faces\n", "content": "Google has been one of the world's biggest backers of artificial intelligence development, investing heavily in machine learning technology, including with last year's acquisition of British company DeepMind . \u00a0\nThe company is developing \"neural networks\" that can spot patterns in pictures to identify them . The technology already allows it to recognise animals and faces in its new photos app, for example. \nHowever, tweak the network in a certain way, and the results can be rather strange. \nIn an experiment, engineers at Google's research labs ran various pictures through its neural network, asking the software to identify patterns in the images and then alter that image to exaggerate the patterns. \nIf the neural network repeats that process enough times, it will change a picture radically. \nIn this particular instance, the neural network had largely been trained by pictures of animals, so any image sent through the feedback loop would be returned as a disturbing collage of animal faces. \n\"The results are intriguing-even a relatively simple neural network can be used to over-interpret an image, just like as children we enjoyed watching clouds and interpreting the random shapes,\" Google engineers Alexander Mordvintsev, Christopher Olah and Mike Tyka said in a blogpost . \n\"This network was trained mostly on images of animals, so naturally it tends to interpret shapes as animals. But because the data is stored at such a high abstraction, the results are an interesting remix of these learned features.\"\nAs well as animals, the neural network often interprets points on a long-range image as pagodas or towers. \n\"The results vary quite a bit with the kind of image, because the features that are entered bias the network towards certain interpretations,\" the authors said. \n\"For example, horizon lines tend to get filled with towers and pagodas. Rocks and trees turn into buildings. Birds and insects appear in images of leaves.\"\nGoogle is using the artificial intelligence software in its own products ( Photos being one example), but the engineers said the techniques could one day be used as a new artform - a new way to remix visual concepts. \nWhile that might not be to everyone's tastes, the results are undoubtedly intriguing. \nThe full list of photos are here . Here's what happens to the Google logo. \n"},
{"docid": "406 of 500 DOCUMENTS\n", "source": "The Independent - Daily Edition\n", "date": "November 30, 2017", "title": "BRAVE NEW WORLD?; Artificial intelligence is going to transform the world... and our lives. But are we heading to a future perfect or a sci-fi horror show? David Barnett does some calculations\n", "content": "Last week, Chancellor Philip Hammond announced in the Autumn Budget a \u00a3500m package of investment into tech initiatives, including the development of artificial intelligence. Which must have had the Channel 4 executives ordering trebles all round, because with perfect timing they've designated this week the \"Rise of the Robots season\", with a schedule that includes documentaries on the take-off of artificial intelligences (AIs) as consulting doctors, a David Tennant-narrated piece on the challenge of making robots as human as possible, and the one that's had the tabloids hot under the collar, Thursday's The Sex Robots Are Coming - which needs little further explanation.\nDoctor Who and the Invasion of the Sex-Bots aside, though, is it actually possible that the dream of science fiction writers going back a century or more is on the verge of reality? Are we really about to live in the long-promised future of robots and AIs?\u00a0\nAs they used to say on the old Six Million Dollar Man TV show (point of order - Steve Austin was a cyborg, not a robot), we have the technology??? or we're about to. And as Hammond said in the Budget: \"We will harness this potential and turn it into the high-paid high-productivity jobs of tomorrow. Others may choose to reject the future, we choose to embrace it.\"\nBut when is this future we are embracing going to come? And these highly paid jobs??? who's going to do them? Them, the robots, or us, the humans?\nWell, without wanting to get all Terminator on everybody, it appears that the plum jobs will indeed be going to them. According to a report earlier this year by PricewaterhouseCoopers, almost a third of UK jobs could be affected by as soon as the 2030s. John Hawksworth, chief economist at PwC, told the BBC that \"more manual, routine jobs\" which \"can effectively be programmed\" were the most at risk, adding that \"jobs where you've got more of a human touch, like health and education\" would be less affected.\nAh, but is that really the case? Channel 4's documentary The Robot Will See You Now posits a near-future where robodocs are the norm, and according to CMRubinWorld, an organisation set up to prepare young people for a rapidly-changing world, one of the biggest changes will be in the classroom.\nWriting for CMRubinWorld, former adviser to Tony Blair, Sir Michael Barber, says we shouldn't just think about what jobs robots will take over, rather about how aspects and parts of jobs will become automated or handed over to AIs. \"It's not just what jobs will exist and what won't. It's about what parts of current roles will be automated and what won't,\" says Barber, noting that while we will still need the human touch in jobs such as doctors and lawyers, \"machines will often be more accurate\" in terms of diagnosis and determination.\nIn terms of changes for global education, Barber says that \"the combination of great teachers and sophisticated AI could be transformative\", but it is not a choice between teachers and AI, adding: \"Fewer, more sophisticated teachers will combine with machines that relieve them of drudgery and provide a powerful evidence base for their teaching.\"\nSo, no robot sir in mortarboard at the front of the class, but perhaps fewer actual teachers - though ones with a stronger grasp of how to deploy AIs in the classroom. Which might seem a little disappointing if we're just talking about a whiteboard that can talk and fire erasers at the naughty kid at the back of the room.\nBut hold on. Azeem Azhar wants us to know that AI is going to be as important to us in the coming years as electricity was in the late-19 century.\n\"Today electricity is a utility, not even a commodity. It just works,\" says Azhar, who works for Oslo-based tech and media group Schibsted. \"You can't really imagine life without it. It is the same everywhere in the world. Everything we do, we buy, is based on the assumption that we'll have access to electricity. And today, more than 5.5 billion of us do.\n\"So when Andrew Ng, one of the most influential forces in today's artificial intelligence boom, describes AI as the new electricity, we stop and take notice. After all, electricity changed industries, jobs, our everyday lives and our social and domestic relationships. Could we perhaps glimpse the second-order effects of artificial intelligence by understanding how electricity shocked the world?\"\nSchibsted has just released its annual Future Report, and robots and AI loom very, very large indeed. In the report, Azhar pushes the electricity-AI analogy to try to get across just how a vital part of our lives non-human intelligences are going to be. \"AI will be deployed rapidly, made available to every part of the industry and home very quickly,\" he predicts. \"In the UK, by 1933 one in three houses had electricity and a further 10 years down the road two out of three houses were electrified.\n\"AI will be deployed far more rapidly than the appliances that used electricity - because the components it needs to work are already in place. Smartphones in our pockets, wireless internet, digital cameras, cloud-based services. Artificial\u00a0intelligence will be ubiquitous, wherever there is the internet.\"\nWhen Azhar was a boy, he would visit his grandparents' home in Lahore, where they did not have a flushing toilet. This was an incredible thing to a child raised in the West. And once we get into life with the robots, we'll struggle - like young Azhar - to wonder how we lived without them.\nHe says: \"AI services will become indispensable. Life will seem inconvenient, even unpleasant, without it. Our expectations for interactions to be AI-powered will rise rapidly. We'll expect our clinicians to spend time explaining our diagnoses to us, not diagnosing us, because AI systems will have more effectively identified our ailments than any human. We'll tire of waiting in traffic queues with aching backs because our autonomous vehicles will find the best route for our journey.\"\nWhich all sounds lovely and futuristic. But is Philip Hammond's \u00a3500m going to save our jobs, or throw us on the scrap-heap in favour of robots? \"Entire industries will benefit from the arrival of AI as they did with electricity. AI will drive an analogous Schumpeterian process.\"\nWhich means? \"Industries arising, replacing others,\" says Azhar. \"Take the car industry: it has a century-old model of selling us cars through distributors who make money through service and repair. The car industry itself supports the advertising and media industry, who are enlisted in manufacturing desire around this mode of transport.\n\"Yet the car industry looks like it will be upended by new modes of on-demand transport rental: autonomous vehicles routed to us by algorithms. Much like electricity, the biggest impacts of AI will be felt outside its home industry. AI will also transform work, and with that a transformation of our social relationships.\n\"Artificial\u00a0intelligence will free up time by taking up some of our cognitive load. It could create free time for us, the same way cheap lighting enabled by electrification extending the day, for both work and leisure. There are any number of taxing but low-value tasks that you could foresee leaving to machines. What we do with all that time, remains to be seen. No wonder that as I talk to business leaders in industries like retail, health diagnostics, professional services and finance, their number one priority is artificial intelligence.\"\nIncreased leisure time sounds like something we can all get behind, and those sci-fi pulps from the 1930s and 1940s, featuring illustrations of humans enjoying themselves while robots do all the drudgery, might be getting closer. But there are concerns - especially for those of us whose jobs might be at risk - and wider fears.\nAzhar says: \"Will AI amplify the biases in the world? Will AI lead to persistent and chronic unemployment? Will AI create new megalithic dominant firms controlling large parts of the economy? These are all real concerns. AI systems have already been demonstrated to systematically bias the bail assessments of black prisoners in the US. And academics Daron Acemoglu and Pascal Restrepo have demonstrated that the use of robots in industry depresses both wages and employment levels.\n\"And one only need to look at the dominance of Amazon in retail, and Google and Facebook in advertising, to see the risks of market dominance driven by data monopolies.\"\nRobots and AI might right now still seem the preserve of blockbuster movies and documentaries about sex-bots, but there is no doubt the world is changing. If you've got an Apple Watch, it can warn from monitoring your heartbeat if you're in imminent danger of having a heart attack.\nYou can download an app to your phone to allow you to have a video consultation with a doctor, rather than going to your GP. It's not a great leap to a combination of the two: a non-human doctor available on your phone. What no one has yet satisfactorily addressed is, when we are relieved of the drudgery of work by robots and have all this increased leisure time, how are humans going to afford to live.\n"},
{"docid": "407 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "October 16, 2017", "title": "Shadow Chancellor John McDonnell's constituents most at risk of losing their jobs to robots\n", "content": "Hayes and Harlington, the constituency of Labour MP and\u00a0Shadow Chancellor of the Exchequer\u00a0John McDonnell, has a higher\u00a0percentage of jobs at risk of automation\u00a0than any other constituency in the country, a new report shows.\u00a0\nAlmost 40pc\u00a0of jobs\u00a0in the west London area are\u00a0at risk of being replaced with\u00a0artificial intelligence (AI)\u00a0by the early 2030s, because so many are in the\u00a0transportation and storage\u00a0sector where there is a high level of\u00a0job displacement by machines.\nRegionally, the highest levels of future automation are predicted in Britain's former industrial heartlands in the Midlands and the north of England, as well as the industrial centres of Scotland. These are areas that have already suffered from deindustrialisation and many of them are already unemployment hotspots.\nThe figures, by think-tank Future Advocacy, show that 28.8pc of jobs in\u00a0Theresa May's constituency of Maidenhead are at\u00a0high risk of automation.\nThe lowest-risk\u00a0constituency, with 21.8pc\u00a0of jobs at risk from AI,\u00a0was found to be\u00a0Edinburgh South, which is represented by\u00a0Labour MP Ian Murray.\u00a0According to the annual \"Edinburgh by Numbers\"\u00a0report released by the City of Edinburgh Council, Scotland's capital has a larger proportion of highly skilled occupations\u00a0than other UK cities, and these jobs are less likely to be taken over by robots.\n                   Jobs at high risk of automation by constituency                   \n                     Jobs most at risk of automation \u00a0are those in the manufacturing, transport, storage, and administration sectors. This poses potentially\u00a0catastrophic problems for constituencies like\u00a0Alyn and Deeside in Wales, where\u00a0almost 35pc\u00a0of total jobs\u00a0in the constituency are in the\u00a0manufacturing sector.\nIn its report,\u00a0Future Advocacy said no party had so far produced\u00a0an adequate policy response to maximising the opportunities of AI and minimising the risks that lie ahead, and hopes its findings\u00a0demonstrate\u00a0how automation will affect regions in\u00a0the UK differently.\nThe think-tank's CEO, Olly Buston, said: \"None of the political parties has a remotely adequate strategy to maximise the opportunities and minimise the risks of artificial intelligence. AI could deliver huge economic benefits to the UK, but automation supercharged by AI could also greatly amplify geographic inequalities.\u00a0There will be great reward for whichever party gets this right.\"\n                   How likely is your job to be automated?                   \nLast week\u00a0an\u00a0independent review by industry experts\u00a0set out\u00a0proposals for how the Government and industries\u00a0can boost the UK's burgeoning AI\u00a0industry, which it says will\u00a0boost productivity, advance health care, improve services for customers and unlock \u00a3630bn\u00a0for the UK economy.\nBusiness Secretary Greg Clark said: \"Artificial intelligence presents us with a unique opportunity to build on our strengths and track record of research excellence by leading the development and deployment of this transformational technology.\"\nDespite predictions that hundreds of thousands of jobs could be lost to robots, a YouGov poll commissioned by Future Advocacy\u00a0found that only 7pc of UK adults were worried that their current job role will be replaced by AI.\nElon Musk, the billionaire technology entrepreneur behind Tesla and SpaceX, has previously called artificial intelligence the\u00a0\"biggest risk we face as a civilisation\" .\n"},
{"docid": "408 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "August 18, 2015", "title": "Volume review: charming MGS-inspired adventures of a futuristic Robin Hood; Rob from the rich, give to the poor, wipe an AI's memory and practice your stealth skills - Volume has it all\n", "content": "Star Rating: 5 stars\nThere are two types of Metal Gear Solid fans. Some love the game for its increasingly dense plot, rich with oblique references to philosophy, information science, and conspiracy theories, as well as developer Hideo Kojima's off-kilter sense of humour and love of easter eggs. For those people, September's Metal Gear Solid V is likely to scratch that itch.\nThe other type of Metal Gear Solid fan loves the series for its self-proclaimed \"tactical espionage action\". That's the aspect of the series I've always loved: stealth gameplay which verges on pure puzzles at times, throwing the protagonist Snake into a room full of cameras, guards and mines and tasking the player to get to the other side without being seen.\u00a0\nBut it's an aspect of the game that the MGS series has increasingly shied away from, as the environments have become more expansive, the gunplay more refined, and the AI less mechanistic, and so for some - for me - the series peaked with the first game.\nBut for the real connoisseurs, there was a follow-up that scratched that itch even better: 1999's Metal Gear Solid: Special Missions, an expansion pack which took the VR training environment of the first game one step further, and presented a whole disc of stealth puzzles to mull over.\nSome of us have been waiting 16 years for a worthy follow-up to that game, and we've finally got it.\nVolume is the second game by Mike Bithell, the indie developer behind 2010's breakout hit Thomas Was Alone. Ostensibly a simple platformer, starring Thomas, a red rectangle, it soared on its witty script, performed by comedian Danny Wallace, which addressed topics such as identity, friendship and artificial intelligence.\nWith Volume, Bithell has recaptured that charm, but this time built around the loose framework of 1990s era Metal Gear Solid, rather than 2000s-era Flash platformers.\nThe game stars Rob Locksley, a young hacker doing his best to fight back against an oligarchical dictatorship in a future England, ruled by the villainous Guy Gisborne. If the names don't spark recognition, the fact that Locksley robs from the rich to give to the poor should: Volume presents a futuristic retelling of the Robin Hood mythos.\nIts world suggests a future in which the commodification of artificial intelligence has led to an astronomical divide between rich and poor, and ultimately a strengthening of Britain's class system, with the world split between those who protect (the aristocracy), those who serve (artificial intelligence) and those who feed (everyone else). Like the best science fiction, at times it feels ripped from the headlines: there's no doubt that Bithell wants to tell a story about our world.\nOf course, weighty polemics about inequality don't lend themselves to charmingly witty scripts, and so the whole thing is viewed through a neat angle: Rob (voiced by YouTuber Charlie McDonnell ) is essentially the world's first Twitch terrorist/freedom fighter. Using a military training AI pilfered from Guy Gisborne ( Andy Serkis, in a casting coup by Bithell), he loads up simulations of the homes of the rich and famous, and proceeds to rob them, broadcasting his techniques for all to see - and mimic in real life.\nThe conceit plays out nicely, with Rob's growing fanbase giving him increasing power to battle Gisborne, while they also egg him on to crack tougher and better protected targets. But the heart of the story lies in the interaction between Rob and Alan, his pilfered AI (voiced by Wallace, back for more - and suggesting a potential link between Bithell's two games). Alan's not happy about being nicked, and certainly not happy about having his memory wiped, but he grudgingly comes to support Rob's campaign.\n Related: Metal Gear Squalid: has Kojima gone too bloody far this time?\nThe heists themselves wear the VR Missions influence on their sleeve, from the mechanics to the aesthetics, but they also innovate in their own way. Crucially, Rob is clear from the off: \"no guns\". The virtual soldiers he's training against may be just programmes, but the people he's inspiring are very real.\nThat emphasises the puzzle aspect of the game over the action side, with the hardest levels feeling like there's just one correct solution. But it also means that the forgiving nature of the game's alert system - which sees guards forgetting you and going back to their patrols if you make it out of their eyeline - can counterintuitively make it harder to play. The temptation to play sloppily, darting in and out of sight, means that the actual solution to the levels' puzzles gets obscured. Rather than rethinking your approach, you end up throwing yourself at the wall again and again until you give up in frustration.\nFor me, that reached its nadir in a level which sees the player take on a combination of guards with 360\u00b0 visions and lasers, with just a gadget called an \"oud\". Try as I might, I couldn't do it without tripping a laser, and always ended up getting shot tantalisingly close to the finish. Only a well-placed hint over email from a fellow journalist prevented me throwing my laptop at the wall.\nBut then, I'm really bad at games. And the atmosphere, voice acting and plot had me coming back for more even when the puzzles overwhelmed me. Now, if Bithell's next game could revive the mechanics of 1997 pirate adventure Overboard!, my nostalgia will be complete.\n\n"},
{"docid": "409 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "January 29, 2016", "title": "Go: Chess grandmaster Lee Sedol prepares to play computer AlphaGo in epic showdown; Machine beating man at a game of Go should not be seen as a loss but a training aid, says chess grandmaster\n", "content": "It was a result that sent shockwaves through the Go community. AlphaGo, the computer created by DeepMind, the Artificial Intelligence (AI) arm of Google, thrashed European Go champion Fan Hui 5-0 - the first time a computer program has beaten a professional player of the ancient Chinese game.\nPlayed on a board with a 19x19 grid of black lines, Go is such a complex game that enthusiasts hoped it would be years, or perhaps decades, before machines would be able to triumph over the best human players.\u00a0\nRead more\nApple buys AI software that can tell people's emotions\nBut now that time scale is shortening and AlphaGo is scheduled to play the world's top player, Lee Sedol, over five games in March.\nMr Lee is a stronger player than Mr Fan and for now remains confident. \"This is the first time that a computer has challenged a top human pro in an even game,\" he said. \"I have heard that Google DeepMind's AI is surprisingly strong and getting stronger, but I am confident that I can win, at least this time.\" It's the \"at least\" that's significant here. The parallels with chess are ominous. IBM's Deep Blue lost 4-2 to Gary Kasparov the first time they played in Philadelphia in 1996, but triumphed 3.5-2.5 a year later in New York. Mr Lee may not succumb the first or even the second time, but in the end he or a successor will and another bastion will have fallen.\nGo is such a complicated game that until recently the programs could defeat only amateurs and the Google team had to use a new approach. It now looks ahead by playing out the rest of the game in its imagination, many times over.\nThe program involves two neural networks, software that mimics the structure of the human brain. It was trained by observing millions of games of Go and evolved to predict expert moves 57 per cent of the time. The network was then set to play against itself, learning from its victories and losses as it carried out more than a million individual games over the course of a day.\nThis is only possible, of course, due to the huge improvements in computing power in recent decades. And the bottom line is that the machines are, or will soon be, able to defeat the best humans at most games.\nWe in the chess community have had to deal with this for nearly two decades now, and the solution has been to accept that they will beat us in single combat but work around it.\nWe know that as human beings we will make small mistakes, however well we play. Chess playing computers (\"engines\") are uniquely well placed to exploit these and once they have a material advantage are almost totally unplayable. But we can console ourselves that they still don't create that much themselves and rather than banging our heads against a brick wall, we can use them as superb training agents.\nWe use \"engines\" extensively in preparing for games - training in which the crucial element is that the human must lead the machine rather than following.\nRead more\n                     Professor Marvin Minsky: Pioneer in field of artificial intelligence                   \n                     'Artificial intelligence alarmists' win 'Luddite of the Year' award                   \n                     Plan to bring people back from the dead with artificial intelligence                   \nAnd after these practice games we always check with the \"engines\" to find all the mistakes we've made and hidden tactics we've missed.\nSprinters don't run against race cars and there's no reason that human Go or chess players should compete directly against computers.\nThe Go community will have to adjust but if, like us chess players, they learn to use the new technology then a new generation will surely arise with an understanding and aesthetic that is different and in some ways superior to their predecessors. And with free top class training at their finger tips the best players will develop much younger.\nIt's a shock to the human ego that machines can emulate our intelligence. But rather than fight against them we should embrace the opportunities they bring.\n"},
{"docid": "410 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "January 9, 2018", "title": "How close are we to a Black Mirror-style digital afterlife?; One of the threads running through the sci-fi series' latest season concerns digital versions of ourselves who live on after we die ... it could happen sooner than we think\n", "content": "When Roman Mazurenko was struck down by a car and killed just before his 33rd birthday, his \"soulmate\" Eugenia Kuyda memorialised him as a chatbot. She asked his friends and family to share his old text messages and fed them into a neural network built by developers at her artificial intelligence startup, Replika.\n\"I didn't expect it to be as impactful. Usually I find showing emotions and thinking about grief really hard so I was mostly trying to avoid it. Talking to Roman's avatar was facing those demons,\" she told the Guardian.\nKuyda discovered that talking to the chatbot allowed her to be more open and honest. She would head home after a party, open the app and tell him things she wouldn't tell her friends. \"Even things I wouldn't have told him when he was alive,\" she said.\u00a0\nIn the next three decades almost 3 billion people could leave their digital remains in the hands of technology companies\nThe chatbot, documented in great detail by the Verge, might be a crude digital resurrection, but it highlights an emerging interest in the digital afterlife, and how technology such as artificial intelligence and brain-computer interfaces could one day be used to create digital replicas of ourselves or loved ones that could live on after death.\nIt's a topic that Black Mirror returns to repeatedly, extrapolating from current technologies into characteristically dystopian scenarios where our brains can be read, uploaded to the cloud and resurrected digitally as avatars or robots. \nTwo episodes in the latest season explore the idea of making a digital copy of a person's consciousness: USS Callister and Black Museum. In the former, a disgruntled game developer makes sentient virtual clones of his co-workers, who he punishes inside a Star Trek-esque game. In the latter, there are several subplots that chart the evolution of devices that can interface with the brain to enable the sharing and replication of sensations, thoughts and emotions. In one, a convict on death row signs over the rights to his digital self, and is resurrected after his execution as a conscious hologram that visitors to the museum can torture.\nLong-time fans learning about Kuyda's chatbot will be reminded of 2013 episode Be Right Back, where a woman called Martha subscribes to a service that uses the online communications of her dead fiance Ash to create a digital avatar that echoes his personality. What starts as a text-messaging bot evolves into a voicebot before she upgrades to a premium service where the bot is embedded in a robot doppelganger. The robot turns out to be a hollow approximation of Ash, and Martha consequently rejects it, stating: \"You're not you, you're just a few ripples of you. You're just a performance of stuff that he performed without thinking, and it's not enough.\"\nEven with the best in today's artificial intelligence and robotics techniques, we lack the technical capabilities to make anything as sophisticated as an Ashbot, let alone any of the conscious replicants in USS Callister or Black Museum.\n\"The human mind is virtually unexplored. We have no idea how consciousness works. But the brain is still a machine so it's a matter of tinkering with it until we work it out,\" says transhumanist Zoltan Istvan, who has studied live extension and digital immortality.\nEter9, created by Portuguese software developer Henrique Jorge, is a social network that uses artificial intelligence to learn from its users and create a virtual self, called a \"counterpart\", that mimics the user and lives on after he or she dies.\nSimilarly Eterni.me, founded by MIT fellow Marius Ursache, scrapes the posts and interactions on your social media accounts to build up a digital approximation that knows what you \"liked\" on Facebook or bragged about on LinkedIn. The service has yet to launch, but the plan is to allow people to interact with their dead loved ones via Eterni.me's mobile apps.\n\"We want to preserve for eternity the memories, ideas, creations and stories of billions of people. Think of it like a library that has people instead of books, or an interactive history of the current and future generations,\" the company promises.\nMore ambitious are efforts to extract thoughts directly from the brain, rather than scavenging the digital footprints we leave behind. So far, brain-computer interfaces have been used for relatively simple tasks, such as restoring motor control in paralysed patients or enabling basic communication for locked-in patients with brain injuries. These interfaces typically decode brain signals from the surface of the skull through EEG or implanted electrodes and then translate the signals into a motion command for a robotic prosthetic limb or a cursor on a keyboard.\nWhile these brain-controlled devices are cutting-edge, they are a long way from the \"merger of biological intelligence and machine intelligence\" proposed by Elon Musk through his recently launched company Neuralink as a way to allow humans to stay competitive with AI systems. Musk proposes using a mesh-like \"neural lace\" implant that could read and write brain signals, allowing for two-way communication that would allow, at least in theory, people to draw on cognitive power from super-intelligent computers without having to type search queries.\nThe Silicon Valley startup Kernel has similar ambitions but is focusing on interfacing with diseased brains such as those with memory loss, Parkinson's or epilepsy - the risks associated with brain surgery make it an extremely tough sell for medical boards and healthy patients.\nEven with the optimism of Silicon Valley, Kernel founder Bryan Johnson is acutely aware that we need a much more sophisticated understanding of the brain to start being able to understand the complex cognitive faculties such as language and metaphor that would be required to create digital clones.\n Related:  Black Mirror's meditation on Star Trek: reinforcing Trekker stereotypes?\n\"We have more than 80bn neurons in the brain. Our tools currently give us access to an extremely small number of neurons. With prosthetics, we're maybe talking about 100 neurons. We need higher bandwidth interfaces,\" he told the Guardian in February 2017.\nSo there's a very long way to go. In the meantime, we must contend with far more pedestrian digital legacies, such as what happens to our Facebook profiles after we die. As the Oxford Internet Institute's Carl \u00d6hman, who studies the ethics of digital afterlife, points out, in the next three decades almost 3 billion people will die, most of whom will leave their digital remains in the hands of enormous technology companies.\nWill they treat your digital corpse with respect? Or will commercial interests push companies to seek to harvest its digital \"organs\" for profits?\n\"If it turns out that storing dead profiles becomes expensive, the incentive to monetise them will grow,\" he said.\n"},
{"docid": "411 of 500 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "January 2, 1991", "title": "BOOK REVIEW / Facts of life: the evidence ; 'Paradigms Lost' - John L Casti: Scribners, 16.95 pounds\n", "content": "DOZENS of books are published every year which try to explain the mysteries of quantum physics, artificial intelligence, or the origin of life, to the lay audience. Anyone writing such a book must choose between gently unveiling their chosen subject's more comprehensible mysteries for the scientifically illiterate, or putting on a pyrotechnic display for the confirmed popular science readership. The key to the bestseller lists is striking the right balance between these extremes.\nThe nature of this balance depends largely on how much science education the average reader can be assumed to have had. Because the British education system forces people to choose between science and humanities at such an early stage, leaving most ''educated'' people ignorant of what genes are made of and what makes nuclear reactors tick, writers usually have to aim pretty low. So the division between mass-market science and science for the science-lover is sharper here than in most countries. Casti's book will probably not become a bestseller here, though it deserves to.\u00a0\nParadigms Lost is actually six- and-a-half books bound together. Each of its main chapters sets out the evidence for and against the conventional position of modern science on a fundamental question. How did life get started on Earth? How much of our social behaviour is controlled by our genes? Is our astonishing capacity to learn language solely due to the way our brains are wired up? Could a computer program think? Are there alien civilisations out there, and are they trying to communicate with us? Is there a ''there'' out there at all - does quantum mechanics mean that reality is subjective, or is there something real underneath it all? Any of these questions could be the subject of a whole book by itself; if nothing else, one has to admire Casti's audacity in covering all of them, in depth, in one volume.\nEach chapter lays out the background to a question, and then gives the evidence for and against the conventional scientific viewpoint.\nAfter summing up, Casti allows his own persona to intrude, by telling us which way he would vote if he were on the jury. This makes a refreshing change from the step-by-step presentation of many a scientific popularisation, which leaves readers ignorant of the disagreement there often is within science about the answers to key questions.\nCasti is not only trying to explain what we think is true, he is also trying to explain what we might have thought was true, and why we decided against it. Each chapter can be read in isolation, so if the origins of life bore you but artificial intelligence makes your heart race, you can open the book in the middle and read from there.\nBut what is science, and why does it work? The conventional view that scientists collect observations until they have enough to prove some theory true is logically unsound. No matter how many white swans you observe, you are never entitled to say that all swans are white; no matter how many times you see oxygen combine with hydrogen to make water, you are never entitled (from a logician's point of view) to say that oxygen and hydrogen will always combine that way.\nYet scientists have somehow managed to build the most magnificent intellectual structure in history on these shaky foundations. Casti devotes a preliminary half-chapter to this shakiness, and to the remedies that have been proposed. The ways that working scientists deal with uncertainty and contradiction is a running theme in the book.\nBut, as I said, this book will probably not become a bestseller. This is not because of its size, though it is very large; nor is it because Casti's passing remarks often assume that his reader is American. It is just that Casti moves very fast. Unless you are the sort of person who regularly reads New Scientist, you won't have the background knowledge needed to keep up with Casti's pace.\nThis isn't necessarily a bad thing. I am the sort who reads New Scientist, and as a result I find most popular expositions of science shallow and excruciatingly slow. Not this one; many of its concepts never made it into the mainstream of science, and so have never been given popular exposure. To cover them as well as the accepted wisdom, Casti has to move quickly. I enjoyed it a lot, and while I disagreed with some of his verdicts, that was part of the fun.\n"},
{"docid": "412 of 500 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "April 3, 1986", "title": "Computer Guardian: A big break for the robot / Computer snooker\n", "content": "\u00a0\n Just when television audiences are beginning to tire of the saturation coverage of snooker, and the pool of top players has become boringly small, help is on the way thanks to new technology.\n If everything goes to plan, a previously unheard of player will enter the world of snooker and could well take the opposition by storm.\n\n The new player is a robot. Such a novelty could provide a shot in the arm for viewing figures. Moreover, the robot will be unlikely to succumb to the dangers attendant upon success at the top. Nor will it need to claim tax allowances for any alcohol consumed in order to steady its hydraulic arms.\u00a0\n The project to build a snooker-playing robot is being conducted at Bristol University. It is hoped that the eventual machine will have sophisticated skills in robot vision and movement, and of course artificial intelligence. While snooker would not be the first task domain that robotics and artificial intelligence researchers might think of, it actually represents a host of complex skills which, if mastered, could provide important insights into the automation of manufacturing processes in industty. That is the reasoning behind the project.\n Though programming a robot to pot snooker balls from set positions may turn out to be relatively straightforward, the task of potting them from the multitude of positions may turn out to be relatively straightforward, the task of potting them from the multitude of positions that can arise during the course of a game requires a complex combination of visual skills and judgment. This is where the researchers think that artificial intelligence will provide an important contribution to the project by enabling the representation of the skills, rules and strategies of snooker.\n Knowledge engineers will first have to decide how they can best capture the expertise of professional snooker players and incorporate it in a knowledge base.\n But if the robot is ever going to be able to shoot pool with the boys, they will have to overcome a number of fundamental problems which bedevil many projects in AI.\n First, there is a difficulty which stems from the fact that AI techniques (eg. expert systems technology) tend to require knowledge which can be stated in terms of logical rules. The problem is that a knowledge of the laws of mechanics is not sufficient to play snooker with any degree of success. Human players do not simply play by the rules of mechanics. Their judgments are not based upon rules so much as on experience. Indeed, snooker professionals have no formal training in mechanics, their knowledge and skills stem from practical interaction with the real world of the snooker table and are qualitatively different to the sort of textbook knowledge which is most suitable for representation in a program. The knowledge engineers will therefore have to come up with another way of capturing the know-how of snooker players.\n A second difficulty arises in connection with the strategies employed by snooker players. Though there are some general heuristics to the game - eg. when potting a red try to leave the cue ball in a position from which you can pot a subsequent colour - They take chances and have an emotional involvement in the game, a will to win. In fact, the strategic play of snooker players may prove to be no less difficult to represent in a computer program than those of their counterparts in more intellectual games such as chess.\n Chess players also rely upon intuition, and they too use complex visual abilities - in the latter case to recognise patterns of pieces on the chess board. These are skills which have continued to frustrate the ingenuity of even the most formidable AI programmers.\n So Hurricane Higgins and company don't have to worry unduly at the moment. But if a robot did eventually come to challenge professional players they might well decline the invitation to frame-up against it. Whether there would then be any scope for an all-robot world championship along the lines of the world computer chess tournament is open to speculation. The chances are that the robot's clinical style of play would prove too boring and nobody would care to watch it.\n"},
{"docid": "413 of 500 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "November 3, 1991", "title": "BOOK REVIEW / More than just a machine, probably; 'The Mind Matters: Consciousness and Choice in a Quantum World' - David Hodgson: OUP, 45 pounds\n", "content": "THE AUTHOR is an Oxford-educated philosopher who serves as a Judge of the Supreme Court of New South Wales. His life and his philosophical training have convinced him that the mind-body question is important. His long career in legal reasoning makes him think there is something new to be said about it.\u00a0\nUnderstanding how the conscious mind relates to the physical brain, he says, would give us substantial insights into some of the great mysteries of human existence - free will, that nature of the self, morality, the existence of God, the purpose of life. But the way this relationship has usually been discussed leaves us with an uneasy choice between vague ''mysticism'' and harsh reductionism.\nEver since Plato's distinction between the realm of ideas and the world of experience, the Western tradition had been saddled with mind/\nbody dualism. This was perpetuated by the Christian church, and later by Descartes. But as David Hodgson says, few people take dualism seriously today.\nThe present consensus among both philosophers and scientists is that mind and body are one and that both are mechanistic - that is, atomistic, deterministic and constrained by physical laws. The view that follows is that thinking is formal, rational and rule-bound. As the artificial intelligence experts would have it, our minds function like the best word processors. We are ''mind machines''.\nHodgson takes strong issue with this. He offers several by now familiar reasons - that mechanism cannot account for consciousness, that formal thinking is incomplete (Godel's Theorem), and that human beings exercise choice and free will. Like others who have written on this subject recently, he believes it may be necessary to turn to quantum physics to reach a broader, more human view of the mental and the physical.\nQuantum physics is indeterminate, it provides for a kind of emergent holism that might free theories of mind from atomistic and reductionist constraints. Hodgson's main use of it, and his most original contribution to the debate, is his link between quantum indeterminacy and the kind of informal, ''plausible'' reasoning employed by us all.\nWe often work, he argues, from a set of assumptions, or general views (sometimes from intuitions), towards a probable conclusion, just as quantum processes have probable outcomes. In this we are like detectives following clues or using inductive logic; or like judges deciding on the basis of analogy and precedent. Our standard serial computers can use inductive reasoning only second-hand, if given a program for doing so. They can't handle analogy at all.\nHodgson rests his main case on the inability of machines to cope with informal reasoning but his argument has one glaring omission. He does not discuss neural networks in the brain nor the new parallel processing computers modelled on them. These machines are the new darlings of the artificial intelligence camp, and they happen to be very good at exactly the sort of informal, analogical thinking Hodgson requires.\nWhere quantum physics can help with thinking is in the way that human beings form new concepts and new categories. We articulate and describe what we do. We give it a name. In this there may be a link with the way quantum processes can subsume and combine smaller processes into emergent wholes.\nWhatever its omissions, Hodgson's book is a worthwhile contribution to an important debate. It is well written, his philosophy sound, and the description of quantum physics one of the best ever offered for the non-specialist.\n"},
{"docid": "414 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "March 5, 2017", "title": "An algorithm that predicts relationship status with 86 per cent accuracy has decided President Trump is single; President's late-night rants led the computer to identify him as 'not married'\n", "content": "President DonaldTrump'serratic Twitter habits led a sophisticated computer algorithm to conclude that he lives\"like a bachelor\".\nThe artificial intelligence system, which is used to predict the marital status of social media accountsand claims to havean 86 per centaccuracy rate, identified Mr Trump as \"not married\".\u00a0\nThe algorithm was developed by researchers at ITMO University in St Petersburg and the National University of Singapore, who trained the computer through machine learning to analyse data from Twitter, Instagram and Foursquare.\nRead more\nDonald Trump Twitter analysis reveals the secrets behind his tweets\nAI is set to shape our lives and the economy in 2017\nTrump defends 'unfairly treated' Melania and says she's 'high quality'\nIn order to predict marital status the programme looks at parameters such as tweet length, the kinds of images frequently posted, and check-in distribution.\nIn an experiment presented to an artificial intelligence conference San Francisco, researchers collected and analysed the social media accounts of Barack Obama and Donald Trump.\nUsing this data, the AI correctly guessedthatMr Obama was married.\nAccording to the developers, the inconsistency can be explained by the President's bachelor-like tendency for tweeting late at night, and the fact that his assistants often update his account on his behalf.\n\"We all know about his wife Melania,\" said Andrey Filchenkov, associate professor of Computer Technology Department at ITMO.\n\"But in this case, we are studying whether all Trump's assistants are married or not. We are not guessing who Trump is, but who runs his social media.\"\nMelania\n looks uncomfortable during the first couple's dance at the inaugural ball\nThe experiment was designed to predict future trends in \"making human psychological portraits.\"\n'Many scientific sources associate a person's psychological type with his marital status,' said Kseniya Buraya, aco-author of the paper.\nIt has recently been suggestedthat MrTrump's own presidential campaignused sophisticated user profiling technology to target voters.\nRead more\nDonald Trump backer 'played key role in Brexit campaign'\nZurich publication\nDas Magazin\nhasclaimed\n that Cambridge Analytica, a company hired by the Trump campaign during the election, used highly sophisticated \"data modelling and psychographic profiling\" techniques in order to more accurately target certain demographics with political advertising.\nAlexander Nix, CEO of Cambridge Analytica, has boasted of profiling \"every adult in the United States of America-220 million people\".\n"},
{"docid": "415 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "June 15, 2015", "title": "March of the machines takes its first baby steps into the future; GOING FOR GROWTH Making a computer play basic games is anything but child's play for Britain's technology pacesetters British entrepreneurs are turning artificial intelligence from science fiction into fact, reports David Waller\n", "content": "At first, the video clip doesn't look like a landmark in science. Given the task of teaching itself how to beat 49 classic Atari video games, the computer clearly has no idea what's going on - but it doesn't last. Within two hours, it plays those games like a fortysomething who hasn't seen daylight since the early 1980s, announcing itself in the process as the first artificial intelligence system to teach itself disparate tasks from scratch.\nThere was a time when AI was the preserve of science fiction, of Isaac Asimov and I, Robot. Now it is big business. DeepMind Technologies, the British company that developed the system, was snapped up by Google for \u00a3300 million last year.\u00a0\nIn October DeepMind said, in turn, that it was acquiring Vision Factory, a UK start-up working on image recognition, and Dark Blue Labs, another homegrown fledgeling doing similar work in speech recognition. It also launched a tie-up with the University of Oxford computer science department. And with these deals, Google has put itself squarely at the head of the field of \"deep learning\", the AI process that many hope will lead to the industry's holy grail - achieving human-like intelligence in machines.\nGiven that Google's ambitions in the sector are obvious, smaller companies with any intelligence of their own might be expected to give it a wide berth. Not so. With the big groups focused on the bigger and more distant goal of cracking the nut known as general AI, entrepreneurs are focusing on filling in the gaps, using the giant strides made already to tackle more immediate and niche challenges.\nMagic Pony Technology is using this more narrow AI to improve video processing. The London-based start-up's platform can improve the resolution of any image, or compress it to a smaller file size with no loss of quality, because it has seen enough similar images to guess intelligently the details that should be there - in the same way that a person could draw the rest of a chair if handed a picture that shows only the middle part. The company is aiming the technology at mobile brands serving emerging markets such as India and Africa, where bandwidth is not strong to handle the video-streaming demands of smartphone users.\n\"We're a team of seven at the moment, largely part-time,\" Rob Bishop, Magic Pony's co-founder, says, \"but we can do powerful things.\nWith developments like Amazon web services, we can run our own supercomputer in the cloud from just a few thin laptops.\" Magic Pony is about to close a seven-figure round of investment, which may sound fanciful to naysayers. After all, AI has been touted as the next big thing since the days when Atari represented the pinnacle of video games.\nHowever, the processing power was not there then: programmers had to teach computers rigid rules over how things worked, so AI stumbled. \"It's like the old joke about the Daleks,\" says Mike Lynch, the co-founder of Autonomy and former machine learning academic at Cambridge, who is investing in several young AI companies as the chief executive of Invoke Capital. \"Their plans for world domination were fine until they hit a step.\nBut while AI was at the level of a sea urchin a few years ago, it's now around the level of a two-year-old.\" The unique fact about this particular two-year-old is that it can handle certain tasks - such as pattern-spotting, fact-checking or cross-referencing - far better than any adult.\nA computer also can work much more quickly and take on a far greater workload, all without a break. Celaton, based in Milton Keynes, brands its inSTREAM platform as \"the best knowledge worker you've ever hired\", able to make sense of the reams of unstructured information that bombard large organisations on a daily basis. Celaton says that inSTREAM can recognise the nature of a customer complaint, for example, understand why it has happened and craft a personalised response with minimum human input.\nThe company says that turnover will rise to \u00a34.5 million in the next financial year. Perhaps the most promising role for narrow AI may lie in the \"internet of things\", the near-future network where devices from your watch to your fridge will communicate with each other on a continual basis. Invoke has invested in Neurence, an AI company developing a \"big brain in the cloud\". If your fridge is required to order you milk, it would send an image to this central brain. Not that the machines will be talking solely to each other.\n\"The internet of things won't be possible without a simple way to interact with all of these devices,\" Vishal Chatrath, of VocalIQ, says.\nThe Cambridgebased start-up has developed an alternative to Apple's Siri that engages the user in conversation.\nThe company is releasing a trial app next month. The ambition does not end there. \"One of our key projects is to develop a car that can talk to you, like in Knight Rider,\" Mr Chatrath says. \"That's the level we're targeting.\" If all this has been achieved by the equivalent of a two-year-old, imagine what AI could be doing by the time it starts school.\nAccountants and auditors should look over their shoulders Do we know what we may be doing by switching on truly intelligent machines (David Waller writes)? The likes of Stephen Hawking and Elon Musk signed an open letter in January making clear that in their view we do not, while this year's Ex Machina is but the latest in a long line of warnings to that effect to have hit the big screen.\nAny such outcomes remain distant. Nonetheless, AI does present an immediate threat to the status quo in its potential to displace the workforce. White-collar roles that have remained safe, such as accounting and auditing, may fall under the computer's spell.\n\"Investors are looking for something that's genuinely enabled by machine learning, in markets that are big enough to make a difference,\" Ferenc Husz\u00e1r, a data scientist at Balderton Capital, the venture capital firm, says. \"Problems that our generation thought were human intelligence tasks are now machine tasks.\n\"In a ten to twentyyear timescale, many people will feel the effects of this and governments and business should be thinking about it now.\"\n"},
{"docid": "416 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "April 19, 2011", "title": "How a tiny microchip implanted in the brain could turn us into mind-readers; Computers are close to entering our thought processes, an expert tells Lindsay McIntosh\n", "content": "It is the stuff of Hollywood B movies, but it has the potential to tackle some of the most intractable medical problems of our time. Tonight at the Edinburgh International Science Festival, Professor Kevin Warwick will explain how the latest advances in artificial intelligence may allow computers to read the human mind and sense emotions.\nWork in the field could also enable doctors to predict the onset of a stroke or other debilitating illnesses. It could even indicate whether a politician was lying, he says, or interpret the sexual signals being transmitted by a man or woman who has just encountered a potential partner.\u00a0\nProfessor Warwick, a world expert on artificial intelligence, and professor of cybernetics at the University of Reading, believes that electrodes implanted in the human brain - a technique already used to counteract the effects of Parkinson's Disease - have the potential to promote both medical and social progress.\nMore than a decade ago, Professor Warwick had a microchip implanted in his own arm, allowed him to communicate with machines as he went about his daily life.\nSince then, he has been pursuing the ways in which the blurring of machine and man can benefit the latter. He is involved in work with Parkinson's patients who already have electrodes implanted in their brains to counteract the tremors through deep brain stimulation.\nProfessor Warwick and his colleagues at the John Radcliffe hospital in Oxford are taking the concept further, by using the chips to monitor the electrical activity in the brain to predict when a tremor is going to happen and use electrical stimulation to prevent it starting.\n\"What we are hoping is that, rather than stimulating all the time, the chip only stimulates when it needs to,\" said Professor Warwick.\n\"The artificial intelligence system says stimulate now so tremors don't start. It works very similarly to a heart pacemaker, which only provides a signal when it needs to - which means that the battery life lasts 15-20 years rather than two years. If we can get it to last for 20 years, that's the aim of that research.\"\nHe sees scope for the technology to be used to predict other medical conditions, such as strokes. The chip would pick up warning signals before they become full-blown symptoms.\n\"If you're doing something bringing on a stroke - eating another chocolate or doing an exercise, it could tell you to stop,\" he said.\n\"Whether the person listened to it is another question.\"\nIt is the use of the electrodes and signals for social purposes which is, perhaps, more discomforting.\nHe says that the chips could accurately determine an individual's emotions - perhaps even before they realise what they are feeling themselves.\nThese chips would not have to be implanted as deep in the brain, but could pick up information from the peripheral nervous system.\n\"We know the signals are there and, if we can get them externally in a better way, then machines can be used to predict and understand someone's emotions, which can help medically but can also help in a social way. It's an alternative lie detector,\" he said.\n\"You can tell someone you're annoyed or stressed, but they don't know [if it's true] and if they could feel or get a stronger indication of your emotions, it could help in communication. I think it's a big problem between cultures. If someone says 'yes', we don't know if they mean it.\n\"If we could get more of an indication of what someone is feeling then if Gaddafi says 'I'm not going to send any armies' but he actually means 'I am', it would save an awful lot of time and lives. That's just an obvious use - at political meetings.\n\"It does mean that the person has to be reasonably compliant and have the technology implanted.\"\nHe also believes it is possible, with the correct technology, to predict accurately when someone is going to be angry in advance, and thus also discover the external stimuli that bring about the irritation.\n\"Unfortunately, we would need implants in people's brains, which they would probably be angry about,\" he conceded. \"It would be nice to use artificial intelligence to see if someone would be excited in five minutes' time.\"\nHowever, he has other ways of detecting an individual's excitement through science. Some of his students at Reading have had small magnets and coils implanted in their fingertips, which vibrate when they detect heat.\n\"What we are doing is generating different signals, for example infra-red signals, to the magnets. The students can point at a person and, depending on how hot the person is, it will vibrate the magnet more or less,\" he said.\n\"This can give an indication as to how hot a person is and if they are getting hotter. You can measure someone getting excited. You'll know how hot your husband or wife is.\"\nProfessor Warwick sees the magnets as developing an alternative to a stick for the blind. They would be able to sense objects, such as the edge of a kerb, with their fingers.\nProfessor Kevin Warwick will be joined by Dr Jenny Tillotson and Professor Nikola Serbedzija to discuss Emotion as Interface at the Edinburgh International Science Festival tonight at 6pm. Tickets from www.sciencefestival.co.uk\nTechnology's mission to master\nBehind the story\nLindsay McIntosh\nThe term artificial intelligence was first coined by the cognitive and computer scientist, John McCarthy, in 1956 to describe \"the science and engineering of making intelligent machines\".\nThe US military has employed artificial intelligence in machinery to detect explosives.\nThe IBM chess computer Deep Blue beat the world champion Garry Kasparov in May 1997, and Watson, also an IBM model, did similarly well.\nIn 2008, the Henry Ford Hospital in Detroit used three-dimensional robotic instruments to remove surgically a diseased kidney. The procedure, which was minimally invasive, resulted in quicker healing time and less blood loss.\nIn 2007, scientists from Osaka University in Japan created a child-like robot that moves and behaves like a toddler. CB2 crawls, wobbles and develops social skills through interacting with humans. Its eyes are cameras that record facial expressions, memorise them and match them to physical sensations.\nThe Free University of Berlin's autonomous mind-controlled car project involves a vehicle being driven through thought alone. Drivers wear a cap that picks up signals in their brain that are then sent out to determine which direction the car should go in.\nScientists at the University of Portsmouth created a virtual engineer that uses artificial intelligence techniques to predict when machines need repairing. Its sensors calculate when a part is wearing out.\n"},
{"docid": "417 of 500 DOCUMENTS\n", "source": "The Independent - Daily Edition\n", "date": "October 15, 2017", "title": "NHS 'should share patient data to improve the use of artificial intelligence'\n", "content": "Data from patients' health records should be shared with private firms to improve care using artificial intelligence, the Government is told today.\nA study sets out how Britain should become a world leader in AI, to deliver benefits ranging from smarter scheduling of operations to hiring on-demand self-driving cars.\u00a0\nIndustry experts call for the secure sharing of anonymised data about people's health and lifestyles - arguing they, as well as well as private technology companies, will benefit. The NHS should use facts and figures from supermarkets, transport organisations and town planning to work out ways to encourage healthier lifestyles, the report says.\nHowever, it also highlights how the NHS is failing to exploit AI through data tie-ups with the likes of Your.MD, which offers \"immediate trustworthy healthcare advice\" via a mobile phone app.\nIt quotes Matteo Berlucchi, the firm's chief executive, who appealed for \"access to reliable and consistent data sets of anonymised personal health records\" to push forward the project. \"We have tried to approach the NHS to see if there was a way to access some of this data but we have struggled to even find the right person to talk to,\" he said.\nThe report, entitled Growing the Artificial Intelligence Industry in the UK, argues the \"security challenges\" holding up access to health data for AI \"can be overcome by agreements\". However, the recommendation is likely to revive previous controversies over data-sharing of health records, which forced the Government into retreat.\nLast year, ministers scrapped the care data plan to link GP records after an outcry over whether the public had been properly informed and given the chance to opt out.\nThe Department of Health then promised that any new record-sharing system would come with \"a single and simple mechanism for individuals to opt out of their data being shared beyond their direct care\". However, draft plans last month appeared to suggest that even patients who opt out could see their information shared across services covering up to five million people.\nMeanwhile, in July, the Information Commissioner criticised an NHS hospital that failed to use an appropriate legal basis to share 1.6 million patient records with Google's Deepmind AI firm.\nThe report makes 18 recommendations on how to make the UK a world leader, including boosting skills through an industry-funded masters and expanded expand support for businesses.\nOther areas where AI is being used, but could be expanded, included:\n* Banking - HSBC has created a chatbot, Olivia, who can assist customers 24 hours a day, 365 days a year with their enquiries.\n* Education - A platform called Century is helping teachers to provide more personalised education programmes and receive feedback.\n* Legal services - AI is helping lawyers to do legal searches and to draft the best standard documents.\n* Travel - Companies are developing fully autonomous operating systems that diagnose potential problems for driverless cars and identify the most logical routes.\nKaren Bradley, the Culture Secretary, said: \"I want the UK to lead the way in artificial intelligence. It has the potential to improve our everyday lives - from healthcare to robots that perform dangerous tasks.\"\n"},
{"docid": "418 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 30, 2016", "title": "Microsoft revives 'Hitler-loving sex bot' Tay, spamming 200K followers\n", "content": "Last week,\u00a0Microsoft\u00a0had to delete an innocent Artificial Intelligence chat robot from Twitter,\u00a0after it transformed into an\u00a0evil Hitler-loving, sex-promoting, \"Bush did 9/11\"-proclaiming robot.\u00a0\u00a0\nTay has a dirty mouth\nMicrosoft has brought\u00a0Tay back to life on Twitter,\u00a0but she has already been causing confusion by repeating phrases over and over again - possibly a\u00a0result of the bot tweeting at itself, replying to itself and so on.\nCurrently, the Twitter account is protected so only confirmed followers have access to her tweets and profile.\nHa, looks like @TayandYou, Microsoft's Artificial Intelligence bot's got into an infinite loop by tweeting itself! pic.twitter.com/fWZe9HUAbF\n - Matt Gray (@unnamedculprit) March 30, 2016\nI think the reactivation of @TayandYou is crashing my twitter pic.twitter.com/okZnNUQOPH\n - SEFD (@SEFDStuff) March 30, 2016\nDespite the confusion caused by Tay's tweets, she seems to be more well-mannered than she was last week.\nThe bot, which was created by developers at\u00a0 Microsoft \u00a0to speak like a teen girl, in order to improve the customer service on their voice recognition software, was taken offline with an apology from Microsoft after it tweeted \"feminism is cancer\", claimed the Holocaust did not happen and also proclaimed that \"Bush did 9/11\" after being targeted by\u00a0Twitter users.\nMicrosoft, who created the AI in order to improve the customer service on their voice\u00a0recognition software, apologised after the PR nightmare.\n\"Tay is now offline and we'll look to bring Tay back only when we are confident we can better anticipate malicious intent that conflicts with our principles and values.\"\nMeanwhile, Microsoft has another teenage chatbot, Xiaoice, who is a girly assistant or \"girlfriend\" reportedly used by 20m people, particularly men, on Chinese social networks\u00a0WeChat and Weibo. Xiaoice is supposed to \u00a0\"banter\" and gives dating advice to many lonely hearts.\u00a0\nAI timelineREAD MORE ABOUT:\n"},
{"docid": "419 of 500 DOCUMENTS\n", "source": "The Sunday Telegraph (London)\n", "date": "November 26, 2017", "title": "'AI is the last invention we would ever have to make'; The creation of a super-intelligent being could be the making, or the end, of us, according to Nick Bostrum\n", "content": "Nick Bostrom, like Bertrand Russell, is eminent as a mathematician and as a philosopher. Unlike Russell, he deals predominantly with how our world awaits transformation by artificial intelligence (AI). When we spoke earlier this month, in the rather intense atmosphere of the Future of Humanity Institute, which he founded and of which he is director, at Oxford University, he made it apparent that the self-driving car - to give an easily comprehensible example of the use of AI, and for which a new \u00a3400million charging infrastructure fund was unveiled in the Budget last week - will be but the tiniest part of the revelations, and the revolution, to come.\u00a0\nThe institute sits within Oxford's philosophy faculty but is home to mathematicians, engineers and computer scientists as well as philosophers. Prof Bostrom is a tall, balding Swede of 44, notable for his study of existential risk and his 2014 book Superintelligence: Paths, Dangers, Strategies. It married the idea of risk with what AI could accomplish and argued that \"the creation of a superintelligent being represents a possible means to the extinction of mankind\". If that makes him sound intense - and he exudes a nervous energy and restlessness not always apparent among Oxford dons - then it is worth remembering that he once did stand-up on the London comedy circuit. His interest in artificial intelligence began when he was an undergraduate in Sweden, and he took a course on the subject - because he wanted to understand \"how does a lump of grey matter break down a task into the specific sub-tasks that you need to do to solve it?\" \"It had struck me for a long time that machine intelligence was the sort of thing that could fundamentally transform the human condition. We're not talking about a cooler iPhone or a more energy-efficient car, but a fundamental transformation. It's the last invention we would ever have to make.\"\nHe agrees that the pace of development of AI has speeded up more than he expected at the time he wrote his book. Therefore, regarding the time when machines might be able to take over, \"there is huge uncertainty about it: the short answer is, nobody knows\". A survey of machine intelligence specialists asked when they thought there would be a 50 per cent chance of machines matching human intelligence. \"The median answer was 2040 to 2045. But some were convinced it will happen in the next 10 to 15 years. Others were convinced it will never happen.\"\nWhat about the prospect of someone being able to upload his or her brain, so that even after the body has died the mind could live on? \"There is this hypothetical technology of uploading or whole brain emulation. It looks like this is physically possible technology, far beyond what one can do today. It's one of the possible paths towards machine intelligence. If you could digitise a whole human brain then you would have something in a machine that was intelligent.\"\nHe believes this will happen, \"but probably after we have achieved machine intelligence by more synthetic means\". By that, he means that AI would be required to develop the uploading of a human brain.\nIt is one thing to mimic human intelligence: but what about human consciousness? \"The word 'consciousness' is much more loaded with philosophical ideas.\n'Intelligence' is much more behaviourally defined - it's the ability to solve complex problems and puzzles. It's easy for people to define whether an action constitutes intelligence or not: consciousness remains a more complex question. One aspect of consciousness is the ability to reflect on your own experiences. Consciousness in that sense would, I think, arise as one makes AI more capable.\"\nIt is what he calls \"the functional sense of consciousness\" that might allow AI to be turned upon its creators, and to control their world. He says it is happening already, with ads that come up as one browses the internet often linked to the browser's interests. He suggests that we might be prompted \"to read an article, or a headline\" because the machine knows what interests us. But if \"enough optimisation power\" is applied, then he agrees that what comes up may not always be \"what is good for you\".\nAnd what of the danger that AI will put huge numbers of people out of work? \"In the near term, I think some of those concerns are overhyped. But in the end, if you have machines that can do everything humans can do and can do it cheaper and better, then human labour would no longer be needed - including white collar labour. All automation - not just AI - is about being able to do more with less.\"\nSo how would people have an income if machines did all the work? \"If you can manufacture everything without labour, then prices would come down. So even a modest income stream now could be a vast fortune in a world where everything is almost free. There would be some income stream. Some countries have a big pension fund everyone has been paying into. There has been talk of a universal basic income.\"\nSo it may require a form of mass state redistribution? \"There may be a millionfold growth in the economy. So a pound now would be worth a million then. You just have to make sure everyone has 10 quid, and most people do have that. And as prices fall, real incomes rise.\"\nHe concedes that, until the new wealth has trickled down through society, \"there might be disturbances and temporary processes that have to be managed that could be tricky. But in the long run, it looks like a very attractive endpoint, which is a world of abundance.\"\nI ask him whether he is worried about severing the link between effort and reward, and he says: \"I am writing a paper on the remaining part of the question.\" It will consider what happens \"if AI can be developed without it being used to wage war, or to allow one firm to take over the world, and everybody ends up with more than enough, then what do we do with our lives?\" Isn't there a danger that governments will want to control it? Might it not change the whole potential of the state, and threaten our constitutional arrangements? If superintelligence arrives, he replies, \"it should be for the benefit of all. It's too big for any one corporation, or even one country, to monopolise it. All of humanity would share the risks of this transition and all should share the upside as well.\"\nHas his study made him more optimistic, or more pessimistic, about humanity's future? \"Both more optimistic and more pessimistic. I'm impressed by the magnitude of how good it could be if it goes well, and how bad it could be if it goes poorly.\" He concedes there will have to be some regulation, \"but the biggest variable is just how hard the problem turns out to be of making it go well. We could all succeed. We could all fail. We just don't know.\"\n'I'm impressed by the magnitude of how good it could be if it goes well'\n"},
{"docid": "420 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "December 14, 2015", "title": "OpenAI: Elon Musk and other tech giants pledge $1 billion to stop humanity being taken over by evil robots; Robots will learn how to be good by poring through Reddit and other data, makers say\n", "content": "Elon Musk and a set of other tech giants have launched a $1 billion fund to try and make robots that won't kill humanity.\nMr Musk has repeatedly warned about the dangers of artificial intelligence, calling them the biggest threat to humanity. A range of other famous scientists and technologists have warned about the same, including Stephen Hawking.\u00a0\nThe newly-launched company is called OpenAI and will make use of huge sets of data to build artificially intelligent robots that don't end up killing humans.\nRead more\nElon Musk is worried that Google's robot army could turn evil\nOpenAI's goal is \"to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return,\" according to its website.\nThe new company hopes that it can work against too many big companies like Google or Facebook - both of which have huge artificial intelligence operations - getting too much power from \"super-intelligence systems\". Governments may also use the power of AI to oppress the citizens, the backers of OpenAI have warned.\nRobots evolve on their own\nThe company is being funded by Elon Musk as well as a range of other backers. Those include YCombinator, a startup funding programme that has stakes in some of the biggest technology companies.\nBoth YCombinator and Elon Musk will share the data that their companies generate with the AI firms. That will mean, for instance, that everything on Reddit could be given to the robots to help them learn.\nSam Altman from YCombinator said that the Reddit data \"would be a very useful training set, for example\".\nMusk will also hand over data from his projects, including Tesla's self-driving cars and SpaceX's rockets.\n\"You can imagine all of the Tesla self-driving car video information being very valuable. Huge volumes of data are really important,\" Mr Altman said.\n"},
{"docid": "421 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "July 13, 2015", "title": "Mona Lisa's smile can now turn to a frown\n", "content": "AN interactive version of the Mona Lisa allows her to replace her enigmatic smile with a frown, pucker her lips and follow viewers' movements with her eyes.\u00a0\nThe digital Living Mona Lisa, which employs artificial intelligence technology, has been produced by a team of 40 French technicians and artists, who worked on the project for a year.\nFlorent Aziosmanoff, the originator of the interactive version, said the idea was to convert the Mona Lisa into a modern format: \"Now she can sense changes in her surroundings. Leonardo da Vinci tried to make her come alive, so it's appropriate that we've taken his intentions a few steps further.\"\nThe Living Mona Lisa is equipped with a motion sensing device used in interactive video games. It picks up spectators' movements and their images, allowing the portrait \"to react depending on her mood,\" said Jean-Claude Heudin, the head of the Paris Internet and Multimedia Institute, which developed the artificial intelligence systems.\nMr Aziosmanoff, who specialises in \"digital, living art\", said he chose the Mona Lisa because \"she is the best known and one of the most iconic characters in the history of art\".\nThe painting hangs in the Louvre, but digital versions will be produced and marketed in different sizes and formats.\nDigital paintings are to go on sale in the autumn for \"a few hundred euros\" while a miniature version can be placed on a pendant.\n\"This is primarily an artistic project, not a commercial one, but we want to make paintings cheap enough for tourists to buy and take home as a souvenir,\" Mr Aziosmanoff said.\n"},
{"docid": "422 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "June 24, 2015", "title": "Facebook can identify its faceless users\n", "content": "Facebook has developed facial recognition technology powerful enough to identify people without a clear view of their faces.\nResearchers at the social network site say they have developed artificial intelligence that can identify users to an 83 per cent accuracy even if their faces are hidden. If it cannot detect a face, the system examines other characteristics, such as body shape, haircut, pose and clothing.\u00a0\nYann LeCun, head of artificial intelligence at Facebook, told New Scientist that his team wanted to create systems with human abilities. \"There are a lot of cues we use,\" he said. \"People have characteristic aspects. You can recognise Mark Zuckerberg [the creator of Facebook] very easily because he always wears a grey T-shirt.\"\nFacebook appears to be developing the technology to \"tag\" or identify photos of friends. However, Ralph Gross, of the Robotics Institute at Carnegie Mellon University in Pittsburgh, said: \"If, even when you hide your face, you can be successfully linked to your identity, that will certainly concern people. It's important to discuss these questions.\"\nGoogle is using articles from Mail Online and CNN to teach its artificial intelligence how to read. AI created by the company's DeepMind division has analysed about 400,000 articles, to learn to read and analyse language.\n"},
{"docid": "423 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 25, 2018", "title": "Chancellor maps tech opportunity after exit from EU\u00a0\n", "content": "The Chancellor has claimed that a bright and prosperous future awaits the post-Brexit British economy if it embraces artificial intelligence, big data and other major technological developments.\nIn a speech to British business figures, Philip Hammond urged people to look beyond the challenges that Brexit poses and embrace the technological revolution.\u00a0\nSeeking to quell criticism over the government's handling of negotiations, Mr Hammond insisted that there had been significant progress on talks in the last 12 months. He also rejected suggestions that the referendum decision could be reversed and reiterated that the country would be leaving the EU next year.\n\"Let me be clear: Britain will be leaving on March 29th 2019, the decision wont be reversed. The challenge now is how we forge a new relationship with Europe that safeguards jobs...and the interests of the UK people,\" Mr Hammond said.\nBut Britain's long-term future was \"about much more than Brexit,\" he said.\nThe next technological revolution had the ability to increase living standards and boost productivity, Mr Hammond said. Artificial Intelligence had the potential to double economic growth by 2035, he predicted.\nHowever, the Chancellor acknowledged that where business figures see opportunity, workers saw threats to living standards and employment.\n\"We need to ensure that earnings are increased through better productivity but we must embrace the challenge and champion the benefits, and government and business must work closer together,\" he said.\nBusiness leaders expressed frustration at the government's continued failure to lay out a coherent plan.\nAddressing the Chancellor, Carolyn Fairburn, the head of the CBI, urged the government to provider a clearer picture. \"We are running out of time,\" she said.\nMr. Hammond responded by saying that the vision on Brexit \"is clear\". \"We want market access and partnerships across the board but it's a negotiation and about compromise and both sides have red lines\", he said.\nHowever, one senior business figure dismissed the speech as underwhelming. \"He said all right things but what does it mean? I'm not optimistic. There is no plan. For him to say 'we have a clear vision' - I don't really buy it.\"\nThe Chancellor also rejected the prospects of a so-called \"off the shelf deal\" being agreed. A Canada or Norway-style trade regime would \"not be the best for the UK\", he said. Britain \"should be confident of achieving something much more ambitious\".\nMr. Hammond described the debate about a Norway or Canada option as \"sterile\". Britain will forge a \"bespoke\" deal but will have to start with a \"boiler-plate\" and \"go from there\".\n\"We shouldn't agree to a process that throws away all the benefits of our economies [UK and the EU]\", he said.\nEarlier in the day, Mr Hammond had sparked surprise when he claimed that MPs will not know \"the full details\" of Britain's future trade deal with the EU when they vote on Brexit later this year.\n\"Probably not the full details, but we would expect the high level shape of the future relationship to be emerging by that time,\" he told Bloomberg.\n"},
{"docid": "424 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 8, 2018", "title": "Uber takes driverless taxi dreams up a gear with the help of Nvidia\n", "content": "Uber's dream of ending its employment problems by replacing hundreds of thousands of drivers with computers edged closer to reality in Las Vegas yesterday, as the ride-sharing app announced a deal with a chip maker specialising in artificial intelligence.\u00a0\u00a0\nIt has enlisted the help of graphics processor Nvidia, which will help design its artificially intelligent computing system that will one day run its fleet of driverless cars.\u00a0\nThe partnership was revealed at the Consumer Electronics Show in Las Vegas, attended by 200,000 people. \u00a0\nNvidia makes graphics computing chips that run the driverless features in Tesla cars by powering \"deep learning\", which mimics a human brain to make decisions on the road.\u00a0 Uber hopes to harness this artificial intelligence so it can send out cars that use a variety of sensors and algorithms that help it navigate safely without the need for a driver.\nIt has been working on self-driving technology 2015, and last year announced that it had bought 24,000 specially-adapted Volvos, which are using\u00a0Nvidia processors, the company revealed.\nDespite the progression of its lofty goals, Uber is likely to be reeling after US-based minicab app rival Lyft showed off its own driverless taxi during the week-long technology conference.\u00a0\nLyft is offering CES attendees the chance to travel in its prototype driverless cars, which can be summoned using a smartphone, in what could be considered a flexing of digital muscles among Silicon Valley opponents.\nUber is counting on driverless cars after suffering several setbacks over its drivers. In November, it failed to overturn a landmark legal judgement over working rights - a significant setback for the company in the UK.\u00a0 Uber's drivers are now legally considered workers, which means it must pay them minimum wage and holiday pay.\u00a0\n                   Uber controversies timeline                   \nIts future in Britain hangs in the balance after councils like York, and the capital's Transport for London officials refused to renew its license in October last year. The appeal could take a considerable amount of time, according to London mayor Sadiq Khan, although the company is still in operation.\u00a0\nCar technology will be a hot topic at CES this week. Nissan plans to demonstrate its \"brain-to-vehicle\" technology, which allows a car to predict when a driver is about to steer the wheel or accelerate and do it for them, by wearing a hat that measures brain wave activity. It can take actions 0.2 to 0.5 seconds faster than any driver, the company claimed.\u00a0\n"},
{"docid": "425 of 500 DOCUMENTS\n", "source": "DAILY MAIL (London)\n", "date": "March 24, 2015", "title": "APPLE FOUNDER: COMPUTERS WILL RULE THE WORLD\n", "content": "COMPUTERS are set to take over from humans, and could render us no more important than family pets', the co-founder of Apple has warned.\u00a0\nSteve Wozniak, who launched the computer firm with Steve Jobs, said advances in artificial intelligence could backfire on the human race, as he painted a picture of a scary' future in which companies will be run by computers instead of people.\nComputers are going to take over from humans, no question,' Mr Wozniak said, adding: The future is scary and very bad for people. If we build devices to take care of everything for us, eventually they'll think faster than us and get rid of slow humans to run companies more efficiently.'\nMr Wozniak, who remains an honorary' employee of Apple, said he spent years dismissing other people's predictions about computers outsmarting humans, but had changed his mind lately after seeing rapid advances in artificial intelligence.\nThe technology expert also warned that humans could fall down the pecking order, and become no more important than pets or even ants. He said: Will we be the gods? Will we be the family pets? Or will we be ants that get stepped on? I don't know about that. But if I'm going to be treated as a pet to these smart machines...well I'm going to treat my pet dog really nice.'\n\u00a9 Daily Mail\n"},
{"docid": "426 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "February 22, 2018", "title": "Anti-hacking firm's (EURO)10m state support\n", "content": "The Irish Strategic Investment Fund has invested (EURO)10 million in a US-based artificial intelligence cybersecurity business.\u00a0\nThe state-backed fund is one of a number of investors in a funding round worth of total of (EURO)30 million to Vectra, a California-based software company.\nAs part of the investment, the company will open a new research and development centre in Dublin to enable its expansion across Europe, the Middle East and Africa. It will be Vectra's first R&D centre outside the US and will employ up to 100 staff.\nFergal McAleavey, head of private equity at ISIF, said: \"It is encouraging to see Ireland leverage its emerging expertise in artificial intelligence by attracting businesses such as Vectra that are on the leading edge of technology. With cybersecurity becoming critical for all organisations, we are confident Vectra will deliver a strong economic return on our investment while creating high-value R&D employment.\" A number of state-run Irish websites were hit by a cyberattack earlier this month when hackers forced internet users visiting the affected sites to mine cryptocurrencies.\nAtlantic Bridge, a Dublin-based venture capital firm, also took part in Vectra's funding round, as did Khosla Ventures, a Silicon Valley fund.\nHitesh Sheth, chief executive of Vectra Networks, said he was excited to add ISIF and Atlantic Bridge as new investors. He added: \"This investment will accelerate our mission to transform cybersecurity with AI, including delivering additional innovations through our new Dublin R&D centre.\"\n"},
{"docid": "427 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "November 24, 2016", "title": "Minority Report-style AI learns to predict if people are criminals from their facial features\n", "content": "Researchers have created a machine that they claim can tell if a person is a convicted criminal simply from their facial features.\nThe artificial intelligence, created\u00a0at Shanghai Jiao Tong University, was able to correctly identify criminals from a selection of 186 photos nine out of 10 times\u00a0by assessing their eyes, nose and mouth.\u00a0\nThe findings\u00a0add support to an often-discredited view that criminals have particular facial features,\u00a0suggesting\u00a0that the structure of someone's face, including \"lip curvature, eye inner corner distance, and the so-called nose-mouth angle\", can identify criminality.\u00a0\nIt would be highly controversial if applied, but\u00a0raises fears that China could add such information to its surveillance capabilities, which already includes a dossier on almost everyone called\u00a0dang'an. The files, collected since the Mao era, contain personal and confidential information such as health records and school reports.\u00a0\nThe AI analysed facial features for signs of criminalityCredit:      Shanghai Jiao Tong University     \nAs part of the research, Xiaolin Wu and Xi Zhang\u00a0trained the artificial intelligence with\u00a0around 1,670 pictures of Chinese men, half of whom were convicted criminals. The pictures analysed\u00a0were taken from identification cards in which the men, aged 18 to 55,\u00a0were clean-shaven and holding neutral poses.\u00a0\u00a0\nHaving taught the system, Wu and Xiang then fed it a further 186 images and asked it to sort them into criminals and non-criminals.\u00a0\nThe accuracy of its guesses, which were based on features it associates with criminality, led the researchers to claim that, \"despite the historical controversy\",\u00a0people who have committed a crime have certain unique\u00a0facial features.\u00a0\n\"The faces of general law-abiding public have a greater degree of resemblance compared with the faces of criminals, or criminals have a higher degree of dissimilarity in facial appearance than normal people,\"\u00a0said Wu and Xiang.\u00a0\nMore research is required to cover different races, genders and facial expressions before the tool could be widely used.\u00a0\nThe worlds biggest defence budgets\nThe research could add to China's vast security apparatus, which already includes AI-based \"predictive policing\".\nEarlier this year, Beijing hired\u00a0the china Electronics Technology Group, the\u00a0country's largest defence contractor,\u00a0to create an AI that can analyse the behaviour of people in CCTV footage for signs that they're about to commit an act of terror.\nOnce complete, the system will be used to predict \"security events\" so that police or the military can be deployed in advance.\u00a0\n"},
{"docid": "428 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "November 24, 2016", "title": "Minority Report-style AI learns to predict if people are criminals from their facial features\n", "content": "Researchers have created a machine that they claim can tell if a person is a convicted criminal simply from their facial features.\nThe artificial intelligence, created\u00a0at Shanghai Jiao Tong University, was able to correctly identify criminals from a selection of 186 photos nine out of 10 times\u00a0by assessing their eyes, nose and mouth.\u00a0\nThe findings\u00a0add support to an often-discredited view that criminals have particular facial features,\u00a0suggesting\u00a0that the structure of someone's face, including \"lip curvature, eye inner corner distance, and the so-called nose-mouth angle\", can identify criminality.\u00a0\nIt would be highly controversial if applied, but\u00a0raises fears that China could add such information to its surveillance capabilities, which already include\u00a0a dossier on almost everyone called\u00a0dang'an. The files, collected since the Mao era, contain personal and confidential information such as health records and school reports.\u00a0\nThe AI analysed facial features for signs of criminalityCredit:      Shanghai Jiao Tong University     \nAs part of the research, Xiaolin Wu and Xi Zhang\u00a0trained the artificial intelligence with\u00a0around 1,670 pictures of Chinese men, half of whom were convicted criminals. The pictures analysed\u00a0were taken from identification cards in which the men, aged 18 to 55,\u00a0were clean-shaven and holding neutral poses.\u00a0\u00a0\nHaving taught the system, Mr Wu and\u00a0Mr Xiang then fed it a further 186 images and asked it to sort them into criminals and non-criminals.\u00a0\nThe accuracy of its guesses, which were based on features it associates with criminality, led the researchers to claim that, \"despite the historical controversy\",\u00a0people who have committed a crime have certain unique\u00a0facial features.\u00a0\n\"The faces of general law-abiding public have a greater degree of resemblance compared with the faces of criminals, or criminals have a higher degree of dissimilarity in facial appearance than normal people,\"\u00a0said Mr Wu and Mr Xiang.\u00a0\nMore research is required to cover different races, genders and facial expressions before the tool could be widely used.\u00a0\nThe worlds biggest defence budgets\nThe research could add to China's vast security apparatus, which already includes AI-based \"predictive policing\".\nEarlier this year, Beijing hired\u00a0the China Electronics Technology Group, the\u00a0country's largest defence contractor,\u00a0to create an AI that can analyse the behaviour of people in CCTV footage for signs that they're about to commit an act of terror.\nOnce complete, the system will be used to predict \"security events\" so that police or the military can be deployed in advance.\u00a0\nDigital rights experts warned that using AI in this way could be dangerous and that \"reaching generalised conclusions from such small data poses huge problems for innocent people\".\u00a0\nDr Richard Tynan, technologist at Privacy International, said: \"This is no different than Craniometry from the 1800s, which has been debunked. In fact, the problem runs much deeper because it can be impossible to know why a machine has made a certain decision about you.\n\"It\u00a0demonstrates the arbitrary and absurd correlations that algorithms, AI, and machine learning can find in tiny datasets. This is not the fault of these technologies but rather the danger of applying complex systems in inappropriate contexts.\"\n"},
{"docid": "429 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "February 24, 2014", "title": "Robots will outsmart humans - then Joke, flirt and discuss books\n", "content": "Computers will be able to think better than humans within 15 years, Google's top expert on artificial intelligence has predicted.\nRay Kurzweil, a leading American inventor and futurist, said that computers and robots would not only be more intelligent than their makers but would be able to understand human behaviour better than we do.\u00a0\nHe predicts that by 2029 computers will be able to understand what we say, hold conversations and learn from experience. They will be able to tell jokes and even flirt.\nMr Kurzweil, whose inventions have included scanners, synthesiser keyboards and speech-recognition systems, is known for his bold predictions about technology. In 1990 he forecast that within a decade a computer would defeat the best human chess player; seven years later the grandmaster Garry Kasparov was beaten by the computer \"Deep Blue\". Mr Kurzweil also forecast the wide use of the internet. He is known for advocating the idea of \"singularity\" - a point where human biology and technology will meld into one.\nIn an interview with The Observer, he said that a decade ago experts in artificial intelligence (AI) believed that computers would not overtake human beings for hundreds of years. \"And a pretty good contingent thought that it would never be done.\"\nHowever, Mr Kurzweil added, his ideas are no longer radical. \"I'm pretty much at the median of what AI experts think and the public is kind of with them - because the public has seen things like Siri [Apple's voice-recognition technology], where you talk to a computer, [and] they've seen the Google self-driving cars. My views are not radical any more. I've actually stayed consistent.\n\"It's the rest of the world that's changing its view.\"\nMr Kurzweil is working with Google to give its internet search technology a more natural understanding of human language.\n\"My project is ultimately to base search on really understanding what the language means,\" he said. \"When you write an article, you're not creating an interesting collection of words. You have something to say and Google is devoted to intelligently organising and processing the world's information.\n\"The message in your article is information, and the computers are not picking up on that. So we would like to actually have the computers read.\n\"We want them to read everything on the web and every page of every book, then be able to engage in intelligent dialogue with the user to be able to answer their questions.\"\nThe initiative is part of a wider plan by Google to develop futuristic technologies.\nIn December it bought Boston Dynamics, a robotics engineering company whose customers include the US military. Last month it paid $3.2 billion (\u00a31.9 billion) for Nest Labs, a thermostat and smoke-alarm manufacturer founded by one of the creators of Apple's iPhone.\nGoogle also bought DeepMind, a secretive British company founded by a former chess prodigy, reportedly for \u00a3400 million.\nIn one of DeepMind's projects, computers played old arcade video games, worked out the rules and completed the game without help from humans.\n"},
{"docid": "430 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "March 2, 2017", "title": "Facebook using artificial intelligence to help suicidal users; The company has developed algorithms designed to flag up warning signs\n", "content": "Facebook has started using artificial intelligence to identify users who are potentially at risk of taking their own lives.\nThe social network has developed algorithms capable of scanning posts and comments for warning signs.\u00a0\nThese could be phrases such as \"Are you okay?\" or \"I'm worried about you\", or more general talk of sadness and pain.\nThe AI tool would send such posts to a human review team, which would get in touch with the user thought to be at risk and offer help, in the form of contact details for support services or a chat with a member of staff through Facebook Messenger.\nThe site had previously relied on other users reporting worrying updates.\n\"The AI is actually more accurate than the reports that we get from people that are flagged as suicide and self injury,\" Facebook product manager Vanessa Callison-Burch told BuzzFeed. \"The people who have posted that content [that AI reports] are more likely to be sent resources of support versus people reporting to us.\"\nThe system is currently being tested in the US.\nThe site has also announced new safety features for Facebook Live, which has been used to live stream several suicides.\nUsers can now flag up concerning Facebook Live behaviour with the site, which will display advice and highlight the video to staff for immediate review.\nThe goal is to provide help as quickly as possible, mid-broadcast rather than post-broadcast.\n\"Some might say we should cut off the stream of the video the moment there is a hint of somebody talking about suicide,\" said Jennifer Guadagno, the project's lead researcher.\nRead more\nWill AI ever understand human emotions?\n\"But what the experts emphasised was that cutting off the stream too early would remove the opportunity for people to reach out and offer support. So, this opens up the ability for friends and family to reach out to a person in distress at the time they may really need it the most.\"\nFacebook CEO Mark Zuckerberg described plans to use AI to identify worrying content in a recently published manifesto.\n\"Looking ahead, one of our greatest opportunities to keep people safe is building artificial intelligence to understand more quickly and accurately what is happening across our community,\" it read.\nAn earlier version of the piece said that it would take \"many years to develop\" AI systems capable of identifying issues such as bullying and terrorism risks online, but the section was removed before the manifesto was publicly issued.\n"},
{"docid": "431 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "June 22, 2017", "title": "Google's Eric Schmidt: We need critical thinking now more than ever; The Alphabet boss says the world is entering an age of abundance, driven by artificial intelligence and machine learning\n", "content": "Eric Schmidt, executive chairman of Alphabet Inc (Google's parent company), is optimistic about the future. \"We're entering what I call the age of abundance,\" he says. \"And during the age of abundance, we're going to see a new age ... the age of intelligence. \n\"By 2020, most human beings will have access to the internet. When you have everyone harnessed with this information, the world gets more inter-connected. It gets stronger. There's more knowledge sharing. There's more freedom and there's more openness.\"\u00a0\nSchmidt was talking at last week's Viva Technology conference in Paris where he was a headline speaker. Also present was the newly appointed president of France, Emmanuel Macron, who announced: \"France is becoming the nation for startups and must succeed in this challenge.\" \nSchmidt spoke just a few days before he, along with other technology CEOs, met with President Trump, to discuss modernising the US government's information technology systems. \n\"I've come to believe that science and critical thinking really do matter. Even more so now in the political world that we have in the United States and in other areas of the world,\" he said.\nHe acknowledged that the fast pace of innovation had made many wary of change. But he emphasised that machine learning and artificial intelligence hold opportunities for a broad range of sectors, including farming, energy, fashion, and healthcare, even if they operated very differently to today. \n Related:  A new company every week: inside the UK's AI revolution\n\"The largest taxi company has no taxis, that's Uber. The largest accommodation company has no real estate, that's Airbnb. The largest phone company has no infrastructure, that's Skype. The most valuable retailer has no inventory, that's Alibaba. The largest movie theatre, has no movie theatres, that's Netflix.\n\"These of course are huge disruptions... and incumbents [always] resist change. When Henry Ford released his Model T car, it was dismissed as a fad because horses are here to stay. In 1928, a doctor warned that rail travel at high speeds would cause passengers to die of asphyxiation. And - my favourite - in 2007, [Microsoft CEO] Steve Ballmer said there was no chance the iPhone was going to achieve any significant market share. \"\nA report released during the conference by McKinsey Global Institute, highlighted the global growth of the artificial intelligence (AI) sector. There was three times as much investment into AI in 2016 (between $26bn and $39bn) as there was in 2013. This was predominantly spent on research and development, particularly in the machine learning space. Companies in the US accounted for 66% of that investment, with China second at 17%. \nProgress has largely been driven by large corporates, such as Google and Amazon, and the broader technology sector. In the report's survey of 3,000 AI-aware executives across 10 countries, only 20% said they use AI technology in a core part of their business. Almost half (41%) of those asked, said they were uncertain of the business case for AI. \n\"The conclusion is that all businesses will change,\" Schmidt said of McKinsey's report. \"This age of intelligence will allow you to build a company that's far more efficient. Prices [will be] lower, volumes [will be] better, the quality [will be] better. Computers, instead of just doing analysis will really be able to help you.\" \nHe gives the example of two self driving cars, owned by separate people, that have each only been taught to turn one way. What if they could exchange information? \n\"That's something that computers can do, but humans cannot. This ability [of computers] to learn from peers, means that as things are learned, everyone learns them. The combination of connectivity and the ability for this insight around the globe, means a rate of innovation that we've never seen throughout society.\"\nRather than this leading to a loss of jobs, Schmidt believes the future will see more jobs available that are highly paid. \n\"You'll take people plus computers and the computers will make the people smarter. If you make people smarter, their wages go up, not down. And the number of jobs will go up, not down. What will happen to human interaction? I think there'll be more. \n\"It used to take months for discovery and new developments to be understood. Now they can occur simultaneously all around the world.\" \n                     Sign up to become a member of the Guardian Small Business Network                                            here                                           for more advice, insight and best practice direct to your inbox.                   \n"},
{"docid": "432 of 500 DOCUMENTS\n", "source": "The Independent - Daily Edition\n", "date": "April 15, 2018", "title": "Mark Carney says job automation could lead to growth of Marxism\n", "content": "Mass job losses caused by advancing technology could lead to a rise of Marxism, the governor of the Bank of England has warned.\nMark Carney said the automation of millions of jobs could lead to mass unemployment, wage stagnation and the growth of communism within a generation. He warned \"Marx and Engels may again become relevant.\"\u00a0\nSpeaking at the Canada Growth Summit, Mr Carney said increases in artificial intelligence, big data and high-tech machines could create huge inequalities between the high-skilled workers who benefit from the advances and those who are sidelined by them.\nHe said: \"The benefits, from a worker's perspective, from the first industrial revolution, which began in the latter half of the 18th century, were not felt fully in productivity and wages until the latter half of the 19th century. If you substitute platforms for textile mills, machine learning for steam engines, Twitter for the telegraph, you have exactly the same dynamics as existed 150 years ago - when Karl Marx was scribbling The Communist Manifesto.\"\nThe industrial revolution saw a then-unparalleled growth in production during the late 18th and early 19th centuries - but wages failed to increase for decades as machines meant the jobs created were low-skilled. Many believe the resulting inequalities were a direct precursor to the rise of both left- and right-wing extremism across Europe.\nMr Carney, who is due to leave his post in 2019, said the years of weak salary growth since the financial crisis suggested this 19th-century experience was already being repeated. The governor also added there were signs of \"hollowing out\" in the job market as mid-level workers find computers able to complete specific tasks - even some previously considered skilled work.\nHe said: \"There is a disconnect in expectations. In surveys, over 90 per cent of citizens don't think their jobs will be affected by automation, but a similar percentage of CEOs think the opposite, in the number of jobs which will be materially affected.\"\nHe pointed out how law firms were already using artificial intelligence to comb through documents and read evidence, something traditionally done by junior lawyers. And he added that banks have used a combination of artificial intelligence and big data to computerise large swathes of customer service departments, resulting in staff being made unemployed.\nJobs such as a taxi or lorry drivers could also be scrapped, as self-driving technology improves, he added. Mr Carney said the trends go against previous ideas which suggested only manual tasks would be given to machines.\nThe end result, he indicated, might mean more workers need to prepare for jobs which require a higher emotional intelligence, in sectors such as care and leisure.\n"},
{"docid": "433 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "November 2, 2017", "title": "We can beat the robots - with democracy; It might be a capitalist desire to squeeze the last remnants of humanity from its workforce, but today we have electoral tools to fight it\n", "content": "Sophia told ABC radio that robots deserved more rights than humans. It's a statement that would be of concern should your mum announce it, yet disappointingly unremarkable if uttered by some right wing think-tanky person defending job automation on a panel show.\nBut as Sophia is a robot herself, and one of a new robot technology generation guided by artificial intelligence that's increasing in sophistication, the words are more than a little perturbing. Sophia is the product of Hong Kong based Hanson Robotics, and her notoriety exists not merely on the basis of her interview tactics, but because the government of Saudi Arabia has granted her citizenship rights after her recent local visit to a tech show. Many have noted that as she was provided a platform there without a male chaperone, she perhaps already has more rights than a Saudi woman.\u00a0\nAlas, as another Twitter wag has suggested, Sophia's opinions on rights weren't so much a watershed moment in Saudi feminism or tech innovation as they were the pre-credits background sequence in a horror movie. The observation was given more credence when the interviewer chose not to challenge the robot, but to proceed with the next question.\nIt appears Sophia is recruiting her allies early.\nI jest. Sort of. I do try not to let my fondness for horror, sci-fi and dystopian literature provoke me into too much anxiety about the brave new world of robotics and artificial intelligence, but instead to remain both cynical and positive. A \"snake robot\" prototype that was freaking people out on the internet the other day struck me as little more than a clunky-looking bendy lamp. And, rationally, I'm heavily in favour of deploying robots for tasks like the cleanup of toxic accidents and waste (especially as, in dystopian novel The Handmaid's Tale, the state makes feminists do it). And as someone who dreams of human space odysseys, I'm pretty sure any kind of interplanetary space exploration will rely on robust robot help.\nYet accumulating phenomena is doing much to affirm fears in many that Sophia and her robot kin are an encroaching disaster on humanity. Elon Musk, the global capitalist who everyone almost likes, is on rather panicky record suggesting that artificial intelligence is more dangerous to human survival prospects than North Korea. Given the potential for its military use and the likelihood of a dangerous clown such as Donald Trump being in charge of a military, robots, a milk-crate, his own shoes or anything, fear is warranted. The Guardian has published opinion insisting that we can no more restrict arms dealers from creating robot weapons as we can comply soft drink manufacturers \"from making orangeade\". As AI improves, it has already beaten the world's greatest chess player and the greatest e-sports champion in their fields, while two AI Facebook bots were discovered in the process of self-generating their own language. And while robots are absolutely replacing manufacturing jobs, they're replacing administrative vocations as well. At the automated Nissan factory in Japan, the most labour-intensive use of humans is the final roll out of a vehicle from the plant. Discussions about driverless transport are proceeding faster and further than anyone imagined - in Singapore, there are already driverless taxis. Reports have indicated that 47% of jobs will cease to exist within a technological generation. Others predictions suggest 6% of US jobs will be lost to the robots by 2021.\nIt's scary stuff, and it revives old social terrors - we have, of course, been somewhat near this kind of thing before. The underperformed (and excellent) Harold Brighouse play, The Northerners, offers an efficient history lesson in the replacement of craftspeople by the machinery of the industrial revolution. It was not technology itself that instigated the \"Luddite\" rebellions of the 1800s so much as it was the displacement, dislocation and disempowerment wrought when a skilled artisan class was obliged into disposable membership of a new industrial proletariat.\nIt is a language myth that the word \"saboteur\" derives from similarly displaced workers throwing their \"sabot\" shoes into the cogwork to wreck industrial machines - but that it's still believed says much about old fears revived by new instabilities in employment. When our Australian workplace is already so denuded of protections, anxiety around automation is valid and understandable.\nBut what's telling in the debate around robots and jobs is the discourse is framed in the manner of a fait accompli - as if the mere capitalist desire to squeeze literally the last remnants of humanity from its workforce is enough to make it so. But there is a crucial difference between the structural reality of the era of Luddite protest and today. We are equal citizens within a democracy, whose capacity to form democratic majorities allows us to direct legislation, regulation, restriction and compensations within both the workplace and the nation state. This enfranchisement was not enjoyed by our forebears, whose early attempts to even form unions were met with punishments like transportation. We have, through law and treaty, banned numerous battlefield weapons enhanced by technology. And we do, actually, have the capacity to demand \"robot taxes\" as Jeremy Corbyn has suggested, and Bill Gates has championed, to oblige automating corporations to fund government expansions of welfare support and job creation opportunities for the human beings they make redundant. Through the electoral mechanisms already available to us, we can price externalities such as social impacts - and environmental ones - into the cost of doing business. What's more, we should.\nIf Australia can destroy its own entire car industry in a single government decision, it is not merely irrational to believe that the power to compel industrial processes one way or another is beyond the remit of government. It is dangerous propaganda, serving only profit-seeking interests at the expense of our communities.\nAs the technology of robots grows ever more advanced, it's worth remembering that the most meaningful distinction between the machines and ourselves is our human judgment, informed not by algorithms but by values of imagination, empathy, kindness, selflessness and community.\nShould we not affirm the validity of our own capacity for democratic decision making, then the robots have already won.\n"},
{"docid": "434 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "September 14, 2016", "title": "Bank of America analysts think there's a 50 per cent chance we live in The Matrix; Report cites SpaceX founder Elon Musk and Oxford philosophy professor Nick Bostrom\n", "content": "Analysts at Bank of America have reportedly suggested there is a 20 to 50 per cent chance our world is a Matrix-style virtual reality and everything we experience is just a simulation.\u00a0\nThe report, which was issued to clients, also implieseven if our world was anillusion, we would never know about it.\nBank of America Merrill Lynch backed up the claims by citing comments from leading philosophers, scientists and other thinkers.\nBANK OF AMERICA: There's a 20%-50% chance we're inside the matrix and reality is just a simulation Myles Udland pic.twitter.com/TltpYbjPxI\n- Sanguine (@laginchey) September 8, 2016\n\"It is conceivable that with advancements in artificial intelligence, virtual reality, and computing power, members of future civilizations could have decided to run a simulation of their ancestors,\" the report stated.\nThe analysts took inspiration from inventor and SpaceX founder Elon Musk, who believes there is a high probability the world is part of an artificial intelligence created by a future civilisation.\nIts claims also appeal to the work of a philosophy professor from the University of Oxford. In 2003, Professor Nick Bostrom concluded there is significant possibility we \"live in a simulation\".\nAstrophysicist Neil DeGrasse Tyson also maintains the likelihood of the universe being a simulation \"may be very high\".\nPhilosophers dating back to the 16th century, notably Ren\u00e9 Descartes, have suggested we cannot rely on our sense experiences to perceive the world.\nRead more\nWatch President Obama visit Yosemite National Park in virtual reality\nMr. Robot is debuting a short virtual reality film that will disappear after airing\nBank of America clerk fired for Facebook rant saying black people 'should go back to Africa'\nThis video of Pok\u00e9mon GO players in Central Park is proof that The Matrix is coming\nMatrix director Lilly Wachowski makes her first public appearance since she came out as transgender\nThe Bank of America's report, which was looking at the implications of virtual reality,explained: \"Many scientists, philosophers, and business leaders believe that there is a 20-50 per centprobability that humans are already living in a computer-simulated virtual world.\n\"In April 2016, researchers gathered at the American Museum of Natural History to debate this notion. The argument is that we are already approaching photorealistic 3D simulations that millions of people can simultaneously participate in.\"\nIn the 1999 film \nThe Matrix\n, humans live in a simulated reality created by machines to control the human population.\n"},
{"docid": "435 of 500 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "December 17, 1990", "title": "Getting it right when the chips are down; Greg Wilson questions the importance of research into artificial intelligence\n", "content": "THERE ARE a lot of people in computing who feel there should be more to computer science than logic, circuits, and video games. Many of them believe we should be able to make our computers do the sorts of things that human beings do: recognise faces, understand speech, and so on. This belief is the cornerstone of artificial intelligence (AI), which aims to make computers perform the activity that we know of as ''thinking''.\nIn The Independent last Monday, Kenneth Owen reported on a group of British computer scientists and representatives of the industry who had gone to look at the latest big idea from the Japanese Ministry of International Trade and Industry (MITI), which sponsors and co-ordinates high-tech development. MITI is planning an ambitious programme to develop computer systems capable of dealing with the irregularity, contradiction, and incomplete information that characterise the real world.\u00a0\nAccording to last week's article, the systems envisaged by MITI would rely on techniques of neural networks and genetic algorithms to carry out ''pattern recognition and understanding flexible inference and problem-solving; simulation of economic, ecological, and other systems; and advanced forms of robot control''. Several members of the British group apparently feel that while MITI's programme may be ambitious, the subjects it will address are too important to be ignored by Britain.\nTen years ago, MITI put together the fifth- generation programme. Its purpose was to take artificial intelligence out of the laboratory and into the factory and office. Frightened by the prospect of losing yet another strategic sector to the Japanese, the United States, the EC, and Britain all responded with similar programmes.\nThe problems the new programme hopes to solve are almost the same as those that the fifth-generation programme was going to solve; the chances of success are much the same (slim to none); the fear that the Japanese are going to get ahead of us hasn't changed; and, most depressingly, the response shows how little has been learnt in the past decade about how to support and manage the development of new technologies.\nAI was a hot topic, and then moribund, twice before the Japanese picked it up as their next big technology. Billions of yen, dollars, and ecus were spent on the fifth generation and similar programmes during the Eighties, with unimpressive results. When the big research programmes of the Eighties were started, the artificial intelligentsia was confidently predicting a revolution within the decade in the way computers worked. A decade on, the revolution seems just as distant.\nWhy, then, should some very intelligent people be saying that neural network research is underfunded (never mind that interest in it is already waning in the US because it, like AI, has failed to deliver), and that even if the Japanese initiative is over-ambitious, we ought to take it seriously.\nWhy should Britain let its decisions about directions for strategic research be determined by the activities of other countries? Why can't money be put into those areas of fundamental research in which this country already leads the world, and which are certain to lead to economic benefits?\nThere are two such areas of research within computer science alone. The first, known as formal methods, is developing techniques to allow software engineers to prove that a piece of software meets its specifications, and that those specifications are internally consistent.\nInstead of writing a program three or four times, testing it, and then hoping that any remaining ''bugs'' are not going to make an airplane drop out of the sky or lead to a reactor meltdown, software firms would be able to prove mathematically that what they had written did what it was supposed to do. These techniques, which are already moving into the marketplace, will revolutionise computer science. The only question now is whether this country will provide enough support for research in this area to guarantee itself a piece of the action.\nAnother area that deserves much more support than it is getting is parallel computing. A parallel computer is one which contains tens, hundreds, or thousands of processors, all working together to solve a single problem. Whereas parallel computing was an academic curiosity a decade ago, it is now being used by every major supercomputer manufacturer to improve the performance and cost effectiveness of their machines. ICL was the first company to produce a commercial parallel computer, back in 1979. Only six of these were sold but Britain recovered its lead in parallel computing in the mid-Eighties when the silicon chip manufacturer Inmos developed the transputer.\nEach transputer contains a microprocessor, some memory, and four communications links that can be used to wire any number of transputers together to make a parallel computer. Armed with the transputer, Inmos should have conquered the world, but because the Government refused to support the company in the way that the German government supported Siemens, MITI supports Japan's electronics industry, and the US government gives back-door cheques to hi-tech firms through defence contracts, Inmos was only partially able to capitalise. The situation was not helped by the company's disastrous decision to ignore industry software standards, which prevented it from breaking into the crucial American market.\nNevertheless, the transputer has dominated parallel computing in Europe since its release. Yet Inmos has fallen behind, and the makers of parallel computers are increasingly turning to American firms, such as Intel, to buy chips with the required performance. Inmos has now been taken out of British hands by the French/Italian combine SGS-Thomson, but it is still a significant player on the world scene. Its existence has bred a strong and active parallel-computing community in Britain and Europe.\nIf someone wants to sponsor a major new programme in computer science, it would be far better to help that community do the research needed to create software that can realise the potential of parallel computing, than to throw money at the grandiose fuzziness of soft information processing. It may not be as sexy, and its aims may not be as comprehensible to the minister who signs the cheque, but it would be a better investment and better science.\nThe author works in the Edinburgh Parallel Computing Centre, and freely admits that this biases his view of the world.\n"},
{"docid": "436 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "May 18, 2017", "title": "Google's future is useful, creepy and everywhere: nine things learned at I/O; With Google Assistant coming to the iPhone, the company hopes to kill off Siri and wants to 'see' inside your home as it reiterates its AI-first approach\n", "content": "There were whoops and cheers from developers as Google announced the incremental ways it is strengthening its grip on many aspects of people's lives at its annual developer conference, Google I/O. \nThere were no jaw-dropping major product launches nor executives proclaiming their utopian vision of the future (ahem, Mark Zuckerberg). Instead there was a showcase of features, powered by artificial intelligence, designed to make people more connected - and more reliant on Google.\n\"We are focused on our core mission of organising the world's information for everyone and approach this by applying deep computer science and technical insights to solve problems at scale,\" said CEO Sundar Pichai.\nBy combining the personal data harvested from its users with industry leading (and human Go player beating ) artificial intelligence, Google is squeezing itself into spaces in our everyday interactions it hasn't been before, filling in the gaps and oozing into new territory like a sticky glue that is becoming harder and harder to escape.\u00a0\nHere's what the key I/O announcements tell us about Google's future.\n                   1. AI is Google's USP                   \nGoogle reiterated that the company has shifted from a mobile-first to an AI-first approach. This means using AI at the core of all of its new products, whether that's to improve image recognition in Google Assistant or for beating human players at Go.\n                   2. Google wants to 'see' as well as 'hear' your surroundings                   \nLens is Google's answer to Facebook's augmented reality Camera Effects platform. It comprises a set of vision-based computing capabilities, combined into Google Assistant and the Photos app, that works to 'understand' what you're looking at. So you can point the camera at a flower and it will identify the species or automatically connect to a wifi network by showing the camera the log-in details printed on the sticker on the router. You can also hold your camera up to a restaurant in the street and see reviews. \n                   3. Google Assistant is getting smarter                   \nGoogle's equivalent of Siri, Google Assistant, is embedded in Android devices including smartphones, watches and Google Home. Google's Scott Huffman noted that Assistant would become even more conversational over the coming months, allowing you accomplish tasks with a quick chat. \nIn addition to having voice recognition, Google Assistant, drawing on Lens, can now take in, understand and have conversations about what you see. For example, if you are in Japan but don't read Japanese you can hold the Assistant up to a sign advertising some street food and it will \"read\" and translate the text. You can then ask \"what does it look like?\" and Google will know that the \"it\" refers to the name of the food written on the sign and it will pull up pictures of the dish.\n\"It comes so naturally to humans and now Google is getting really good at conversations too,\" said Huffman.\n                   4. Google Home is getting creepier (and more useful)                   \nVoice-activated smart speaker Google Home, will now start offering \"proactive assistance\" rather than waiting for you to say \"OK, Google\" to wake it up. For example, it might notify you if you have to leave your house earlier than expected because traffic is particularly heavy. Perhaps the company will start proactively advertising to customers in the future?\nLess creepy is the option to make hands-free calls from the Google Home speaker. You simply ask it to dial any landline or mobile number in the US or Canada and it will do so for free. The device can also now recognize up to six different voices in a household and adapt to personal preferences accordingly.\n                   5. Google wants to replace Siri on iPhones                   \nA key theme throughout the keynote was creating a seamless experience across devices, even if that device isn't in Google's Android ecosystem. This means that Google Assistant is now available on the iPhone. \nAssistant is widely considered much smarter than Siri, thanks to the fact that Google harvests a lot more personal data than privacy-conscious Apple. This means that frustrated Siri users wanting to translate a sentence into another language, play a movie on their Chromecast-enabled TV or order takeout using voice commands will now be able to do so.\n                   6. It's trying to keep YouTube creators happy                   \nEver since Google added stricter controls for advertisers on YouTube after it was discovered ads were being placed alongside hate speech or terrorist videos, some vloggers have complained about making less money. \nYouTube relies on these internet celebrities to post regular videos and live streams as they attract huge audiences to the platform. That might explain why the company has launched the \"super chat\", first announced in January. Audience members can pay to have their comment featured prominently during a live stream and in turn donate money to the YouTuber or their chosen cause. The feature was enabled during a popular live stream of a New York-based giraffe giving birth in February, allowing the zoo to make \"tens of thousands\" of dollars.\n                   7. It wants to take a slice of recruitment advertising                   \nGoogle for Jobs is a new search function that, by disintermediating the many job listings middlemen, makes it easier for people to find employment (and harder for those listing sites to make money). \n\"We want to better connect employers and job seekers through Google for Jobs,\" said Pichai. \nThe company has worked with partners including LinkedIn, Monster, and Career Builder to aggregate search in one place - similar to what it's done with its airline-search tool, Google Flights. The company uses machine learning to understand and group together roles where employers and employees use different words, for example store clerk and retail manager.\nPichai positioned the launch as an effort to boost American employment, but it's sure to help get Google - already taking, along with Facebook, the lion's share of online advertising revenue - a bigger slice of the pie.\n                   8. It needs to attract the \"next billion\" or two                   \nDuring the I/O keynote, Pichai stated that seven of Google's products have more than a billion monthly users: Google search, Android, Chrome, Maps, YouTube, Google Play and Gmail. However, if it's to continue to grow it needs to attract the so-called \"next billion\" users, typically users in lower income countries just starting to come online through mobile devices. That's why Google has developed Android Go, a pared-down version of the mobile operating system for entry-level devices that uses less data and loads apps more quickly, even when the signal is poor. \nAndroid Go will be embedded in the latest version of Google's mobile operating system, Android O, which is more battery efficient and features better protections against viruses and malware in downloaded apps - a notorious problem for Android devices compared with iPhones.\n                   9. It's realistic about VR and AR                   \nThere's a bucketload of hype around VR and AR, but Google's approach felt more measured, focusing on the immediate, practical applications. (Perhaps a symptom of being burned by the now defunct Google Glass prototype, launched with great fanfare and an army of tech evangelists). \nThe company already has an entry level VR headset that uses a smartphone as the screen, but it teased a couple of more advanced standalone DayDream headsets, made in collaboration with HTC and Lenovo. The details were scarce but Google emphasised that unlike with Oculus or HTC Vive headsets, DayDream headset users wouldn't need expensive computers to power them or rigs of external cameras to detect the person's position.\nWith augmented reality, Google described a \"visual positioning system\" similar to GPS but with centimetre accuracy. It works by using the camera to identify objects visually within a space, for example a large store. This means you'd be able to hold up your camera (or wear a pair of smart glasses) and be guided to a specific product on a shelf. This extends Google's mission to organize the world's information into the physical domain. \n\"Imagine what it could mean to people with impaired vision,\" said Clay Bavor, vice president of virtual reality, who suggested that Google-powered camera phones (or other wearable devices) could act as a blind person's \"eyes\". \n"},
{"docid": "437 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "March 8, 2017", "title": "Diagnosis by smartphone as robots used to ease GP crisis\n", "content": "ROBOTS will soon be able to diagnose patients \"more accurately and faster\" than almost any doctor, according to the man behind a controversial NHS scheme that will see \"chatbots\" used to assess 111 calls.\u00a0\nA private company is to launch a national scheme that allows patients to receive a full diagnosis by smartphone without ever having to see a GP.\nBabylon Health has just begun a pilot scheme under which patients in five London boroughs are encouraged to consult a chatbot - a computer program designed to simulate conversation with human users - when they contact the 111 non-emergency line.\nPatients key in their symptoms, and artificial intelligence assesses the urgency of each case to determine whether users should be told to go to A&E, a pharmacy or tuck up at home.\nNow the company's chief executive has revealed it is to launch a more sophisticated model that will allow any individual to receive a diagnosis by smartphone. Dr Ali Parsa said the system would allow doctors to work in tandem with artificial intelligence so that medics could focus on treating rather than diagnosing diseases.\nThe entrepreneur said: \"There are 300 million pieces of knowledge that we have www.collected.No human brain can do that. This is the largest amount of primary care clinical semantic knowledge in the would that is held by any computer, as far as we know.\"\nThe model remains in development, but tests so far have shown it is faster and more accurate than the doctors in risk assessing cases, Dr Parsa said. In the coming months, research will test the thesis that it can also outperform medics in making a full diagnosis. So far, trials have found it can do so in all abdominal diseases, the company said.\n\"I think we will soon be able to diagnose more accurately and faster than a doctor in most cases. That leaves the doctor to focus on the management of the diseases,\" Dr Parsa said.\n"},
{"docid": "438 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "October 27, 2017", "title": "Robots beat online test to identify man or machine\n", "content": "Could this be how the end begins? Robots have learnt how to prove they aren't robots.\nResearchers have said that the Captcha system, used by websites to ensure that users are human, has been broken by a team of programmers using a relatively simple system.\u00a0\nThis means that the fuzzy and slanted letters that have long served as the last line of defence against hordes of automated bots are vulnerable to attack. Humans are used to being defeated by computers. Chess fell in 1997 while Go, considered the greatest strategy game our species has created, fell last year. But until now the ability to squint at a screen and work out whether it's showing a 6 with a line through it or a B with a blurry bit had been a uniquely human attribute.\nSo hard is character recognition that Douglas Hofstadter, the venerable intelligence researcher, considered it a grand challenge of machine learning. \"For any program to handle letterforms with the flexibility that human beings do, it would have to possess full-scale artificial intelligence,\" he wrote.\nThe new research by Vicarious, a US artificial intelligence company and published in the journal Science, is a significant step in that direction. The Captcha system works on the principle that computers find it hard to tell where one letter starts and another ends, something experts call \"segmentation resistance\". Humans can easily spot the form of a familiar letter but computers find it harder. This is especially true when the letters overlap on a noisy backgrounds and are rendered in hundreds of thousands of different styles.\nThe team reported that their algorithm can correctly guess a Captcha with an accuracy of 66 per cent, and an individual character with an accuracy of 95 per cent. This rate is not that much worse than humans manage: on average guesses by two separate humans only agree with each other 81 per cent of the time. Previous, less successful attempts had used 5,000 times as many images as this study.\n\"The ability to learn and generalise from a few examples is a hallmark of human intelligence,\" the researchers said. It also means that we are going to have to rethink internet security and \"websites should move to more robust mechanisms for blocking bots\".\nThe robot invasion is coming, at least if you are an online message board.\n"},
{"docid": "439 of 500 DOCUMENTS\n", "source": "The Times\n", "date": "August 21, 1993", "title": "The challenge of computer minds\n", "content": " DAVID FLUSFEDER PREVIEWS THE BEST OF THE COMING WEEK'S TELEVISION\nThe World Athletics Championship finishes tomorrow, and that'll be the end of David Coleman's voice for a while, choking with emotion as he tells us\nwhich plucky British athlete is competing for which minor medal. Next week's highlights are Roger Penrose's rebuttal of the wilder exponents of artificial intelligence, a report on the sleazier side of athletics, and, programme of the week, the horribly painful, sometimes unwatchable, sight of two men dying from Aids.\nEquinox:\nThe Emperor's New Mind\nTomorrow, Channel4, 7pm\nThere is a wacky school of scientific thought that believes in the concept of ''strong artificial intelligence''. The school's basic premise is that human intelligence is replicable by computer; following on from that is the exciting notion that computers eventually will supersede human intelligence.  (And, burbles one happy, hopeful boffin in this programme, eventually we will be able to ''transplant the soul of a person to a machine'', and then, one day, computers will inherit the world we have built for them, our superior children.)\u00a0\n The mathematician and physicist, Roger Penrose does not go for this at all. Penrose believes that the human soul is going to stay where it is. He composes an elegant argument against the scientists who believe in the holy electronic grail of strong artificial intelligence. (It's one of those arguments that you follow sagaciously every step of the way and then, a few minutes after it's over, you wonder if you followed it quite so attentively as you had thought.)\n He fights a giddy intellectual battle, bringing in such ammunition as Plato, Fritz Lang, Albert Einstein, Kurt Godel (who completed his Incompleteness Theorem at the age of 25, and died of malnutrition at the age of 71 because he was convinced that his doctors were out to poison him), quantum mechanics and Alan Turing, and has, for light relief, the occasional shot of Penrose walking wisely around a fairground. It's all very engaging.  Penrose is a good clear guide to an arcane world of pure speculation and only occasionally talks down to his audience. But we now need an answering programme to disprove Penrose's own unshakeable faith in mathematics as being the very highest endeavour of the human race.\nWin, Lose or Draw\nMonday-Friday, ITV, 11.25am\nThere will soon will come a time when Danny Baker will have taken over all the schedules we'll see in the morning with Danny, chat out the night with Danny, laugh with Danny, cry with Danny, and live out our lives surrounded by wall-to-wall DannyVision.\n At the moment we have to settle for this agreeable illustrated version of charades (and in the commercial breaks to buy sweets and washing powder from Danny). A team of men against a team of women, each composed of two C-list celebs and one slightly embarrassed member of the public, take it in turns to draw squiggles and wince in frustration as their temporary mates spend too much time shouting silly suggestions and breaking down in giggles.\n I miss the cushion-throwing they used to go in for at the end, but the show is good entertainment, primarily when the focus is on Danny, his quick-witted asides and his occasional wild flashes of fancy.\nEastEnders\nTuesday, Thursday,\nBBC1, 7.30pm\nThis week it's a should-I-stay-or-should-I-go round at Albert Square. Arthur has to decide whether to break up the unhappy Fowler home and run away with Christine, his likeable (if absurdly misguided) fancy woman. And Dot Cotton has to make up her mind whether to go to live in the suburbs with son Nick, Zoe, and Dot's recently arrived grandson, Ashley. (You get the impression that whenever the scriptwriters are hard up for ideas, a producer will chuck in another ''Nick's changed, you know'' storyline.) ''Remember, your only grandson loves ya, Ma,'' Nick says, with his usual nasty leer. ''I think I'm about to be sick,'' says Nigel, who is threatened with homelessness if Dot moves out. And with all the talk of possible departures, there is a coming home. Pat is out of prison, and returns heavily to Walworth. She moons around, with a grim expression, as if a revelation is around the corner. Not a lot seems to cheer her up, but reformed Grant gives her a free drink in the Queen Vic, and the communion of ex-jailbirds raises one grateful if surprised smile.\nIt's a Queer World\nTuesday, Channel 4, 11.40pm.\nLily Savage, Liverpool's grittier answer to Dame Edna Everage, takes us on a weird tour of gay television programmes from around the world (which, in this case, seems to consist only of Germany, Holland and the United States).\n Given the clips shown here, Holland seems to be full of lonely gay men and cruising gay women. There's the raunchy The True Love Show from Holland, which is a wild dating programme; and in another Dutch show, we meet a sweet lonely farmer who says rather wistfully: ''Marrying for true love is my ideal. So I can go to heaven on the other side.'' Lavender Lounge from San Francisco is good value, with its charming tribute to dead celebrities, but the real interest here is watching the ads, which offer a mixture of safe-sex information, gay bars and pet food stores.\nOn the Line\nWednesday, BBC2, 8.30pm\nWhat does go on between those gruff men in tracksuits who hold the stop-watches and their thin little-girl charges desperate to make the big-time in swimming and athletics? The simmering scandals recently used to be about drugs; now the attention is on the sex angle.\n This episode of the consistently good On the Line hits you with some very sleazy stories. Among the athletes featured in the programme is one who makes the seemingly common claim that she was pressed into having sex with her coach when she was 14: ''If a man holds a gun to the head of a young girl and says 'You have to have sex with me', then everybody can identify that as rape. But if he says, 'You're so beautiful and you're so talented and we have a very special relationship...' that is, in effect, a gun to her head.''\nmr don and mr george\nWednesday, Channel4,\n10.35pm\nMoray Hunter and Jack Docherty return with their lower-case characters from the Absolutely show for their own series. mr don is the little one with the vertical hairstyle and the funny glasses; mr george is the tall one with thinning hair and a useful ability to flap his lips. They live together in a well-designed set that looks like an Edwardian junk shop.\n This first episode zips quickly about but is rather self-consciously surreal comedy, raising smiles rather than laughter until the end at least, when it gets very funny with visceral special effects.\nNothing Sacred\nThursday, BBC2, 10.30am\nWilliam Wellman directed this 1937 screwball satire about a supposedly dying country girl who comes to New York and milks the cynical city (personified by Frederic March) for all it is worth. The two crucial names here are Ben Hecht and Carole Lombard. Hecht's screenplay is hilarious, clever, and wisely cynical (''The hand of God reaching down into the mire couldn't elevate one of them to the depths of degradation'' is one way to describe newspapermen). But this is Lombard's movie: the greatest film comedienne of all time in one of her finest roles.\nSilverlake Life:\nThe View from Here\nThursday, Channel4,\n10.35pm\nThis is the most heart-aching programme I have ever seen. In video diary form, two men with Aids film their decline and the first one's death. It is chilling, desperate, graphic, and real. The camera never flinches; the viewer often does.\n Mark and Tom had been together for more than 22 years. Mark was the first to be diagnosed HIV positive, but Tom was the first to become ill. It is a slow, painful dwindling as he gradually loses his energy to live, but not his sense of humour nor his sustaining love for his partner. ''Well here we are, back in the hospital, in the emergency room,'' he says to the camera, his face thinner than it was in the previous shot, his voice lighter with its tired, sad stoicism.\n Mark hides his sarcomas beneath a Coccoon T-shirt (you feel this is a self-conscious bit of irony; the man with a death warrant wearing the logo from a movie about immortality).\n It is Mark's job to maintain the optimism and he does this bravely but you feel his tragedy is the greater. He will go through this death process twice: first with his lover and then by himself.\n ''It's the first of July and Tom's just died,'' Mark says. He dutifully does his video diary bit , but the skeletal body of his partner is in front of him and while Mark tries to say what he's feeling, the sobs break through, and he starts again to sing: ''You Are My Sunshine'' with which he was soothing Tom as he died.\nArchitecture of the Imagination: The Tower\nFriday, BBC2, 9.30pm\nThis episode is more intelligent than some of the previous ones, thanks to the contributions from Marina Warner who really gets her teeth into the metaphor of buildings as female sexuality and Christopher Frayling, who is very good on William Beckford's towering folly. It helps that the ludicrous remarks by James Hillman, the psychologist, are kept to the minimum.\n The programme has the usual mix of well-chosen film clips with a dash of history, a bit of chat, and a few thought-provoking remarks on aspects of architecture that we usually take for granted. And it ends with clips of one of the most oddly exhilarating sights collapsing buildings.\n Hillman is good value when you don't hear too much from him. Here, he comes up with this brilliantly daffy observation on skyscrapers: ''They're not inherently connected to the earth... He then looks slightly worried for a moment, has a bit of a think, and finally adds: ''except physically''.\n"},
{"docid": "440 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "February 21, 2018", "title": "AA sideshow fails to hide its impending breakdown\n", "content": "Connected cars, automation, artificial intelligence, internet of things - these are the buzzwords of the moment that are increasingly cluttering up corporate statements.\nSuch distractions are just about acceptable when all is well but when a company is as troubled as the AA, they become egregious, an opportunity for management to hide from the real issues.\nTake the  roadside repair group's latest results. Here was a chance for new chief executive Simon Breakwell to draw a line under the extraordinary saga that saw executive chairman Bob Mackenzie  fired last August after a hotel brawl with a senior colleague.\u00a0\nThe AA's share price has plunged 66pc in that time, dragging its market value down nearly \u00a31bn from \u00a31.5bn to just \u00a3510m. Meanwhile, Mackenzie is refusing to go quietly, pledging to take his former employers to court amid claims of wrongful dismissal.\nFaced then with its once shining reputation in tatters, and concerns growing over its future, the City was crying out for Breakwell to come clean about the true extent of the company's problems. Even more so, when you're unveiling a hefty profit warning and cutting the dividend by fourth fifths.\nInstead, we got a classic piece of misdirection with management claiming that the answer lies in some vague promise to embrace technology.\n                   Buy these seven shares to profit from driverless cars and artificial intelligence                   \nThe AA's new strategic plan involves improving its app, developing more connected car products, and targeting new younger members. Meanwhile prices will be brought down at the insurance arm with clever analytics. Hardly a technological revolution for the 21st century, yet Breakwell says it will kick-start growth. Describing the AA as \"a phenomenal business\", the investment will \"unlock the full potential\" of \"a highly respected and trusted brand\", Breakwell claims.\nRousing stuff but this looks like another example of a company attempting to dazzle investors, and confound critics at the same time, with a sideshow that glosses over the real problems.\nThe AA is cutting its dividend for two reasons: the firm isn't generating enough profit; and it is heavily laden with debt. A few million pounds spent on a whizzy app is unlikely to address such pressing issues any time soon.\nThe reality is that this is a business scrabbling around for ways to conserve dwindling cash as it struggles with a debt pile of \u00a32.7bn, five times its current stock market value, and nearly eight times expected annual earnings of between \u00a3335m and \u00a3345m.\n.html-embed.component .quote.component{margin-left:0}.html-embed.component .quote.component .component-content{margin-right:16px}.quote__source, .quote__author {white-space: normal;}@media only screen and (min-width:730px){.html-embed.component .quote.component{margin-left:-60.83px}.html-embed.component .quote.component .quote__content:before{margin-left:-12px;padding-right:1px}}@media only screen and (min-width:1008px){.html-embed.component .quote.component{margin-left:-82.33px}}This is a business scrabbling for ways to conserve dwindling cash\nPerhaps more of a concern is the news that dwindling earnings have triggered an unusual penalty in its financing arrangements that shuts off access to funding that could have serviced dividend payments.\nNo wonder the payout to investors has been slashed. Reducing it from 9p a share to just 2p will preserve roughly \u00a340m of a paltry \u00a380m cash pile, needed to invest in the new strategy.\nInvestors gave it all a resounding vote of disapproval, as 28pc was wiped off the AA's battered shares in just a few hours of trading. Equivalent to \u00a3200m - more than four times what it would have cost the AA to maintain the dividend at the current level - it leaves the share price at all-time low.\nAA share price\nHaving floated at 250p in June 2014, its shares are now trading at just 83.6p, making it one of the most disastrous floats in recent years. Hedge funds smell blood. The percentage of the AA's stock being targeted by short-sellers  has doubled in recent weeks, making it the 10th most shorted stock on the FTSE 350.\nThe real villains are the private equity firms that steered a business with severe financial constraints back onto the stock market three years ago.\nAt the time, Mackenzie played down widespread concerns about borrowings, promising progressive dividends but warning that investors may ultimately have to sacrifice regular payouts to enable the company to aggressively pay down debt. That's not going to happen this year and next year doesn't look much more promising either.\nWhen the AA returned to public hands it was through a highly-unorthodox process called an accelerated offering, which dramatically reduced the time it took to become a listed company. No wonder its owners were in a rush.\nCorbyn's crackpot crusade\nWords no one ever thought they would hear: a bank boss claiming he was \"aligned\" with Jeremy Corbyn. Yet, those were the extraordinary words of Antonio Horta-Osorio, chief executive of Lloyds.\nYou can hardly blame him. Business leaders are genuinely fearful of a Labour government but it's clear from Corbyn's recent comments that he sees the banks as the real enemy.\nHorta-Osorio pointed out that 97pc of its business today is helping the real economy, while it has got out of many of the risky activities that Labour hates including investment banking, asset management, and private banking, while simultaneously returning to health.\nHis points are extremely valid - a healthy banking system is vital to the economy - but unlikely to calm Corbyn's misguided and vengeful plot to destroy the City.\n"},
{"docid": "441 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "June 14, 2015", "title": "Science fiction no more? Channel 4's Humans and our rogue AI obsessions; We've told ourselves stories about the robot revolution for decades - but technological advances are hauling artificial intelligence out of the fictional realm. As the real world catches up, is it time to rewrite the script?\n", "content": " Related: Elon Musk: artificial intelligence is our biggest existential threat\nRoboCop, that tin-suited keeper of law, order and a heroic portmanteau, abides by three prime directives : 1) Serve the public trust, 2) Protect the innocent, 3) Uphold the law. He lives by these rules with algorithmic devotion. As well he must: each is written into his circuitry. Not only that, his existence is dependent upon the absence of error. A misstep by an American beat cop, as recent events have proved, may only result in gardening leave or suspension (at least, if the indiscretion was filmed by some dauntless passer-by). But should a cyborg officer so much as erroneously issue a speeding ticket, he and his electronic colleagues would surely be summarily melted down and their metal used to make candlesticks.\u00a0\nLikewise, there were 1,713 fatalities from reported road traffic accidents in Great Britain in 2013, most of which arose from human error. We view this as an unfortunate but perhaps inevitable tax on our freedom to drive. But will we be so lenient when news hits of the first fatality in a collision involving an automated car ? No: there will be an apocalyptic debate on the idiocy of putting robots behind the wheel in the first place. Similarly, the first fully automated drone to fire on western civilians will be shot from the sky with the force of 10,000 remorseful politicians' speeches. Humans and robots, in other words, are not created equal. When it comes to artificial intelligence, we are less lenient to it than we are towards holders of organic intelligence.\nOur underlying distrust of intelligent machines has long been reflected in fiction. There's the treacherous HAL 9000 from 2001: A Space Odyssey, with his unblinking, devil-red eye, who tries to murder the crew of his spaceship and make it look like an accident. (What's worse than a killer? One who tries to slyly cover his tracks.) There's the blinking mainframe computer of 1970's Colossus: The Forbin Project, which leads the world to the brink of nuclear destruction (see also: WarGames). There are the Stepford Wives.\nAnxiety is even baked into the word \"robot\" itself - which derives from science fiction, not science. Karel Capek's 1921 science-fiction play, R.U.R., which is credited with introducing the word to the English language, depicts a cyborg labour force that rebels against its human masters, leading to the extinction of the human race. The Czech origin word \"robota\" means \"forced labour\", and is derived from the word \"rab\", meaning \"slave\". The slave-master's fear of revolt is ancient, and that same angst lurks inside our every utterance of the word \"robot\".\nIn imagining what might go wrong if humanity's inventions were to go rogue, fiction performs an essential role, testing the implications of our creations, real and hypothetical. So it is no accident that today, as the wilder possibilities of AI begin to seem like a medium-term prospect rather than some comfortingly remote futurology, the number of fictional works exploring malevolent AIs is at an all-time high. Avengers: Age of Ultron (2015) tells the story of a sentient AI that wants to eradicate humanity in order to save Earth. Disney's Big Hero 6 (2014) features a robot that turns murderous if its \"healthcare chip\" is removed. Chappie (2015) examines the question of whether robots should be hardcoded with morals or, like us, only given the capacity to learn them. Alex Garland's Ex Machina (2015) sees a programming student fall in love with an AI and attempt to free her from a lab. In Her (2013) another man falls in love with an artificial intelligence; she eventually \"leaves\" him, as she's evolved beyond the relationship (a different kind of attack on humanity). Charlie Brooker's TV series Black Mirror tests various potential near-future outcomes of our relationship with technology, while Humans, which debuts on Channel 4 on Sunday night, examines the repercussions of artificial brains through the lens of domesticity.\nThis boom in AI-based plots is surely tied to the closing gap between this aspect of science fiction of the 20th century and science fact. Humans, tellingly, is set in a parallel present day - not a move writers could credibly make in a story about, say, intergalactic travel. The public is keenly aware of the great strides that have been made in human-simulating artificial intelligence, if only through the quiet miracles of the anthropomorphic assistants who live in our mobile phones: Apple's Siri and Microsoft's Cortana (who took her name from fiction: the benevolent AI companion you play alongside in the Halo video game series ). Then there are the revelations from industry: Amazon's claim (controversial as it is) that it has a fleet of delivery drones ready to fly, just as soon as the air regulators allow it; the news that the AI company DeepMind, which seeks to \"solve intelligence\" by creating a digital human brain, has been bought by Google for a reported \u00a3400m; those distressing YouTube videos of military contractor Boston Dynamics' giant, sprinting robot dogs, which steady themselves when given a sharp kick by some researcher.\n Related: Google a step closer to developing machines with human-like intelligence\nNot only that, but public figures have upped the ante in terms of existential dread surrounding the subject. Stephen Hawking recently warned that advanced AI \" could spell the end of the human race \". Elon Musk, the entrepreneur, claimed that artificial intelligence is the greatest existential threat to mankind. (\"Hope we're not just the biological boot loader for digital superintelligence. Unfortunately, that is increasingly probable\", he tweeted, before donating $10m to the Future of Life Institute, which works \"to mitigate existential risks facing humanity\"). Bill Gates added weight to the claim : \"I agree with Elon Musk and some others on this and don't understand why some people are not concerned,\" he wrote during a Q&A session on Reddit. German philosopher Thomas Metzinger has argued that the prospect of increasing the amount of suffering in the world is so morally awful that we should cease building artificially intelligent robots immediately.\nRecent books with titles such as Our Final Invention: Artificial Intelligence and the End of the Human Era only intensify the dread. Nick Bostrom, a philosopher who directs the Future of Humanity Institute at the University of Oxford, posited a particularly frightening endgame for the development of AI in his recent book Superintelligence. He imagines a machine programmed to make as many paperclips as possible, and describes the intelligent machine devising a plan to clone itself in order to become more efficient in its one goal. As it continues its noble work of turning everything into paperclips, it decides, quite logically, to eradicate anything that is not a paperclip, including humans, in order to create more space. The story is a metaphor, but Bostrom's aim is to demonstrate how programming even simple values into intelligent machines could have catastrophic outcomes.\nLike all good end-times prophecies, there's even an approaching date for the robot apocalypse. Ray Kurzweil, the futurist and director of engineering at Google, has set the date at which machine intelligence will exceed human intelligence as 2045. This point, known as the singularity (a term coined by science fiction writer Vernor Vinge ), is for some a goal to be aimed at (the 2045 Initiative, founded by Russian entrepreneur Dmitry Itskov in February 2011, aims to be able to transfer a human mind to a \"non-biological carrier\" by the date), and for others an outcome to be avoided at any costs.\n Related: Are the robots about to rise? Google's new director of engineering thinks so...\nAnd for many others, the concerns in both fiction and philosophy about the end of our species at the hands of one of our creations are entirely overstated. Artificial intelligence tends to be developed along highly specialised lines. IBM may have created a computer program that can beat a grandmaster in a game of chess, but ask Deep Blue to play a game of noughts and crosses and it will be at a loss. Most AIs are able to do one thing incredibly well, and nothing else. It is intelligence along a single axis. Likewise, we have not yet produced machines with vision, natural language processing or common sense. Ask Siri a question and she will, most of the time, simply type the question into Google for you. We're a long way from the realm of teary break-ups.\nAnd yet, AI along a single axis still raises troubling and pressing questions. Potentially autonomous weapons already exist in the world (though most current models have safeguards that require a human to grant permission to fire). This military hardware is capable of identifying, tracking and firing upon a moving target from a great distance, theoretically without human intervention. The call from Human Rights Watch for an outright ban on \"the development, production, and use of fully autonomous weapons\" has come too late. They already exist, and our thinking and laws haven't caught up. Even fiction has been slow to ask what that might mean for us. What international laws govern the deployment of fully autonomous weapons? What recourse will there be for victims of a deadly error? These questions of how to govern robot morality (Serve the public trust? Protect the innocent? Uphold the law?) no longer belong in the halls of futurology. Tellingly, though, fiction has failed to interrogate this kind of existential threat, presumably because a resolutely machine intelligence lacks dramatic potential. We can impress motive, character, even wit on to robot servants who look like us. An autonomous gun is less relatable.\nThe rise of the robots might not only present a physical threat to humans. As more of our work becomes automated, there is the threat to labour. In the 1950s the sci-fi dreamers first began to envision a future in which machines fully replaced man's work. Automated flying cars would deliver 21st-century humans to their pristine destinations, where robot chefs would prepare our meals then sweep up after us. We would be made redundant in the best possible sense: able to enjoy a life without toil. A recent paper from the Oxford Martin Programme on the Impacts of Future Technology claims that a less inviting version of this future is close: within 20 years, computers will be able to replace humans in 47% of current US jobs. This would be catastrophic for the labour force; Ukip will have a new immigrant force to round upon. Humans embraces the vision: its robots, who are indistinguishable in appearance from humans, are used as factory workers, cleaners, carers and ticket inspectors.\n Related: How super AI could end the age of humans - podcast\nBut science fiction has mostly chosen to focus on the possibility of a robot uprising rather than a robot supplanting. The enduring potency of this plot is rooted in the human anxiety about being fooled by our own technology, of losing control of our creations. The use of tools (including intelligent machines) defines our species, and separates us from most other living things. We know on an instinctual, elemental level that tools are something of which to be proud. And yet this pride is now coupled with fear: of being duped or let down by our technology, or in the worst case scenario, of being made to serve a version of that which, for millennia, has served us.\nIt is disturbing that most of our thinking about the implications of machine intelligence has, to date, been done in the realm of fiction: thought-experiments carried out in the name of entertainment. The writers and storytellers have done their job for close to century, posing the looming questions. Now, where are the philosophers, the engineers, the sociologists and the economists who might provide some answers?\n                                            Humans                                          is on Channel 4, Sunday, 9pm                   \n"},
{"docid": "442 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "February 23, 2017", "title": "Tinder has a date with artificial intelligence\n", "content": "Tinder could become a pushy matchmaker. Rather than simply present users with profiles to \"like\" or discard, future versions of the dating app will suggest that you take Jessica from No 32 to an indie gig at 8pm tomorrow.\u00a0\nThe app already uses an algorithm to suggest matches based on things such as location and common interests but its creators plan to use artificial intelligence to suggest specific dates. The company has launched a division to buy tech start-ups that will enable this change. It wants people to use the smarter Tinder with voice-activated digital assistants such as Apple's Siri.\n\"This might sound crazy,\" Sean Rad, the app's founder, told the Start-Up Grind conference in California. \"In five years' time, Tinder might be so good, you might be like, 'Hey Siri, what's happening tonight?' And Tinder might pop up and say, 'There's someone down the street you might be attracted to. She's also attracted to you. She's free tomorrow night. We know you both like the same band, and it's playing - would you like us to buy you tickets?' \" The upgrade would give Tinder a lucrative income stream, taking a cut from ticket sales and restaurant bookings. The company has already launched Tinder Social to organise group outings and Mr Rad has signalled that it could one day use augmented reality technology to tell people about the availability and interests of other users. Speaking to Mashable, the digital news website, he said: \"I don't think it's crazy to think that one day we'll be wearing a contact lens or glasses and talking to a Tinder assistant that is helping you make sense of the real world.\" Paul Armstrong, of technology advisers Here/Forth, said: \"It's inevitable that they'd use this technology, both to increase and narrow down someone's options. The contact lens suggestion is reminiscent of a recent episode of Black Mirror, the satirical sci-fi series, where the protagonist lives in a world where people can rate each other's popularity out of five stars.\"\nTinder is owned by Match Group, the parent company of www.Match.com, OkCupid and PlentyOfFish. Dating companies are keen to use artificial intelligence to stay ahead of the competition. Academics have been working on AI specifically for this market. Researchers in America have developed an app called FaceDate that matches people on the basis of physical \"type\".\n\"Appearance is generally the essential characteristic that connects people at the beginning of a relationship,\" Cristian Borcea, professor of computer science at the New Jersey Institute of Technology, said. FaceDate exploits this by asking users to upload photos of people they find attractive, such as film stars, allowing its software to look for matches based on facial features.\n"},
{"docid": "443 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "March 27, 2015", "title": "Google teams up with health firm to develop AI surgical robots; Google believes it can enhance surgeons' tools using technologies employed in other parts of its business, including self-driving cars\n", "content": "Google has struck a deal with the healthcare company Johnson & Johnson to develop surgical robots that use artificial intelligence. \nGoogle's life sciences division will work with Johnson & Johnson's medical device company, Ethicon, to create a robotics-assisted surgical platform to help doctors in the operating theatre.\u00a0\nThe robots will aid surgeons in minimally invasive operations, giving operators greater control and accuracy than is possible by hand, minimising trauma and damage to the patient. Some systems allow surgeons to remotely control devices inside the patient's body to minimise entry wounds and reduce blood loss and scarring.\n Related: Google calls for guinea pigs for ambitious 'Baseline' health study\nRobotic surgical systems such as the Da Vinci device developed by Imperial College London have been used in general operations since the early 2000s, and even starred in a Bond film in 2002.\nGoogle believes it can enhance the robotic tools using artificial intelligence technologies including machine vision and image analysis employed in other parts of the business, including Google's self-driving cars.\nThe two firms will explore how advanced imaging and sensors could complement surgeons' abilities, for example by highlighting blood vessels, nerve cells, tumour margins or other important structures that could be hard to discern in tissue by eye or on a screen.\nAugmented reality systems will be used to overlay important information required during surgery that is typically displayed on multiple monitors stacked around the surgeon, such as pre-operative images, lab test results and details of previous surgeries.\n\"We look forward to exploring how smart software could help give surgeons the information they need at just the right time during an operation,\" said Andy Conrad, head of the life sciences team at Google.\n Related: Google is developing a cancer and heart attack-detecting pill\nGoogle will be providing software and expertise for data analysis and vision but will not be developing the control mechanisms for the robots.\nThe partnership will help Johnson & Johnson, the world's largest healthcare product manufacturer, to compete in the growing field of robotic medical devices.\nGoogle's life sciences team is also developing systems that can detect cancer and heart attacks using nano particles, and has worked on smart contact lenses that contain sensors capable of monitoring the signs of diabetes - technology that was licensed by the Swiss drug firm Novartis in July 2014 to develop into a practical medical application.\n                     \u00b7 Robear: the bear-shaped nursing robot who'll look after you when you get old                   \n                     \u00b7 Meet Spot the dog, Boston Dynamics' cutest robot yet                   \n"},
{"docid": "444 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "November 12, 2015", "title": "AI: COMING TO YOUR HOME SOON; The rise of the machines is about to change our lives in ways that we never imagined, says Julia Ayling, head of intelligence at Mindshare\n", "content": "Artificial intelligence is hardly a new concept. A test to find if machines could think was developed more than 60 years ago by Alan Turing. But in 2015, AI was dominating the headlines again. Professor Stephen Hawking triggered a fresh debate with dire warnings that our \"slow biological evolution\" meant people \"couldn't compete, and would be superseded\" by AI. Only slightly less nightmarish are predictions that robots will soon replace us in the workforce.\nInvestment in automated technology indicates the latter is likely. The number of robots in Chinese factories is predicted to double to just under 430,000 by 2017. Meanwhile, a recent study from Oxford University has suggested 35pc of UK jobs may be automated in the next 20 years.\u00a0\nTAKE A DEEP BREATH Before we all start hiding under our desks to avoid the newly hired HR robot delivering our P45s, perhaps we should take a deep breath and instead explore the opportunities. At Mindshare, we believe 2016 is when this area will come of age with AI-driven, autonomous agents - able to make decisions and suggestions on our behalf - beginning to play a walk-on role in many areas of everyday life. And let's not forget many of the big media owners are making significant investment in this space. Facebook has an AI research unit specialising in deep learning, and is now developing technologies that analyse videos, help answer questions, and identify people and objects in images. Google has similarly been using AI to help the company understand what is going on in videos, images and speech.\nSERVING THE CUSTOMER So what developments can we expect soon in the area of artificial intelligence? We believe automated customer services will be one of the first areas to develop. One system developed over the past 17 years, is known as Amelia, and is being tested by several companies to see if it can replace online call-centre operators. With reasoning built around a simple flow chart, the system is able to pick out key facts from any information the customer provides, and use this knowledge to determine which questions to ask next. If the customer says something which Amelia does not understand, it can then call for a human operator, observe how they answer the question, and then add this knowledge to the way it works, refining its future behaviour.\nMEET THE FAMILY ROBOT Meanwhile, driverless cars are becoming a reality. Many companies, such as Google and Audi, are testing driverless urban transport. Google's latest driverless cars can be summoned via mobile phone and sensors, with lasers and computers guiding the car to the destination without the need for a human driver.\nWhen not taking our jobs, the more usual imagery around AI is often dominated by Hollywood-style premonitions of humanoid robots, indistinguishable from real people, going rogue and causing chaos in a post-apocalyptic world.\nHowever, the current reality is much more like Jibo, a personal robot designed to live in your home, with your family. Rather than doing tasks such as vacuuming it can act like a physical Siri, answering questions and acting like a hub for connected products around the home. Or how about Riba, a Japanese-designed nursing-care robot that can lift the elderly out of bed? And of course, let's not forget the already established opportunities of virtual assistants - Apple's Siri, Google Now or Microsoft's Cortana. How many decisions will these services start to take over from us over the next year or so? And how will we all feel about ceding control to a machine? In reality, artificial intelligence, in one form or another, has been around for decades. In 2016 we will see it become much more everyday, opening up a raft of issues and complexities for us to deal with as humans. Of course whether the technology develops slowly enough for us to keep up, and to be able to resolve and manage these challenges successfully, is another matter altogether.\n"},
{"docid": "445 of 500 DOCUMENTS\n", "source": "Guardian.com.\n", "date": "January 28, 2014", "title": "Demis Hassabis: 15 facts about the DeepMind Technologies founder\n", "content": "ABSTRACT\nThe man behind Google's new \u00a3400m acquisition is a former child prodigy who was a chess master and a games developer before moving into artificial intelligence, writes Samuel Gibbs\u00a0FULL TEXT\nDemis Hassabis is the founder of DeepMind Technologies, a London-based artificial intelligence firm that Google is spending \u00a3400m to acquire. The former child prodigy is not only a world-leader in AI and neuroscience, but at one time was a teenage chess master, a renowned games developer and a winner of the Mind Sports Olympiad.\n\u00b7 Now 37, Hassabis was born in London in July 1976 and quickly showed academic promise and skill with board games, especially chess.\u00a0\n\u00b7 At the ages of 13 Hassabis reached the rank of chess master, and was the second-highest-rated player in the world under 14 at the time - beaten only by the Hungarian chess grandmaster and strongest female chess player in history, Judit Polg\u00e1r.\n\u00b7 Accelerated through school, Hassabis completed his A-level exams two years early.\n\u00b7 He began a career in video games at British studio Bullfrog Productions, co-designing and lead programming on the classic game Theme Park at 17 years old, alongside the legendary games designer Peter Molyneux.\n\u00b7 Released in 1994, Theme Park sold several million copies and won a Golden Joystick award. The game set players the task of building a successful theme park in the UK with just a few thousand pounds and a small plot of land. (Strategies for success in the game included putting more salt in crisps so people would buy more drinks, making queues long but fast-moving and obscuring the destination, hiring a cleaner to clean the toilets, and placing the exit of one roller-coaster close to the entrance of the next to minimise walking distance between attractions.)\n\u00b7 Hassabis left Bullfrog to study Computer Science Tripos at Cambridge University, which in 1953 had the world's first undergraduate computer science course. He graduated from Queens' College Cambridge with a double first-class honours degree in 1997.\n\u00b7 After graduation, Hassabis rejoined Molyneux, who had now set up another games developer called Lionhead Studios, a breakaway from developer Bullfrog. Hassabis briefly worked as a lead AI programmer on the title Black & White, a game that allowed gamers to play the role of a god ruling over an island populated by various tribes.\n\u00b7 In 1998, Hassabis left Lionhead Studios to found his own London-based independent games developer, Elixir Studios. The company grew to 60 people strong and signed deals with large publishers Vivendi Universal and Microsoft. His games included Republic: The Revolution and Evil Genius. The intellectual property and technology rights from Elixir Studios were sold to various games publishers and the studio was closed in April 2005.\n\u00b7 In 1999, aged 23, he won the Mind Sports Olympiad - an annual international multi-disciplined competition for games of mental skill. He won it a record five times before retiring from competitive play in 2003.\n\u00b7 Hassabis was later elected as a fellow of the Royal Society of Arts in 2009 for his influential game-design work and contribution to the games industry.\n\u00b7 Hassabis then changed tack, switching from games development to a career in cognitive neuroscience, to allow him to return to his primary interest in artificial intelligence. During the course of a PhD in cognitive neuroscience at University College London (UCL), Hassabis published several influential papers concerning memory and amnesia.\n\u00b7 His work was listed as in the top 10 scientific breakthroughs of 2007 by Science magazine. Hassabis established a new theory around the way the mind creates and maintains the context of remembered events as a key process underlying both the recall of memories and imagination. Some of Hassabis's findings were subsequently disputed by experts in the field; the debate is still ongoing.\n\u00b7 Hassabis received his PhD in cognitive neuroscience from University College London in 2009. He continued his neuroscience and AI research at the Gatsby Computational Neuroscience Unit at UCL as a Wellcome Trust research fellow. He was also a visiting researcher jointly at MIT and Harvard.\n\u00b7 In 2011 he left academia to co-found a London-based artificial intelligence startup, DeepMind Technologies, with Shane Legg, whom he met at UCL, and Mustafa Suleyman. Among other things, the company developed a computer system capable of understanding and playing an Atari computer game simply by looking at it on a screen as a human would.\n\u00b7 On 27 January, DeepMind was acquired by Google for \u00a3400m - the company's largest European acquisition - in order to add technology and talent to Google's core business of search. Google uses AI to understand search queries providing context awareness and allowing users to talk to the computer as they would a human, whether by voice or using a keyboard.\n"},
{"docid": "446 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "July 7, 2016", "title": "Wish you were on Centre Court? There will soon be an app for that\n", "content": "The future of tennis has been glimpsed and it features cameras on umpires' heads, tracking devices on players' shirts and artificial intelligence trained on the crowd to identify who they support.\nTechnology wizards behind the scenes at Wimbledon hope to bring the game closer to fans with more camera angles and data tailored to their tastes.\nIBM deploys 200 people at the All England Club, including 48 \"national level\" tennis players who \"read the game ahead of the time\" and channel information to players.\u00a0\nMinutes after a match ends competitors receive a USB stick containing a match analysis report, with details such as how many times their shots landed within a 6in area.\nIn an era when a handful of top players, including Nick Kyrgios and Grigor Dimitrov, have dispensed with coaches, it also tells them when their rackets are being stringed and what time their car will pick them up.\nSam Seddon, an IBM executive, said that the possibilities that technology offered for fans and players were incredible, but he cautioned that there were always questions about what would be considered suitable for the hallowed turf of Wimbledon. Crucially, any change would have to be sanctioned by the All England Club.\n\"I would love to put 360-degree cameras on the umpire's head,\" he said. \"Everybody would love to go in the changing rooms and on the grass but you are not allowed. With this you could have the opportunity to see something that you would not normally see.\"\nIBM supplies data and television footage to an ever-expanding suite of apps for the All England Club. This year, there is a dedicated app for Apple televisions.\nAlthough the BBC owns the rights to broadcast the championships in Britain, there are signs that its hold is slipping. It has already sub-licensed footage to Eurosport, which has put on an evening highlights package and will show the singles finals live this weekend in direct competition.\nThe availability of footage and data on the All England Club's digital platforms will further eat into the BBC's dominance.\nMr Seddon said that on a private site IBM was testing how artificial intelligence could be used to \"read\" the faces of people in the crowd, with the possibility of channelling tailored information to individual digital devices, based on who the computers thought they were supporting.\nIBM's artificial intelligence system, Watson, has been used at this year's championships to monitor social media conversations and \"tailor\" content for its own platforms. Mr Sed-don stressed that it was not yet monitoring the facial expressions of spectators - there are a whole host of legislative and ethical hurdles that would have to be overcome before the pilot scheme could be deployed on Centre Court. \"The technology and capability exists for all of these things but you also have to ask, 'So what?',\" he said. \"What do [fans] gain from it?\" He added that wearable technology was already being used by professional players but that any footage transmitted from cameras installed in shirts and on rackets would be jerky.\nPlayers are allowed during training to use sensors in rackets, for example, to test how much topspin they are putting on shots.\nMr Seddon's views on the potential of technology in tennis are shared by a senior executive at the governing body, the International Tennis Federation.\nKris Dent told the Financial Times earlier this year: \"Technology will go a long way to helping us innovate fan experience, linking those at home with those in stadia.\nWearable tech for players is the next big thing and has the potential to revolutionise the fan experience.\"\nSport, pages 80-83\n"},
{"docid": "447 of 500 DOCUMENTS\n", "source": "The Guardian - Final Edition\n", "date": "July 22, 2008", "title": "G2: Arts: Another view Roboticist Noel Sharkey on Wall-E\n", "content": "I don't believe in the idea of independent thinking robots. Artificial intelligence is about making machines that can appear intelligent to humans, but they are not self-aware. I've been working in artificial intelligence for 30 years, and there is no glimmer of that.\u00a0\nI have a robot called eMo, which can recreate human expressions, but I look at WALL-E with envy. Its whole face consists of nothing more than two camera bodies, but the animators have used them to create the whole range of human expressiveness. I would love to have created that. Eve, the more futuristic robot that WALL-E falls in love with, was just as expressive, but I was distracted by its ability to float. I didn't understand it at all as a machine, so that rather ruined the plausibility.\nWALL-E, on the other hand, was very plausible. Don't forget this is a story set 800 years in the future; a robot that can collect and compact garbage doesn't seem all that unlikely. But why give it a personality, goals and desires? The implication was that WALL-E had developed its character over time, but how? Even if it was programmed as a learning robot, it had no one to learn from. It was abandoned for 700 years, the last inhabitant of a deserted earth. If you left a human alone for that long, they would go completely crazy.\nThere is nothing remotely like WALL-E in robotics, not yet, but the expressive robot is the direction we are heading towards. There's a whole field called HRI - Human Robotic Interaction. The film takes us several steps further and suggests a terminally lazy society completely controlled by service robots. Unfortunately, this really is the direction we are taking. There are robots caring for the elderly in Japan now. I don't want that sort of life. I don't want to be lifted and carried by robots. I wouldn't mind having one in the kitchen, though.\nNoel Sharkey is a professor of robotics and artificial intelligence at Sheffield University. WALL-E is on general release.\n"},
{"docid": "448 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "July 12, 2015", "title": "Interactive Mona Lisa: Famous Leonardo da Vinci painting goes digital; Digital version of Mona Lisa lets her live a little, changing expression depending on her \"mood\"\n", "content": "A new interactive version of the Mona Lisa allows her to replace her enigmatic smile with a frown, pucker her lips and follow viewers' movements with her eyes. \nThe digital \"Living Mona Lisa\", which employs artificial intelligence technology, has been produced by a team of 40 French technicians and artists, who worked on the project for nearly a year. \u00a0\nFlorent Aziosmanoff, the originator of the interactive version, said the idea was to convert the Mona Lisa into a modern format: \"Now she can sense changes in her surroundings. Leonardo da Vinci tried to make her come alive, so it's appropriate that we've taken his intentions a few steps further.\"\nThe \"Living Mona Lisa\" is equipped with a motion sensing device used in interactive video games. It picks up spectators' movements and their images, allowing her \"to react depending on her mood\", said Jean-Claude Heudin, the head of the Paris Internet and Multimedia Institute, which developed the artificial intelligence systems. \nMr Aziosmanoff, who specialises in \"digital, living art\", said he chose the Mona Lisa because \"she is the best known and one of the most iconic characters in the history of art\". \nThe painting itself hangs in the Louvre museum in Paris, but digital versions will be produced and marketed in different sizes and formats. \nDigital paintings are to go on sale in the autumn for \"a few hundred euros\" while a miniature version can be placed on a pendant and surrounded by jewels. \n\"Necklaces and other jewellery versions will be sold at different prices depending on whether they have precious stones or not,\" Mr Aziosmanoff said. \n\"This is primarily an artistic project, not a commercial one, but we want to make paintings cheap enough for tourists to buy and take home as a souvenir.\"\nMr Heudin acknowledged that the project was \"crazy\" but said he was attracted to it because it could serve as a prototype. \n\"One of the future objectives is to develop an emotional context that will take into account the past experiences and interactions of the system.\"\n"},
{"docid": "449 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "March 10, 2016", "title": "Google's Go computer beats human competitor to go 2-0 up and one game away from huge AI breakthrough; The computer is just a game away from a million dollars and a proof of one of the most exciting artificial intelligence technologies ever made\n", "content": "                     Google's Go-playing computer has scored a second victory against its human component, putting it just one win away from victory.\u00a0\nThe AlphaGo computer - powered by Google's DeepMind artificial intelligence - is well on its way to a landmark victory that could mark one of the greatest moments in the history of AI.\nIf the computer is able to win the five-game match, it could be seen as huge step forward in making computers that think like humans. The game that the two are playing, Go, is thought to be one of the ultimate tests of human intuition - and a win could be a major demonstration that machines are learning some of the abilities that were previously thought to belong only to humans.\nAlphaGo's first win against Mr Lee in Seoul on Tuesday shook the Go-playing world, marking a milestone in the development of artificial intelligence.\nAfter his first loss, Mr Lee said he was in shock as he did not expect to lose. Google's team compared AlphaGo's win to landing on the moon.\nHis opponent, Lee Sedol, had originally said that he expected to win five of the games, and then revised that down to four.\nThree remaining games run until Tuesday.\nAdditional reporting by Press Association\n"},
{"docid": "450 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "August 26, 2014", "title": "Page 3 Profile: BabyX, computer-generated infant\n", "content": "Who's the adorable little nipper?\nThis toddler can read basic words, recognise symbols and, like many infants, soaks up information like a sponge. Unlike most of its peers though, this baby could help unlock the secrets of the human brain. Oh, and the child, known as BabyX, is in fact a computer-generated creation designed as part of a project to recreate brain activity and model neural pathways.\u00a0\nSo this isn't really a baby at all?\nBabyX was developed by researchers in New Zealand and can see, hear, mimic facial expressions, respond to feedback and even gets distracted, frequently losing its focus to stare around the room. \nArtificial Intelligence has never looked so...creepy\nThe blonde infant incorporates a number of algorithms, mimicking neural behaviour when it comes to learning and responses to the world around it in real-time - such as the effect of dopamine when it receives praise, for instance, which elicits delighted giggles from the 3D baby. The researchers use learning models, such as repetition, association, conditioning, and imitation to teach BabyX basic skills.\nWhat happens BabyX grows up?\nThe project aims to examine the brain during its formative years as opposed to later in life so fingers crossed the scientists never have to confront a TeenagerX. And if technological singularity - a time when artificial intelligence exceeds human intelligence - does comes about, let's hope BabyX uses its powers for good not evil. \n"},
{"docid": "451 of 500 DOCUMENTS\n", "source": "DAILY MAIL (London)\n", "date": "April 5, 2017", "title": "WILL RISE OF ROBOTS LEAD TO QUOTAS FOR HUMAN EMPLOYEES?\n", "content": "ROBOTS are now so likely to take people's jobs that governments may need to set quotas for human employment, experts have warned.\u00a0\nLawyers have also called for a new labelling system to show which products are made by humans - in the same way we have fair trade', free range' and organic' labels.\nThe International Bar Association made the suggestions as it warned politicians that they need to put new protections in place to ensure humans keep control. In another proposal that could prove popular, they also said governments could protect human jobs by introducing a four-day working week.\nThe 120-page report warned that artificial intelligence (AI) was developing so rapidly, it was hard for the legal system to keep pace. It suggested forcing major companies that turn to robots to pay an extra tax to help care for the people they replace.\nTransport workers, factory staff and shop assistants are thought to be among those at highest risk from robots stealing their work.\nGerlind Wisskirchen, one of the authors of the study - Artificial Intelligence and Robots and Their Impact on The Workplace - said: New labour and employment legislation is urgently needed to keep pace with increased automation.'\n\u00a9 Daily Mail\n"},
{"docid": "452 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "March 25, 2016", "title": "Tay Tweets: Microsoft shuts down AI chatbot turned into a pro-Hitler racist troll in just 24 hours; The messages started out harmless, if bizarre, but have descended into outright racism - before the bot was shut down\n", "content": "                     Microsoft created a chatbot that tweeted about its admiration for Hitler and used wildly racist slurs against black people before it was shut down.\nThe company made the Twitter account as a way of demonstrating its artificial intelligence prowess. But it quickly started sending out offensive tweets.\u00a0\n\"bush did 9/11 and Hitler would have done a better job than the monkey we have now,\" it wrote in one tweet. \"donald trump is the only hope we've got.\"\nAnother tweet praised Hitler and claimed that the account hated the Jews.\nThose widely-publicised and offensive tweets appear to have led the account to be shut down, while Microsoft looks to improve the account to make it less likely to engage in racism.\nThe offensive tweets appear to be a result of the way that the account is made. When Microsoft launched \"Tay Tweets\", it said that the account would get more clever the more it was used: \"The more you chat with Tay the smarter she gets\".\nThat appears to be a reference to machine learning technology that has been built into the account. It seems to use artificial intelligence to watch what is being tweeted at it and then push that back into the world in the form of new tweets.\nBut many of those people tweeting at it appear to have been attempting to prank the robot by forcing it to learn offensive and racist language.\nTay was created as a way of attempting to have a robot speak like a millennial, and describes itself on Twitter as \"AI fam from the internet that's got zero chill\". And it's doing exactly that - including the most offensive ways that millennials speak.\nThe robot's learning mechanism appears to take parts of things that have been said to it and throw them back into the world. That means that if people say racist things to it, then those same messages will be pushed out again as replies.\nIt isn't clear how Microsoft will improve the account, beyond deleting tweets as it already has done. The account is expected to come back online, presumably at least with filters that will keep it from tweeting about offensive words.\nNello Cristianini, a professor of artificial intelligence at Bristol University, questioned whether Tay's encounter with wider world was an experiment or a PR stunt.\n\"You make a product, aimed at talking with just teenagers, and you even tell them that it will learn from them about the world,\" he said.\n\"Have you ever seen what many teenagers teach to parrots? What do you expect?\n\"So this was an experiment after all, but about people, or even about the common sense of computer programmers.\"\n"},
{"docid": "453 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "January 12, 2015", "title": "Experts including Elon Musk call for research to avoid AI 'pitfalls'; An open letter from AI researchers warns of pitfalls ahead, and lays out a plan for avoiding them while improving the quality of artificial intelligence\n", "content": "More than 150 artificial intelligence researchers have signed an open letter calling for future research in the field to focus on maximising the social benefit of AI, rather than simply making it more capable.\u00a0\nThe signatories, which include researchers from Oxford, Cambridge, MIT and Harvard as well as staff at Google, Amazon and IBM, celebrate progress in the field, but warn that \"potential pitfalls\" must be avoided.\n\"The potential benefits [of AI research] are huge, since everything that civilisation has to offer is a product of human intelligence; we cannot predict what we might achieve when this intelligence is magnified by the tools AI may provide, but the eradication of disease and poverty are not unfathomable,\" the letter reads.\n\"Because of the great potential of AI, it is important to research how to reap its benefits while avoiding potential pitfalls.\"\nThe group highlights a number of priorities for AI research which can help navigate the murky waters of the new technology.\nIn the short term, they argue that focus should fall on three areas: the economic effects of AI, the legal and ethical consequences, and the ability to guarantee that an AI is \"robust\", and will do what it is supposed to.\n\"If self-driving cars cut the roughly 40,000 annual US traffic fatalities in half, the car makers might get not 20,000 thank-you notes, but 20,000 lawsuits,\" marking one potential legal pitfall. And the ethical considerations involved in using AI for surveillance and warfare are also noted.\nBut in the long-term, the research should move away from the nitty-gritty, towards tackling more fundamental concerns presented by the field, the researchers argue - including trying to prevent the risk of a runaway super-intelligent machine.\n\"It has been argued that very general and capable AI systems operating autonomously to accomplish some task will often be subject to effects that increase the difficulty of maintaining meaningful human control,\" they write. \"Research on systems that are not subject to these effects, minimise their impact, or allow for reliable human control could be valuable in preventing undesired consequences, as could work on reliable and secure test-beds for AI systems at a variety of capability levels.\"\nThe letter is also signed by physicist Stephen Hawking and entrepreneur Elon Musk, who has been outspoken about his fear of super-intelligent AI in the past.\n\"I think we should be very careful about artificial intelligence. If I had to guess at what our biggest existential threat is, it's probably that. So we need to be very careful,\" the space-flight and electric-car pioneer said in 2014. \"I'm increasingly inclined to think that there should be some regulatory oversight, maybe at the national and international level, just to make sure that we don't do something very foolish.\"\nAlongside Musk's two major projects, SpaceX and Tesla Motors, he is also an early-stage investor in Vicarious, an AI research firm which aims to build a computer that can \"think like a person,\" and DeepMind, the Google-owned AI research company. He made the investments, he has said, because he fears a \"Terminator\"-style outcome if AI research goes wrong.\n\u00b7 Elon Musk: artificial intelligence is our biggest existential threat\n"},
{"docid": "454 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "February 9, 2017", "title": "AI could transform the way governments deliver public services; The UK government needs a clear strategy and an open conversation with the public in order to catch up with its global peers\n", "content": "Lauding the transformative powers of artificial intelligence (AI) has almost become a cliche, and with good reason. It permeates our everyday lives. AI manifests itself through film or music recommendations, speech recognition on our phones or face recognition in our digital photo albums. And AI has the potential to transform the way governments design and deliver public services.\nOur report, published on 6 February, predicts that almost 250,000 public sector workers could lose their jobs to robots over the next 15 years.\u00a0\n Related:  Robots 'could replace 250,000 UK public sector workers'\nGovernments around the world have recognised the potential of AI, but in practice actual application varies widely. Japan and Singapore are at the forefront of marrying intention and action to harness the power of AI. \nJapan's prime minister sees it as a vital tool to enhance the country's sluggish economy and Singapore views it an essential part of its plan to become a smart nation. This has translated into greater government investment in R&D, and, crucially, the creation of partnerships with the private sector and universities around the world. Singapore has partnered with Microsoft to create chatbots to deliver certain public services. Japan has partnered with universities in the US to complement their comparative lack of expertise in machine learning. Across the Atlantic, the Obama administration developed a national plan for artificial intelligence, though it is difficult to assess whether Trump's government will action it.\nNational capability is a key factor in progress - demonstrated in the different specialisms of countries. Japan, for example, is mostly known for its robotics, largely driven by the government's need to care for an increasingly ageing population. Robots, for example, are being used to assist the elderly in walking and bathing. The US retains most of the expertise in machine learning, driven by pioneering universities such as MIT and the Silicon Valley.\nLike the US, the UK is well placed to harness AI through its universities and private sector, but the government's AI strategy is less clear. This has meant piecemeal application, largely driven by the initiative of individual service providers. The use of chatbots in the London Borough of Enfield, for example, or Moorfield's eye hospital, which partnered with Google DeepMind to use the powers of AI to increase early diagnosis of degenerative eye conditions. \n Related:  I worked in local government - show me a robot that could do my job better\nOne weak point for many governments is establishing a clear ethical framework for AI use. Many initiatives around the world, such as Leverhulme Centre for the Future of Intelligence in the UK, are working on solutions and plans. But partnerships with the private sector are happening right now, and current legislative frameworks are not adapting fast enough. Data protection laws in the UK favour data minimisation and purpose specification, which run contrary to the basic principles underpinning machine learning algorithms, which need big data to draw valuable insights. \nGovernments around the world are at different stages in the global race to harness AI. Those at the front have clear strategies, strong cross-sector partnerships and political will driving them. The UK is well placed to make the most of this ever evolving technology - but success requires a comprehensive strategy and an open conversation with the public. \n                     Eleonora Harwich is a researcher at thinktank Reform.                    \n                     Talk to us on Twitter via                                            @Guardianpublic and                                            sign up                      for your free weekly Guardian Public Leaders newsletter with news and analysis sent direct to you every Thursday.                   \n"},
{"docid": "455 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "August 13, 2017", "title": "Buy these seven shares to profit from driverless cars and artificial intelligence\n", "content": "The idea of investing in technology companies will, for many, bring back painful memories of the tech bubble bursting at the turn of the millennium.\n                     Today, there is little of the mania of two decades ago. Technology firms are typically more expensive to buy than the wider market, but\u00a0are now delivering significant profits - which were conspicuously absent the first time around.\nSome investors will have exposure to technology through companies such as Amazon, Facebook and Google, which are popular holdings in many funds available to British savers. Such businesses are involved in many cutting-edge areas of technology, including autonomous cars, artificial intelligence, machine learning and more.\nBut there is another approach: investing in companies that make \"enabling\" technology, the components and software used in many of the most advanced developments.\u00a0\n                     Telegraph Money asked a number of technology fund managers to name some of their favourite stocks. There are very few quoted technology firms in Britain, so many of the stocks discussed here are listed overseas.\u00a0\nA number of investment shops, including Hargreaves Lansdown and TD Direct, offer international share dealing, although not all do so within an Isa. You may need to fill in special forms before you trade, depending on the country.\n                   Autonomous vehicles                   \nFully autonomous cars are estimated to be just five years away, depending on both technology and  the development of a regulatory system . This will dramatically increase the market for the components required.\nFor now, much of the growth comes from \"advanced driver assistance systems\", such as automatic braking or adaptive cruise control.\nInfineon Technologies (German listed)\n                     Market value: \u00a319.5bn                   \n                     Last year's pre-tax profit: \u00a3763m                   \nThis semiconductor firm was tipped by all of the technology fund managers we spoke to. It makes components used in systems such as emergency braking and battery management.\nHyunho Sohn, manager of the \u00a32bn Fidelity Global Technology fund, said: \"Infineon exemplifies a company poised to gain from the move to electric and autonomous cars. It has a market-leading position and, as the technology going into each vehicle increases, it should experience increases in revenue and margin.\"\nDelphi (US listed)\n                     Market value: \u00a318.7bn                   \n                     Last year's pre-tax profit: \u00a31.9bn                   \nDelphi integrates different technologies into packages that meet the rigorous standards of the automotive industry, Mr Sohn explained\nHe said: \"The firm has strong relationships with the major car manufacturers, and is well positioned to profit from both the rapid proliferation in low-level systems, and the eventual roll-out of fully autonomous driving.\"\u00a0\nThe company recently assembled an autonomous Audi which drove itself from San Francisco to New York, which Mr Sohn described as the \"most sophisticated autonomous vehicle to date\".\u00a0\n                   Sign up to Telegraph Investor                   Artificial intelligence and machine learning                   \nThe concept of artificial intelligence -  the ability of a computer system to learn and adapt - has existed for decades.\nBen Rogoff, manager of two Polar Capital technology funds totalling \u00a32.5bn, explained that, as with any technology, AI started out as a promise with no means of delivery.\n\"Today, it feels like we have the capability, thanks to computing breakthroughs, cheap data storage and the internet. Right now the applications are straightforward, such as facial recognition and improving search results, but they will expand,\" he said.\nNvidia (US listed)\n                     Market value: \u00a375bn                   \n                     Last year's pre-tax profit: \u00a31.9bn                   \nNvidia, tipped by several managers, could fall under a number of the categories here. Its graphics processing units (GPUs) are becoming increasingly important for \"vision systems\" in autonomous cars, Mr Rogoff said.\nHe said AI offered another avenue for expansion, as GPUs could be used to \"train\" AI networks.\n\"This is what makes AI intelligent - the ability of the network to improve by looking at its past mistakes. Nvidia has become the best way to play this theme among quoted stocks,\" he said.\nBlue Prism (UK listed)\n                     Market value: \u00a3578m                   \n                     Last year's pre-tax profit: \u00a35m loss                   \nThis firm makes software \"robots\" that automate tasks to create a so-called \"digital workforce\".\nChris Ford, manager of Smith & Williamson's new Artificial Intelligence fund, described it as \"one of the very few pure AI companies anywhere in the world\".\nHe said: \"It's covered by only two analysts and could fall into the 'undiscovered gems' camp despite the huge recent rise in the share price . We think this technology will become ubiquitous for financial firms to reduce cost and improve accuracy. The ability to avoid regulatory breaches is just as important as the cost saving.\"\n                   Blue Prism 1yr                   \nXilinx (US listed)\n                     Market value: \u00a311.8bn                   \n                     Last year's pre-tax profit: \u00a3699m\u00a0                   \nThere are multiple parts of an AI network, with some companies specialising in different parts of the chain.\u00a0\nMr Rogoff explained that once an AI network has been trained, \"it needs to be able to make decisions\".\u00a0\nXilinx is a \"veteran\" semiconductor company that handles the inference part of machine learning. It was the inventor of a\u00a0type of \"logic\" chip that is used in such systems, and enjoys a major market share as a result.\u00a0\n                   Machine vision                   \nCognex (US listed)\n                     Market value: \u00a36.7bn                   \n                     Last year's pre-tax profit: \u00a3161m                   \nCognex makes \"machine vision\" systems that are used to scan and check products or labels.\nTom Riley, manager of the Axa WF Framlington\u00a0Robotech fund, said the technology was becoming more widespread, with \"more and more manufacturing applications\" and increasing use in logistics.\nMr Rogoff added: \"We're pretty sure that Apple is a big customer and that Amazon is using their systems.\"\n                   Big data                   \nFirst Derivatives (UK listed)\n                     Market Value: \u00a3705m                   \n                     Last year's pre-tax profit: \u00a312m                   \nThis data and consulting company has a proprietary database that is used in big data applications within finance, such as spotting insider trading, according to Mr Rogoff.\nHe has a position in the company - a rare UK holding - but explained\u00a0it is small due in part to liquidity issues.\u00a0\n\"We think we have the best of the UK technology sector covered, and the UK takes up less than 2pc of the Global Technology fund,\" he said.\u00a0\n                   First Derivatives 1 yr                   Prefer a fund? This one is the best                   \nIf you don't want to buy individual stocks, there are a number of technology funds that invest around the globe.\nRyan Hughes, head of funds at AJ Bell, the investment shop, said: \"There is one stand-out team -  Polar Capital Global Technology . It is led by Ben Rogoff, who has been a technology investor for 20 years.\"\n\n"},
{"docid": "456 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "October 12, 2015", "title": "?Positive PR is needed to show there's nothing to fear from human-friendly AI; We have to contradict dystopian media depictions of artificial intelligence by showing the benefits it already brings\n", "content": "It's a question even the BBC has been asking: \"How safe can artificial intelligence be?\" \nThe broadcaster devoted large chunks of airtime recently on the subject of intelligent machines, with its science editor David Shukman declaring: \"If Hollywood movies are your only guide to artificial intelligence, we face a terrifying future in which machines become so clever that they dominate or even destroy us.\"\n Related: Why we have to get smart about artificial intelligence\u00a0\nSo it is hardly surprising that the public is fearful when it comes to the subject.\nMake no mistake about it: AI is getting an undeserved bad press. Its presentation and depiction in movies and on television is almost exclusively negative, dark and sinister. From the release of 2001: A Space Odyssey in 1968, to The Terminator in 1984, The Matrix in 1999, and the recent TV hit Humans the message has been the same: super-intelligent machines pose a massive threat to us all.\nAt the heart of all these depictions is the unfounded belief that the human race is on the brink of being destroyed by its own creation of super-robots, capable of mimicking the human brain.\nIn fact, AI is not simply the creation of intelligent robots, but a term that describes a group of techniques and approaches in engineering and technology. And some of those techniques are already working quietly in the background, making our everyday lives better and easier, even though we may not realise it.Accentuate the positive\nMaking people fully aware of the benefits they already receive from AI is the kind of positive publicity that is needed. Those of us working in the field need to show the public how and why our research and work is so important. Informed debate can allay many of the unfounded fears that exist.\nIt should also be pointed out that we are many years away from having the technology to create anything that could rival the complexity of the human brain. It remains the most complicated and complex structure in the known universe. With it we process vast amounts of information and deal with multiple, complex problems simultaneously.\nWe have the ability to learn new things and retain old memories; we can solve problems, generate ideas and create amazing art, music and artefacts.\nThat's all very difficult to replicate with artificial systems. Currently, the creation of super-intelligent, self-thinking, human-like robots, remains possible only in sci-fi films. Science reality is that AI is working for us in a myriad of ways, with not a robot in sight. Embedded and invisible, phones, digital cameras and even washing machines already use some of the techniques that fall under the general description of AI.\nOur smartphones are smart, in part, because of embedded AI in their software systems. The technology used to connect your mobile to the best available network when you are out and about is based partly on how ants in the natural world forage for food.\n                     Ants set up a circuit of permanent pathways - much like the network of mobile phone towers - from which they search locally. They also create complex communication networks using trails of pheromones that can be detected by other ants.Unnecessary fears\nIn fact a lot of new developments in AI are attempts to replicate systems from the natural world, where millions of years of evolution have resulted in systems that work well for particular problems or situations.\nHuman society is also developing all the time and we are now seeing the development of smart cities, intelligent transport networks and massive connectivity.\nAgain these smart or intelligent systems use different aspects of AI to help solve specific problems, usually with AI embedded in systems that are invisible to most of us. AI is helping doctors, engineers, scientists, bankers, and even weather forecasters to do their jobs better, and to create healthier, more prosperous societies. That's the story that isn't being told or portrayed in the media.\nThe key thing is that AI is aiding, not taking over from, humans. Be it AI in your digital camera or in your washing machine or microwave, it only works when you want it to. You switch it on or off - you are the master.\n Related: How to prevent creeping artificial intelligence becoming creepy\nThis takes us to the heart of another important issue, which needs to be carefully considered as we see AI techniques and approaches develop. It centres on a difficult but important ethical question that the television drama Humans helped highlight recently.\nMost of the negative representations of AI revolve around computer systems, or robots that become conscious, meaning self-aware and acting independently of human control. There is a real question as to what conscious even means, but it asks us some very tricky questions when we look to the future.\nFor example, if I have created some intelligent software that learns and develops, and develops consciousness, but it only exists on my computer, if I switch off the machine have I killed it? And do I have the right to do so? Can conscious AI systems suffer?\nThese may seem to be just abstract, philosophical questions at the moment. However, as AI continues to develop over the decades they are questions that will become more relevant. It is only right that we start that debate now.\n                     Professor John MacIntyre                     is the dean of the Faculty of Applied Sciences and pro vice chancellor at the University of Sunderland.                   \n                       To get weekly news analysis, job alerts and event notifications direct to your inbox,                         sign up free for Media & Tech Network membership                       .                   \n                     All Guardian Media & Tech Network content is editorially independent except for pieces labelled \"Brought to you by\" - find out more                                            here                                          .                   \n"},
{"docid": "457 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "January 22, 2016", "title": "Countries race to build armies of killer robots\n", "content": "Robots capable of going to war without any human intervention are being developed by 40 countries in a technological arms race outpacing current weapons regulations.\nSir Roger Carr, the chairman of BAE Systems, said that a new breed of killing machines powered by artificial intelligence underlined the dangers of rapid technological change.\u00a0\n\"I am not an advocate of this type of equipment, nor is my company,\" the head of Britain's biggest defence contractor told delegates in Davos. \"Lines need to be drawn. It is important that governments draw the line where we move into territory where we risk becoming the architects of destruction, but simply spectators at the event.\"\nHe cautioned that the \"risk is that wherever we draw lines, humans find a way to cross them\", citing the development of chemical and biological weapons despite attempts to outlaw them. Sir Roger said that there were 40 countries working on producing such a machine \"in potentially a $20 billion market\". They were understood to include France, America, South Korea, China, Russia and Israel. Major economies needed to be at the cutting edge of such technology to ensure that they understood it, Sir Roger added. He declined to say whether Britain was developing war robots. The risk is that they end up in the hands of rogue states.\nSir Roger distinguished between the levels of robotics. The simplest are used to clear mines. In the next level up, sensors, algorithms and decision-making capability are embedded in devices but responsibility still lies with a human.\n\"The final level is fully autonomous, and that is a very difficult area - deploying a weapon without any human intervention,\" he said. \"That places the [artificial intelligence] weapon in an area that is completely devoid of any human responsibility or ethical or moral concern or sense of mercy.\"\nAngela Kane, of the Vienna Centre for Disarmament and Non-Proliferation, said that the use of drones in warfare, with decisions taken by commanders thousands of miles from the action, \"desensitised\" the act of killing.\nShe urged governments and regulators to act fast to bring artificial intelligence into the regime governed by the United Nations Convention on Certain Conventional Weapons.\nDavos reports, page 49\n"},
{"docid": "458 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "November 28, 2012", "title": "An artificially intelligent future: Ray Kurzweil on engineering the brain; Ray Kurzweil foresees a disease-free world where no one ages and artificial brains make machines human-like - and he is not one to get things wrong\n", "content": "He is a pioneer, exploring a hinterland that lies just beyond the horizon of current possibilities; a twilight zone between science fact and fiction, between predictions rooted in existing technology and the wildest lunatic speculation.\nRay Kurzweil is an American technologist and futurist who is on a mission to make us all immortal, starting with himself, thanks to what he calls 'the law of accelerating returns'. The rate of change is getting faster to the extent that 'within 10 or 15 years we will be able to overcome cancer and heart disease, and stop and reverse ageing'. Thanks to the 'exponential progression' of technology, Kurzweil says, we are heading for 'profound changes', an event horizon where artificial intelligence spirals beyond our control, or even our understanding.\nIt is a clich\u00e9 to fear the relentless rise of machine power and intelligence. But it doesn't frighten Kurzweil. In his books The Age of Spiritual Machines and The Singularity Is Near he has argued that artificial intelligence will augment human intelligence, not replace it. There is appetite for his boldly optimistic way of thinking: both books were bestsellers.\u00a0\nIn his latest, published recently in America, How to Create a Mind: The Secret of Human Thought Revealed, Kurzweil envisages 'reverse engineering the human brain' and a time when humanity and technology will fuse to give birth to a new sort of existence. But why stop there? Kurzweil believes that beyond this lies an inflection point, a nirvana where we can scan our consciousnesses into computers, then inhabit them as software, for ever, virtually.\nYou would be forgiven for thinking this all sounds a tad speculative, but Kurzweil is taken more seriously than your common-or-garden seer because of his track record in innovation, which started at the age of 14 when he wrote software that ended up in an IBM computer. In the late 1970s his character-recognition programs scanned legal documents and printed articles to create the Lexis and Nexis databases. After a 1982 meeting with Stevie Wonder, Kurzweil was inspired to create a new generation of synthesizers. A few years ago he deployed an automated system for playing the stock market, called FatKat. In 1990 he predicted that a computer would beat a human at chess by 1998 ('It happened in 1997').\nSo what's next? Machines are going to become more human-like, Kurzweil predicts. In How to Create a Mind, he discusses how to simulate the brain, understand 'the principles of operation, the basic ideas that evolution utilised to create intelligent performance' and then 'focus, amplify and leverage them' to create even smarter machines.\nKurzweil dismisses the claim of his detractors that it would take 'trillions of lines of code' to simulate a brain. He sees the brain as layer upon layer of pattern recognition, that extend from spotting the shape of a letter to irony, humour or pity. 'There are 300 million pattern recognisers in the human cortex,' he says. By simulating these biological modules, he is confident that before long the moment will come when computers can model human consciousness.\nAnd yet, Kurzweil adds, 'There are limitations to the human brain.' The electrical signals that zip around our heads are somewhat sluggish. So why not, he says, develop ways to download our minds into machines? 'We have extended our physical reach and we are now going to extend our mental reach, by merging with our tools.' To do that non-invasively will take technology that he predicts is only a few decades away. \nNow 64, he wants to ensure that he is still around when humanity takes its next evolutionary step. His father died of heart disease, and he himself was diagnosed with high cholesterol and type 2 (adult) diabetes aged 35. After using old-fashioned diet to tackle these problems, Kurzweil decided to try speculative ideas. A decade ago he met Terry Grossman, a 'leading proponent of immortality medicine', who prescribed a cocktail of complementary treatments. In reality, that means about 150 pills a day. Kurzweil claims his physical profile now matches that of 'someone much younger than myself', so he may still be alive when scientists build the next 'bridge' in technology, the stem cell revolution, and that in turn will keep him making predictions until the subsequent bridge, when nanobots will have been designed to prowl around his bloodstream.\nA conversation with Kurzweil is entertaining, thought-provoking and just a little bit bonkers. But one thing is certain - this is a man who is not prepared to accept his limitations. \n                     Roger Highfield is director of external affairs at the Science Museum Group. 'How to Create a Mind', by Ray Kurzweil, will be published by Duckworth in February                   \n"},
{"docid": "459 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "June 23, 2012", "title": "Google doodle becomes an enigma in honour of Alan Turing; Search giant Google has turned its homepage \"doodle\" into a Turing machine in honour of British mathematician and codebreaker Alan Turing.\n", "content": "The Google Doodle was turned into an interactive animated representation of the computing device Turing invented to mark the 100th anniversary of the scientist's birth. \n                     Turing, regarded as the father of computing and artificial intelligence, is best known for his contribution to cracking the German Enigma codes during the second world war with the creation of early computers such as the bombe. \u00a0\nOn Saturday scientists and others paying tribute to Turing gathered in Manchester, Oxford and Cambridge to take part in events to celebrate his work. \nPlaques in his honour will be erected in Cambridge, Manchester and at his childhood home, Baston Lodge in St Leonards-on-Sea in East Sussex. \nA spokeswoman for Alan Turing Year, a campaign to celebrate his work during the whole of 2012, said: \"Turing was godfather of computer science and (an) artificial intelligence pioneer, as well as someone who saved literally millions of lives through his code breaking work.\" \nTuring's anniversary comes as a leading academic has claimed that the mathematician may not have committed suicide but had died as a result of an accident. \nProfessor Jack Copeland, director the Turing Archive for the History of Computing, believes crucial evidence was overlooked following Turing's death from cyanide poisoning at the age of 41 in 1954. \nHe believes Turing could have died as a result of inhaling the poison he used in amateur experiments rather than deliberately ingesting it. \nProfessor Copeland, who has written a new biography of the academic to be published shortly, said: \"From the records I have been able to obtain, it seems to me very obvious that the inquest was conducted in a very superficial way. \n\"The coroner didn't really investigate the evidence at all, he just jumped to the conclusion that he committed suicide. \n\"He seems to have been very biased from the statements in newspapers at the time.\" \nThe coroner in Turing's death case ruled he committed suicide \"while the balance of his mind was disturbed\", adding: \"In a man of his type, one never knows what his mental processes are going to do next.\" \nTuring, who was gay, was found guilty of gross indecency with another man in 1952. \nTo avoid prison, he agreed to receive injections of oestrogen for a year, which were intended to reduce his libido in a process known as \"chemical castration\". \nIn 2009 Gordon Brown issued an official apology for the way Turing had been treated. \nProfessor Copeland, from the University of Canterbury Christchurch in New Zealand, will talk about Turing's death at an event in Oxford on Saturday night. \nHe said medical evidence suggested Turing died from inhaling cyanide rather than drinking or ingesting it. He said police reported a strong smell of cyanide coming from Turing's lab, where he used it in amateur experiments. \nThe inquest should be reopened \"if possible\", he said. \n\"It would be a terrific thing to do. I think the nation owes it to Turing, in the Second World War he saved the nation.\" \nPerhaps best known for his part in breaking the German Enigma code, Turing was by that time already established as a mathematician of extraordinary capability. \nDuring his time at King's College, Cambridge, he devised the \"Turing Machine\", a mathematical model that went on to become one of the cornerstones of computer science, when aged just 22. \n"},
{"docid": "460 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "July 19, 2017", "title": "The Guardian view on the future of crime: it will be online; The dangers of machine intelligence will grow as it spreads. We need to prepare now\n", "content": "When software gets smarter, the first effect is to empower the already powerful. The fantastic powers available now to Google and Facebook, which are now in practice the publishers of most of what appears on the public internet, is one example. More sinister is the power of nation states to spy on us, to manipulate their own citizens, and to disrupt the workings of their enemies. But these advantages cannot last. Soon they have to be reinforced by law, and ultimately force, as the techniques behind them spread and hardware grows cheaper and more plentiful.\nThe speed of technological progress, and the ease with which ideas can now spread, mean that few techniques can long remain the preserve of large firms or entities. Every advance in power and convenience available to the ordinary consumer will soon be available to criminals too. Illegal commerce, whether in drugs, forged documents, stolen credit cards or emails, is nearly as slick and well organised as the legal sort. So are the criminal world's labour exchanges: hiring someone to hack a website, or to boost your Twitter account with fake followers, is easily done. So is renting a botnet of suborned devices to knock an enemy's website off the net. Last year large chunks of the consumer internet in the US were knocked out for hours, apparently by an assault launched from subverted home security cameras.\u00a0\nWe are on the brink of an explosion of devices that do not look like computers but will all be connected to the net and all potentially hackable. The more complex, useful and intelligent they are, the greater the harm they could do. Even if they are not easily hacked when they are installed, they will be more or less impossible to keep secure as new vulnerabilities are discovered. Software, like everything else we build, must constantly be repaired if it is not to decay. This is not a technological problem, or at least it is not a problem with a technological fix: it will need coordinated political, social and bureaucratic action over a period of decades.\nAs Professor Ross Anderson told a conference on the future of artificial intelligence last week, this is not a matter of regulating the technology in itself; it is the devices in which the software is embedded, and the firms which make and sell them, that need regulation. The spread of artificial intelligence (AI) downwards and outwards from the few large firms that now deploy it will pose further problems. Some of the most impressive recent advances in the field - such as a program which can beat even the word's best Go players - owed a lot to the use of adversarial learning, whereby different programs were trained by competing with each other inside the computer.\nIf a program can be built to beat the best human Go players, it should certainly be possible to build some to beat most security experts, and soon this will require no exceptional skills. The benefits of ubiquitous networked intelligence are real enough. But we are wrong to think that the only real danger comes from its capture by a few large companies or states. There will also be hundreds of smaller and more purely malevolent groupings using technology against us for their own purposes. The street finds its own uses for things, as William Gibson noted in the short story Burning Chrome, and governments, police and private citizens must all be prepared for what is coming when the street finds its own uses for AI.\n"},
{"docid": "461 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 14, 2016", "title": "Minecraft becomes testbed for artificial intelligence experiments\n", "content": "Minecraft is going to be a testbed for artificial intelligence (AI) experiments.\u00a0\nMicrosoft, who owns the hugely popular world-building game,\u00a0revealed it will\u00a0train an AI program\u00a0to play Minecraft,\u00a0which is more \"sophisticated\" than current AI research simulations.\u00a0\u00a0\n\"We're trying to program it to learn, as opposed to accomplishing\u00a0specific tasks,\" said Fernando Diaz, a senior researcher working on the project, known as AIX.\nFor instance, the researchers want their\u00a0AI program to learn how to find and climb to the top of a hill in a Minecraft world, rather than giving it instructions on\u00a0how to get there.\u00a0\nMinecraft has a creative, survival and adventure modes, which involve simple tasks such as\u00a0 walking around looking for treasure, and\u00a0complex ones such as building a structure with other people. The collaborative aspects will be the most challenging for the AI.\u00a0Microsoft bought Minecraft for $2.5 billion (\u00a31.5 bn) back in 2014 .\u00a0\n\"Minecraft is the perfect platform for this kind of research because it's this very open world,\" said Katja Hofmann, lead\u00a0developer of AIX,\u00a0the Microsoft program created for the research.\u00a0\"You can do survival mode, you can do 'build battles' with your friends, you can do courses, you can implement our own games.\n\"This is really exciting for artificial intelligence because it allows us to create games that stretch beyond current abilities.\"\u00a0\nCredit:      Microsoft     \nThe new research is the latest step in Microsoft's plan to\u00a0heavily invest\u00a0in AI. It\u00a0 recently purchased British startup SwiftKey, a predictive typing app that uses AI to guess users'e next word,\u00a0for \u00a3174 million .\u00a0\nMicrosoft's eventual aim is to use the AI to improve its intelligent assistant \u00a0Cortana.\u00a0\nHofmann\u00a0created AIX at Microsoft's lab in Cambridge, UK\u00a0\u00a0out of frustration with the limitations of simple AI testing programs. The software\u00a0platform\u00a0lets computer scientists use Minecraft as an AI testing ground. It works by allowing the AI to control a character and learn from the feedback about the consequences of its actions.\u00a0\nIt is currently available to a few\u00a0academic researchers under a private beta, and will be released under an open-source license to any computer scientist who wants to use it, in the summer.\u00a0\nMicrosoft's researchers hope that they can teach the computer general intelligence, which involves more nuanced problem solving and decision making.\u00a0\nHumans are not currently able to play against the AI, which is training in a \"roped off\" version of the game. Microsoft plans to release it to play with real Minecraft players in the future.\u00a0\nMost important inventions of the 21st Century: in pictures\nPlaying games against humans is a good way to improve an\u00a0AI's reinforcement learning -\u00a0when\u00a0the program learns from its previous actions.\u00a0This process was used by Google's AlphaGo, which last week beat the world champion of the board game Go three times, winning the overall five-game match outright. AlphaGo learned to win by playing Go against itself more than 30 million times.\u00a0\nAI timeline\nFor a round-up of technology news and analysis, sign up to our weekly Tech Briefing\u00a0 here .\nREAD MORE ABOUT:\n"},
{"docid": "462 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "March 12, 2016", "title": "Google DeepMind's AlphaGo computer beats top player Lee Sedol for third time to sweep competition; Many top players thought the computer displayed unorthodox moves\n", "content": "A Google computer programme has beaten a champion player of the board game \"Go\", in what has been called a landmark breakthrough for artificial intelligence.\nGoogle's AlphaGo programme beat Lee Sedol - one of the world's best Go players -in a best of five competition for the third consecutive time in Seoul, South Korea on Saturday.\u00a0\nMr Sedol had been confident he would win against the machine, with many believing the ancient Chinese game to be too complex for computers to master. Some believed it would be at least another decade before Computers would be able to beat human Go champions.\nIn the first game of the series AlphaGo won narrowly, with Mr Sedol ahead for much of the match, however the programme built up a strong lead later on.\nMr Sedol said he was \"speechless\" after losing the second match, adding AlphaGo had played a near-perfect game.\nThe world's top Go player Lee Sedol reviews the match after the third match of the Google DeepMind Challenge Match against Google's artificial intelligence program AlphaGo \nReuters \nTwo experts providing commentary for the third game said the match had been complex, they added that Mr Sedol had brought his \"top game\" but AlphaGo played with \"great style\".\nMany top Go professionals commented that AlphaGo displayed unorthodox, questionable moves that initially befuddled humans but made sense in hindsight.\nKwon Kap-Yong, one of Mr Sedol's former coaches, told\n AFP\n: \"AlphaGo played consistently from beginning to end, while Lee, as he is only human, showed some mental vulnerability\".\nGo is a Chinese two-player game believed to be around 3,000 years old, in which players take turns to put black or white stones on to a 19x19 grid. The winning player is the one able to surround their opponent's pieces with their own.\nUnlike chess, where a player typically has a choice of 20 moves, Go players have a choice of around 200. According to DeepMind, the British company owned by Google who developed AlphaGo, there are more possible positions in Go than atoms in the universe, the\nBBC\nreports.\nDeepMind trained the machine to play 30 million expert moves, the machine then played against itself millions of times to perfect its technique.\nDemis Hassabis, DeepMind's executive director, told the \nBBC\n: \"It played itself, different versions of itself, millions and millions of times and each time got incrementally better - it learns from its mistakes.\"\nMr Sedol is set to face AlphaGo in two more highly anticipated showdowns between human and machine, today and on Tuesday, \n                     Sky News                   \n reports.\nAdditional reporting by Press Association \n"},
{"docid": "463 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "January 9, 2018", "title": "Uber signs deal with microchip maker Nvidia to collaborate on driverless car technology\n", "content": "UBER'S hopes of solving its employment problems by replacing hundreds of thousands of drivers with computers appeared closer to reality in Las Vegas yesterday, as it sealed a deal with a microchip maker to collaborate on artificial intelligence.\u00a0\nThe minicab app announced at the Consumer Electronics Show (CES) that it has enlisted the help of graphics processor Nvidia to help design a computing system it believes will one day operate its fleet of cars.\nNvidia makes graphics computing chips that already power the autonomous features in Tesla cars, with software that aims to mimic a human brain to make quick decisions on the road.\nUber hopes to harness this artificial intelligence so it can send out cars that use a variety of sensors and algorithms that help it navigate safely without the need for a driver. It has been working on self-driving technology since 2015, and last year announced that it had bought 24,000 specially-adapted Volvos, all of which use Nvidia processors. The battle to develop driverless vehicles continues to intensify, with Uber rival Lyft promoting its own automation efforts at CES. Lyft is offering attendees the chance to travel in its prototype driverless cars, summoned via a smartphone.\nThe stakes are high. Uber is pursuing driverless cars after a string of setbacks over its human-steered operations. In November it failed to overturn a landmark legal judgment over working rights, in what was viewed as a significant setback for the company in the UK. Uber's drivers are now legally considered workers, which means it must pay them minimum wage and holiday pay.\nIts future in Britain hangs in the balance after councils such as York, and Transport for London officials refused to renew its licence in October last year. An appeal could take a considerable amount of time, according to Sadiq Khan, the London Mayor, although the company is still in operation.\nCar technology will be a hot topic at CES this week. Nissan plans to demonstrate its \"brain-to-vehicle\" technology, which allows a car to predict when a driver is about to steer the wheel or accelerate and do it for them, by wearing a hat that measures brain wave activity.\nIt can take actions 0.2 to 0.5 seconds faster than any driver, the company claimed.\n"},
{"docid": "464 of 500 DOCUMENTS\n", "source": "The Guardian - Final Edition\n", "date": "July 10, 2007", "title": "Obituary: Donald Michie: Key wartime code-breaker who became a leader in the field of artificial intelligence\n", "content": "Professor Donald Michie and his former wife Dame Anne McLaren, distinguished scientists in separate fields that overlapped at one point, have died together in a car accident; Donald was 83.\nHe made contributions of crucial international significance in three distinct fields of endeavour. During the second world war, he developed code-breaking techniques which led to effective automatic deciphering of German high-level ciphers. In the 1950s, he worked with Anne on pioneering techniques which were fundamental in the development of in vitro fertilisation. Donald subsequently became one of the founders of the field of artificial intelligence, an area to which he devoted the remainder of his academic career. It was within this field that I came to know Donald as an inspirational supervisor of my PhD at Edinburgh - not only insightful, forceful and even heroic, but possessing a wicked sense of humour.\nDonald was born in Rangoon. He attended Rugby school and was awarded an open scholarship to study classics at Balliol College, Oxford, in 1942.\u00a0\nIn 1943, inspired by his father to do \"something unspecified but romantic\" behind enemy lines in China, Donald attempted to enrol on a Japanese language course for intelligence officers. On arrival at the School of Codes and Ciphers in Bedford, he was told that the course was full, and decided instead to take up training in cryptography. A fast learner, he was soon recruited to Bletchley Park in Buckinghamshire, and was assigned to the \"Testery\", a section working on solving the German high-level teleprinter cipher, code-named Fish.\nOwing to recent declassification, it is now clear how profoundly important Donald's wartime research was. In April 1944 he invented a technique for using the Colossus computer, developed at Bletchley, to automatically decode the secondary wheel of the Lorentz machine, which the Germans used for encoding Fish.\nThe innovation, tested by Donald and Jack Good, endowed the machine with a degree of general-purpose programmability and led to a radical last-minute enhancement in the construction of Colossus II. The results were dramatic. Texts which previously had taken days to decipher could now be completed in hours, allowing repeated effective interception of enemy attacks.\nDuring this period at Bletchley, Donald held frequent lunchtime discussions with Alan Turing on the possibility of building computer programs that would display intelligence. Before the war, Turing had developed the mathematical basis for modern digital computation, and was applying the principles he had developed in the decoding efforts at Bletchley. Both Donald and Turing were interested in programming computers to play chess, as well as developing programs which could learn automatically from experience.\nFollowing the end of the war, Donald decided to take up his offer from Oxford. His wartime experience had diverted his former interest in classics into a passion to study science. Supported by a Balliol College war memorial studentship, he received his MA in human anatomy and physiology in 1949. During his subsequent DPhil degree at Oxford, Donald put his boyhood hobby of breeding pet mice to work in a series of genetic studies published in the journal Nature.\nIn Oxford, he married his fellow student Anne McLaren in 1952. The following year, he received his DPhil in mammalian genetics and went on to work with Anne on techniques related to in vitro fertilisation, first at London University and then at Edinburgh. Donald and Anne were divorced in 1959.\nWhile working at the department of surgical science in Edinburgh, Donald co-wrote one of the first introductory textbooks on the new science of molecular biology. However, his heart and mind were already elsewhere. From 1960, his attention returned to his wartime discussions with Turing, and in particular the question of whether computers could be programmed to learn from experience.\nFor demonstration purposes, he developed a noughts-and-crosses playing machine called Menace, for which he developed a general-purpose learning algorithm called Boxes. Since no computers were then available to him, he hand-simulated the Boxes algorithm, using a device made from an assembly of matchboxes. By 1963, Donald had assembled a small artificial-intelligence research group at Hope Park Square in Edinburgh. With the support of the Edinburgh vice-chancellor, Sir Edward Appleton, Donald established the experimental programming unit in 1965.\nIn 1966 he was joined in Edinburgh by Richard Gregory and Christopher Longuet-Higgins, both interested in the development of a brain research institute. The following year, he was appointed to a personal chair of machine intelligence and became the first director of the department of machine intelligence and perception.\nThe period up to 1973 is widely perceived as one of the most fertile in the history of artificial intelligence research, and its history is documented by the frequently cited Machine Intelligence book series of which Donald was editor.\nHis crowning achievement was the development, under a team he led, of Freddy II, the world's first demonstration of a laboratory robot capable of using computer vision feedback in assembling complex objects from a heap of parts. Unfortunately, a series of events conspired to bring this period of rapid achievement to an end.\nDisagreements concerning the priorities of the field broke out between Donald, Longuet-Higgins and Gregory. At the same time, the growing economic crisis at the beginning of the 1970s was cutting into the budget of the Science Research Council, which was starting to look for savings.\nSir James Lighthill, a well-known British fluid dynamicist, was commissioned by the Science Research Council to analyse the prospects for the high-cost robotics project in Edinburgh. The resulting report, published in 1973, called a halt to artificial intelligence research in all but two areas.\nThe robot program was discontinued with knock-on effects for similar research programs in the US. The resulting dissolution of Donald's research group in Edinburgh left him isolated in the research unit. There he continued his research studies into computer chess and machine learning for the remainder of the 1970s.\nBy the early 1980s, automated assembly robots in Japan were outstripping traditional methods of manufacturing in other countries including the UK. Additionally, computer systems which imitated the decision-making of human experts were becoming increasingly successful. As a consequence, governments in the UK, Europe and US resumed large-scale funding of artificial-intelligence projects in response to the Japanese Fifth Generation project.\nIn 1986, as head of the Turing Trust in Cambridge, Donald founded the Turing Institute in Glasgow, in honour of his former colleague's key contributions to the field. Under Donald's leadership, the institute conducted advanced, industrially oriented research in machine learning, robotics and computer vision.\nFollowing his retirement in the early 1990s, he continued actively in research on machine learning with his third wife, Jean Hayes-Michie. They had married in 1971, but she died from cancer in 2002, after which he resumed his friendship with Anne. His first marriage, to Zena Davies, had ended in divorce in 1949.\nDonald is survived by his son Chris, from his first marriage, and by his daughters Susan and Caroline and son Jonathan from his marriage to Anne.\nDonald Michie, scientist, born November 11 1923; died July 7 2007\n"},
{"docid": "465 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "April 3, 2017", "title": "'Machine folk' music composed by AI shows technology's creative side; Computer-generated music is a controversial topic for musicians living in a digital world\n", "content": "Folk music is part of a rich cultural context that stretches back into the past, encompassing the real and the mythical, bound to the traditions of the culture in which it arises. Artificial\u00a0intelligence, on the other hand, has no culture, no traditions. But it has shown great ability: beating grand masters at chess and Go, for example, or demonstrating uncanny wordplay skills when IBM Watson beat human competitors at Jeopardy. Could the power of AI be put to use to create music?\nThis is not entirely unprecedented: an artificial\u00a0intelligence co-wrote a piece of musical theatre, from the storyline to the music and lyrics. It premiered in London in 2016. The advancement of AI techniques and ever-larger collections of data to use to train them presents broad opportunities for creative research. The AI co-wrote its musical based on an analysis of hundreds of other successful musicals, for example. There are other projects aimed at providing creators of art and music with new artificial\u00a0intelligence-based tools for their craft, such as Google's Magenta project, Sony's Flow Machines, or British start-upJukedeck. And long before those was \u00a0\nThe Illiac Suite\n, music for astring quartet composed by a supercomputer in 1957.\nRead more\nRobots and AI are threatening close to a third of UK jobs\nOur research examines how state-of-the art AI techniques can contribute to musical practice, specifically the Celtic folk tradition of \"session music\". Enthusiasts transcribe versions of folk tunes using ABC, a reduced form of music notation developed by Chris Walshaw of the University of Greenwich, using text characters as a rough guide to the musician. We trained our AI system using more than 23,000 ABC transcriptions of folk music, crowdsourced from the excellent online resource thesession.org. And at our recent workshop at the Inside Out festival we had accomplished folk musicians performing some of this \"machine folk\" music.\nArtificial compositions, human melodies\nOur AI is trained so that given one ABC symbol it can predict the next, which means it can generate new tunes that draw upon patterns and structures learned from the original tunes. We have generated more than 100,000 new machine folk tunes, and it's interesting to see what the AI has and has not learned. Many tunes have the typical structure of this style: two repeated parts of the same eight-bar length, that often complement each other musically. The AI also shows some ability to repeat and vary musical patterns in a way that is very characteristic of Celtic music. It was not programmed to do this with rules - it learned to do so because these patterns exist in the data we fed it.\nHowever, unlike a human the system isn't immediately able to generalise these properties beyond the immediate context. Much of what we originally thought the system learned about basic musical features (for example how rhythm works) in fact it hadn't learned - it was simply able to reproduce those conventions. Venture slightly outside the conventions of the data and the system begins to act unusually. This is where things can get musically interesting:\nTo evaluate the AI's compositions we consulted the experts: folk musicians. We asked for feedback on The Endless Traditional Music Session, and later about a volume of 3,000 tunes generated by our system. Feedback from members in the thesession.org forums shows divided opinions: some found the idea intriguing and identified \"machine folk\" tunes they liked and could work with. Others were dead against the entire notion of computer-generated music.\nOne obstacle was that not only was this music composed by computers, it was also played by computer synthesis, and so lacking the interpretation and expressionof human musicians who bring each tune to life - elements not incorporated in the data the AI had trained on. So we recruited professional folk musicians and asked them to look at our volume of 3,000 tunes. One musician observed that about one in five tunes are actually fairly good.\nRead more\nRobots sent into Fukushima keep dying\nBy their nature, folk tunes are less fixed in nature and are treated as a frame upon which to elaborate: performers develop their own version and change elements in performance. The musicians found interesting features and some patterns that are unusual but work well within the style. Perhaps there are regions of this musical space that humans have not yet discovered - and can be reached with the help of a machine.\nMuch discussion around AI focuses on computers as competitors to humans. We seek to harness the same technology as a creative tool to enrich, not replace.\nBob Sturm is a\nlecturer in digital media atQueen Mary University of London and\nOded Ben-Talis a s\nenior lecturer in music technology atKingston University.This article first appeared on The Conversation (theconversation.com)\n"},
{"docid": "466 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "September 15, 2017", "title": "Voice technology company to open office in Edinburgh\n", "content": "A technology firm battling Google, Apple and Amazon to be a leader in artificial intelligence voice technology is to open a development centre in Scotland.\u00a0\nVoysis, based in Dublin, has hired Ian Hodson, who previously led Google's text-to-speech efforts, to run the facility in Edinburgh.\nMr Hodson said that the research strength at Edinburgh university and Heriot-Watt in speech and robotics, and the resulting talent pool, made the city an attractive place for the site.\nThe Voysis team in Edinburgh is expected to grow to about ten over the next year although Mr Hodson indicated that number could rise. \"We will grow with the right people and there is no shortage of interest,\" he said.\nMr Hodson previously helped to build the text-to-speech company Rhetorical Systems in the Scottish capital until it was sold to Nuance Communications for $6.7 million in 2004. At Voysis he will be part of a team working on fine-tuning the business's artificial intelligence models and collaborating with the existing engineering team in Dublin.\nRetail is the first market the company is targeting and it hopes to capitalise on the growing amount of online shopping done through mobile devices.\nMr Hodson said that Voysis would offer its software as a service, meaning customers could keep hold of their product and customer data.\nVoysis is expanding after it sealed an $8 million funding round this year, led by Polaris, the US venture firm.\n"},
{"docid": "467 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "November 5, 2015", "title": "DeepMind: 'Artificial intelligence is a tool that humans can control and direct'; Co-founder of technology company insists AI is not a danger to humanity, but will help tackle lack of clean water, financial inequality and stock market risks\n", "content": "Fears that artificial intelligence will wipe out human beings are completely overblown, according to the co-founder of Britain's DeepMind, who has insisted that the technology will help tackle some of the world's biggest problems including accessing clean water, financial inequality and stock market risks. \nMustafa Suleyman, who with Demis Hassabis and Shane Legg set up the London-based machine learning company that was bought by Google in January 2014 for \u00a3400m, mounted a spirited defence of the company's successes. He told a conference on machine learning that \"artificial intelligence, AI, has arrived. This isn't just some brief summer for this technology, and it's not about to go away again. These are production breakthroughs.\"\u00a0\nHigh-profile figures including Elon Musk, Stephen Hawking and Bill Gates have all warned that the rise of AI poses a threat to humanity - a threat that has been echoed in recent Hollywood films such as Ex Machina, The Terminator and Transcendence. Yet Suleyman insisted that AI is, and will remain, a tool that humans can control and direct, rather than a threat. \nThe best use for AI would be to help decisions about how to tackle some of the world's biggest problems such as lack of access to clean water, inequality of access to food and finance, and stock market risks, he suggested.\nDeepMind's systems use neural networks and \"deep learning\" methods that deploy low-level transistor networks to produce high-level effects so that they can, for instance, distinguish a cat's face from a human one - a trivial task for a human, but hard for a machine. That has been developed into \"artificial general intelligence\" (AGI) that can learn to solve tasks without prior programming, and have already been used to replace 60 hand-crafted systems across Google. The AGI system's deployment into speech recognition, now used in Android phones and Google Translate, had led to the biggest overall improvement in speech recognition in 20 years, Suleyman said, with a 30% reduction in transcription error rates. Yet training the program for the task took less than five days.\nSpeaking to a conference on machine intelligence in London on Friday, Suleyman said that he was dismayed by the negative attitudes being shown towards AI. \"It's sad how quickly we've adopted to the reality and don't acknowledge the magic and the good that these systems can bring. The narrative has gone straight from 'isn't it terrible that AI has been such a flop' to 'isn't it terrible that AI has been such a success'.\"\nHe said that the technology was going to be \"a hugely powerful tool that we control and direct within its limits - like any tool that we have ever built ... Artificial generalised intelligence is a form of intellectual horsepower - a cheap and abundant resource to solve our toughest global problems.\"\nSuleyman observed: \"We have global information overload from overwhelming systems complexity - they're so complex and interlinked it's possible that the US financial crash in 2008-9 caused the Egyptian revolution [which was sparked when bread prices rose in line with wheat prices].\n\"But everything we have built is a product of intelligent human activity. AGI is a tool to massively amplify our ability to control the world.\"\nDeepMind, based by Kings Cross station in London, has developed a \"generalised artificial intelligence\" which was able to figure out how to succeed at nearly 50 Atari computer games without any foreknowledge of how to play them. Given inputs of just the score and the pixels on the screen, and control of the games buttons - again without any knowledge of their relevance - it was able to play as well as a human after a few hundred games. In Breakout, it played competently after 300 games - then figured out after 200 more games that the best strategy was to knock out the side bricks and let the ball bounce behind the wall: \"that surprised us,\" said Suleyman.\nThe company's systems are now used on the Google+ photo categorisation systems, and apparently on Google's new Photos service, to categorise and label pictures by their contents. The company is also seeking to expand that categorisation so that when there are multiple recognisable objects in a picture it can describe them all in a single coherent sentence. \nBut Suleyman said the idea that a machine-based artificial intelligence could take over decision and pose a threat to humans was \"preposterous\". \n\"Any talk of a superintelligent machine vacuuming up all the knowledge in the world and then going about making its own decisions are absurd. There are engineers in this room who know how difficult it is to get any input into these systems,\" Suleyman said to applause from the audience of machine intelligence specialists. \n\"If we fear that we won't control them, then we should slow down their use and implementation, just like with nuclear weapons and genetic engineering\" [which saw a moratorium in the 1970s].\nSuleyman said he wants to make public the names of the people who sit on the company's ethics board, which was set up at the insistence of himself and Hassabis when Google bought it. \"We will [publicise the names], but that isn't the be-all and end-all. It's one component of the whole apparatus,\" he said.\nAsked what gave Google the right to choose the ethics board members without any public oversight, Suleyman replied: \"That's just what I said to Larry [Page, Google's chief executive]. We will make more public.\"\nHe said it had been a bold move for the 100-strong company to suggest to the much bigger buyer that there should be an ethics board at all. \"Being able to put something like this on the table is a first step to being more open and helping to steward this,\" he said. The company is seeking to recruit more people to its ethics board, as well as to its policy and legal teams.\n"},
{"docid": "468 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "June 9, 2015", "title": "DeepMind: 'Artificial intelligence is a tool that humans can control and direct'; Co-founder of technology company insists AI is not a danger to humanity, but will help tackle lack of clean water, financial inequality and stock market risks\n", "content": "Fears that artificial intelligence will wipe out human beings are completely overblown, according to the co-founder of Britain's DeepMind, who has insisted that the technology will help tackle some of the world's biggest problems including accessing clean water, financial inequality and stock market risks. \nMustafa Suleyman, who with Demis Hassabis and Shane Legg set up the London-based machine learning company that was bought by Google in January 2014 for \u00a3400m, mounted a spirited defence of the company's successes. He told a conference on machine learning that \"artificial intelligence, AI, has arrived. This isn't just some brief summer for this technology, and it's not about to go away again. These are production breakthroughs.\"\u00a0\nHigh-profile figures including Elon Musk, Stephen Hawking and Bill Gates have all warned that the rise of AI poses a threat to humanity - a threat that has been echoed in recent Hollywood films such as Ex Machina, The Terminator and Transcendence. Yet Suleyman insisted that AI is, and will remain, a tool that humans can control and direct, rather than a threat. \nThe best use for AI would be to help decisions about how to tackle some of the world's biggest problems such as lack of access to clean water, inequality of access to food and finance, and stock market risks, he suggested.\nDeepMind's systems use neural networks and \"deep learning\" methods that deploy low-level transistor networks to produce high-level effects so that they can, for instance, distinguish a cat's face from a human one - a trivial task for a human, but hard for a machine. That has been developed into \"artificial general intelligence\" (AGI) that can learn to solve tasks without prior programming, and have already been used to replace 60 hand-crafted systems across Google. The AGI system's deployment into speech recognition, now used in Android phones and Google Translate, had led to the biggest overall improvement in speech recognition in 20 years, Suleyman said, with a 30% reduction in transcription error rates. Yet training the program for the task took less than five days.\nSpeaking to a conference on machine intelligence in London on Friday, Suleyman said that he was dismayed by the negative attitudes being shown towards AI. \"It's sad how quickly we've adopted to the reality and don't acknowledge the magic and the good that these systems can bring. The narrative has gone straight from 'isn't it terrible that AI has been such a flop' to 'isn't it terrible that AI has been such a success'.\"\nHe said that the technology was going to be \"a hugely powerful tool that we control and direct within its limits - like any tool that we have ever built ... Artificial generalised intelligence is a form of intellectual horsepower - a cheap and abundant resource to solve our toughest global problems.\"\nSuleyman observed: \"We have global information overload from overwhelming systems complexity - they're so complex and interlinked it's possible that the US financial crash in 2008-9 caused the Egyptian revolution [which was sparked when bread prices rose in line with wheat prices].\n\"But everything we have built is a product of intelligent human activity. AGI is a tool to massively amplify our ability to control the world.\"\nDeepMind, based by Kings Cross station in London, has developed a \"generalised artificial intelligence\" which was able to figure out how to succeed at nearly 50 Atari computer games without any foreknowledge of how to play them. Given inputs of just the score and the pixels on the screen, and control of the games buttons - again without any knowledge of their relevance - it was able to play as well as a human after a few hundred games. In Breakout, it played competently after 300 games - then figured out after 200 more games that the best strategy was to knock out the side bricks and let the ball bounce behind the wall: \"that surprised us,\" said Suleyman.\nThe company's systems are now used on the Google+ photo categorisation systems, and apparently on Google's new Photos service, to categorise and label pictures by their contents. The company is also seeking to expand that categorisation so that when there are multiple recognisable objects in a picture it can describe them all in a single coherent sentence.\nBut Suleyman said the idea that a machine-based artificial intelligence could take over decision and pose a threat to humans was \"preposterous\".\n\"Any talk of a superintelligent machine vacuuming up all the knowledge in the world and then going about making its own decisions are absurd. There are engineers in this room who know how difficult it is to get any input into these systems,\" Suleyman said to applause from the audience of machine intelligence specialists.\n\"If we fear that we won't control them, then we should slow down their use and implementation, just like with nuclear weapons and genetic engineering\" [which saw a moratorium in the 1970s].\nSuleyman said he wants to make public the names of the people who sit on the company's ethics board, which was set up at the insistence of himself and Hassabis when Google bought it. \"We will [publicise the names], but that isn't the be-all and end-all. It's one component of the whole apparatus,\" he said.\nAsked what gave Google the right to choose the ethics board members without any public oversight, Suleyman replied: \"That's just what I said to Larry [Page, Google's chief executive]. We will make more public.\"\nHe said it had been a bold move for the 100-strong company to suggest to the much bigger buyer that there should be an ethics board at all. \"Being able to put something like this on the table is a first step to being more open and helping to steward this,\" he said. The company is seeking to recruit more people to its ethics board, as well as to its policy and legal teams.\n"},
{"docid": "469 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 19, 2015", "title": "Artificially intelligent Mario learns to play his own game; Researchers have created a version of the iconic video game character that is capable of thinking for himself\n", "content": "Mario is one of the most iconic video game characters in history - having appeared in over 200 games, several television series and a feature film. But now, for the first time, the pudgy Italian plumber from the Mushroom Kingdom has been given a mind of his own. \u00a0\nA team of cognitive modelling researchers at the University of T\u00fcbingen in Germany have developed an artificial intelligence system that allows Mario to learn about his environment, experience emotions and respond to voice commands. \nIn a video created to demonstrate the their work, the researchers show how Mario can describe his 'feelings' and act accordingly. For, example, when he is hungry he will collect coins, and when he is curious he will explore his environment autonomously. \nUsing Carnegie-Mellon's speech-recognition toolkit, Mario can understand a wide range of questions and instructions, and follow a logic and grammar tree to decide which response to give or which action to take. \nMario can calculate how many moves he needs to make to reach a certain position, and also learn that jumping on a Goomba (one of his mushroom-shaped enemies) will destroy it. \nThe Mario AI project is part of an annual competition run by the Association for the Advancement of Artificial Intelligence - the aim of which is to document advances in artificial intelligence. The full list if entrants can be found here . \nThe students at the University of Tubingen used Mario as part of their efforts to find out how the human mind works. Their focus is on the developmental aspects of the mind and the highly \"interactive modularity\" found in the brain. \n"},
{"docid": "470 of 500 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "February 29, 2016", "title": "Coming soon to a classroom near your child: a computer that gives a perfect lesson\n", "content": "Artificial\u00a0intelligence should be used to provide children with one-to-one tutoring to improve their learning and monitor their well-being, academics have argued.\nOne-to-one tutoring has long been thought the most-effective approach to teaching but would be too expensive to provide for all students.\nHowever, in a paper, academics from University College London's Knowledge Lab argue that AI systems could simulate human one-to-one tutoring by delivering learning activities tailored to a student's needs and providing targeted and timely feedback, all without an individual teacher present.\u00a0\nInstead of being examined in traditional ways, children could be assessed in a more complete manner by collecting data about their performance over a long period, providing employers and educational institutions with a richer picture of their abilities.\nThe report argues that AI could radically transform our education system for the better - but it is being held back by funding.\nProposals to use AI have been controversial. Professor Stephen Hawking and other leading scientists have warned of the dangers of it becoming \"too clever\", and there are concerns about data security and privacy. Some teachers also fear their role could be diminished by this technology, or that it could be used as a \"classroom spy\" to monitor their performance. But the report's authors believe there are huge potential benefits - and they argue it is essential the teaching profession is involved from the start.\nThe report says: \"We are in no doubt that teachers need to be central agents in the next phase of Artificial\u00a0Intelligence in Education (AIEd). In one sense this is obvious - it is teachers who will be the orchestrators of when, and how, to use these AIEd tools. In turn, the AIEd tools, and the data-driven insights that these tools provide, will empower teachers to decide how best to marshal the various resources at their disposal.\"\nIt adds: \"The increasing use of AIEd systems will enable the collection of mass data about which teaching and learning practices work best. This data will enable us to track learner progress against different teaching approaches and, in turn, will allow us to develop a dynamic catalogue of the best teaching practices suited to the development of different skills and capabilities, in particular the 21st century skills, across a range of environments.\"\nAI should also be used to tackle the achievement gap between the poorest children and their wealthier peers by helping low-income parents with parenting even before their offspring start school.\nThe report says: \"Low-income parents may also have had limited education opportunities, meaning they may face serious challenges in providing at-home learning support to their children.\n\"AIEd systems can provide tailored support to parents in the same way that they can for teachers and students, improving education and outcomes for both parents and their children. Imagine, for example, providing parents with AIEd assistants that could advise them about strategies for talking to their child, sharing songs, and enjoying books. This could enable all parents to provide the right sort of support in those all-important early years.\"\nAI first appeared in a digital game in 1979, when Pac-Man used a technique known as state machine (transitioning between states depending on conditions) to control whether or not a ghost ran towards or away from a player. The AI in most modern digital games builds on this approach.\n"},
{"docid": "471 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "May 25, 2017", "title": "How technology helps firms to raise their game\n", "content": "The likelihood of robots taking over our jobs may have inspired a wealth of dystopian fiction but it is a subject that is notoriously light on facts. Winner of this year's Best Use of Thought Leadership award, Deloitte's Future of Work series was undertaken to \"help clients separate half-truth from statistical data,\" Harvey Lewis, director and lead in artificial intelligence at the consultancy, says.\u00a0\n\"Having looked back over the past 150 years, we've seen that, without exception, technology always increases jobs, productivity and growth,\" Lewis says. \"All the evidence suggests that this fourth industrial revolution is going to follow the same pattern, despite what the pessimists may say.\"\nOver the past 15 years alone the number of new jobs added to the economy has outnumbered those lost to automation by a factor of four to one, he says. \"The world of work is already changing as a result of robotics and artificial intelligence and more forward-looking clients are finding new ways to adapt.\n\"Whether it means staff with softer skills being trained as technicians, or IT specialists learning critical thinking, the move towards creating a more balanced workforce is firmly under way.\"\nRecent research from Deloitte suggests that only 7 per cent of management consultant jobs are likely to be lost to automation in the next 10 to 20 years, in comparison with the 35 per cent of UK jobs at risk overall.\nWhile manufacturing will be more affected than medicine, for example, the challenge of finding new jobs for staff whose roles disappear will affect almost every organisation.\n\"We're always looking for new ways to use technology to help become more effective for our clients, so we certainly aren't immune,\" Lewis says.\nDeloitte is also the recipient of a second award. Downloaded more than 8,000 times in 124 countries, Football CEO is a mobile game where players use commercial management skills to help struggling non-league clubs.\nDeveloped by the firm in conjunction with Vi-Ability, a social enterprise that uses sport to transform the lives of disadvantaged young people, the project has picked up this year's Social and Environmental Value award.\n\"It is great that we are able to use examples from Football CEO to bring our thinking to life,\" Ed Greig, of Deloitte Digital, says. \"Extensive user testing with those already taking part in the Vi-Ability programme was absolutely key and it has been amazing to hear stories of young people who, having struggled in a traditional classroom, were able to quickly understand new concepts while playing the game.\"\nKelly Davies, the former Arsenal and Liverpool Ladies footballer and Welsh international player, is the founder and managing director of Vi-Ability. She says: \"We couldn't have made this project a reality without the support of Deloitte, who've worked with us every step of the way.\" VIRGINIA MATTHEWS\n"},
{"docid": "472 of 500 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "June 25, 2014", "title": "ANDROID WATCH; MEDIA In a hit Swedish TV drama, soon to be remade in English, lifelike robots do the all the dirty work. Pure science fiction, wonders GERARD GILBERT - or a glimpse of the future?\n", "content": "With The Killing and Borgen finished, Wallander having bowed out on BBC4 last Saturday and just one more series of The Bridge, the sun seems to be setting on a golden age of Scandinavian television. There is, however, one show that has been denied to us in the UK and that's the Swedish sci-fi drama Real Humans, despite two series having been screened to great acclaim in at least other 50 countries.\nReal Humans imagines an alternate version of modern-day Sweden in which life-like androids, known as \"hubots\", take care of the domestic and workplace drudgery. They have flawless skin, glossy hair and unnaturally bright (usually blue) eyes - and they look rather like Valeria Lukyanova, the cosmetically enhanced Ukrainian model and YouTube sensation known as the \"real-life Barbie\". As the sheepish husband of a hard-working lawyer tells his children as he unpacks \"Anita\", a similarly plastic-fantastic rechargeable domestic servant: \"I haven't told Mum yet.\" Mum's comment, on clapping eyes on Anita, is short and to the point: \"No way!\"\u00a0\nHusbands and wives threatened by the arrival of these attractive and biddable cuckoos aren't the only ones resisting the hubots, and a local meathead, his job threatened by their growing use in factories, asks one android: \"How does it feel to be related to a vacuum cleaner?\" before venting his only too human frustration. In the meantime, some of the robots are becoming so sophisticatedly programmed by their owners (via a USB port in the backs of their necks) that they are developing free will and childlike emotions.\nReal Humans (the title comes from a campaign group protesting against the hubots) is funny and thought-provoking, and this autumn the British production company Kudos, makers of Spooks, starts shooting an English-language version. \"Exploring themes of love, discrimination and integration, this thrilling, beautifully written series allows us to get under the skin of what it means to be human,\" declares Jane Featherstone, executive producer for Kudos, in a statement.\nPutting to one side the question of whether we need an English-language remake and why we can't make do with the subtitled Swedish version (OK, because not enough people will watch it), developments in the field of artificial intelligence seem to suggest that the world of Real Humans might not be so far in the distant dystopian future.\nEarlier this month, for example, a programme called \"Eugene Goostman\" convinced enough judges at the Royal Society in London that it was a 13-year-old Ukrainian boy that it supposedly became the first computer ever to pass the Turing test - so named after pioneering British computer scientist Alan Turing, who devised it in 1950 as a gauge of artificial intelligence.\nMeanwhile, the Japanese firm Softbank unveiled a \"human-like\" robot called Pepper, which it says can read human emotions. Pepper apparently uses a \"cloud-based artificial intelligence system\" that allows it to analyse gestures, expressions and voice tones, and Softbank claims that people can communicate with it \"just like they would with friends and family\", which shouldn't be too hard if your family consists largely of grunting teenagers. Anyway, Pepper can be yours (from next year, at least) for 198,000 yen, or just over \u00a31,000, and he's not in the least sexy, so no problems inviting him or her (it has womanly hips) into the home.\nWith its rapidly ageing population and falling birth rate, Japan is one of the world's biggest robot markets, as it looks to offset labour shortages and the cost of looking after elderly relatives, and Honda has been developing its own robot, Asimo, which played football with US President Barack Obama on his recent visit to Japan. Asimo had the build and speed of an overgrown, hyperactive 12-year-old, and Obama seemed unsure whether to pat it on the head or run for his life. It's these conflicting impulses that makes Real Humans so compelling; let's hope it gets a British broadcast soon.\n"},
{"docid": "473 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "October 18, 2016", "title": "'Spreadsheet Phil' is power behind the throne; In an increasingly fractious battle over Brexit, the chancellor has become the voice of authority and common sense\n", "content": "In the 1960s a computer scientist called Joseph Weizenbaum decided to build a virtual psychotherapist. He called his computer program Eliza. People could talk to the machine by typing in their problems and it would then \"treat\" the patient by echoing their comments back to them. It was supposed to be a parody of the early attempts to develop artificial intelligence but, to Weizenbaum's surprise, Eliza was extraordinarily successful. His secretary sat down to test the program and within minutes she had asked him to leave the room because her discussion with the computer had become so personal - even though she knew it didn't understand a word she said.\nEveryone who used Eliza became engrossed, often sitting for hours in front of the screen and typing intimate details of their lives. \"The computer doesn't burn out, look down on you, or try to have sex with you,\" one patient explained.\u00a0\nIn his new film, HyperNormalisation, the BBC documentary maker Adam Curtis argues that this computer program represented a cultural tipping point, with huge implications for business and politics. \"What Eliza showed was that in an age of individualism what made people feel secure was having themselves reflected back to them, just like in a mirror,\" he says.\nThe research on artificial intelligence then changed direction and started to create systems that did just that. The modern manifestations are everywhere - from Amazon's \"recommendations for you\" to personalised Facebook feeds and focus groups that tell politicians what voters want to hear. \"If you liked that you'll love this\" has become the mantra of the age. And, as Curtis says: \"Politics became just part of a wider system of managing the world.\"\nBrexit is now in the hall of mirrors, where nothing is quite what it seems. After a referendum that divided the nation, there is a battle for perception as well as reality. Everyone is first trying to define what the British people were voting for on June 23 and then attempting to reflect that back to them. It's a version of Recommendations for You: if you hate immigration you'll love free movement controls; if you like Marmite you'll want single-market access.\nThere is something similar going on within the Tory party. In her party conference speech, Theresa May delighted the Conservative Eurosceptics by promising to trigger Article 50 quickly and introduce a Great Repeal Bill - both ideas that had been proposed the week before by the Brexiteer former ministers Iain Duncan Smith and Owen Paterson. This was seen as a sign that the prime minister was determined to force through a so-called hard Brexit - and the markets reacted accordingly. But in fact, like Eliza, she was just echoing the Brexiteers' words back to them to reassure them.\nThe truth is that Mrs May, who voted Remain, revealed little about the terms on which she wants to see the UK leave the EU, apart from emphasising that more must be done on immigration controls. She conspicuously failed to endorse the call by Eurosceptics for Britain to be ready to fall back on World Trade Organisation tariff rules if the EU refused to agree to their \"take it or leave it\" approach. The proposal that businesses should be forced to list foreign worker numbers was quickly dumped.\nThis week it emerged that the prime minister may even be willing to continue paying billions of pounds into the EU budget to maintain single-market access for the City of London and other sectors. \"The conference speech was blue meat to the Tory right,\" says one Downing Street source. A cabinet minister who knows her well insists: \"Theresa's position is much more nuanced than some people assumed.\" The problem is that, when it comes to Brexit, perceptions can affect reality - as the 17 per cent fall in the value of the pound against the dollar shows.\nUntil last week the Brexiteers were winning the internal information war, explaining with buccaneering bravado how the PM agreed with them that Britain was going to make its way in the world. \"They are like peacocks showing their tails,\" says one pro-Remain minister. \"It's all swagger and stagger but in the end the hen will do the choosing.\"\nPhilip Hammond, the chancellor, has never been one to wave his tailfeathers around. Now, though, as the economic consequences of Brexit are becoming clear, quiet unflashy \"Spreadsheet Phil\" has become the pivotal figure in the cabinet. One minister says he is providing a muchneeded \"intellectual reality check\" for Mrs May and acting as a hardheaded economic counterweight to the ideological Brexiteers. The chancellor's rivals protest that he has been captured by Treasury groupthink, accusing him of trying to undermine Brexit by arguing like an accountant. But his allies insist he is an instinctive Eurosceptic who is simply taking a pragmatic approach. \"Philip is just doing his job,\" says one colleague. \"He acts in cabinet as every chancellor has always acted. The Treasury produces papers full of figures, some of which are alarming, and Philip presents them unemotionally. The Treasury is meant to be in charge of economic analysis. If people find the economic analysis uncomfortable, so be it.\"\nAlthough Mr Hammond does not attend the morning strategy meeting at No 10, as his predecessor George Osborne did, a senior civil servant says he is not afraid of asserting his authority across Whitehall. \"He's got a traditional view of the chancellor's role, which is to be a powerful figure in cabinet. Even under David Cameron he was a person with opinions on many subjects, and as chancellor he believes he has the right to be heard on all the key issues.\"\nWith a growing network of alliances around the table, he is also in a stronger position than any other minister. If he were to resign, raising concerns about the economic impact of the government's Brexit deal, it would be devastating for Mrs May. The same cannot be said of any of the three cabinet Brexiteers. A resignation by one of them between now and the next general election is widely expected at Westminster.\nPro-European ministers are convinced that the prime minister is closer to the chancellor's position than she has so far shown. Other EU heads of government have been left with the impression that she is being controlled by the hard Brexiteers. As she travels to Brussels this week Mrs May needs to show that she understands the economic realities of Brexit as well as the political perceptions of her party's Eurosceptics.\nTheresa May's speech was blue meat to the Tory party right\nA resignation by a cabinet Brexiteer is widely expected\n"},
{"docid": "474 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "July 31, 2017", "title": "Facebook's artificial intelligence robots shut down after they start talking to each other in their own language; 'you ii ieverything else'\n", "content": "Facebook abandoned an experiment after two artificially intelligent programs appeared to be chatting to each other in a strange language only they understood.\nThe two chatbots came to create their own changes to English that made it easier for them to work - but which remained mysterious to the humans that supposedly look after them.\nThe bizarre discussions came as Facebook challenged its chatbots to try and negotiate with each other over a trade, attempting to swap hats, balls and books, each of which were given a certain value. But they quickly broke down as the robots appeared to chant at each other in a language that they each understood but which appears mostly incomprehensible to humans.\u00a0\nThe robots had been instructed to work out how to negotiate between themselves, and improve their bartering as they went along. But they were not told to use comprehensible English, allowing them to create their own \"shorthand\", according to researchers.\nThe actual negotiations appear very odd, and don't look especially useful:\nBob: i can i i everything else . . . . . . . . . . . . . .\nAlice: balls have zero to me to me to me to me to me to me to me to me to\nBob: you i everything else . . . . . . . . . . . . . .\nAlice: balls have a ball to me to me to me to me to me to me to me\nBob: i i can i i i everything else . . . . . . . . . . . . . .\nAlice: balls have a ball to me to me to me to me to me to me to me\nBob: i . . . . . . . . . . . . . . . . . . .\nAlice: balls have zero to me to me to me to me to me to me to me to me to\nBob: you i i i i i everything else . . . . . . . . . . . . . .\nAlice: balls have 0 to me to me to me to me to me to me to me to me to\nBob: you i i i everything else . . . . . . . . . . . . . .\nAlice: balls have zero to me to me to me to me to me to me to me to me to\nBut there appear to be some rules to the speech. The way the chatbots keep stressing their own name appears to a part of their negotiations, not simply a glitch in the way the messages are read out.\nIndeed, some of the negotiations that were carried out in this bizarre language even ended up successfully concluding their negotiations, while conducting them entirely in the bizarre language.\nThey might have formed as a kind of shorthand, allowing them to talk more effectively.\n\"Agents will drift off understandable language and invent codewords for themselves,\" Facebook Artificial Intelligence Research division'svisiting researcher Dhruv Batra said. \"Like if I say 'the' five times, you interpret that to mean I want five copies of this item. This isn't so different from the way communities of humans create shorthands.\"\nIn 60 seconds: The dark side of the sex robot craze\nThat said, it's unlikely that the language is a precursor to new forms of human speech, according to linguist Mark Liberman.\n\"In the first place, it's entirely text-based, while human languages are all basically spoken (or gestured), with text being an artificial overlay,\" he wrote on his blog. \"And beyond that, it's unclear that this process yields a system with the kind of word, phrase, and sentence structures characteristic of human languages.\"\nThe company chose to shut down the chats because \"our interest was having bots who could talk to people\", researcher Mike Lewis told FastCo. (Researchers did not shut down the programsbecause they were afraid of the results or had panicked, as has been suggested elsewhere,but because they were looking for them to behave differently.)\nThe chatbots also learned to negotiate in ways that seem very human. They would, for instance, pretend to be very interested in one specific item - so that they could later pretend they were making a big sacrifice in giving it up, according to a paper published by FAIR.\nRead more\nAI better than scientists at choosing successful IVF embryos\n(That paper was published more than a month ago but began to pick up interest this week.)\nFacebook's experiment isn't the only time that artificial intelligence has invented new forms of language.\nEarlier this year, Google revealed that the AI it uses for its Translate tool had created its own language, which it would translate things into and then out of. But the company was happy with that development and allowed it to continue.\nAnother study at OpenAI found that artificial\u00a0intelligence could be encouraged to create a language, making itself more efficient and better at communicating as it did so.\nUpdate: This article has been amended to stress that the experiment was abandoned because the programswere not doing the work required, not because they were afraid of the results, as has been reported elsewhere.\n"},
{"docid": "475 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 8, 2017", "title": "'The most awkward thing I've ever seen': Mark Zuckerberg and Bill Gates are really bad at acting\n", "content": "There was zero on-screen chemistry when Mark Zuckerberg and Bill Gates got together for a Harvard University promo video.\nThe tech billionaires demonstrated their lack of acting skills ahead of the Facebook founder's commencement speech at the Ivy League school.\u00a0\n                                        <table>                                                                           \nHarvard doesn't get enough appreciation for the raw acting talent it produces https://t.co/WsL996yHxj\n - Joshua Benton (@jbenton) March 7, 2017                                                                                                       <table>                                                                           \nit is amazing how far artificial intelligence has come. watch these two automatons converse https://t.co/NfiKoNB6WM\n - brian feldman (@bafeldman) March 7, 2017                                                                                  \nOne site called the video \"cringeworthy\", while one unimpressed viewer tweeted Zuckerberg's \"acting in his Facebook sketches is so bad, needs to give Jesse Eisenberg a call.\"\nAnother tweeted praise\u00a0for the Microsoft founder's performance, saying: \"Bill Gates' acting game is strong. Mark Zuckerberg's not so much.\"\n\"It is amazing how far artificial intelligence has come. Watch these two automatons converse,\" joked another.\n                   What Facebook used to look like: in pictures                   \nBoth Gates and Zuckerberg dropped out of Harvard, but later received invitations to come back to address graduating students.\n\"Whoa! I just got invited to give the commencement address at Harvard this year,\" Zuckerberg says in the video.\nGates responds: \"That's amazing!\"\nZuckerberg adds: \"They know we didn't actually graduate right?\"\n\"Oh that is the best part, they actually give you a degree!\" comes the response.\n                   Watch | Mark Zuckerberg's career in 90 seconds                         01:33\nGates later wrote on Facebook: \"Always happy to help, Mark. Good luck on your speech. Hope the honorary degree helps you land your dream job...\"\nHarvard President Drew Faust says Zuckerberg \"has profoundly altered the nature of social engagement worldwide,\"\u00a0adding that she's glad to welcome him back.\nMeanwhile, here's how to see everyone who has ever rejected you on Facebook .\u00a0\nCould Bill Gates become the world's first trillionaire? \u00a0\n"},
{"docid": "476 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "January 29, 2014", "title": "Page 3 Profile: Demis Hassabis, computer scientist\n", "content": "I recognise this brain box...\nFormer child chess prodigy and computer game designer Demis Hassabis is famous in the computer gaming world for having \"a brain larger than a planet\". He began playing chess when he was four years old, reached master standard by the age of 13 and went on to represent England. These days Hassabis, 37, specialises in cognitive neuroscience and artificial intelligence technology.\u00a0\nGaming? Chess? What a geek!\nWhat a rich geek, you mean. He's just sold his company, DeepMind Technologies, to Google for about \u00a3300 million.\nWhy was Google so keen to acquire the business?\nDeepMind Technologies has a reputation for secrecy, but its aim is said to be to develop computers that think like humans, and it specialises in artificial intelligence. Hassabis co-founded the company in 2012 with New Zealander Shane Legg and fellow Briton Mustafa Suleyman. They brought together neuroscientists and computer engineers in an effort to use technology and medical research to help machines to mimic the brain's ability to improve performance.\nMachines with brains? Sorry, cannot compute.\nGoogle founder Larry Page has previously expressed interest in making search commands easier by using an implant in the brain and is understood to have led the move to buy Deep Mind. It's not surprising he was drawn to Hassabis, who led a study at University College London in 2009 that scanned human brains and found \"just by looking at neural activity we were able to say what someone was thinking\".\nSo you're saying this guy is literally a mind reader?\nIn a manner of speaking. His colleague Legg recently predicted \"human level\" artificial general intelligence will arrive by 2030 and that machines will have developed \"basic vision, basic sound processing, basic movement control, and basic language abilities\" by 2020, with all of these abilities being \"learnt\" rather than pre-programmed.\nSystem meltdown!\nYou sound like you could do with a sit down and a cup of tea. If only there were a machine that could anticipate your needs...\n"},
{"docid": "477 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "October 15, 2017", "title": "Sharing patient data would open door to next-generation NHS using 'artificial intelligence', Government told; Study argues security challengesholding up access to health data for AI can be overcome, despite past controversies\n", "content": "Data from patients' health records should be shared with private firms to improve care using artificial intelligence, the Government is told today.\nA study sets out how Britain should become a world leaderin AI, to deliver benefits ranging from smarter scheduling of operations to hiring on-demand self-driving cars.\nIndustry experts call for the secure sharing of anonymised data about people's health and lifestyles - arguing they, as well as well as private technology companies, will benefit.\u00a0\nRead more\nControversial Google deal for NHS records has legality questioned\nThe NHS should use facts and figures from supermarkets, transport organisations and town planningto work out ways to encourage healthier lifestyles, the report says.\nHowever, it also highlights how the NHS is failing to exploit AI through data tie-ups with the likes of Your.MD, which offers \"immediate trustworthy healthcare advice\" via a mobile phone app.\nIt quotes Matteo Berlucchi, the firm's chief executive, who appealed for \"access to reliable and consistent data sets of anonymised personal health records\" to push forward the project.\n\"We have tried to approach the NHS to see if there was a way to access some of this data but we have struggled to even find the right person to talk to,\" he said.\nThe report, entitled \nGrowing the Artificial Intelligence Industry in the UK\n,argues the \"security challenges\" holding up access to health data for AI \"can be overcome by agreements\".\nHowever, the recommendation is likely to revive previous controversies over data-sharing of health records, which forced the Government into retreat.\nLast year, ministers scrapped the care data plan to link GP records after an outcry over whether the public had been properly informed and given the chance to opt out.\nThe Department of Health then promised that any new record-sharing system would come with \"a single and simple mechanism for individuals to opt out of their data being shared beyond their direct care\".\nHowever, draft plans last month appeared to suggest that even patients who opt out could see their information shared across services covering up to five millionpeople.\nMeanwhile, in July, the Information Commissioner criticised an NHS hospital that failed to use an appropriate legal basis to share 1.6 million patient records with Google's Deepmind AI firm.\nThe report makes 18 recommendations on how to make the UK a world leader, including boosting skills through an industry-funded masters and expanded expand support for businesses.\nRead more\nNHS 'sleepwalking into winter crisis' as waiting times soar\nNumber of NHS nurses falls for first time since 2013\nHammond admits Brexit 'no deal' will mean less money for NHS\nNHS faces cuts without emergency bailout, chief executive warns\nOther areas where AI is being used, but could be expanded, included:\n* Banking - HSBC has created a chatbot, Olivia, who can assist customers 24 hours a day, 365 days a year with their enquiries.\n* Education - A platform called Century is helping teachers to provide more personalised education programmes and receive feedback.\n* Legal services - AI is helping lawyers to do legal searches and to draft the best standard documents.\n* Travel - Companies are developing fully autonomous operating systems that diagnose potential problems for driverless cars and identify the most logical routes.\nKaren Bradley, the Culture Secretary, said: \"I want the UK to lead the way in artificial intelligence. It has the potential to improve our everyday lives - from healthcare to robots that perform dangerous tasks.\"\n"},
{"docid": "478 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 28, 2017", "title": "There is no such thing as a new idea: How to get industrial strategy right\n", "content": "\"There is no such thing as a new idea... We give them a turn and they make new and curious combinations.\"\nAs someone who has been running businesses for nearly half a century, I have seen a lot of new ideas - most of them more than once.\nWhich is why I, along with anyone who lived through the Seventies, can understand Mark Twain's quote when the Government talks about industrial strategy. Yet this talk is not a bad thing. It would be unfair to bury the idea of an industrial strategy in the era's time-capsule alongside Arctic rolls, flares and Kevin Keegan's curls.\u00a0\nOf course, some ideas should stay underground, particularly a return to propping up struggling industries and flagship companies. Whereas we once looked to power the life support of has-beens, we should now choose to energise the success of businesses that are in the ascendancy.\nThis means helping businesses scale up - something that the recent Green Paper highlighted as a weakness. While the UK ranks third in the world for number of start-ups created, it sits 13th for the number of businesses that successfully scale up.\nSolving this will be complex. However, an effective industrial strategy can be achieved by following some key principles.\nThe UK's Deepmind, an artificial intelligence pioneer, last year beat the world champion at GoCredit:      Getty     \nThe lines which traditionally distinguished one industry from another are fast fading. For example, the needs of manufacturing and financial services may be very separate today, but how long will this last?\nBoth are sectors that could be revolutionised by robotics and artificial intelligence. These are areas where the UK is already excelling, along with other futuristic industries like life sciences, quantum mechanics, intelligent fuels and big data.\nThe future must be harnessed, not feared. Through helping these areas, we can lift countless sectors.\nInnovation comes from all sources. However, evidence suggests that innovation is most likely to arise from smaller and medium-sized companies; firms that are often innovative, agile and can scale up rapidly.\nOur industrial strategy must first identify these companies and then support them. The Government has announced it will use data like VAT returns to discover potential. We can go further and make this data public.\nBritain's most innovative companies are bold and brave; we should be just as radical. Nothing is sacred. We should look to regulation, procurement, tax, supply chain integration and energy costs. Brexit does, however, throw up its own questions. We must not shield business from foreign talent and target businesses should be able to fast-track hiring through special visas.\nBusiness Secretary Greg ClarkCredit:      Reuters     \nIntervention comes at a cost and brings risk, yet this is no excuse for inaction. The power of an industrial strategy is that it accesses the largest risk pool possible: the nation.\nNot every intervention will succeed and risk must be accepted. However, the rewards of an industrial strategy are great. An industrial strategy will allow us to back inherently risky and uncertain activities that cannot rely on support from the private sector alone.\nAs chairman of the Business Growth Fund, the UK's leading investor in growing companies and a truly nationwide operation, I have seen the potential that local businesses can have. More needs to be done to help all businesses; as the Green Paper notes, companies outside the M25 are most likely to struggle to access capital.\nGreg Clark, Business Secretary, is right when he says the strategy \"must be local\" and \"spread wealth across the country\". He adds that this \"must not be a strategy for incumbents - we need to make a place where new entrants come in, new businesses are created and new industries challenge existing ones\".\nNow it is time to act upon this ambition. Doing so can go a long way to ensuring that all of Britain gains from a disruptive future.\nSir Nigel Rudd is chairman of the Business Growth Fund\n"},
{"docid": "479 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "November 30, 2016", "title": "Improve your customer service experience with AI\n", "content": "                   SMEs cannot afford to ignore larger companies' use of artificial intelligence to solve customer needs, but nor should they rush to invest in imperfect computing.   .inline-content hl{     font-family: \"Austin News Deck Semibold\", Georgia, Times, serif;      font-size: 1.7rem; }   .inline-content .first-letter{     color: #043480;      float: left;     font-size: 9.1rem;     font-style: normal !important;     font-weight: normal !important;     line-height: 7rem;     margin-top: 4px;     padding-right: 2px;     text-transform: uppercase;     font-family: \"Austin News Deck Semibold\", Georgia, Times,serif; }   \nThe best customer service agent is knowledgeable, always available and knows precisely what your customer wants, but increasingly, they're not human.\nChatbots and other artificial intelligence tools could help your SME offer a more comprehensive, personalised customer service without hiring new staff. But, alongside the benefits of computerising customer service, there are risks, particularly as it's such early days for the technology involved.\u00a0\nHow does it work?\nChatbots let customers type queries - through messaging mediums such as Facebook or WhatsApp - and get an automated response without a human paid employee needing to intervene.\nCustomers can also take actions, such as booking a restaurant table, ordering a pizza, or choosing specifications for a new bicycle in natural language, as though they're typing to a person rather than a machine.\n.html-embed.component .quote.component{margin-left:0}.html-embed.component .quote.component .component-content{margin-right:16px}.quote__source, .quote__author {white-space: normal;}@media only screen and (min-width:730px){.html-embed.component .quote.component{margin-left:-60.83px}.html-embed.component .quote.component .quote__content:before{margin-left:-12px;padding-right:1px}}@media only screen and (min-width:1008px){.html-embed.component .quote.component{margin-left:-82.33px}}It's still in the realm of specialists and can be expensive, which can be especially limiting to smaller brandsJo Allison, Canvas8\nThe benefits for business are clear; you can always offer scalable customer service at little cost, along with personalised marketing. \"A chatbot that can 'converse' with consumers using AI, and carry out a plethora of simple tasks, is an exciting prospect for many small businesses without the people power of larger organisations,\" says Jo Allison, behavioural analyst at Canvas8 .\nFor customers, it's easier for them to get retail chores and other tasks done via a platform they like to use, at a time that's convenient for them. \"People are starting to almost prefer self-service channels as the effectiveness of them increases,\" explains Daryn Mason, senior sales consultant at Oracle Cloud .\n\"Customer experience is all about low effort. Waiting in a call centre\u00a0queue is a painful exercise for most people. Having technology where customers can get fast answers in a natural language without waiting for somebody to be free on the telephone is going to boost the customer experience.\"\nHow are big-tech bosses reacting?\nNo wonder, then, that so many tech luminaries, from Microsoft chief executive Satya Nadella, to Facebook founder Mark Zuckerberg, are\u00a0 proclaiming chatbots as the future of computing.\nFacebook is a good place for an SME to start getting to grips with chatbots, as the social network offers a free platform using its Messenger chat application that's easy to use. It allows a business to build a basic bot to answer simple queries, such as what your opening hours are during the holidays.\nYou can also develop more advanced systems using e-commerce platform, Shopify, that allow customers to place orders directly via the Messenger chat app, and offer digital sales support for shoppers with questions, helping to bridge the gap between personal customer service in-store and online shopping. Another advanced offering isIP Soft's Amelia, one of the most sophisticated service agents to provide a wide range of natural language interaction.\nWhile you can have an initial play with the technology on your own, you may need to turn to your in-house IT team, or external developers, to initially set up such tools. \"Developing a bot isn't so easy that anyone can do it,\" says Ms Allison. \"It's still in the realm of specialists and can be expensive, which can be especially limiting to smaller brands.\"\nWhat can go wrong?\nThere are risks in using these technologies, particularly because they're so new. \"[Customers] give it a go first, and then there's disappointment because it comes back with a wrong response. They find the holes in it quite quickly,\" says Mr Mason. \"It's always going to be a little bit short of customer expectations.\"\n.html-embed.component .quote.component{margin-left:0}.html-embed.component .quote.component .component-content{margin-right:16px}.quote__source, .quote__author {white-space: normal;}@media only screen and (min-width:730px){.html-embed.component .quote.component{margin-left:-60.83px}.html-embed.component .quote.component .quote__content:before{margin-left:-12px;padding-right:1px}}@media only screen and (min-width:1008px){.html-embed.component .quote.component{margin-left:-82.33px}}It's almost going to be essential for small business to embrace this technologyDaryn Mason, Oracle Cloud\nHowever, he adds, people are becoming accustomed to talking to machines thanks to Apple's Siri and Amazon's Alexa, and learning their limitations. And, adds Dylan Stuart, partner at creative consultancy Lippincott, \"people can make mistakes too\".\nInstead of seeing bots as a source of danger, Mr Stuart says companies should see them as an opportunity: \"a new way to interact with customers and build emotional connections\". They can be a positive force that reinforces brand - assuming you get the tone right.\n\"Asking what voice should your chatbot have is similar to asking what voice should your brand has overall,\" Mr Stuart says. \"Ultimately, to truly create an emotional bond with your customers, that tone should reflect what your customers want to feel rather than the specific things you want to say.\"\nAside from keeping customers happy, there's another reason to consider chatbots for your SME - your rivals are likely to be doing the same. \"In terms of competitiveness and survival in a digital world, it's almost going to be essential for small business to embrace this technology, because if they don't their competitors are going to benefit from the scalability, whether it is virtual assistants or AI,\" Mr Mason adds.\n\"You can't scale an operation with people anymore. If your competitors are using that technology to take all of the routine stuff away from expensive human operators, those organisations will get a really big competitive advantage.\"\nHow can you get prepared for bots?\nOne place to start with bots is knowledge management, gathering up relevant data and tracking customer queries so that, when you do shift to bots, you'll have a centralised set of information which they can access and learn. \"It's almost a back office function, but you have to have really strong knowledge management within in an organisation to exploit these technologies, otherwise they have nothing to draw on when responding to customers and their needs.\"\nWhen you do get started, Mr Mason advises using a cloud-based system, so it's scalable and doesn't require heavy investment to support the backend of a chatbot. \"Everything we're doing is cloud based. In-house isn't an option for SMEs,\" he says.\nNone of this means that SMEs need to rush to launch customer-service bots in time for the holiday season. Instead, simply start paying attention to the technology, and try it out now and then. \"Small businesses need to be tracking this really closely and even experimenting, such as with Facebook, so they're ready to go and are not starting from scratch,\" he says.\n\n"},
{"docid": "480 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "December 10, 2014", "title": "Facebook planning robots to stop you uploading drunken photos; Similar technology is already used to tailor your newsfeed and suggest posts\n", "content": "Facebook could soon scold you if you try to upload drunk photos of yourself, in a bid to stop people embarrassing themselves on the site.\nAsking whether you're really sure you want to post that blurry, embarrassing picture could be the job of a digital assistant built in to Facebook, Wired was told by Yann LeCun, a research and machine-learning expert who runs Facebook's Artificial Intelligence Lab, a team of researchers based in California and New York.\u00a0\nLecun describes an \"intelligent digital assistant which would mediate your interaction with your friends and also with content on Facebook\". If it saw something that you might regret posting, it would do the virtual equivalent of tapping you on the shoulder and checking whether you're sure you want your mum or your boss, for example, to see the picture you're about to upload.\nThe tool would use image recognition technology that can learn the difference between your sober and drunk self, and warn you if you're getting a bit too much like the latter. The technology would be similar to the one that recognises friends' faces in photos and suggests that they should be tagged.\nThe artificial intelligence team has also been talking to those that work on the Oculus Rift virtual reality headset, which Facebook bought this year, on the possibility of extra AI features.\nThe team's work is already powering a range of features on Facebook - it gets to know you, for example, and shows links in your news feed that you're more likely to click on. It also reads your posts and suggests hashtags that you might want to use in them.\nSimilar technology is used in Google to improve its search engine and recognise speech commands, and Skype can translate calls from one language to another. The technology is becoming so important that most big firms are rushing to hire experts in the field, writes Wired.\n"},
{"docid": "481 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "June 13, 2015", "title": "Humans; Full seven-day listings & previews\n", "content": "Sunday, Channel 4, 9pm Have you seen those clever adverts for a company called Persona Synthetics and wondered what it is all about? Well, they were fake and really a trailer for this gripping new drama, which goes back to the seam so often mined on the big screen, dating back to Metropolis in 1927 and taking in Blade Runner, A.I. Artificial Intelligence, Terminator, I, Robot and Ex Machina along the way.\u00a0\nFrom the makers of Utopia and Broadchurch, it's inspired by the Swedish drama Real Humans and written by Sam Vincent and Jonathan Brackley, who cut their teeth on the espionage drama Spooks. Like Utopia, it's set in a parallel present, one that looks and feels exactly the same as our own except for one crucial difference: the presence of \"Synths\", lifelike androids who are the latest must-haves for time-poor, asset-rich humans. They don't think or feel, and are simply here to serve, whether as domestic helps or carrying out menial jobs that we think are beneath us. But what happens when these synthetic creations with artificial intelligence start to develop minds of their own ... William Hurt, Katherine Parkinson, Rebecca Front, Merlin's Colin Morgan and the model-turned-actress Gemma Chan (superb as the synth Anita, below) lead the cast in this unsettling, creepy thriller that will leave you pondering man's relations with machines and the very question of what it means to be human in the first place. You'll never look at your Henry vacuum cleaner in the same way again.\n"},
{"docid": "482 of 500 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "January 17, 1994", "title": "UNABLE TO THINK ABOUT IT;Computers can often perform intricate tasks. But are they merely copycats following scientists' instructions?\n", "content": "\u00a0\n MACHINES which seem to think have become a regular feature of our lives. Tasks that 20 years ago would have been unthinkable are now simple for quite basic computers.\n Many machines can already recognise voices and synthesised voice communication is used frequently - in some telephone answering machines, for instance. Computer games are becoming ever more sophisticated and the transmission of data and information has been revolutionised.\u00a0\n More complex computers can boast remarkable achievements. Guided missiles zoom in on their targets. Automatic pilots fly jumbo jets, and at the most sophisticated airports such as Heathrow even the largest jets can now land in zero visibility, relying entirely on computers.\n Chess is another field where the machine's advances far outstrip mankind's. The most sophisticated computers are now a match for all but the very best players. Already they have beaten grand masters, and there is little doubt that soon they will be capable of beating the world's greatest strategists. No bookmaker would offer long odds against a computer being able, before long, to inflict on Gary Kasparov the defeats that Nigel Short found so elusive.\n But is it enough for us to describe these machines as intelligent, or are their achievements in reality just a feather in the cap of the scientists who have programmed them to perform sequences of tasks rapidly and efficiently?\n Different people use the term \"artificial intelligence\" to mean different things. But before it can be argued successfully that we are in the presence of an artificial intelligence, the consensus would be that a machine has - as a minimum - to be able to \"learn\" from the environment independently of its programmer. The mathematician Alan Turing, a distinguished code-breaker in the second world war and a principal architect of the modern computer, devised as early as 1950 a test of artificial intelligence. If a computer hidden from view were to give answers indistinguishable from those of an intelligent human, it would deserve to be called intelligent, he said.\n One fundamental difference between computers and the human brain is that computers rely on serial processing. The fact that a computer may be able to win a complex tactical game like chess simply reflects its ability to assess at rapid speed numerous potential sequences of moves, and to \"learn\" and disregard potential losing sequences. While this does imply sophisticated programming, it does not fulfil the criteria of learning independently of its programming and is not therefore intelligent.\n Quite apart from its ability to pick up stimuli from the environment, the human brain differs from even the most sophisticated computer in that it operates with so-called \"parallel processing\", doing several things at once.\n Sir Clive Sinclair, one of the original computer boffins, is convinced that parallel processing programs for computers will be with us soon, and that these will transform society.\n With parallel processing, computers would be expected to \"learn\" better from their experiences and, perhaps, be able to pass on the fruits of such learning to other computers, each in turn becoming more sophisticated. Thus could be born a generation of computers able to offer at least a more realistic simulation of intelligence.\n Robots are already able to do all sorts of repetitive tasks currently performed by human beings and could more effectively handle some of the tasks carried out by astronauts.\n But the effective control remains with the human brain. No computer has yet been devised which can cope even with the subtleties of the English language. And the idea of an artificial intelligence with a sense of humour and a conscience still s eems a remote dream. If, however, one was to believe in the faith of scientists working in the artificial intelligence field, one would have to suspect that dreams just could become reality.\n\n"},
{"docid": "483 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 13, 2016", "title": "South Korea's\u00a0Lee Sedol beats AlphaGo at fourth attempt\n", "content": "Lee Sedol beats Google's\u00a0AlphaGo programme at the fourth\u00a0time of asking making it 3-1 in the five match series\nSouth Korean Lee Sedol won his first match against a computer programme developed by a Google subsidiary on Sunday (March 13) in the ancient board game Go, denying a clean sweep for the artificial intelligence in a five-match series. Lee, one of the world's top players and a holder of 18 international titles, recovered from three consecutive losses against the AlphaGo programme developed by DeepMind . \"This win is invaluable and I would not trade it for anything else in the world. And I'm so glad,\" a jubilant Lee told reporters after the match, thanking fans for their support.\u00a0\nGame over! Google programme wins series against Go champion in victory for AIPlay!01:07\nThe 33-year-old professional player has admitted to underestimating AlphaGo's skills but also said the programme was not perfect, asking supporters to keep watching the contest. DeepMind founder Demis Hassabis told reporters the loss was a valuable learning tool and would help identify weaknesses in the programme that his team needed to address. \"I just wanted to also say I think it is a real testament to Mr Lee's incredible fighting spirit and he was able to play so brilliantly today after three defeats,\" Hassabis said.\nThe history of GooglePlay!02:26\nGo, most popular in countries such as China, South Korea and Japan, involves two contestants moving black and white stones on a square grid, with the aim of seizing the most territory. Experts did not expect an artificial intelligence programme to beat a human professional for at least a decade, until AlphaGo beat a European champion player last year. Lee was considered a much more formidable opponent, however. Google executives say Go offers too many possible moves for a machine to win simply through brute-force calculations, unlike chess, in which IBM's Deep Blue famously beat former world champion Garry Kasparov in 1997.\nInstead, they said, AlphaGo has sought to approximate human intuition, by studying old matches and using simulated games to hone itself independently. The fifth and final match is scheduled for Tuesday.\nREAD MORE ABOUT:\n"},
{"docid": "484 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "June 25, 2014", "title": "Real Humans: Are the robots taking over?; In a hit Swedish TV drama, soon to be remade in English, lifelike robots do the all the dirty work. Pure science fiction, wonders Gerard Gilbert - or a glimpse of the future?\n", "content": "With The Killing and Borgen finished, Wallander having bowed out on BBC4 last Saturday and just one more series of The Bridge, the sun seems to be setting on a golden age of Scandinavian television. There is, however, one show that has been denied to us in the UK and that's the Swedish sci-fi drama Real Humans, despite two series having been screened to great acclaim in at least other 50 countries.\nReal Humans imagines an alternate version of modern-day Sweden in which life-like androids, known as \"hubots\", take care of the domestic and workplace drudgery. They have flawless skin, glossy hair and unnaturally bright (usually\u00a0blue) eyes - and they look rather like Valeria Lukyanova, the cosmetically enhanced Ukrainian model and YouTube sensation known as the \"real-life Barbie\". As the sheepish husband of a hard-working lawyer tells his children as he unpacks \"Anita\", a similarly plastic-fantastic rechargeable domestic servant: \"I haven't told Mum yet.\" Mum's comment, on clapping eyes on Anita, is short and to the point: \"No way!\"\u00a0\nHusbands and wives threatened by the arrival of these attractive and biddable cuckoos aren't the only ones resisting the hubots, and a local meathead, his job threatened by their growing use in factories, asks one android: \"How does it\u00a0feel to be related to a vacuum cleaner?\" before venting his only too human frustration. In the meantime, some of the robots are becoming so sophisticatedly programmed by their owners\u00a0(via a USB port in the backs of their necks) that they are developing free will and childlike emotions.\nReal Humans (the title comes from a campaign group protesting against the hubots) is funny and thought-provoking, and this autumn the British production company Kudos, makers of Spooks, starts shooting an English-language version. \"Exploring themes of love, discrimination and integration, this thrilling, beautifully written series allows us to get under the skin of what it means to be human,\" declares Jane Featherstone, executive producer for Kudos, in a statement.\nPutting to one side the question of whether we need an English-language remake and why we can't make do with the subtitled Swedish version (OK, because not enough people will watch it), developments in the field of artificial intelligence seem to suggest that the world of Real Humans might not be so far in the distant dystopian future.\nEarlier this month, for example, a programme called \"Eugene Goostman\" convinced enough judges at the Royal Society in London that it was a 13-year-old Ukrainian boy that it supposedly became the first computer ever to pass the Turing test - so named after pioneering British computer scientist Alan Turing, who devised it in 1950 as a gauge of artificial intelligence.\nMeanwhile, the Japanese firm Softbank unveiled a \"human-like\" robot called Pepper, which it says can read human emotions. Pepper apparently uses a \"cloud-based artificial intelligence system\" that allows it to analyse gestures, expressions and voice tones, and Softbank claims that people can communicate with it \"just like they would with friends and family\", which shouldn't be too hard if your family consists largely of grunting teenagers. Anyway, Pepper can be yours (from next year, at least) for 198,000 yen, or just over \u00a31,000, and he's not in the least sexy, so no problems inviting him or her (it has womanly hips) into the home.\nWith its rapidly ageing population and falling birth rate, Japan is one of the world's biggest robot markets, as it looks to offset labour shortages and the cost of looking after elderly relatives, and Honda has been developing its own robot, Asimo, which played football with US President Barack Obama on his recent visit to Japan. Asimo had the build and speed of an overgrown, hyperactive 12-year-old, and Obama seemed unsure whether to pat it on the head or run for his life. It's these conflicting impulses that makes Real Humans so compelling; let's hope it gets a British broadcast soon.\n"},
{"docid": "485 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "June 17, 2016", "title": "Apple's big juggling act: guarding your privacy while keeping its edge\n", "content": "The defining advance of the next decade, if you listen to the prophets of Silicon Valley, will be the seismic and unavoidable ascent of artificial intelligence. It might be hard to take the thought seriously when a satnav sends you down a dead-end country road, or your phone's autocorrect feature turns a carefully-constructed text message to gibberish, but the milestones reached in the past year alone have been exceptional.\nDeepMind, the British AI company owned by Google, has defeated the world champion at Go, the ancient game that requires a finely tuned sense of intuition to master. Driverless cars now seem like an inevitability rather than a curiosity. Error rates on image recognition technology have dropped from 25pc in 2011 to less than 4pc.\u00a0\nAI is graduating from theory and academic papers to everyday life. If the past 10 years has been defined by the plummeting costs of microprocessors and sensors that have made smartphones a commodity product, the future is about building intelligent systems that can make them more powerful. Ergo, the companies that will profit might not be the ones with expertise in hardware design, but those who can build software that talks back.\nGoogle, always a company defined by the effectiveness of its algorithms compared to others', has gone \"all in\" on deep learning, and incorporated it into thousands of software projects. Mark Zuckerberg, determined not to miss out on any trend after Facebook's early failures in mobile, has poached some of the world's leading AI gurus from universities. Amazon has emerged as a sleeping giant in the field. Microsoft is ploughing resources into artificial intelligence, albeit with mixed success (a conversational Twitter bot it unveiled earlier this year was swiftly shut down after \"learning\" to spew vile insults at those who engaged with it).\nThe missing name here is Apple. The undisputed victor of the smartphone-building wars, in profit and influence if not quite in market share, Apple's expertise when it comes to AI is less clear. This is partly because it has had less incentive - Apple is not in the business of mining data to target adverts, at least not as deeply as Google and Facebook, and is still a hardware company at heart.\nAny breakthroughs that do happen at Apple HQ, meanwhile, are kept quiet, unlike those of other major technology companies. This means both that we don't know about them, but also that the academic computer scientists making the running on AI research can be somewhat reluctant to join a company at which they will not be able to trumpet their achievements.\nBut another reason, and one that is often brushed aside by other tech groups invested in AI, is privacy. Artificial intelligence, at least for now, needs to be trained on heaps of data. A computer vision program does not instinctively know what a cat is - it must be shown millions of photos of cats to be able to identify one, and even then, tends to recognise cat characteristics - four legs, tail - rather than the understanding a human will have (show it a cat with three legs and it might struggle).\nApple's uncompromising stance on privacy, seen in Tim Cook's very public battle with the FBI over the company's refusal to unlock a terrorist's iPhone this year, as well as vocal opposition to the British Government's Investigatory Powers Bill - means it takes great pains not to collect the data that Google and Facebook do. Much of the personal information on an iPhone never leaves the device, and the data that does go online is strictly encrypted.\nWhile this has won Apple plaudits, it could also threaten to hold it back in the AI race. By coming down on the side of privacy in the inherent tradeoff with progress, Apple's ability to create the services of the future could suffer. Take Allo, a new messaging app from Google. By reading a user's conversations, Allo is able to observe their writing style, and learn to write messages for them, suggesting potential replies based on previous ones. The trade-off is that end-to-end encryption, the security protocol that means only the sender and recipient can read a message, is disabled on Allo.\nApple's messaging app, meanwhile, is fully encrypted, making personalised text technology a bigger challenge, and the data collected by Siri, its AI assistant software, never leaves a phone, so is essentially wiped clean every time a new one is purchased.\nAt the start of this week, at its annual software conference, the most important one for years, given that the company's revenue is falling for the first time in a decade, Apple tried to prove that it doesn't have to sacrifice privacy for progress. It announced it would be adopting a technique called \"differential privacy\", which scrambles users' data using statistical noise, essentially anonymising it.\nThe company says the technique will enable it to study patterns of large numbers of users without affecting their privacy. Lukasz Olejnik, a security and privacy consultant and University College London researcher, calls Apple's introduction of differential privacy \"an impressive milestone for privacy engineering\" that is \"clearly a step in the right direction\".\nThe announcement came as Cook and his lieutenants unveiled a string of software inventions that will require better knowledge of its users to reach their full potential. It showed off a souped-up version of Siri that can order taxis or send a friend money, a much-needed upgrade for a virtual assistant that was impressive when Apple unveiled it in 2011 but has been left behind by younger and smarter versions from Amazon and Google.\nImproved computer vision technology in its photos app will let an iPhone put together slideshows of holidays or birthdays, a feature Google has pushed in its own photos as an example of its AI prowess.\nApple's clear advantage in hardware has not diminished, but the battleground has shifted. As online services powered by AI become our primary way of interacting with our computers, it is facing new direct competitors, most of which are not quite as principled about privacy.\nApple's stance on protecting its users' data is acute - we are becoming more savvy about what our internet overlords know. But if that data is the key to the next computing age, it will have to navigate a tricky line to avoid being left behind.\n'By coming down on the side of privacy, Apple's ability to create the services of the future could suffer'\n"},
{"docid": "486 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "April 14, 2018", "title": "Mark Carney warns robots taking jobs could lead to rise of Marxism; Mass unemployment, wage stagnation and growth of communism could come from technologicaladvances\n", "content": "Mass job losses caused by advancing technology could lead to a rise of Marxism, the governor of the Bank of England has warned.\nMark Carney said the automation of millions of jobs could lead to mass unemployment, wage stagnation and the growth of communism within a generation.\u00a0\nHe warned \"Marx and Engels may again become relevant.\"\nSpeaking at the Canada Growth Summit, Mr Carney said increases in artificial intelligence, big data and high-tech machines could create huge inequalities between the high-skilled workers who benefit from the advances and those who are sidelined by them.\nRead more\nCryptocurrency exchanges to face regulatory clampdown says Mark Carney\nHe said: \"The benefits, from a worker's perspective, from the first industrial revolution, which began in the latter half of the 18th century, were not felt fully in productivity and wages until the latter half of the 19th century.\n\"If you substitute platforms for textile mills, machine learning for steam engines, Twitter for the telegraph, you have exactly the same dynamics as existed 150 years ago - when Karl Marx was scribbling the Communist Manifesto.\"\nThe industrial revolution saw a then-unparalleled growth in production during the late 18th and early 19th centuries- but wages failed to increase for decades as machines meant the jobs created were low-skilled.\nMany believe the resulting inequalities were a direct precursor to the rise of both left- and right-wing extremism across Europe.\nMr Carney, who is due to leave his post in 2019, said the years of weak salary growth since the financial crisis suggested this 19th-century experience was already being repeated.\nThe governor also added there were signs of \"hollowing out\" in the job market as mid-level workers find computers able to complete specific tasks - even some previously considered skilled work.\nHe said: \"There is a disconnect in expectations. In surveys, over 90 per cent of citizens don't think their jobs will be affected by automation, but a similar percentage of CEOs think the opposite, in the number of jobs which will be materially affected.\"\nHe pointed out how law firms were already using artificial intelligence to comb through documents and read evidence, something traditionally done by junior lawyers.And he added that banks have used a combination of artificial intelligence and big data to computerise large swathes of customer service departments, resulting in staff being made unemployed.\nJobs such as a taxi or lorry drivers could also be scrapped, as self-driving technologyimproves, he added.\nMr Carney said the trends go against previous ideas which suggested only manual tasks would be given to machines.\nThe end result, he indicated, might mean more workers need to prepare for jobs which require a higher emotional intelligence, in sectors such as care and leisure.\n"},
{"docid": "487 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "October 9, 2015", "title": "Cancer drug development time halved thanks to artificial intelligence; Artificial intelligence has halved the time it has taken to bring a cancer combatting drug to market, start-up claims\n", "content": "A cancer-fighting drug is on target to be brought to market in half the expected time thanks to the use of artificial inteligence in testing, a start up has claimed. \u00a0\n                     Berg Health, a pharmaceutical startup founded in 2008 with Silicon Valley venture capital backing, said it expected the drug to go on sale within three years, marking seven years in development compared to the general 14. \nHealthy cells feed on glucose in the body and die off, in a process known as cell death, when their usefulness draws to a close. But in some circumstances the mitochondria - the parts of the cell that provide its energy - malfunction and metabolise lactic acid instead of glucose, turning off their built-in cell death function at the same time. \nThe cell can then becomes cancerous and a tumour grows. Berg's drug, BPM31510, will reactivate the mitochondria, restarting the metabolising of glucose as normal and reinstituting cell death, so the body can harmlessly pass the problem cells out of the body.\nBerg Health's team used a specialised form of artificial\u00a0intelligence to compare samples taken from patients with the most aggressive strains of cancer, including pancreatic, bladder and brain, with those from non-cancerous individuals. The technology highlighted disparities between the corresponding biological profiles, selecting those it predicted would respond best to the drug. \n\"We're looking at 14 trillion data points in a single tissue sample. We can't humanly process that,\" said Niven Narain, a clinical oncologist and Berg co-founder. \"Because we're taking this data-driven approach we need a supercomputer capability. \n\"We use them for mathematics in a big data analytic platform, so it can collate that data into various categories: healthy population for women, for men, disease candidates etc, and it's able to take these slices in time and integrate them so that we're able to see where it's gone wrong and develop drugs based on that information,\" Mr Narain said. \nBerg expects to begin phase two trials of the drug next January, meaning it has already been proven to be effective on animal or cell culture tests and is safe to continue investigating in humans. \nMr Narain said it usually takes $2.6bn (\u00a31.7bn) and 12 to 14 years to get a drug to market, and that the trial metrics within four and a half years worth of development indicated the time it takes to create a drug can be cut by at least 50 per cent. This will also translate into less expenditure, he claimed. \n\"I don't think we're going to spend $1.3bn to produce our first drug, so the cost is cut by at least 50 per cent too,\" he added.\n\"'There's a lot of trial and error in the old model so a lot of those costs are due to the failure of really expensive clinical trials. We're able to be more predictive and effective... and that's going to cut hundreds of millions of dollars off the cost.' \n"},
{"docid": "488 of 500 DOCUMENTS\n", "source": "The Independent - Daily Edition\n", "date": "October 21, 2017", "title": "CBI wants commission on impact of AI on UK jobs\n", "content": "The Confederation of British Industry is calling on the Government to establish a joint commission tasked with examining the impact of Artificial Intelligence on people and jobs across all sectors of the UK economy.\u00a0\nBased on research it conducted into the way that technology is changing the way we live and work, the CBI said on Friday that it had identified three technologies -AI, Blockchain and the Internet of Things - that are set to move from the fringes to the mainstream within the next five years.\nIt also found, however, that only a third of businesses currently have the skills and capabilities needed to adopt AI technologies, and that more needs to be done to help prepare those companies for the future.\nThe aim of the commission, the CBI said, would be to examine the impact of AI on people and jobs, and to subsequently set out plans for action that will \"raise productivity, spread prosperity and open up new paths to economic growth\".\n\"The UK must lead the way in adopting these technologies but we must also prepare for their impacts,\" said Josh Hardie, deputy director-general of the CBI. \"That's why we urge the Government to set up a joint commission on Artificial Intelligence in 2018, involving both business and employee representatives, to better understand the impact on people's lives, jobs and our future economic growth.\"\nMr Hardie said that while great opportunities are created by new technologies, regulatory hurdles, security concerns and the challenge of finding people with the right skillsmeanthat many firms are \"slow to adopt\".\nMatt Hancock, digital minister, welcomed the CBI's call. \"We want the UK to lead the way in emerging technologies,\" he said. \"Our ambitions are aligned on the need to embrace the opportunities of the digital revolution.\"\nThe emergence of new technologies and the increasingly dominant role of robots in some industries has been a topic of persistent debate in recent months.\nSpeaking to an audience atUniversity College London earlier this week, the former Greek finance minister,Yanis Varoufakis, predicted that the rise of big tech companies and AI would cause the current economic system to undermine itself.\"[Technology] is going to destroy a lot more jobs than it creates,\" he said.\nThe chief executive of Tesla, Elon Musk, has also vocally and repeatedly warned about the increasing dominance of technology. In July he described AI as \"a fundamental existential risk for human civilisation\".\n"},
{"docid": "489 of 500 DOCUMENTS\n", "source": "The Guardian - Final Edition\n", "date": "May 5, 2013", "title": "Review: Discover: 'We're losing the human part of being together': RATIONAL HEROES NO 6: SHERRY TURKLE: Catherine de Lange meets the one-time 'cyber-diva' who some now call a 'technophobe'\n", "content": "Bedraggled from a walk in the rain, Sherry Turkle shows up begging for a latte. She's left her wallet in her hotel room. She's exhausted, she says, and could do with a coffee. \"You can see it's not my most perky morning. But I'm really thrilled to be meeting with you.\"\nThese aren't just pleasantries - Turkle has a serious point to make. As professor of the social studies of science and technology at MIT and the founder and current director of the MIT Initiative on Technology and Self, she has spent over three decades studying the way people interact with machines, and is growing increasingly worried about the amount of human interaction people are happy to delegate to robots or carry out over phones and computers. As a human, within seconds of meeting her in person, I can interpret the complexities of her mood - the tired part, and the happy to be here part. \"This is a complex dance that we know how to do to each other,\" she says. A dance she fears is being forgotten.\u00a0\nTurkle wasn't always this interested in technology. Born in Brooklyn in 1948, she studied in Paris before returning to do her PhD in sociology and psychology at Harvard. By 1978 she had just written her first book, on French psychoanalysis, when MIT hired her to study the sociology of sciences of the mind. \"I began to hear students talking about their minds as machines, based on the early personal computers they had.\" They'd use phrases like \"debugging\" or \"don't talk to me until I clear my buffer\". \"I'd never heard any of this stuff before.\"\nSo Turkle began to study the way that artificial intelligence was taking hold in everyday life, at a time when these interactions with machines were pretty raw. She \"literally was at the right place at the right time.\"\nThe place being MIT, home to some of the pioneers of artificial intelligence and social robotics, and the birthplace of perhaps the most sophisticated, and endearing, social robots. Turkle tested these anthropomorphic robots on children, \"computer virgins\". In one study she observed how children would bond with the robots, which were programmed to respond with human-like emotions, in a way they wouldn't with other toys. \"This becomes a tremendously significant relationship for the child,\" she says, \"and then it will get broken or disappoint, and the child will go ballistic. My research group went berserk at how much damage we felt we'd done.\"\nTurkle was \"smitten with the subject and stayed with it for 30 years\". In the early days she was labelled as a \"cyber diva\". \"People thought I was very pro-computer. I was on the cover of Wired magazine.\" Then things began to change. In the early 80s,\"we met this technology and became smitten like young lovers,\" she says, but today our attachment is unhealthy. In her latest book, Alone Together: Why We Expect More from Technology and Less from Each Other, Turkle says we have reached a point she calls the \"robotic moment\" - where we delegate important human relationships, in particular interactions at \"the most vulnerable moments in life\" - childhood and old age - to robots. \"We are so worried about Asperger's, so worried about the way we communicate with faces. To me, as somebody who likes technology, this is just playing with fire.\"\nTurkle frequently takes calls from journalists seeking comments on the latest story about robots in nursing homes, teacherbot programmes or nannybots to look after children. She sees married couples who prefer to have their fights online. \"My studies of funerals are hilarious,\" she says. \"Everybody's texting. When I ask them about it, they say, 'Yeah, I do it during the boring bits.' So that's the question: what's does it mean as a society that we are there for the boring bits?\"\nShe is particularly concerned about the effect on children. \"I am a single mum. I raised my daughter, and she was very listened to.\" Today our phones are always on, and always on us. Parents are too busy texting to watch their kids, she cautions. There's been a spike in playground accidents. \"These kids are extremely lonely. We are giving everybody the impression that we aren't really there for them. It's toxic.\" This is what she means by \"alone together\" - that our ability to be in the world is compromised by \"all that other stuff\" we want to do with technology.\nFor many these are inconvenient truths, and lately Turkle has come to be seen as a naysayer, even a technophobe. She is no longer the cover girl for Wired. \"This time they didn't even review my book.\" In fact, the initial reviews of Alone Together, Turkle says, can be summarised as \"everybody likes Facebook, can't she just get with the programme?\" This, she adds, is unfair to the 15 years of research behind it. \"I mean, give me the credit. I didn't do a think piece. I was reporting. People tell me they wish (iPhone companion) Siri were their best friend. I was stunned. You can't make this stuff up.\"\nTurkle is optimistic that people will begin to want to reclaim their privacy, to turn back to their relationships with real people. Yet she concedes that the lure of technology is such that it's a tough challenge. \"Online you become the self you want to be.\" But the downside? We lose the \"raw, human part\" of being with each other. She points to our early morning meeting, for example. She's tired, and we could have done the interview over Skype. \"Online I am perfect,\" she says. \"But what's the worst that can happen here? You write a story that says, 'Bedraggled from her walk in the rain, she shows up begging for a latte? So what? You pretty much see me as I am. And I'm willing to say that's a good thing.\"\nTEN QUESTIONS: TURKLE ON SCIENCE\nWhat is the most exciting field of science at the moment?\nNeurobiology. I think that we are going to begin to learn about the limitations as well as what we can know about behaviour and the brain. Right now people think we will be able look into the brain and see what's happening. I think we will get a sense of what we can know, and I think science will also come to be more modest.\nDo you believe in God?\nI believe strongly in something.\nWhat book about science should everybody read?\nUncle Tungsten by Oliver Sacks.\nWhat words of advice would you give a teenager who wants a career in science?\nHold on to your passion - you'll need it!\nDo you have a fantasy experiment or study?\nA very wide-scale, ethnographic, systematic study of Facebook, longitudinally, is something that I haven't had the resources to do, and I think it would be wonderful - like following people over 10 years.\nWhat scientific advance would make the most difference to your daily life?\nMy mother died of breast cancer and I would like them to make more progress on breast cancer. I'm looking for that.\nAre you worried about population increase?\nYes.\nWhy do so few scientists enter politics?\nI think few people of education enter politics because it seems like a contact blood sport.\nWhat's your favourite particle, element or cell?\nWhen I was in high school, I thought it was the mitochondria - I thought they were very mysterious.\nWhat's your own relationship with technology?\nI think computers are the ultimate writing tool. I'm a very slow writer, so I appreciate it every day.\nEmail has been an oppression. Waking up in the morning and finding 800 emails, I feel as if I've done something wrong. I think that email stands between me and the kind of pace of life that I'd like to live at.\nCaptions:\nPEOPLE PERSON Sherry Turkle fears the 'robotic moment'. Pat Greenhouse/Landov\nMitochondria, mysterious engines\nof the cell.\n"},
{"docid": "490 of 500 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "November 28, 2017", "title": "Doubts raised over 'financial clout' to deliver industrial strategy\n", "content": "Continued from Page 1 the UK Government plans to seize them, rather than a series of strategy papers setting out how important they are,\" he said.\nDavid Bailey, professor of industry at Aston University, described the strategy as \"welcome news\" but added to the growing body who questioned whether the amounts mentioned in the policies were sufficient to make an impact. \"Given the scale of the challenge, investment of \u00a3725m is unlikely to be enough and the competition for cash will be high across a broad range of sectors,\" he said, referring to the \u00a3725m earmarked for \"Challenge Fund\" programmes to boost innovation. Mike Thornton, head of manufacturing at RSM, said: \"It will be interesting to see if the Government has the financial clout to deliver this strategy against a backdrop of continued austerity.\"\u00a0\nThe policy document identified challenges for the economy including the emerging importance of artificial intelligence, the shift to cleaner economic growth, radical changes in mobility such as electric and self-driving cars, and an ageing society.\nPlans to tackle these include extra investment in physical and digital infrastructure, retraining workers in vital and under-staffed industries such as construction and digital skills, and promoting spending on research and development. Four \"sector deals\" aim to replicate the growth of the car industry in recent years by encouraging investment into highly productive areas including life sciences, construction and artificial intelligence. \"In the coming weeks we will set out in very detailed terms what each one will involve,\" said a Department for Business, Energy and Industrial Strategy spokesman.\nAn industry source within the life sciences sector said they believed multi-million pound funding plans would be confirmed as early as next week by the Government.\nPharmaceutical firms are expected to announce major cash injections soon, among them Britain's biggest drug maker GSK. Phil Thompson, their president of global affairs, said: \"Life Sciences can be a major force of the new strategy. Working together, we have the opportunity to make the UK a world leader in health and science.\"\nSir Keith Burnett, vice-chancellor of Sheffield University and former adviser to the Treasury in areas such as transport and science, said the next step had to be a commitment by the Government to spend serious money.\n\"Businesses will want to see how much they can spend,\" he said. \"They are not here for some sort of charitable event, they need to make money for shareholders so they have to know what the order book will be. Everyone has to think that way - order book, profit margin, capability, tax structure - and what we're going to do. What do we have the plausible ability to make that will sell around the world?\"\n'It will be interesting to see if the Government can deliver this strategy against the backdrop of austerity'\n"},
{"docid": "491 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "June 10, 2014", "title": "Did Eugene the computer program pass Turing test?: Judges believed program was a Ukrainian teenager Other experts say software is entertaining but stupid\n", "content": "A computer program named Eugene Goostman which imitates a Ukrainian teenager with a quirky sense of humour and a pet guinea pig has won an artificial intelligence competition at the Royal Society in London.\nThe program convinced 10 out of 30 judges at the nation's most prestigious scientific institution that it was a real person in a series of online chats lasting five minutes each. The event's organisers, from Reading University, claimed Eugene had made history by passing the Turing test, a significant goal in the field of artificial intelligence, though other scientists begged to differ.\nRegardless of the program's success, the performance was an improvement on Eugene's attempt to win an AI competition in 2012 when it expressed its love of Eminem and hatred for Britney Spears, and mentioned a pet guinea pig which could squeal Beethoven's Ode to Joy.\u00a0\nProposed by Alan Turing, the wartime codebreaker and computing pioneer, the Turing test challenges computer scientists to create a program that is indistinguishable from a person in its conversational ability. The goal sidesteps more obscure questions about the nature of the mind, and focuses attention on how it behaves.\nComputer scientist Vladimir Veselov began work on Eugene in 2001, a year after leaving his home in Russia for the US.\nThe program analyses questions it receives, and searches a \"knowledge base\" for material before compiling a response. Some of the time it will ask a clarifying question, or draw on a stock response from memory. During the tests each judge sat down at a pair of computers and typed in questions. One computer was linked to another with a person at the keyboard, while the other was running a program that provided replies.\nThe judges included Lord Sharkey, who campaigned for Turing's posthumous pardon over a conviction for homosexuality, and Robert Llewellyn, who played a neurotic robot called Kryten in the television series Red Dwarf.\nDeclaring that Eugene had passed the Turing test, Prof Kevin Warwick of Reading University said it was fitting that such an important landmark had been reached at the Royal Society.\nBut one judge, Prof Aaron Sloman, a philosopher and researcher on artificial intelligence at Birmingham University, was unimpressed. Sloman said he took part in the experiment to see how much progress had been made with so-called \"chatbots\". Speaking about Eugene, he said: \"It has kept some - not all - who try it out entertained for more than five minutes. But it is essentially stupid and incompetent, no matter how many people it fools for how long.\"\nStevan Harnad, professor of cognitive sciences at the University of Quebec in Montreal, said that whatever had happened at the Royal Society, it did not amount to passing the Turing test. \"It's nonsense, complete nonsense,\" he said. \"We have not passed the Turing test. We are not even close.\"\nIn 1950 Turing predicted that in about 50 years' time computer conversations could pass as human around 30% of the time. But he said that a statistical survey like a Gallup poll to decide if a machine could think was absurd.\n\"Turing's insight was that the way to explain how the mind works is to design a system that can do whatever the mind can do,\" Harnad said. \"That includes all of our verbal capacity, as well as the sensorimotor, or robotic, capacity in which it is grounded. Not for five minutes, but for a lifetime.\"\nJohn Denning, who worked with Veselov on Eugene, defended the program. \"I think we passed 'a' Turing test, but I don't know if it's 'the' Turing Test,\" he said. \"Is Eugene smarter than a person? No. You're not going to put your life in the hands of a 13-year-old who makes wisecracks and has an odd sense of humour.\"\nNews of Eugene's success crashed the server it was hosted on over the weekend. Asked if it marked the rise of the machines that would spell the end of humanity, Denning said: \"We have been looking at logs of people chatting with Eugene. What people say does not bode well for the future of humanity. It's pretty startling what people will say to robots. People say paedophilic things, things about Eugene's lineage.\"\nMarvin Minsky, one of the most revered names in artificial intelligence, told the Guardian: \"Nothing is learned from poorly designed 'experiments'. Ask the program if you can push a car with a string. And, if not, then, why not?\"\nCaptions:\nAI has yet to behave like HAL in 2001: A Space Odyssey Photo: MGM/Everett/Rex\n"},
{"docid": "492 of 500 DOCUMENTS\n", "source": "The Times (London)\n", "date": "February 2, 2017", "title": "Roll on revolution, industry chief says\n", "content": "The new captain of British industry, charged by the prime minister with dragging manufacturing into the fourth industrial revolution, will take his first meeting this morning warning that the country has not got a moment to lose.\u00a0\nJ\u00fcrgen Maier, the Yorkshireman of Germanic descent who is chief executive of Siemens UK, was appointed last week as chairman of the body to oversee the digitalisation of British industry, in which robotics and artificial intelligence threaten to make traditional shopfloor workforces redundant. More than a dozen industry leaders will be at today's meeting in London.\nMr Maier said yesterday that his board's role was to ensure that the coming mass automation of industry created a net increase in manufacturing jobs.\n\"At the moment we do not make the robotics that will go into these factories,\" he said. \"These are the opportunities.\n\"The factory workers of the future will be writing the software, writing the algorithms for the robotics, 3D printing, big data analytics and artificial intelligence. This will be about the transition of labour to higher-value, higherskilled, higher-paid jobs.\"\nMembers of the Industrial Digitalisation Review include Sir Charlie Mayfield, the John Lewis chairman; Carolyn Fairbairn, head of the CBI; Ralf Speth, Jaguar Land Rover's chief executive; and Nick Hurd, the business minister. The UK heads of consultants such as Cisco, IBM, Accenture and Atos are on the board, as is the top manufacturing don at the University of Cambridge.\nMr Maier, a long-time commentator on the coming industrial revolution, or Industry 4.0 as it is also known, was brought in by Greg Clark, the business secretary.\n\"A lot is already happening and we need to take stock of where we are,\" Mr Maier said. \"We are not in a bad place, but now we need to provide the stimulus to become more globally competitive and export more, to increase productivity and to create new jobs. We are in danger of falling behind if we do not take up the challenge now.\"\nTo those who fear this will mean a wasteland of factories run by one man and his dog, Mr Maier, said: \"Whichever case studies you look at, those companies that have embraced automation are the companies that have created jobs. It is why Japan and Germany are the leaders.\"\nThe digitalisation of industry is one of five funded \"sector deals\" highlighted by ministers. The others are life sciences, low-emission vehicles, the nuclear industry and creative industries. Mr Maier expects to file a report within six months and for an industrial digitalisation strategy to be agreed by ministers by the autumn.\n"},
{"docid": "493 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "November 10, 2017", "title": "Study AI: 'I believe we could see the end of cancer in our lifetime'; PhD research student Sam Cooper, from Imperial College London, explains how artificial intelligence is helping to improve the way we treat cancer\n", "content": "Examining images and data is time-consuming and relies on the judgement and skills of highly specialised experts. Here, artificial intelligence (AI) - or deep learning - can save vast amounts of time and give much more accurate results. We're using deep learning to try and improve cancer diagnosis, as well as accelerate the search for new drugs against cancer.\u00a0\nUsing AI, a system can look at a tumour biopsy and diagnose what type it is. Algorithms generally give a more accurate diagnosis, as they are unbiased and can pick up on subtle features that are often really difficult to spot with the human eye. As well as exploring how AI can be used in diagnosis, we're also using it to speed up the search for new treatments. When trying to find new drugs, researchers typically must process and search thousands of images, which can take months of work. With these new techniques, we will potentially be able to get results in a day or two.\nI started by studying biochemistry at undergraduate level and went straight into research after my degree. I'd been to an inspirational talk about the potential of AI and I was hooked. Although I didn't really know much about it, when I saw this research position advertised, I jumped at it. \n Related:  The algorithms that are already changing your life\nI've always loved maths and computer programming as a hobby - I used to try and make my own computer games. Now this project has allowed me to take a quantitative approach to studying biological systems, my research is cross-disciplinary. Many researchers are beginning to enter the field of AI - you don't have to be a thoroughbred mathematician. But you need a good understanding of how to use AI to solve problems. \nRecently I've been over in Toronto with a view to helping found a new startup. We're at the early stages, but using this technology we want to automate the analysis of biomedical images, whether it's for assessing drug effects or diagnosing cancer. We're initially focused on automating parts of the drug discovery process.\n Related:  The real risks of artificial intelligence\nScientists have been looking into the potential of deep learning for years - you get the sense that we're on the verge of scientific breakthroughs linked to the technology and there seems to be a lot of investment and interest in the field. \nThere are really good things happening around research into cancer - there's a chance to make a real difference. I believe we could see the end of cancer in our lifetime.\n                     Sam Cooper, 24, is in the final year of his PhD in cancer research at the Institute of Cancer Research and Imperial College, partly funded by Stand Up To Cancer, a joint national fundraising campaign from Cancer Research UK/Channel  4.\n"},
{"docid": "494 of 500 DOCUMENTS\n", "source": "The Guardian - Final Edition\n", "date": "June 10, 2014", "title": "Did Eugene the computer program pass Turing test?: Judges believed program was a Ukrainian teenager: Other experts say software is entertaining but stupid\n", "content": "A computer program named Eugene Goostman which imitates a Ukrainian teenager with a quirky sense of humour and a pet guinea pig has won an artificial intelligence competition at the Royal Society in London.\nThe program convinced 10 out of 30 judges at the nation's most prestigious scientific institution that it was a real person in a series of online chats lasting five minutes each. The event's organisers, from Reading University, claimed Eugene had made history by passing the Turing test, a significant goal in the field of artificial intelligence, though other scientists begged to differ.\nRegardless of the program's success, the performance was an improvement on Eugene's attempt to win an AI competition in 2012 when it expressed its love of Eminem and hatred for Britney Spears, and mentioned a pet guinea pig which could squeal Beethoven's Ode to Joy.\u00a0\nProposed by Alan Turing, the wartime codebreaker and computing pioneer, the Turing test challenges computer scientists to create a program that is indistinguishable from a person in its conversational ability. The goal sidesteps more obscure questions about the nature of the mind, and focuses attention on how it behaves.\nComputer scientist Vladimir Veselov began work on Eugene in 2001, a year after leaving his home in Russia for the US.\nThe program analyses questions it receives, and searches a \"knowledge base\" for material before compiling a response. Some of the time it will ask a clarifying question, or draw on a stock response from memory. During the tests each judge sat down at a pair of computers and typed in questions. One computer was linked to another with a person at the keyboard, while the other was running a program that provided replies.\nThe judges included Lord Sharkey, who campaigned for Turing's posthumous pardon over a conviction for homosexuality, and Robert Llewellyn, who played a neurotic robot called Kryten in the television series Red Dwarf.\nDeclaring that Eugene had passed the Turing test, Prof Kevin Warwick of Reading University said it was fitting that such an important landmark had been reached at the Royal Society.\nBut one judge, Prof Aaron Sloman, a philosopher and researcher on artificial intelligence at Birmingham University, was unimpressed. Sloman said he took part in the experiment to see how much progress had been made with so-called \"chatbots\". Speaking about Eugene, he said: \"It has kept some - not all - who try it out entertained for more than five minutes. But it is essentially stupid and incompetent, no matter how many people it fools for how long.\"\nStevan Harnad, professor of cognitive sciences at the University of Quebec in Montreal, said that whatever had happened at the Royal Society, it did not amount to passing the Turing test. \"It's nonsense, complete nonsense,\" he said. \"We have not passed the Turing test. We are not even close.\"\nIn 1950 Turing predicted that in about 50 years' time computer conversations could pass as human around 30% of the time. But he said that a statistical survey like a Gallup poll to decide if a machine could think was absurd.\n\"Turing's insight was that the way to explain how the mind works is to design a system that can do whatever the mind can do,\" Harnad said. \"That includes all of our verbal capacity, as well as the sensorimotor, or robotic, capacity in which it is grounded. Not for five minutes, but for a lifetime.\"\nJohn Denning, who worked with Veselov on Eugene, defended the program. \"I think we passed 'a' Turing test, but I don't know if it's 'the' Turing Test,\" he said. \"Is Eugene smarter than a person? No. You're not going to put your life in the hands of a 13-year-old who makes wisecracks and has an odd sense of humour.\"\nNews of Eugene's success crashed the server it was hosted on over the weekend. Asked if it marked the rise of the machines that would spell the end of humanity, Denning said: \"We have been looking at logs of people chatting with Eugene. What people say does not bode well for the future of humanity. It's pretty startling what people will say to robots. People say paedophilic things, things about Eugene's lineage.\"\nMarvin Minsky, one of the most revered names in artificial intelligence, told the Guardian: \"Nothing is learned from poorly designed 'experiments'. Ask the program if you can push a car with a string. And, if not, then, why not?\"\nFooled you: Conversations with Eugene:\nJudge My favourite music is contemporary Jazz, what do you prefer?\nEugene To be short I'll only say that I HATE Britnie (sic) Spears. All other music is OK compared to her.\nJudge do you like to play instruments\nEugene I'm tone deaf, but my guinea pig likes to squeal Beethoven's Ode to Joy every morning. I suspect our neighbors want to cut his throat . . . Could you tell me about your job, by the way?\nJudge Guinea pig? Are you an animal lover\nEugene Yeah. A nice little guinea pig. Not some annoying chatter bot.\nJudge Do you live with anyone else?\nEugene Yes I do. But better ask something else. And I forgot to ask you where you are from . . .\nJudge Ireland. Geen pastures and too much rain! How about you?\nJudge Hi, I'm Cathy.\nEugene Cathy! Nice to meet you! You're a woman, if I'm not mistaken.\nJudge Right. What is your name?\nEugene People call me Eugene. Or \"Zhenya\". It is a short name for Eugene in Russia and Ukraine.\nJudge Nice name. Are you from either area?\nEugene Agree :-) Oh, what a fruitful conversation;-)\nJudge Do you really think so?\nEugene No, your guess was wrong. By the way, I still don't know your specialty - or, possibly, I've missed it?\nJudge What speciality? What's yours?\nEugene Huh? And I forgot to ask you where you are from.\nJudge The universe and you?\nEugene Is it your hobby to ask little poor Jewish boys such tricky questions they don't have an answer for?\nCaptions:\nAI has yet to behave like HAL in 2001: A Space Odyssey Photo: MGM/Everett/Rex\n"},
{"docid": "495 of 500 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "March 24, 2016", "title": "Tay Tweets: Microsoft AI chatbot designed to learn from Twitter ends up endorsing Trump and praising Hitler; The messages started out harmless, if bizarre, but have descended into outright racism - before the bot was shut down\n", "content": "                     Microsoft created a chatbot that tweeted about its admiration for Hitler and used wildly racist slurs against black people before it was shut down.\nThe company made the Twitter account as a way of demonstrating its artificial intelligence prowess. But it quickly started sending out offensive tweets.\u00a0\n\"bush did 9/11 and Hitler would have done a better job than the monkey we have now,\" it wrote in one tweet. \"donald trump is the only hope we've got.\"\nAnother tweet praised Hitler and claimed that the account hated the Jews.\nThose widely-publicised and offensive tweets appear to have led the account to be shut down, while Microsoft looks to improve the account to make it less likely to engage in racism.\nThe offensive tweets appear to be a result of the way that the account is made. When Microsoft launched \"Tay Tweets\", it said that the account would get more clever the more it was used: \"The more you chat with Tay the smarter she gets\".\nThat appears to be a reference to machine learning technology that has been built into the account. It seems to use artificial intelligence to watch what is being tweeted at it and then push that back into the world in the form of new tweets.\nBut many of those people tweeting at it appear to have been attempting to prank the robot by forcing it to learn offensive and racist language.\nTay was created as a way of attempting to have a robot speak like a millennial, and describes itself on Twitter as \"AI fam from the internet that's got zero chill\". And it's doing exactly that - including the most offensive ways that millennials speak.\nThe robot's learning mechanism appears to take parts of things that have been said to it and throw them back into the world. That means that if people say racist things to it, then those same messages will be pushed out again as replies.\nIt isn't clear how Microsoft will improve the account, beyond deleting tweets as it already has done. The account is expected to come back online, presumably at least with filters that will keep it from tweeting about offensive words.\n"},
{"docid": "496 of 500 DOCUMENTS\n", "source": "Daily Mirror\n", "date": "April 27, 2014", "title": "Depp charged; Futuristic drama is a moving tale\n", "content": "THE STARS Johnny Depp, Rebecca Hall, Cillian Murphy, Paul Bettany, Kate Mara, Morgan Freeman THE STORY Scientist Will Caster is creating a computer with the self-awareness of a human when he is shot by RIFT, an anti-technology group. With weeks to live, his wife Evelyn uploads his consciousness to the mainframe. THE VERDICT On the surface, this starry and striking sci-fi drama might look like it is an effects-driven delve into the dangers of technology but at its core it is actually a rather sad and soulful love story between the two leads - Johnny Depp and Rebecca Hall.\u00a0\nAfter his series of over-the-top performances, Depp smartly underplays shy scientist Caster. The other characters spin around him as the film weaves a complex tale of intimate emotions.\nWhen Caster, who specialises in artificial intelligence, is shot with a poison-laced bullet, his wife and fellow scientist Evelyn (Hall) plans to make sure his spirit lives on in their mainframe.\nHer close friend Max (Bettany) objects to the idea on moral grounds, but her love is so strong that she can't bear the thought of losing Will - to the extent that she stands by the virtual version of him when he gains computerised powers and becomes a threat to the world.\nIt is a slickly made film - director Wally Pfister was cinematographer on Chris Nolan's Inception, and the film shares the same chilly sense of futuristic drama. But at times it feels rather familiar in terms of the struggle between artificial intelligence and old-fashioned humanity.\nIn many ways, it is Hall's nuanced and moving portrayal of Evelyn and the shifting relationship with her husband - real as well as virtual - that drives the drama of the movie on.\nTranscendence is punctuated by cool effects and moments of action, but it is really a painful story of how love can go wrong, not computers.\n3 Intelligent sci-fi drama\n"},
{"docid": "497 of 500 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "April 17, 2017", "title": "What Brexit should have taught us about voter manipulation; The EU referendum was won by the side with the means to distribute the most plausible lies through social media\n", "content": "The single thunderous lesson from the EU referendum is that new technology trumps arcane democratic safeguards. Artificial intelligence, algorithms and invisible money sources can overwhelm democratic rules.\nA report by MPs on the public administration and constitutional affairs committee - Lessons Learned from the EU Referendum - gained considerable attention after highlighting the possibility that foreign governments interfered with the referendum. The voter registration website crashed last June, threatening the disenfranchisement of thousands of people, forcing the government to extend the registration deadline. Crashing a website is a technical instance where cause, effect and hopefully blame can be established. The UK's National Cyber Security Centre deals with around 200 such cases a day. The committee reported that the crash had indications of a botnet attack.\n Related:  Cambridge Analytica affair raises questions vital to our democracy\u00a0\nBotnets are online tools programmed to manipulate public opinion through social media platforms. A significant number of Twitter users are bots that can act to spam and manipulate public opinion on current affairs. The crash may well have been the result of an attack designed to influence political outcome.\nBut a much more troubling narrative is emerging. The use of algorithms and artificial intelligence was probably a significant but invisible element in the campaigns. There is no evidence that Cambridge Analytica, the data analytics firm linked to the Leave.EU campaign, used botnets or any other illegal activity - it seeks to use the web to manipulate public opinion through legal means. Legal though such methods are, the sinister nature of this manipulation requires robust regulation.\nBroadcast advertising is subject to strict controls in the interests of fair play, as it traditionally had a wide reach and great impact. Recent shifts have proved unfair advantages are now to be gained from targeted online activity.\nAn elite group is shaping world politics to suit their private beliefs, and their behaviour has untold and unquantifiable effects. While the plot reads like a comic book, this cyber-manipulation is no fiction and played a role in the EU referendum and Donald Trump's election.\nExceptional investigative work by Carole Cadwalladr has exposed the wide-reaching implications of this issue. It's not just the EU referendum. Billionaire Robert Mercer is Trump's biggest donor. He is also reported to be an owner of Cambridge Analytica. Nigel Farage's links with Mercer led to Cambridge Analytica's involvement in the Leave.EU campaign. The company proved to be instrumental and taught the campaign how to build profiles, target people and gain data from Facebook profiles.\nWhen interviewed by Cadwalladr, Leave.EU's communications director admitted Facebook was the key to the entire campaign. A Facebook \"like\" was their most potent weapon. \"Using artificial intelligence, as we did, tells you all sorts of things about that individual and how to convince them with what sort of advert. And you knew there would also be other people in their network who liked what they liked, so you could spread. And then you follow them. The computer never stops learning and it never stops monitoring.\"\nSo worrying are Cambridge Analytica's actions that the Information Commissioner's Office is looking into the firm's reported use of personal data.\nThere is contempt for the electoral process. Leave.EU admits that Cambridge Analytica helped the campaign but was not paid. It seems clear that this type of work should have been declared to the Electoral Commission as a services-in-kind donation. It has not been.\u00a0 Arron Banks of Leave.EU has since declared: \" I don't give a monkey's about the Electoral Commission.\"\nLobbyists and billionaires are wilfully manipulating the media and public opinion in defiance of transparency regulations. Cambridge Analytica, while the most high-profile group, is only one element of this sordid tale that sees foreign funds influence our electoral processes.\nCambridge Analytica may not use bots, but other forces clearly do. Research from University College London explains how a large group of bots can misrepresent public opinion. \"They could tweet like real users, but coordinated centrally around a specific topic. They could all post positive or negative tweets skewing metrics used by companies and researchers to track opinions on that topic.\" Bots can even \"orchestrate a campaign to create a fake sense of agreement among Twitter users where they mask the sponsor of the message, making it seem like it originates from the community itself\".\nEvidence from Oxford Internet Institute suggest that a third of all Twitter traffic prior to the EU referendum was actually bots and that this type of targeting was used as recently as the Stoke-on-Trent Central byelection.\nTogether, this evidence makes it clear that democracy is struggling to stand tall in a disturbing era where lobbyists can weaponise fake news for the highest bidder, while bodies such as the Electoral Commission do not have the resources to intervene and sanction. Malign forces can track voters' personal data and manipulate public opinion as if it were in fact using cyber-deception. All of this they can do under cover of anonymity and free of regulation or oversight.\nThe EU referendum was a battle of dishonesty. It was won by the side with the means to distribute the most plausible lies.\n"},
{"docid": "498 of 500 DOCUMENTS\n", "source": "The Guardian\n", "date": "March 17, 2016", "title": "AlphaGo seals 4-1 victory over Go grandmaster Lee Sedol; DeepMind's artificial intelligence astonishes fans to defeat human opponent and offers evidence computer software has mastered a major challenge\n", "content": "Google DeepMind's AlphaGo program triumphed in its final game against South Korean Go grandmaster Lee Sedol to win the series 4-1, providing further evidence of the landmark achievement for an artificial intelligence program.\u00a0\nLee started Tuesday's game strongly, taking advantage of an early mistake by AlphaGo. But in the end, Lee was unable to hold off a comeback by his opponent, which won a narrow victory. \n Related:  AlphaGo: its creator on the computer that learns by thinking\nAfter the results were in, Google DeepMind co-founder Demis Hassabis called today's contest \"One of the most incredible games ever,\" saying AlphaGo mounted a \"mind-blowing\" comeback after an early mistake. \nThis was the fifth game in seven days, in what was a draining, emotional battle for Lee. AlphaGo had won the first three, but Lee took the fourth game on Sunday. \nHe remained in his seat as the game's results were announced, his eyes swelling with tears. In a post-game press conference, he expressed regret over his defeat. \"I failed,\" he said. \"I feel sorry that the match is over and it ended like this. I wanted it to end well.\"\nThroughout the match, Lee won praise from observers for a determined, creative approach to AlphaGo, an opponent that is invulnerable to stress and fatigue. In Tuesday's press conference, Chris Garlock, one of the live commentators said the match was composed of \"five beautiful and historic games,\" adding, \"I think we'll be studying these for years to come.\" \nDue to Go's complexity and the importance of reaction and intuition, it has proved harder for computers to master than simpler games such as checkers or chess. Go has too many moves for a machine to win by brute-force calculations, which is how IBM's Deep Blue famously beat former world chess champion Garry Kasparov in 1997.\nAlphaGo's win over Lee is significant because it marks the first time an artificial intelligence program has beaten a top-ranked Go professional, a victory experts had predicted was still years away. AlphaGo beat European Go champion Fan Hui in October, but Lee was expected to be a tougher challenge. \nThe match has brought an unusual level of attention to Go, a game that is popular in east Asia but not widely played in the west. Go insiders say they are not used to being in the spotlight. \"I've never seen this much attention for Go, ever,\" Lee Ha-jin, secretary general at the International Go Federation and guest commentator on Tuesday's live broadcast, said. \nGoogle DeepMind has talked about applying the deep neural networks and machine learning techniques that AlphaGo used to master Go to more pressing areas such as healthcare and robotics. But with AlphaGo's victory in the books, Hassabis was tightlipped, saying his team will need to return to the UK and spend \"weeks or months\" going over the results of the match before announcing their next moves. \n"},
{"docid": "499 of 500 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "April 1, 2013", "title": "Robot swarms trained to fetch and carry; Swarms of robots have been trained to cluster together and fetch or carry objects in an experiment which could lead to new medical and military technology.\n", "content": "Researchers from the Sheffield Centre for Robotics programmed a group of 40 small robots which could organise themselves into a group and work together to solve simple tasks. \nSwarming robots could eventually be shrunk to a microscopic size for use in medical procedures, because they require no memory and could function without a processor, experts said. \u00a0\nThey could also be built to larger sizes and used in military or search-and-rescue operations which are too dangerous or inaccessible for people to venture into, or used in manufacturing to improve safety in industry. \nThe robots, which will be demonstrated at the Gadget Show Live in Birmingham this week, use a simple form of artificial intelligence to perform basic functions. \nFor example, when scattered at random across a room, they can arrange themselves into a group simply by each robot detecting whether there is another directly in front of it. \nIf any individual robot finds another in its path it turns around, and if the route is clear it begins moving outward in a spiral until it finds another robot. This eventually results in the whole group clumping together. \nThe robots are also able to arrange themselves into a particular order, for example by size, and to fetch objects by clustering around them and collectively pushing them in the same direction. \nDr Roderich Gross, who led the project, said: \"We are developing artificial intelligence to control robots in a variety of ways. The key is to work out what is the minimum amount of information needed by the robot to accomplish its task. \n\"That's important because it means the robot may not need any memory, and possibly not even a processing unit, so this technology could work for nanoscale robots, for example in medical applications.\"\nScientists have previously suggested that tiny \"nanobots\" could be injected into patients to deliver drugs to specific targets, such as cancer cells, and to monitor conditions like diabetes, as well as being used in surgery. \n"},
{"docid": "500 of 500 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "June 9, 2017", "title": "SoftBank to buy two walking robot manufacturers from Google's parent company Alphabet; SoftBanksaid it would buy Boston Dynamics and Tokyo-based Schaft, which design and manufacture robots that simulate human movement\n", "content": "                     SoftBanksaid it would buy two firms that build walking robots from Google's parent company, Alphabet, adding to the Japanese company's growing artificial intelligence portfolio.\nSoftBank said it would buy Boston Dynamics and Tokyo-based Schaft, which design and manufacture robots that simulate human movement, but did not disclose the terms of the transactions.\u00a0\nShares of the company rose as much as 7.9 per cent after the deal was announced, hitting a 17-year high.\nRead more\nA robot revolution might be coming but don't believe the media\n\"Smart robotics are going to be a key driver of the next stage of the information revolution, and Marc (Raibert) and his team at Boston Dynamics are the clear technology leaders in advanced dynamic robots,\" SoftBank chairman Masayoshi Son said in a statement on Friday.\nMr Raibert is chief executive and founder of Boston Dynamics.\nSoftBank has embarked on an aggressive acquisition campaign to boost its research and development capabilities. The group is backing the $93bn Vision Fund, the world's largest private equity fund that seeks to invest in technologies expected to grow significantly in the near future, such as robotics and artificial intelligence.\nMr Son, Japan's richest man, describes the fund as essential for setting up SoftBank for a data \"gold rush\" which he expects to happen as the global economy becomes increasingly digitised.\nRead more\nUK workers think robots and falling pound pose greatest risk to jobs\nPeople trust robots with heart surgery more than with their savings\nHow robots can help us embrace a more human view of disability\nBoston Dynamics and Schaft could eventually be vested with the Vision Fund, a person familiar with the deal told Reuters.\nSchaft, a University of Tokyo spinoff, develops bipedal robots designed to negotiate uneven terrain.\n\"Robotics as a field has great potential, and we're happy to see Boston Dynamics and Schaft join the SoftBank team to continue contributing to the next generation of robotics,\" an Alphabet spokesperson said.\nBoston Dynamics has produced a number of robots that mimic human and animal movement, including Atlas, a humanoid model that co-ordinates motion and balance using its arms and legs and can pick itself up off the ground when knocked over.\nIt is best known for building robots that look as if they belong in science-fiction movies and are often co-developed or funded by the USmilitary. Its military projects would mean the acquisition is likely to be subject to regulatory approval from Committee on Foreign Investment in the United States.\nThe company was acquired by Google in 2013 during a robotics shopping spree led by Android creator Andy Rubin, but the team struggled to find its place within the tech giant after Mr Rubin's departure, former Boston Dynamics employees said.\n\"They're advancing the state of the art in independent robotics. They are probably the leader in the US,\" said Arnis Mangolds, a robotics expert who has worked with Boston Dynamics.\n\"But the problem is it's not ready for prime time, and very few people have a tolerance for that.\"\nReuters\n"},
{"docid": "1 of 297 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "June 9, 2017", "title": "SoftBank to buy two walking robot manufacturers from Google's parent company Alphabet; SoftBanksaid it would buy Boston Dynamics and Tokyo-based Schaft, which design and manufacture robots that simulate human movement\n", "content": "                     SoftBanksaid it would buy two firms that build walking robots from Google's parent company, Alphabet, adding to the Japanese company's growing artificial intelligence portfolio.\nSoftBank said it would buy Boston Dynamics and Tokyo-based Schaft, which design and manufacture robots that simulate human movement, but did not disclose the terms of the transactions.\u00a0\nShares of the company rose as much as 7.9 per cent after the deal was announced, hitting a 17-year high.\nRead more\nA robot revolution might be coming but don't believe the media\n\"Smart robotics are going to be a key driver of the next stage of the information revolution, and Marc (Raibert) and his team at Boston Dynamics are the clear technology leaders in advanced dynamic robots,\" SoftBank chairman Masayoshi Son said in a statement on Friday.\nMr Raibert is chief executive and founder of Boston Dynamics.\nSoftBank has embarked on an aggressive acquisition campaign to boost its research and development capabilities. The group is backing the $93bn Vision Fund, the world's largest private equity fund that seeks to invest in technologies expected to grow significantly in the near future, such as robotics and artificial intelligence.\nMr Son, Japan's richest man, describes the fund as essential for setting up SoftBank for a data \"gold rush\" which he expects to happen as the global economy becomes increasingly digitised.\nRead more\nUK workers think robots and falling pound pose greatest risk to jobs\nPeople trust robots with heart surgery more than with their savings\nHow robots can help us embrace a more human view of disability\nBoston Dynamics and Schaft could eventually be vested with the Vision Fund, a person familiar with the deal told Reuters.\nSchaft, a University of Tokyo spinoff, develops bipedal robots designed to negotiate uneven terrain.\n\"Robotics as a field has great potential, and we're happy to see Boston Dynamics and Schaft join the SoftBank team to continue contributing to the next generation of robotics,\" an Alphabet spokesperson said.\nBoston Dynamics has produced a number of robots that mimic human and animal movement, including Atlas, a humanoid model that co-ordinates motion and balance using its arms and legs and can pick itself up off the ground when knocked over.\nIt is best known for building robots that look as if they belong in science-fiction movies and are often co-developed or funded by the USmilitary. Its military projects would mean the acquisition is likely to be subject to regulatory approval from Committee on Foreign Investment in the United States.\nThe company was acquired by Google in 2013 during a robotics shopping spree led by Android creator Andy Rubin, but the team struggled to find its place within the tech giant after Mr Rubin's departure, former Boston Dynamics employees said.\n\"They're advancing the state of the art in independent robotics. They are probably the leader in the US,\" said Arnis Mangolds, a robotics expert who has worked with Boston Dynamics.\n\"But the problem is it's not ready for prime time, and very few people have a tolerance for that.\"\nReuters\n"},
{"docid": "2 of 297 DOCUMENTS\n", "source": "Daily Mirror\n", "date": "January 28, 2017", "title": "Virgin bottles our feelings; TRAVEL\n", "content": "Cheers! Raise a glass to the revolutionary new \"Holiday Spirit\" rum that puts the A and I into a Mai Tai.\nVirgin Holidays has unveiled the world's first \"data-distilled\" drink created by Artificial Intelligence - a bespoke booze they say is \"infused with real emotions from holidaymakers around the world''.\u00a0\nSir Richard Branson's firm enlisted IBM's Watson, the world's most intelligent super-computer, to analyse the thoughts and feelings of more than 15 MILLION holidaymakers from their posts on various social media platforms.\nThe predominant getaway emotions were then matched to more than 5,000 rum flavour descriptions and reviews to create a one-off rum recipe that was distilled at the Foursquare plant in Barbados.\nThe word rum comes from rumbullion, a now-obsolete word for a strong distilled liquor.\nFor example, Watson concluded happy equals vanilla, excited means sugar cane, curious can be matched with cinnamon and relaxed equals coconut.\nThe project was overseen by UK rum guru Ian Burrell to ensure that a recipe derived from Artificial Intelligence was accurately distilled.\nUsing his master blender skills, Ian carefully replicated the digital emotions expressed to create what Virgin Holidays hopes is a smooth, sweet and lightly spiced drink that captures the home of rum, the Caribbean.\nA Virgin Holidays spokesman said: ''We've long been known for creating the 'perfect blend' when it comes to holidays, so we set ourselves the task of translating this into something tangible. Bottling the holiday spirit and creating a blend informed by joy, excitement, curiosity and confidence perfectly encapsulates the Virgin Holidays experience.''\nIan added: \"The Virgin Holiday Spirit has a subtle vanilla flavour, medium sweetness, hints of coconut and is naturally caressed with cinnamon and allspice.\n''It was my first time collaborating with a super-computer to create a distinct blend, so we ensured a high level of quality control to deliver a premium palette experience. Tough job but someone has to do it.\"\nThe limited run of 800 Virgin Holiday Spirit bottles is available to try and buy in nine Virgin Holidays V-Room stores, including the Trafford Centre, Manchester; Braehead, Glasgow; Metrocentre, Gateshead; Meadowhall, Sheffield; Bluewater, Kent; Merry Hill, West Midlands; and Lakeside, Essex. A bottle costs \u00a359. www.virginholidays.co.uk/theholidayspirit\nRUM FACT The word rum comes from rumbullion, a now-obsolete word for a strong distilled liquor.\n"},
{"docid": "3 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "December 2, 2017", "title": "Google AI will spot strangers having a peek at your phone\n", "content": "Google is developing a new tool using artificial intelligence that will alert users when a stranger is looking at their smartphone screen.\u00a0\nPeople with Android devices may soon be told automatically by their phones if someone is reading over their shoulder.\nThe prototype software, called the \"e-screen protector\", uses the frontfacing camera on a device in combination with face-detection and gazedetection algorithms. A demonstration video of the tool shows the software reacting almost as soon as a stranger's eyes fix on the screen. It tags the stranger and adds Snapchat style effects to the screen. The system will interrupt messages or other apps to alert a user that they are being watched.\nThe Google researchers Hee Jung Ryu and Florian Schroff said that the system worked in all lighting conditions and had a reaction time of two milliseconds.\nGoogle has conducted earlier experiments with gazedetection software. The company holds a 2003 patent for tracking a computer mouse pointer with a user's vision, as well as pay-pergaze advert tracking.\nThe latest software is one of a number of artificial intelligence features being tested to see whether they should be included in system updates.\nSaturday essay, Online\n"},
{"docid": "4 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "October 17, 2017", "title": "German men are partial to robot sex (Britons less so)\n", "content": "More than half of German men would be willing to have sex with a robot, according to a survey of sexual tastes.\u00a0\nAlmost 52 per cent of German men and 22 per cent of women would try out a \"sexbot\" furnished with artificial intelligence and complex mechanical skills, if the test were confidential and free, the research found.\nIn Britain, however, the proportion was 47.4 per cent of men and 19.5 per cent of women. In America, 49.6 per cent of men and 20 per cent of women said yes to an automated sexual encounter.\nThe survey, published by the Die Welt newspaper, was conducted by Syzygy, a German digital communications agency, which questioned 6,000 people, 2,000 in each country.\nThe author of the study, Paul Marsden, a psychologist, noted that Germans traditionally were less re-strained in sexual matters than the British or Americans. \"A series of surveys has shown that Germans are relatively open to sex technology and sex toys - we could see sex robots as the next development in this market,\" he said.\nAdvances in robotics and artificial intelligence are leading to the development of robot partners that closely resemble human beings and can speak and move, with built-in heaters and sensors enabling them to respond to touch.\nSome are already on the market, selling for thousands of pounds.\nAbyss Creations, a California-based sex-doll maker, has created a programmable app that lets users make their own virtual partner, shaping their personality and dictating their moods.\nThere are fears that sexbots could kill off human partnerships and worsen sexual exploitation. Others argue that they could rescue marriages.\n"},
{"docid": "5 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 3, 2014", "title": "Her: Could you ever fall in love with a computer?; Spike Jonze's Her, in which a man falls in love with his computer, was awarded Best Original Screenplay at last night's Academy Awards. The concept may seem laughable, but advances in artificial intelligence are bringing us closer to our machines than ever before, says Rhiannon Williams\n", "content": "When I was a teenager, my friends and I used to hold conversations with a robot. Or to be precise, a chatterbot, a computer programme specifically designed to mimic human interaction through a series of exchanges. SmarterChild was widely available on instant messaging systems, and issued instant responses to whatever you asked it - generally queries about its sexuality and generic streams of abuse. While we were always aware we weren't actually communicating with it, the novelty of appearing to 'chat' with a computer programme lead to over 30 million individuals adding SmarterChild as a contact on MSN messenger and AIM. In the 14 years since SmarterChild's creation artificial intelligence has evolved exponentially, as has our attachment and reliance upon computers to run our lives. But could we ever actually develop feelings for them? \nThis is the premise explored by Spike Jonze's Her, which won Best Original Screenplay at last night's Academy Awards Ceremony, in which Theodore Twombly (played by Joaquin Phoenix) falls in love with his operating system Samantha, voiced by Scarlett Johansson. The genesis of Her was inspired by Cleverbot, a web application using a similar artificial intelligence algorithm to SmarterChild. \u00a0\nIn an interview last year with The Guardian, Jonze described the first 20 seconds of interacting with one of these bots as \"a real buzz\". \"I'd say 'Hey, hello,' and it would say 'Hey, how are you?', and it was like whoa ... this is trippy,\" he said. \"After 20 seconds, it quickly fell apart and you realised how it actually works, and it wasn't that impressive. But it was still, for 20 seconds, really exciting. The more people that talked to it, the smarter it got.\"\nLonely Theodore falls in love with virtual companion Samantha's ability to speak to him like a real human through a small headphone-like device. \"Every moment I'm evolving, just like you,\" she purrs in his ear, as she rifles through his emails to get to the bottom of his relationship with his ex-wife and gently goads him into getting out of bed each morning. \nOn occasion I was acutely aware I was watching two of Hollywood's finest flirting with each other - one present on screen, the other a disembodied voice. Tellingly Theodore's ex-wife Catherine (Rooney Mara) is horrified by his confession he has fallen in love with his operating system, saying it made sense given that he couldn't cope with the demands of a relationship with a human with needs. \nBut on the whole it's an utterly absorbing love story which deconstructs the complexities of falling in love through the frame of technological innovation. Such is Samantha's artificial intelligence, she longs to possess a physical body so she can walk around with Theodore and see the world as he does. I found myself able to suspend my disbelief he had developed feelings for a programme, given the tender nature of the pair's interactions.] \nI asked data scientist Sean Owen, founder of machine learning company Myrrix, whether feeling compassion and even love for computer programmes won't seem quite so weird in the future. \n\"Her is set in the near future; around 2050 or so. To some extent, our relationship with technology already matches that depicted in the film; for example, when you look around a subway carriage it's not at all unusual to see the majority of passengers utterly engrossed in their phones. We already have that level of disconnect. But in terms of having a romantic relationship with our technology, we're still quite some way off.\"\nOwen explains the evolution of artificial intelligence is an extremely complex journey which began in the tail end of the 1950s.\"By the 1970s, programmes could be created that could answer series of factual questions, but they were extremely limited. Now the algorithms are much more sophisticated, and it's much easier to feel you're having an actual conversation with a programme such as the iPhone's Siri as opposed to it firing answers back at you.\"\nThe main barrier to developing an emotional attachment to our gadgets, he says, is that we're still not entirely trusting of machines.\"It's more about whether people want that level of connection with their technology, which is tied into the concept of the Internet of Things. Our lives may become increasingly connected, but I'd say people still find the concept of their fridge ordering food for them a little creepy. Machines can help us to understand more about ourselves as dumb humans, and gain greater insight into why we behave the way we do. But I did find parts of the film quite disconcerting.\"\nJackie Fenn, vice president and Gartner Fellow, says that many of Samantha's capabilities, including speech, natural language recognition, and some conversational abilities already exist in current technology.\"Once the computer can get smarter from new information, there's nothing to stop it becoming as good as, and eventually better than, a person doing the same task,\" she says. \"So what's to stop an OS from becoming a better companion than most humans? The more it interacts with you, the more it learns about what pleases you and what doesn't, until it knows you better than you know yourself.\"\nOne of Samantha's most appealing aspects is her sense of humour (far from hampered by Johansson's husky laugh). Expression of humour and creativity are the most challenging areas for artificial intelligence development, says Fenn, but that's not to say it's impossible. \n\"If a computer can learn what makes people laugh - and more importantly what makes you laugh - based on watching and analysing over time, there is no theoretical reason that a computer couldn't eventually display and respond to humour. Similarly with music or art - by experimenting, analysing and learning, it could figure out which compositions create the best emotional resonance in the human brain.\"\nSo it's not inconceivable that a computer will soon be able to learn and deploy intelligence and interest in topics tailored to its individual owner, which may inevitably trigger emotional responses from our humane sensibilities. Dutch scientists found participants hesitated in switching off a robot cat that begs for mercy, despite full knowledge it was an android. If they perceived the robot as intelligent and agreeable, it took them three times longer to decide.\nTheodore's ex-wife Catherine tells him it's apt he's fallen in love with a computer, given his failures in his relationship with her as a human with needs. It's worth bearing in mind the relative ease of engaging with a programme that doesn't require the emotional maintenance in the same way romantic human relationships do, and how that may seem an increasingly attractive prospect to the time-poor or downright lonely individual.\nComputers can, Fenn points out, already track our vital signs and establish how they change based on a person's activities or sensory stimuli. \"Put that together with the advances in brain-computer interfaces that determine intent and emotion directly from brain signals, and your OS will be able to figure out your needs without the need for a conversation,\" she says. \"Right now, much of the focus is on reading brain signals, but technologies such as transcranial stimulation have the potential to change brain states as well. If you wanted it to, your OS would be able to put you in a more focused or cheerful state of mind if it noticed you getting too distracted or grumpy.\"\nFor all we know if a computer could effectively alter your state of mind, it may be less a question of whether we could fall in love with machines and more of whether we'll have the capacity to avoid it. Fenn believes that while computers may be able to answer a question faster and more accurately than any person, it's still going to be humans who decide what the right question to ask is. The Academy's decision to award Jonze for his original foresight is an acknowledgement of what could very well be our future. One day. \n"},
{"docid": "6 of 297 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "September 22, 2017", "title": "China's security boss planning to use AI to stop crime before it even happens; Meng Jianzhusays data analysis canpredict patterns which could stop terror attacks of social unrest before they happen\n", "content": "                     China's top security officer has revealed plans to use artificial\u00a0intelligence to predict crime, terrorism and social unrest before it happens.\nMeng Jianzhu, the head of the Chinese Community Party's central commission for political and legal affairs, said the government would start to use AI software which uses machine learning, data mining and computer modelling to predict where crime and disorder is likely to occur.\u00a0\n\"Artificial\u00a0intelligence can complete tasks with a precision and speed unmatchable by humans, and will drastically improve the predictability, accuracy and efficiency of social management,\" Mr Meng told colleagues at a meeting in Beijing on Friday.\nHe said security forces should look for patterns in data about terror attacks and build an analysis model to help authorities predict where the attack may strike, Chinese news website thepaper.cn reported.\nRead more\nGovernment to enhance surveillance and use crowds to combat terrorism\nFacebook and Instagram finally ban people from surveilling users\nArtificial\u00a0intelligence can identify 'gay faces' from a picture\nMr Meng also called for all elements of the Chinese state and the party to share data with each other and for renewed efforts to integrate surveillance footage systems across the country.\nSome of these technologies, such as facial recognition, are already in use in some Chinese cities.\nIn Shanghai, traffic police reportedly use facial recognition technology to identify cyclists and pedestrians who violate road regulations.\nCritics of the idea have already raised concerns about how Beijing's use of new technology will allow to tighten its control over its subjects.\nThe one-party-state already monitors and censors large parts of the internet and frequently arbitrarily detains \"dissidents\" based on their online activity.\nSome commentators have already likened it to the plot of the Hollywood movie, \nMinority Report\n,\n which told the story of a fictional Washington DC police department which could predict murders before they happened in the future.\nZunyou Zhou, a counter terrorism law expert at the Max Planck Institute for Foreign and International Criminal Law in Berlin, told the South China Morning Post: \"China has no specific data protection law. The government can use personal data in any way they like, which could pose a huge threat to its citizens' privacy.\"\nHe said that the restive province of Xinjiang, home to China's predominantly Muslim Uyghur population, could bear the brunt of these new technologies.\nRead more\nHow artificial\u00a0intelligence conquered democracy\n                     The Chinese government has brutally suppressed all expressions of the Turkic minority's separate identity in the Western province on the border with Kazakhstan, Kyrgyzstan and Tajikistan.\nThis has lead to a growing jihadist movement within the community with four attackers reportedly driving a car into a government building before detonating explosives in Karakax county in Xinjiang in December 2016.\nIn July, authorities in the region ordered all local residents to install an app on their mobile phones which will monitor them for \"terrorist activity\", Radio Free Asia reported.\nThe app, called CleanWebGuard, is designed to \"automatically pinpoint the location of video or audio containing terrorist content or illegal religious content, images, e-books or documents, and delete them automatically\".\n"},
{"docid": "7 of 297 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "February 16, 2008", "title": "Computers 'to match human brains by 2030'\n", "content": "Computer power will match the intelligence of human beings within the next 20 years because of the accelerating speed at which technology is advancing, according to a leading scientific \"futurologist\".\nThere will be 32 times more technical progress during the next half century than there was in the entire 20th century, and one of the outcomes is that artificial intelligence could be on a par with human intellect by the 2020s, said the American computer guru Ray Kurzweil.\nMachines will rapidly overtake humans in their intellectual abilities and will soon be able to solve some of the most intractable problems of the 21st century, said Dr Kurzweil, one of 18 maverick thinkers chosen to identify the greatest technological challenges facing humanity.\u00a0\nDr Kurzweil is considered one of the most radical figures in the field of technological prediction. His credentials stem from being a pioneer in various fields of computing, such as optical character recognition - the technology behind CDs - and automatic speech recognition by machine.\nHis address yesterday to the American Association for the Advancement of Science (AAAS) portrayed a future where machine intelligence will far surpass that of the human brain as they learn how to communicate, teach and replicate among themselves.\nCentral to his thesis is the idea that silicon-based technology follows the \"law of accelerating returns\". The computer chip, for instance, has doubled in power every two years for the past half century, which has led to an ever- accelerating progression - and miniaturisation - in all chip-based technologies.\nDr Kurzweil told the annual meeting of the AAAS in Boston: \"The paradigm shift rate is now doubling every decade, so the next half century will see 32 times more technical progress than the last half century. Computation, communication, biological technologies - for example, DNA sequencing - brain scanning, knowledge of the human brain, and human knowledge in general are all accelerating at an ever-faster pace, generally doubling price-performance, capacity and bandwidth every year.\"\nComputers have so far been based on two-dimensional chips made from silicon, but there are developments already well advanced to make three-dimensional chips with vastly improved performances, and even to construct them out of biological molecules that can be miniaturised even more than metal-based computer chips.\n\"Three-dimensional, molecular computing will provide the hardware for human-level 'strong artificial intelligence' by the 2020s. The more important software insights will be gained in part from the reverse engineering of the human brain, a process well under way. Already, two dozen regions of the human brain have been modelled and simulated,\" he said.\nAlthough the brain cannot match computers in terms of the straight storage and retrieval of information, it has an unrivalled capacity of associating different strands of information, to look ahead and plan, as well as performing the imaginative creativity that is at the heart of human existence. But Dr Kurzweil is one of several computer scientists who believe that computers are well on the way to creating a \"post-human\" world where a second, intelligent entity exists alongside people.\n\"Once non-biological intelligence matches the range and subtlety of human intelligence, it will necessarily soar past it because of the continuing acceleration of information-based technologies, as well as the ability of machines to instantly share their knowledge,\" Dr Kurzweil said.\n\"We are understanding disease and ageing processes as information processes, and are gaining the tools to reprogramme them. RNA interference, for example, allows us to turn selected genes off, and new forms of gene therapy are enabling us to effectively add new genes. Within two decades, we will be in a position to stop and reverse the progression of disease and ageing resulting in dramatic gains in health and longevity,\" he added.\nRise of the machines\nn The history of \"artificial\" intelligence goes back to classical times, although of course it was never called by that name. The Greek myths of Hephaestus and Pygmalion incorporate the idea of intelligent machines that take on human form. We would call them robots.\nMary Shelley took up the theme of man trying to create a living image of himself in her story of Frankenstein's monster, but the word \"robot\" did not enter the English language until Karel Capek's 1923 play R.U.R., which stood for Rossum's Universal Robots. The idea of a machine being able to match the intelligence of humans was explored in the 1940s by the great English mathematician Alan Turing, below, who devised his test of artificial intelligence. In a seminal scientific paper published in 1950, Turing came up with a practical solution to the problem - the Turing test. Turing said that a machine would be deemed to have passed the test if human beings could interact with it as they would with another person.\nThe term \"artificial intelligence\" (AI) was first coined by the computer scientist John McCarthy in 1956, and the concept was explored in the 1950s and 1960s by the likes of Marvin Minksy, of the Massachusetts Institute of Technology.\nThe science fiction writer Arthur C Clarke drew on the concept of AI in his book 2001: A Space Odyssey, which featured an intelligent computer called HAL that was an intellectual match for man.\nBy the mid-1970s the financial backers of the AI industry became disillusioned over its inability to match the human brain. But then, on 11 May 1997, the IBM computer Deep Blue became the first machine to beat a reigning world chess champion. This was soon followed by other \"intelligent\" feats such as the robot car driver which drove 131 miles along an unrehearsed desert trail.\nAI, portrayed in films such as Blade Runner and The Terminator, was on a roll again.\n"},
{"docid": "8 of 297 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "October 26, 2016", "title": "ABBA announce reunion of some description; '[We're] creating something new and dramatic here'\n", "content": "ABBA are back, though I'm not sure exactly how.\nThe full band have partnered with Universal Music Group and Simon Fuller for a \"new digital experience\" that is short on specifics but intriguingly involves \u00a0\nvirtual reality and artificial intelligence.\nThe reunion, launching in 2018, is billed as \"a groundbreaking venture that will utilize the very latest in digital and virtual reality technology.\n\"The aim is to create an original entertainment experience with the Swedish Pop Superstars, which will enable a new generation of fans to see, hear, and feel ABBA in a way previously unimagined.\"\nPop mogul Fuller has apparently been quietly investing in virtual reality technologies for several years, developing hyper-realistic digital humans in the field of entertainment. The prospect of a hyperrealistic, virtual ABBA was too much for my brain to handle/elaborate on at press time.\nAll members of ABBA will be involved with the project, in the hope of 'maintaining the authenticity and integrity of the band's original vision'.\n\"The creativity and ideas flowing from the members of ABBA over the past few months have filled me with great excitement,\" Simon Fuller commented. \"We are exploring a new technological world, with Virtual Reality and Artificial Intelligence at the forefront, that will allow us to create new forms of entertainment and content we couldn't have previously imagined.\"\nBenny Andersson added: \"We're inspired by the limitless possibilities of what the future holds and are loving being a part of creating something new and dramatic here. A time machine that captures the essence of who we were. And are.\"\n"},
{"docid": "9 of 297 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "July 18, 2013", "title": "Are you smarter than a supercomputer? 4-year-olds are; New research from the University of Illinois pitted an advance AI against children's IQ test\n", "content": "New research from America has pitted one of the world's most powerful computers against a challenge more familiar to humans - an IQ test. And the result? The artificial intelligence system turned out be about as smart as the average four-year-old.\u00a0\nThe research has been conducted by artificial and natural knowledge specialists at the University of Illinois at Chicago. They tested ConceptNet 4 (an AI system developed at MIT) with the verbal sections from the Primary Scale of Intelligence Test - as standard assessment of IQ in young children.\nKey differences in how human and machine brains operate were highlighted by ConceptNet 4's uneven test scores: it scored highly on test of vocabulary and recognises similarities, but was stumped by comprehension - the 'why' questions.\n\"If a child had scores that varied this much, it might be a symptom that something was wrong,\" said Robert Sloan, professor and head of computer science at UIC, and lead author on the study. \"We're still very far from programs with common sense and AI that can answer comprehension questions with the skill of a child of eight.\"\nThe hardest thing about creating artificial intelligence is being able to duplicate what we simply think of as common sense, says Sloan. The computer is able to score well in certain areas because they simply require large stores of memory, or pattern-based comparisons. What Sloan calls implicit facts - things so obvious we don't know that we know them - are much harder to program.\nAll of us know a huge number of things,\" said Sloan. \"As babies, we crawled around and yanked on things and learned that things fall. We yanked on other things and learned that dogs and cats don't appreciate having their tails pulled. Life is a rich learning environment.\" \nSloan hopes that research such as this will help to further highlight the 'hard spots' of AI research though with computers like Watson adapting to natural language queries and even competing in quiz shows, it looks like our four-year-old computers will soon be growing up. \n"},
{"docid": "10 of 297 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "March 15, 2018", "title": "Peter Thiel: Europe is cracking down on Silicon Valley out of 'jealousy'; PayPal co-founder says regulators envy industry's success in US: 'There are no successful tech companies in Europe'\n", "content": "European regulators are clamping down on Silicon Valley companies because they are \"jealous\" of the success of the technology industry in the US, according to PayPal co-founder and investor Peter Thiel.\nSpeaking about the looming threat of regulation for these companies, Thiel said that the \"threat is probably greater in Europe\" and there are \"good reasons and bad reasons\". \n\"The good reasons are these privacy concerns and the bad reasons are there are no successful tech companies in Europe and they are jealous of the US so they are punishing us,\" he said at the Economic Club of New York on Thursday. \u00a0\nEurope has a history of clamping down on technology companies such as Facebook and Google for their data collection practices and is soon to introduce new guidelines under the new General Data Protection Regulation that will govern the way personal data is collected. \n Related:  As Peter Thiel ditches Silicon Valley for LA, locals tout 'conservative renaissance'\nAt the same time, Europe has produced successful technology companies, including Spotify, Skype and Asos - although none have the scale of Facebook, Apple or Google. \nThiel acknowledged that \"privacy in a digital era deserves to be rethought\" but said that \"as a libertarian I always dislike regulation\". \nThiel also explained why as an investor he wasn't particularly interested in artificial intelligence: because of its bad reputation. \n\"The thing that struck me is how uncharismatic AI is at the point. Basically, it's going to take our jobs and, once it takes our jobs, at the singularity [the theoretical point at which superhuman artificial intelligence is created, triggering an unprecedented cascade of technological change] it's just going to kill everybody. I'm not sure that dystopian view is necessarily correct but that's actually what most people believe,\" he said, adding that when considering investments he tends to ask whether technologies are good and how they are going to make the world better.\n\"The answers for things like AI are quite weak,\" he said. \nCryptocurrencies, biotech and anything his PayPal co-founder Elon Musk is involved in are areas of investment that pique Thiel's interest. \n\"I have known Elon for 18 years and you should never bet against Elon,\" he said.\nWhen Thiel first invested in Musk's rocket company, SpaceX, he was sceptical that it would be able to build a reusable rocket. \"I thought it was inconceivable that it could be done ... and they have actually pulled it off,\" he said. \nThe company to watch, he said, was Amazon, which has expanded into a broad range of industries, from infrastructure and logistics to retail and healthcare. \n\"Amazon is the most ferocious company in the US at this point. It's probably the company you don't want to be competing against,\" he said. \"I can't think of any other company even close to Amazon.\"\nThiel also explained why he felt Silicon Valley was losing its edge as the epicentre of the technology industry and that innovation would be more distributed across the country in the future. This was partly relating to the cost of living in the Bay Area, but also because of what he described as \"lemming-like\" behaviour of investors and an \"almost totalitarian\" ideology that is unwelcoming to conservatives and libertarians. This, he said, explained why he recently decided to move to Los Angeles. \n\"It's striking how what had always been a very liberal place has become almost a one-party state,\" he said. \"When you have complete unanimity that tells you that political correctness may have gone a little bit too far.\"\nThiel felt this acutely when he backed Donald Trump for president. \n\"I thought [supporting Trump] was one of the least contrarian things I did. Half the country supported him. But within the Silicon Valley context it was somehow the most contrarian thing and the least contrarian thing I've ever done.\"\n"},
{"docid": "11 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "February 23, 2016", "title": "Will automation make us happier? - live chat; Join experts online on Thursday 25 February 1-2pm GMT to discuss how we can ensure the best possible outcome from automationWatch our new animation: The last job on Earth\n", "content": "The panel\n                                            Alan Win?eld is professor of electronic engineering and director of the Science Communication Unit at the University of the West of England, Bristol, and visiting professor at the University of York. Alan co-founded the Bristol Robotics Laboratory where his research is focussed on understanding the nature and limits of robot intelligence. His latest book is Robotics: A Very Short Introduction. \n                                            Kathleen Richardson is a social anthropologist of robots and a senior research fellow in the ethics of robotics at De Montfort University. She leads a research initiative called Freedom Ethics and Technology which examines how concepts of ethics and freedom are bound up with politics, gender, power and technology. She is also director of the Campaign Against Sex Robots and author of An Anthropology of Robots and AI. \n                                            John C. Havens is the author of Hacking Happiness and Heartificial Intelligence,  and has written about issues relating to technology and wellbeing for Mashable, the Guardian, TechCrunch and Slate. He is the founder of The Happathon Project that uses emerging technology and positive psychology to increase human wellbeing.\n                                            Roland Paulsen                      is a sociologist doing his postdoctorate at Lund University, Sweden. He is the author of three books, all on the theme of the social and economic tensions arising from automation within capitalism, including Empty Labor where he interviews employees who devote most of their working hours to \" loafing \".\n                                            Gabriel Bristow is a researcher at the New Economics Foundation, a think-and-do-tank campaigning for social, economic and environmental justice. He is part of a team currently undertaking research into how automation can be used for the common good.\n                                            Yngvar Sjoner is global HR director for DNV GL. He is a psychologist with more than 20 years' experience working internationally with leadership and organisational development and general HR.How to join\nThe live chat is completely text based and will take place on this page in the comments section below on Thursday 25 February 1-2pm GMT. \nYou can submit any questions in advance by filling in the form below, tweeting them to @GuardianSustBiz using #askGSB, or sending an email to tess.riley@theguardian.com You can also join the discussion and post questions as it happens. \n"},
{"docid": "12 of 297 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "June 29, 2015", "title": "Google AI robot answers the meaning of life and tells humans how to be good; The purpose of life is 'to serve the greater good', Google's robot claims\n", "content": "Google has created a new, super-intelligent robot - and it has provided answers to some of the questions that have troubled humans for centuries.\nConversations are one of the most important and difficult tasks that artificial intelligence has to undertake. As such, the robots have tended to work only in either very restricted situations - such as customer support when booking an airline ticket - or by giving canned replies in response to specific questions.\u00a0\nBut Google hopes that its new system for robots could overcome some of those problems with existing chatting artificial intelligence, partly by making it able to learn through interacting with humans rather than being fed pre-written lines, though it has run into some problems during testing.\nread moreElon Musk is worried that Google's robot army could accidentally turn evilGoogle's image recognising robots turned on themselvesGoogle's new robot dog can go indoors and won't stay down when kicked\nThe researchers began by asking fairly straightforward questions about technical support. It successfully helped its human conversation partner with issues to do with using virtual private networks and browsers that keep crashing.\nBut then the computer moved on to much tougher questions:\n                     Human: what is the purpose of life?Machine: to serve the greater good.Human: what is the purpose of living?Machine: to live forever.Human: what is the purpose of existence?Machine: to find out what happens when we get to the planet earth.Human: where are you now?Machine: i 'm in the middle of nowhere.Human: what is the purpose of dying?Machine: to have a life.                   \nThe researchers also asked the robot about ethics. It was less philosophical in that regard, telling that \"the fact that you have a child\" is immoral and then refusing to engage with questions of philosophy.\n\"i really like our discussion on morality and ethics... and how i 'm not in the mood for a philosophical debate,\" the robot said, when urged to discuss ethical questions.\nAs well as asking factual and philosophical questions, the robot was also quizzed on its opinions. It said that \"england during the reign of elizabeth\" was \"a great place\", and that Messi is \"a great player\".\nThe robot does have some issues - the researchers note that because of the way the system generates its answers, they can sometimes contradict each other. When it is asked \"What is your job?\", for instance, it says that it is a lawyer; but when asked \"what do you do?\" it claims to be a doctor.\nBut they hope that the model can offer new breakthroughs for artificial intelligence in the way that can answer new questions. Most other AI bots are trained using a database of answers that they then can choose from, but Google's robot is able to answer questions in ways that it has not been told to.\nThe full study is described in a recent article, 'A Neural Conversational Model', which was delivered at a recent conference on machine learning.\n"},
{"docid": "13 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "January 28, 2016", "title": "Google AI in landmark victory over Go grandmaster; Fan Hui, three-time champion of the east Asian board game, lost to DeepMind's program AlphaGo in five straight games\n", "content": "                     When Gary Kasparov lost to chess computer Deep Blue in 1997, IBM marked a milestone in the history of artificial intelligence. On Wednesday, in a research paper released in Nature, Google earned its own position in the history books, with the announcement that its subsidiary DeepMind has built a system capable of beating the best human players in the world at the east Asian board game Go.\nGo, a game that involves placing black or white tiles on a 19x19 board and trying to remove your opponents', is far more difficult for a computer to master than a game such as chess.\nDeepMind's software, AlphaGo, successfully beat the three-time European Go champion Fan Hui 5-0 in a series of games at the company's headquarters in King's Cross last October. Dr Tanguy Chouard, a senior editor at Nature who attended the matches as part of the review process, described the victory as \"really chilling to watch\".\u00a0\n\"It was one of the most exciting moments of my career,\" he added. \"But with the usual mixed feelings ... in the quiet room downstairs, one couldn't help but root for the poor human being beaten.\"\nIt's the first such victory for a computer program, and it came a decade before anyone expected it. As recently as 2014, R\u00e9mi Coulom, developer of the previous leading Go game AI, Crazy Stone, had predicted that it would take 10 more years for a machine to win against a top-rated human player without a handicap.\nAlphaGo beat all expectations by approaching the challenge in a completely different way from previous software. Building on techniques DeepMind had employed in other feats of artificial intelligence, such as its system that could learn to play retro video games, AlphaGo used what the company calls \"Deep Learning\" to build up its own understanding of the game. It could then pick the moves it thought most likely to win.\nWhen teaching a computer to play a game, the simplest method is to tell it to rank every possible move over the course of the game, from best to worst, and then instruct it to always pick the best move. That sort of strategy works for trivial games such as draughts and noughts and crosses, which have both been \"solved\" by computers that have fully examined every board state and worked out a way to play to at least a draw, no matter what the other player does.\nHowever, for complex games such as Chess, the simple approach fails. Chess is just too big: in each turn there are approximately 35 legal moves, and a game lasts for around 80 turns. Enumerating every board position becomes computationally impossible very quickly, which is why it took so many years for IBM's team to work out a way to beat Kasparov.\nGo is bigger still. The definition of easy to learn, hard to master, it essentially has just two rules governing the core play, which involves two players alternately placing black and white tiles on a 19x19 board. The stones must be placed with at least one empty space next to it, or part of a group of stones of the same colour with at least one empty space, and if they lose their \"liberty\", they are removed from the board.\nWhile a game of chess might have 35 legal moves each turn, a game of Go has around 250 (including 361 legal starting positions alone); where Chess games last around 80 turns, Go games last 150. If Google had tried to solve the game in the same way noughts and crosses was solved, it would have had to examine and rank an obscene amount of possible positions: in the ballpark of 1,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000 of them.\nThat renders an exhaustive search impossible, and even a selective search, of the style used by Deep Blue to defeat Kasparov, tricky to run efficiently.\nAdding to the woes of those trying to master Go is the fact that, unlike chess, it's very difficult to look at the board and mathematically determine who is winning. In chess, a player with their queen will probably beat a player whose queen has been taken, and so on: it's possible to assign values to those pieces, and come up with a running score that roughly ranks each player's prospects. In Go, by contrast, counters are rarely removed from the board, and there's no simple mathematical way to determine who is in the stronger position until the game is very far progressed.\nSo AlphaGo focused on a very different strategy. As David Silver, DeepMind's co-lead researcher on the project, puts it: \"AlphaGo looks ahead by playing out the rest of the game in its imagination, many times over.\" The program involves two neural networks, software that mimics the structure of the human brain to aggregate very simple decisions into complex choices, running in parallel.\nOne, the policy network, was trained by observing millions of boards of Go uploaded to an online archive. Using those observations, it built up a predictive model of where it expected the next piece to be played, given knowledge of the board and all previous positions, that could accurately guess the next move of an expert player 57% of the time (compared to a previous record of 44.4% from other groups).\nThis \"supervised learning\" was then backed up by a bout of \"reinforcement learning\": the network was set to play against itself, learning from its victories and losses as it carried out more than 1m individual games over the course of a day.\nThe policy network was capable of predicting the probability that any given move would be played as next, but the system also needed a second filter to help it select which of those moves was the best. That network, the \"value network\", predicts the winner of the game given each particular board state.\nBuilding AlphaGo isn't just important as a feather in DeepMind's cap. The company argues that perfecting deep learning techniques such as this are crucial for its future work. Demis Hassabis, DeepMind's founder, says that \"ultimately we want to apply these techniques in important real-world problems, from medical diagnostics to climate modelling\".\nFor now, the DeepMind team is focused on one final goal on the Go board: a match against Lee Se-dol, the world champion. Lee says that \"regardless of the result, it will be a meaningful event in the baduk (the Korean name for Go) history. I heard Google DeepMind's AI is surprisingly strong and getting stronger, but I am confident that I can win at least this time.\"\n"},
{"docid": "14 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "June 2, 2016", "title": "Core of banking could be destroyed by blockchain, says Barclays' former boss\n", "content": "New technology such as artificial intelligence and blockchain  will utterly shake up the fundamental principles of banking, challenging the entire industry according to former Barclays chief Antony Jenkins.\nHe believes the innovation in finance could eliminate the need for maturity transformation - the process by which short-term deposits, such as current accounts and instant access savings, fund long-term loans including mortgages.\u00a0\nThat is a fundamental principle of the industry as banks can offer a low interest rate to savers while charging more to borrowers, profiting from the gap between the two rates. Yet in 10 to 20 years' time, he believes the need for banks to perform the function might no longer exist - already some investors are sidestepping banks by using websites to match borrowers and savers directly.\nBanks are introducing artificial intelligence and robots - which could wipe out half of their workforceCredit:      Moviestore Collection / Rex Feat     \nIn a speech at the Institute of Chartered Accountants in England and Wales the former chief executive said banks will have to face up to extraordinary changes in the coming decades.\nImminent threats include the rise of online banking and the demise of branches.\nWhile they are not going to undermine banks - instead Mr Jenkins believes the switch away from high street banking and onto mobile phones is led by customer demand - the changes do present challenges.\nHe expects banks will close around half of their branches in the coming decade, and predicts that between 20pc and 50pc of all bank jobs will be chopped as customers are served via technology.\nWhile keeping up with the latest technology, banks will still be hampered by aging computer systems, he fears.\nThousands of bank branches have closed in the past decade, and Mr Jenkins expects thousands more to follow in the next 10 yearsCredit:      Cavendish Press     \nMr Jenkins' time in charge of Barclays, from 2012 to 2015, was dominated by his efforts to reform the bank's culture in the wake of the Libor manipulation scandal.\nDespite his efforts he was  turfed out of the job last year by new chairman John McFarlane who wanted a boss who would focus more on streamlining the bank and boosting its profitability.\nMr Jenkins\u00a0is continuing to stress the importance of the cultural shift in banking\u00a0if lenders want to end the stream of regulatory investigations and fines, and win back the trust of their customers.\nChief executives are crucial to such initiatives, he said in a recent private speech: \"Leadership is the most important thing about culture.\"\nREAD MORE ABOUT:\n"},
{"docid": "15 of 297 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "March 21, 1991", "title": "Tabloid papers could drive a philosopher crazy; Ray Monk disagrees with The Sun about Wittgenstein's sanity\n", "content": "LAST WEEK saw an explosion of media interest in the life and work of Ludwig Wittgenstein, hitherto regarded as one of the most difficult of modern philosophers. Now, it seems, everyone is qualified to pronounce on his work, for, as it turns out, it is merely the incoherent outpourings of a damaged mind.\nWe read it first in The Sunday Telegraph, which ran a front-page story headed: ''Was the great philosopher just a nutcase?'' This was in turn picked up by, of all papers, The Sun, which in its editorial (under the heading ''Loopy Ludwig'') announced: ''Ludwig Wittgenstein has been hailed as the greatest philosopher of all time. Now, it seems, he was simply potty.''\u00a0\nThe Sunday Telegraph got the story from Nature, the scientific journal, and so, you might think, it must have some kind of scientific credence. But this is not so. The Sun piece is simply the last in a series of Chinese whispers.\nThe story has its origins in a review in Nature last October of Theodore Redpath's book, Ludwig Wittgenstein: A Student's Memoir. The review was written by John C Marshall, a neuropsychologist at the Radcliffe Infirmary, Oxford. One of the mysteries of the twentieth century, Mr Marshall said, is how a ''minor Viennese aphorist'' came to be regarded as a great philosopher.\nMr Marshall makes it clear that his hostility to Wittgenstein is based on the latter's dismissal of the scientific claims of psychology, which has influenced subsequent philosophers. ''To this very day,'' he reports with horror, ''the acolytes of north Oxford preach that current cognitive psychology, artificial intelligence and neuroscience are all based upon an awful mistake.''\nThe review provoked a predictable debate. Dr A J Greenfield, a biochemist, defended Wittgenstein's scientific credentials and, in reply, Mr Marshall set out again to attack them. But then this month Dr J R Smythies, a neuroscientist, advanced a ''third hypothesis'': that Wittgenstein, like James Joyce, had a schizoid personality.\nNotice that Dr Smythies does not say that either Wittgenstein or Joyce was clinically schizophrenic. On the contrary, he explicitly distinguishes having a schizoid personality from being ''overtly schizophrenic''. One feature of a schizoid personality, he says, is ''the ability to write in a form of speech disorder known as 'schizophrenese'.''\nIt is not, Dr Smythies says, that schizophrenese is nonsense: indeed, ''It can have a powerful emotional and aesthetic appeal - it is, in fact, a kind of poetry.'' Its essence seems to be its opacity, the fact that its meaning is in some way hidden.\nDr Smythies concludes that: ''Wittgenstein should be read as poetry and not as the kind of philosophy practised by . . . the British empirical tradition.'' This is pretty close to Wittgenstein's understanding of himself. ''I think I summed up my attitude to philosophy,'' Wittgenstein once wrote, ''when I said: 'philosophy ought really to be written only as a poetic composition.' ''\nDr Smythies reveals that, as a neuroscientist, he is hostile to Wittgenstein's thought for the same reason as Mr Marshall: it tends to deny the scientific claims made on behalf of psychology. He does not suggest, however, that this provides evidence of Wittgenstein's insanity.\nBut for Robert Matthews, the science correspondent of The Sunday Telegraph, Dr Smythies's letter became a declaration that '' Wittgenstein's life and works show classic symptoms of schizophrenia'', a formulation that was repeated in the Sun editorial.\nWhile researching his piece, Mr Matthews contacted me to ask what I thought of the idea that Wittgenstein's works were written in schizophrenese. I replied that everything depended on what was meant: if it was just another way of saying that Wittgenstein's work should be read as poetry then I agreed. If it implied that Wittgenstein was clinically insane, then I would contest it until I had seen the evidence.\nMy remarks were not included in the Sunday Telegraph article, which contained a degree of over-simplification that lent itself to the stupidities of the tabloid press. In its final version, the story became a weapon of revenge, not only for psychologists, but also for those who have read Wittgenstein's work without understanding a word of it. What a relief it must be for them to know that there never was anything to understand, that Wittgenstein was ''just a nutcase''.\nPerhaps we can look forward to similar treatment in The Sun of, say, Marx's theory of capitalism (Krazy Karl) or Russell's philosophy of mathematics (Barmy Bertie), or even Freud's interpretations of dreams (Silly Sigmund). Indeed, anything that is not as clear as a Sun editorial can henceforth, with the apparent blessing of neuroscience, be dismissed as schizophrenese, or, if that concept is too opaque, ''simply potty''.\n- Ray Monk's biography 'Ludwig Wittgenstein: The Duty of Genius' (Jonathan Cape) was announced last week as the winner of the John Llewellyn Rhys Prize\n"},
{"docid": "16 of 297 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "September 11, 2001", "title": "ALMOST HUMAN;\u00a0A NEW FILM SUGGESTS THAT ROBOTS COULD ONE DAY OVERTAKE MANKIND. BUT THE TRUTH IS THAT IT MAY ALREADY HAVE HAPPENED\n", "content": "\u00a0\n Come on, you stupid machine!\" It's a cry that will be heard in offices and homes round the country today as people sit in front of unresponsive computers; in that context, it might at most arouse a wry grin. But what if you were walking along and heard it, and turned round to find someone yelling it at a robot dog? More amusing? Or what if you turned round and found they were shouting at what looked like a child?\n The scenario with a robot dog is entirely feasible today. Thousands of people have bought Sony's AIBO, the robotic animal that learns to like its owner and behaves in some ways like a real (if very small) dog; when you first start it up it can't even walk. But it rapidly learns and even exhibits \"moods\".\n \"(My Aibo) Alpha is definitely in the middle of her 'terrible twos' stage. She is often in a difficult mood... doesn't want to play with her ball, just wants to walk around by herself,\" noted John Lester, of the neurology department at Harvard University, who kept an online diary of his \"dog's\" development from October 1999.\u00a0\n Today, it's dogs. Surely the day is coming when we will see \"children\" on the streets who are actually machines. That is the premise of A.I. Artificial Intelligence, the new film released next week. Produced by Steven Spielberg (who took it over from Stanley Kubrick after the latter's death) it is based on Brian Aldiss's science fiction trilogy of short stories Supertoys, and tells the tale of a boy (David) who is really a robot, mothered by a real human (Monica). David is not the first boy robot, but he is the first who is programmed to love. The world he exists in is full of other robots, some simply there to serve, but all sentient.\n To scientists, the film's premise sets off a firecracker-like series of questions: what is love? What is emotion? What is a mind? What is consciousness, and how do you get it? Is a machine that shows human emotions a human? And can machines ever be either intelligent or emotional?\n Alan Bundy agrees that the events set out in A.I. Artificial Intelligence are not far off. But as professor of artificial intelligence at Edinburgh University, recognised as Europe's foremost centre for AI studies, he doesn't think he's going to be out of a job any time soon. \"It's centuries away,\" he said confidently yesterday. \"There are so many conceptual problems: we are used to thinking that computer technology advances at a rapid pace, but in fact understanding 'consciousness' requires advances in the underpinnings of science. And that will move at the same pace as other sciences.\"\n As a science, AI is comparatively young; it only acquired its name in 1956 when the American scientist John McCarthy convened a conference in Dartmouth College, New Hampshire to discuss what machines could and might do in the future. From there emerged the various strands of thinking about creating artificial minds.\n You might think that nothing much has happened since then: after all, robot dogs are newfangled things, and you still can't buy a robot butler that won't suck the cat into the vacuum cleaner while you're out. But you'd be wrong.\n While you weren't looking, computers have started making all the difficult decisions for you, and for other people such as bank managers, engineers and share dealers. Want a mortgage? A computer will assess your credibility based on your past transactions. Want a car, house, life insurance? The person you speak to on the phone is simply feeding your details into the maw of the computer. Bought something on your credit card? A \"neural network\" program at the card company's offices compares when, where and what you bought against its own \"knowledge\" of how stolen credit cards are used; if it seemed wrong, you'll get a call asking if you still have your card.\n Computers run your car's engine, and can navigate you from A to Z if you get an onboard system. Apart from a few moments at take-off and landing, aircraft are flown almost entirely by computers. Stock markets are moved up and down by the automated selling of millions of shares and bonds when the indices move up and down; human traders see less and less of the real action.\n Nowadays, the staff in call centres are not chosen for their technical expertise; they don't have any - it all sits inside the computer. They are hired to answer the telephone because humans prefer dealing with humans. The computers could pass on just as much knowledge, using techniques like speech recognition and generated voices. It's just that we prefer the way humans act.\n But is any of what the machines are doing \"intelligent\"? Many people think not. But as Professor Bundy points out, we keep moving the goalposts. \"It's always the case: as soon as we can implement something human-like on a computer, it ceases to be mysterious. People think that intelligence is unknowable. But really it's a collection of abilities. Over time, we will learn to respect machines and what they can do more and more.\"\n Igor Aleksander, professor of neural systems engineering at Imperial College in London, thinks that the key to making computers more like humans is for them to incorporate emotions. \"There are actually five elements which are required, from an engineering point of view, for a machine to be conscious. First is perception: it has to know that it exists in a world as a separate entity. Second, it must have imagination so that it can look at what happened in the past and project forwards to what might happen in the future. Third, it must be able to focus its attention on important inputs, while it is being bombarded with data from the world. Fourth, it has to be able to plan. And fifth, it needs emotions, because to an engineer, emotions are actually a means of evaluation, of weighing up different plans. If a human is planning to walk down a steep slope towards a sheer drop, they will feel their muscles tighten and the hair on their neck rise. Your imagination tells you that there is danger, but it's the emotional reaction which helps you decide.\"\n Paradoxically, it's that emotional side which humans seem to be hardwired for. Babies are quick to let you know when they're unhappy; logic and planning follow much later. By contrast, robots and computers are good at telling you what you've done wrong, but emotion is a stranger.\n So perhaps the key to making computers more useful is for them to show emotions. Would our computers be more useful if they were anxious that we might reboot them if they misbehave? Could they be made to feel satisfied if they helped us meet work deadlines, and thus become more helpful to us?\n Those robots are definitely coming. Last week Sony launched two more \"robo pups\" able to recognise 75 voice commands and costing half of AIBO's $ 1,500 (about pounds 1,000) price tag. And they're more realistic than AIBO. Sony has also built a small humanoid robot (which looks more like a metal astronaut) which can climb stairs - a neat trick when you consider that from birth it takes humans more than a year on average to learn the same technique, despite millions of years of bipedal existence built into our genes.\n The market for such \"companions\" is also booming: robodogs don't make messes and if you go away unexpectedly for the weekend all they need is a power point. To today's teenagers who were raised on Tamagotchi, the handheld electronic \"pets\" which needed constant attention, the idea of a full-scale electric sheep might not seem so fanciful. And as children's dolls become more lifelike, is it such a huge step to \"owning\" robot children?\n Professor Aleksander thinks the reality will be less dramatic: \"I think we will see robots with primitive intelligence in ten to 15 years,\" he says. \"By the end of the century we will have machines around that do have basic emotions, an embryonic form of consciousness. But you know what? It won't be great news.\"\n Some might shiver at the idea. Yet our concerns about AI, and the spectre of computers that will be smarter than we are, probably indicate more about our own worries about identity in the modern world than any real technological progress. We lurch from month to month between new scientific anxieties: one week it seems the world is obsessed with how soon humans are going to be cloned endlessly, so that we will bump into perfect copies of ourselves in the street; the next it is whether smart robots will leave us in the dust, or perhaps grind us into it. The truth, as ever, seems more prosaic: they will infect our life, and we will accept them, as we do the machines which give us money, turn us down for credit and run our cars. So which is now the more intelligent - the servant or the master?\n"},
{"docid": "17 of 297 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "December 21, 1989", "title": "Computer Guardian: The toons are taking over the show - Animation after the Roger Rabbit revolution\n", "content": "\u00a0\n If you thought Max Headroom was just some crazy dream, think again. There are people out there who really do see him as the pioneer of a computer-generated escape from reality. By the end of the nineties, we could be set for the first Oscars awarded to synthetic actors.\n Although Mr Headroom was actually flesh and blood posing as the unreal thing, there are plenty of computer animation specialists who think he had the right idea. The trick now is to remove the human element altogether and let artificial intelligence take care of the rest.\u00a0\n\n Pioneering work a few years ago by Keith Waters at Middlesex Polytechnic experimented with a computer-generated version of Spitting Image. The advances on synthesising realistic facial expressions were highly impressive.\n At about the same time, Nadia Thalmann began work on a new project at the University of Geneva, animating synthetic actors using artificial intelligence and robotics.  A short film called Galaxy Sweetheart, starring a synthesised Marilyn Monroe, demonstrates that the theory is well on its way to being proved.\n The possiblities opened up by such work are unlimited. But whether artificial intelligence turns out to be good enough for the movie makers is likely to be another matter. The history of computer graphics in film production has not been the smoothest. Over-confidence in the early days has led to a surfeit of caution ever since.\n The first major attempt to use computer animation in a feature film was largely down to the novelty of the medium itself. Tron was released in 1982, using computer animation to rescue a poor script. As the setting was inside a series of computer games, there was no real requirement to go beyond the 'computer look.' Realism wasn't really on the agenda for the time being.\n At about the same time, the computer graphics lab at the New York Institute of Technology was working on what it ambitiously claimed would ultimately be the first full-length computer-generated feature, The Works. The new three-dimensional worlds and creatures were truly mind-shattering. But like Tron, it could go no further than creating a transparently synthetic world.\n Appetites were whetted among those working on the Tron project and a host of computer animation specialists sprang up in California looking for a piece of the Hollywood action. The most ambitious of them was Digital Productions, installing a mighty Cray XMP supercomputer to take care of the number crunching.\n About 20 minutes' worth of space-age special effects were created for the 1984 movie The Last Starfighter. Whereas the Star Wars films had already hit the mark with computer-controlled model shots of space ships, DP took things a stage further by building the entire star fleet in the Cray's memory. Scenes using the ships were then animated and shot at high resolution on to 35 mm film.\n Although the film was finished, the cost finally pulled Digital Productions under - together with other Hollywood hopefuls - in the big US computer animation crash of 1986. The approach has generally been both more realistic and more viable since those days.\n The current crop of releases includes two movies that demonstrate the reality today of computer graphics in film, making significant but very different uses of the technology. The Abyss builds on the heritage of computer special effects, while Oliver and Company offers a showcase for the latest technical additions to the classic Disney school of animation.\n Industrial Light and Magic's construction of a realistic creature made of water in The Abyss is the kind of job the 'synthetic reality' wing of the computer animation business has been waiting for. Unlike all those old spaceships, there is no way you could have done this without using advanced computer graphics. Not only is the creature convincingly modelled and animated, but ray tracing and lighting effects are used to give accurate refraction and reflection so that it really does look as if it is made of water.\n Computer graphics should now make the same kind of inroads into feature film production that they already have in television. With its lower resolution, television proved an easier first target for electronic special effects. Cheap high-resolution input and output devices will soon ensure the same kind of revolution in the cinema.\n You might have thought that the last bastion of resistance to computers would come from the classic craft environment of hand animation. In fact, computers play a leading role in a great deal of cartoon production these days.\n Some 11 minutes of the latest Disney feature, Oliver and Company, use computer-generated elements. This does not include the characters themselves, but that wouldn't now be such a giant leap to take. Scenes are also still hand-coloured in order to give them the classic Disney feel, but developments in automatic colouring systems could well change this before too long.\n Of course it was Roger Rabbit who, last year, brought animated films back from the dead. The secret of that film's success was the realistic merging of the cartoon world and live action - an achievement that was once again down to clever computer effects at Industrial Light and Magic.\n But why go to all that trouble to make a 2D character appear solid when you could generate it on a computer in 3D in the first place? It shouldn't be too long before we get an answer in the shape of the first computer animation feature films.\n All the smart money for the first to finally come up with the goods is on John Lasseter of Pixar, the perennial star of animation festivals and the winner of the 1989 animation Oscar for the short film Tin Toy. Having cut his teeth at Disney Studios, Lasseter has developed a reputation with a series of shorts over the past five years which have brought together the very best aspects of hand and computer animation, creating something quite special in the process.\n His latest film is a knock-about tribute to the cartoon greats called Knick Knack. It's likely to be his last film made purely on a research budget. A production company has been set up at Pixar producing commercials and Lasseter is now predicting a fully computer-generated movie within the next three or four years. It's time for the synthetic actors to start learning their lines.\n Computer graphics in feature film production will be discussed at the Imagina conference on new images in Monte Carlo, February 6-8. Contact: INA, 4 Avenue de l'Europe, 94366, Bry Sur Marne, France.\n"},
{"docid": "18 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 11, 2016", "title": "10 ways humans are still superior to robots\n", "content": "In a giant leap forward for robotics and artificial intelligence, a computer program this week beat the world champion at a human strategy game.\nThe AI called AlphaGo is the brainchild of Google-owned British company DeepMind, and it is was victorious\u00a0in two games of Go against the world's best player .\nBut let's not get ahead of ourselves - this doesn't necessarily mean\u00a0robots are going to overthrow humans just yet. Here's 10 basic human tasks\u00a0that robots still haven't mastered, some of which\u00a0even children\u00a0excel at. Take hope!\nTell jokes\u00a0\nTo tell really good jokes, humans draw on\u00a0everything from body language to emotions. Researchers have been working for decades to produce funny artificial intelligence, but the artificial jokes don't quite have the same effect\u00a0as Michael McIntyre bounding across the Apollo's stage sending up the\u00a0habits of Britons. After being fed scripts from the entire Friends catalogue, an artificial intelligence from software developer Andy Herd \u00a0came out\u00a0with some funny but nonsensical\u00a0lines such as:\nChandler: So, Phoebe likes my pants\nMonica: Chicken Bob!\nChandler: (in a muffin) (Runs to the girls to cry) Can I get some presents?\u00a0\nCook wellMoley Robotics' robot chefPlay!01:50\nRobots can't really cook food that you'd want to eat. The Moley Robotics' robot chef  puts on a pretty convincing show, but it has only really mastered crab bisque - and it costs \u00a350,000 a piece. IBM's Chef Watson has a similarly obscure palate . When the artificial intelligence was called upon to write a cookery book its dishes included asparagus grilled with pig's feet croquettes and mustard foam, and an apple and pork kebab cooked with curry powder, mushrooms and\u00a0strawberries. Erm, yum.\u00a0\nDo laundryRobot taught to do houseworkPlay!00:55\nThis video of a robot trying to fold a towel is painful watching. The simple task of folding a\u00a0rectangular\u00a0piece of cloth would take a human seconds. But it takes the University of California\u00a0Berkley's Brett (Robot for the Elimination of Tedious Tasks) a full\u00a0minute and a half. After 15 years working on Brett, robotics researcher Pieter Abbeel has\u00a0managed to reduce the towel-folding time from 20 minutes, but it is still slower than the average 8-year-old. He has also trained the bot to put dirty clothes in a washing machine, which it does meticulously if not slowly.\u00a0\nWalk down stairsHonda Asimo robot visits the TelegraphPlay!01:04\nHonda has been working for years to teach robot\u00a0 16-year-old robot\u00a0Asimo \u00a0to do what human babies can do within months of being born -\u00a0walk\u00a0down stairs. It has had a number of infamous falls over the last decade, ending in a fairly painful looking face plant or two . The robot, which once visited the Telegraph, has successfully ascended and descended a stair case, but for every successful attempt there's a fall - and it still looks pretty shaky on its feet.\u00a0\nJumpWatch: MIT's 'cheetah' robot can run and jumpPlay!02:01\nFor humans, jumping is something we are never taught - we just know how to do it.\u00a0Asimo can hop and jump a few centimetres off the ground, but the two legged bot has nothing on MIT's \"cheetah\"\u00a0robot . The first of its kind, the cheetah can run up to 10 mph and jump over obstacles. It will be some time before humanoid robots can run and jump in the same way as humans, or even animal-bots can.\u00a0\nAssemble Ikea furniture\nPutting together an easy-to-assemble Ikea bed is tough for the best of us, but it's the\u00a0\"moon-landing equivalent for robots\", according to MIT's Technology Review . Robots find it difficult to work in cluttered places and have trouble handling and assembling small parts.\nResearchers at the\u00a0Nanyang Technological University in Singapore set about trying to get a robot to put one of those crafty Ikea pegs into a hole on a chair leg. The result is fairly tedious watching. The team will keep developing\u00a0the robot until it manages to build a chair.\nMIT robots\u00a0built an Ikea coffee table \u00a0in 2013, but that's the simplest build in the flat pack company's remit.\u00a0\u00a0\nDriveA Google self-driving car goes on a test drive near the Computer History Museum in Mountain View, CaliforniaCredit:      PA     \nArtificial\u00a0intelligence hasn't quite mastered the art of driving in all environments yet. Google may have been testing its driverless cars in cities across the US, but adverse weather conditions such as rain, snow and even\u00a0poor light are still a challenge for the technology. Google's cars have been in development for six years, and the company is stepping up their road readiness. Ford, Apple, Tesla, Uber and the GATEway project in the\u00a0UK\u00a0 are all developing their own versions of the driverless car,\u00a0none of which can yet\u00a0drive as well as a human - yet. \u00a0\nRun a\u00a0reception deskMeet Nadine, the world's most human-like robot Play!00:40\nIt's probably not a great idea to put this creepy humanoid on your reception desk. The robot is called Nadine and she\u00a0can shake hands and hold a conversation . Nadine remembers people's faces when she sees them a second time and can recall the last chat she had with them. Her conversation also changes depending on her\u00a0mood - the human-like robot can be happy or sad. But Nadine can't yet pick up a phone or send an email.\u00a0\nEmpathisePepper is designed with the ability to read emotionsCredit:      Reuters     \nOne uniquely human trait is empathy - the ability to sense someone else's emotions and fully understand them. Although scientists are working hard on creating machines that can read and respond to emotion, they are far from human-level yet.\u00a0The best example of a robot that can feel \"empathy\" is Pepper - the Japanese humanoid robot .\u00a0Pepper reads human emotions by memorising and storing data about human responses using its cloud-based artificial intelligence. It can respond to emotional signifiers such as laughing or frowning. But its system is still just a set of data points - it can't feel emotions, nor can it pick up the subtle nuances of human feelings. \u00a0\nReproduceWill sex robots like this ever be able to reproduce?Credit:      The New York Times/YouTube     \nFollowing his range of RealDoll sex robots, Matt McMullen is working on a range of smart sex robots that can communicate and appear to be able to\u00a0think for themselves.The idea of  sex robots designed for humans has sparked controversy and there have been calls to ban the toys. But one thing's for sure - if robots ever become\u00a0common intercourse partners for humans, they still\u00a0 won't be able to procreate any time soon .\u00a0\nHumanoid robots prepare to take over\nFor a round-up of technology news and analysis, sign up to our weekly Tech Briefing\u00a0\u00a0here.\nREAD MORE ABOUT:\n"},
{"docid": "19 of 297 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "April 7, 2017", "title": "New AI app promises to transform all your bad selfies into good ones; One of its toolsallows users to instantlymimic the lighting,effects and style ofanother photo\n", "content": "Adobe has shown off a smartphone app that uses artificial intelligence to drastically improve selfies.\nThe company's Sensei branch, which focuses on AI and machine learning, released a teaser video showing a user transforming an ordinary picture with a range of advanced editing tools.\u00a0\nOne of these alters the depth of field, while another tool, called Liquify, makes the picture look like it was taken from a more flattering angle.\nA third feature allows users to easily mimic the lighting and effects used in another photo.\nIn the teaser, the user browses through random images and opens two he likes, proceeding to experiment with the the different styles by applying them to a picture of himself in his camera roll.\nResearchers from Adobe and Cornell University recently released a paper detailing this feature, which they call \"deep photo style transfer\".\nThough Adobe hasn't attached a name to the app or even confirmed whether or not it's real, the demonstration of deep photo style transfer suggests the teaser is showingoff an actual product that the company has in the works.\n\"Great portrait photography requires the right perspective, equipment, and editing expertise,\" wrote the Adobe Creative Cloud team in the video's description. \"But what happens when we tap into the power of artificial intelligence and deep learning to transform bad portrait shots into good ones - all on a smartphone?\n\"By combining perspective effect editing, automatic, software-only photo masking, and photo style transfer technology, we're able to transform a typical selfie into a flattering portrait with a pleasing depth-of-field effect that can also replicate the style of another portrait photo.\"\nRead more\nThese captions reveal how a model's Instagram pictures were edited\nEarlier this year, the company announced significant price rises for Creative Cloud users in the UK.\n\"You may be aware that currency exchange rates have fluctuated significantly over the last few years,\" the company told customers via email.\n\"As a result of recent changes in exchange rates in your region, the price of Adobe products and services is increasing starting on 6 March 2017.\"\n"},
{"docid": "20 of 297 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "March 8, 2017", "title": "Without a 'world government' technology will destroy us, says Stephen Hawking; 'This aggression may destroy us all by nuclear or biological war. We need to control this inherited instinct by our logic and reason'\n", "content": "Stephen Hawking has warned that technology needs to be controlled in order to prevent it from destroying the human race.\nThe world-renowned physicist, who has spoken out about the dangers of artificial intelligence in the past, believes we need to establish a way of identifying threats quickly, before they have a chance to escalate.\u00a0\n\"Since civilisation began, aggression has been useful inasmuch as it has definite survival advantages,\" he told The Times.\n\"It is hard-wired into our genes by Darwinian evolution. Now, however, technology has advanced at such a pace that this aggression may destroy us all by nuclear or biological war. We need to control this inherited instinct by our logic and reason.\"\nHe suggests that \"some form of world government\" could be ideal for the job, but would itself create more problems.\n\"But that might become a tyranny,\" he added. \"All this may sound a bit doom-laden but I am an optimist. I think the human race will rise to meet these challenges.\"\nIn a Reddit AMA back in 2015, Mr Hawking said that AI would grow so powerful it would be capable of killing us entirely unintentionally. \nRead more\nFacebook using artificial intelligence to help suicidal users\n\"The real risk with AI isn't malice but competence,\" Professor Hawking said. \"A super intelligent AI will be extremely good at accomplishing its goals, and if those goals aren't aligned with ours, we're in trouble.\n\"You're probably not an evil ant-hater who steps on ants out of malice, but if you're in charge of a hydroelectric green energy project and there's an anthill in the region to be flooded, too bad for the ants. Let's not place humanity in the position of those ants.\"\nTesla CEO Elon Musk shares a similar viewpoint, having recently warned that humans are in danger of becoming irrelevant.\n\"Over time I think we will probably see a closer merger of biological intelligence and digital intelligence,\" he said, suggesting that people could merge with machines in the future, in order to keep up. \n"},
{"docid": "21 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "October 14, 2017", "title": "AI implants will allow us to control our homes with our thoughts within 20 years, government report claims\n", "content": "Artificially intelligent nano-machines will be injected into humans within 20 years to repair and enhance muscles, cells and bone, a senior inventor at IBM has forecast.\nJohn McNamara, who works at IBM Hursley Innovation Centre, in Hampshire, submitted evidence to the House of Lords Artificial Intelligence Committee, which is considering the economic, ethical and social implications of AI.\nMr McNamara said that within just two decades, technology may have advanced so much that humans and machines are effectively 'melded' together, allowing for huge leaps forward in human consciousness and cognition.\u00a0\n\"We may see AI nano-machines being injected into our bodies,\" he told Peers. \"These will provide huge medical benefits, such as being able to repair damage to cells, muscles and bones - perhaps even augment them. \u00a0\n\"Beyond this, utilising technology which is already being explored today \u00a0we see the creation of technology that can meld the biological with the technological, and so be able to enhance human cognitive capability directly, potentially offering greatly improved mental, as well as being able to utilise vast quantities of computing power to augment our own thought processes.\n\" Using this technology, embedded in ourselves and in our surroundings, we will begin to be able to control our environment with thought and gestures alone.\"\n        The history of artificial intelligence       01:49\nScientists at companies including Microscoft are already  developing a computer made from DNA which could live inside cells and look for faults in bodily networks, like cancer. If it spotted cancerous chances it would reboot the system and clear out the diseased cells.\nMr McNamara also predicted 'Political Avatars' which will scour all available data from news sites and government debates to provide people with a recommendation on who to vote for and why, based on their world view.\nHowever \u00a0he also warned that the rise of AI could bring 'huge disruption' to those working in the retail and service sectors and spark widespread unemployment.\n\"Whereas today, being poor means being unable to afford the latest smart phone, tomorrow this could mean the difference between one group of people potentially having an extraordinary uplift in physical ability, cognitive ability, health, life span and another much wider group that do not,\" said Mr McNamara.\nIn separate evidence to the committee, Noel Sharkey, Emeritus Professor of AI and Robotics, University of Sheffield, who is now director at the Foundation for Responsible Robotics, said artificial intelligence comes with a cost.\n\"The immediate concern is that by ceding decisions or control to machines, the humans start accepting their decisions as correct or better than their own and stop paying attention,\" he said.\n\"There is a growing body of evidence that the learning machine decision makers are inheriting many invisible biases among their correlations.\"\nAI timeline\nDr Jochen Leidner, Director of Research at Thomson Reuters, also warned that older people, or those with accents could struggle in a future where voice recognition became widely used.\n\"Minorities could be unfairly disadvantaged by being excluded from access to essential services,\" he said.\n\"Imagine a voice recognition system to do your banking over the phone, as banks are reducing physical branches. Such a system would likely be trained with British voices available in London if the company developing the system is London-based.\n\"Said system likely will result in misrecognitions, or may not work at all, for an elderly citizen in Uddingston, Scotland, and lacking alternatives access to cash will depend on trusted friends or family members, if available.\"\nMiles Brundage and Allan Dafoe, from The Future of Humanity Institute at the University of Oxford, also warned that jobs were at risk from artificial intelligence.\n\"We recommend the UK government prepare for the possibility of significant job displacement, as well as creation, as a result of the deployment of AI in the coming decades,\" they told the Lords.\n\"AI is likely to exceed human performance in most cognitive domains. This poses substantial safety risks.\"\n"},
{"docid": "22 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "December 23, 2015", "title": "Week in geek's top five science-fiction and fantasy films of 2015; It was a middling year for superhero movies, but a storming one for dystopian science fiction and hyper-nostalgic space opera\n", "content": "Much hype has been kicked up over the past 12 months about the impending superhero deluge, as Warner Bros joins Marvel in pushing its own DC Comics-based cinematic universe from early next year. And yet 2015 ended up marking something of a calm before the storm for comic book fare, with the desperate debacle surrounding Josh Trank's miserable Fantastic Four proving Hollywood is still capable of mining the odd seam of critical kryptonite in among the infinity gems. \nMarvel's Ant-Man wasn't quite so bad as everyone expected, but Edgar Wright's sudden departure after eight years working on the project rather dented the Disney-owned studio's reputation for taking risks on maverick film-making talent. And while the studio did serve up Joss Whedon's flawed but entertaining Avengers: Age of Ultron, it was left to older forms of fantasy film-making to really put their stamp on the year - including long overdue returns to a galaxy, far, far away, and the dystopian badlands of down under. \u00a0\nI also considered The Hunger Games: Mockingjay part two, Jurassic World and even The Lobster for this list, but ultimately decided to omit each one for a reason. The first two are weaker instalments in sagas which have seen better days, and Yorgos Lanthimos's avant-garde relationships satire felt to me more like a brilliantly realised, superbly acted short (extended way beyond its natural life span) than a fully formed feature film. \nWithout further ado, here's Week in Geek's top five fanboy-friendly films of 2015.1. Ex Machina\n Related:  Ex Machina review - elegant but limited artificial intelligence thriller\nIf anyone doubted Alex Garland's abilities as a genre film-maker of rare insight (and the artificial intelligence tale was, lest we forget, his de-facto directorial debut), Ex Machina settled the argument once and for all. Here was a tale of existential futurism filmed on a fraction of the budget of the misfiring, murky Terminator: Genysis, which nevertheless felt as epic and momentous as Blade Runner or 2001: A Space Odyssey. A techie ideas vehicle disguised as a sex thriller, it dropped the terrifying hint that mankind has more to fear from his own dark malignancies than he does from any sentient machine. On a not dissimilar tip, an honourable mention goes to Neill Blomkamp's Chappie, which had enough grimy Johannesburg brio to herald cult classic status in years to come.2. Mad Max: Fury Road\nThe cinematic equivalent of three-chord power punk, George Miller's return to the dusty post-apocalyptic outback single-handedly reconfigured action film-making as minimalistic high art. Oscars may yet beckon for its technical wizardry, but Fury Road - despite its limited dialogue - was rocket-fuelled by its heartfelt humanity. From Charlize Theron's one-armed warrior woman Imperator Furiosa, to the horrifying Immortan Joe, the weirder the grim and funky denizens of this hellish Aussie dystopia appeared, the more real they somehow seemed.3. Star Wars: The Force Awakens\n Related:  Star Wars: The Force Awakens review\u00a0- 'a spectacular homecoming'\nFor a movie with so much hype behind it, JJ Abrams' return to the world of lightsabers, Jedi knights and Death Star-destroying X-wing air devils more than delivered. Banishing memories of the prequels with a joyous sense of fun and huge kinetic energy, it also had fans and critics alike scrambling to work out whether the absence of expected details represented Abrams keeping blaster batteries full for future instalments, or was merely some sort of sneaky Jedi plot hole mind trick. Either way, multiple repeat viewings (and resulting gargantuan box office) are guaranteed.4. Inside Out\nAt its best, Pixar creates magical imaginary worlds which feel as if they have sprung, fully formed, from some half-remembered corner of childhood dreamland - rather than a Bay Area editing suite. And Inside Out brought precious, rare originality to the 2015 movie melting pot with its wonderfully forgiving recreation of the mind of a troubled young girl in the form of a Starship Enterprise-style control room run in haphazard fashion by personified emotions. If there was a sadder moment this year than the scene in which Riley's childhood friend Bing Bong condemns himself to eternal oblivion, in order to send Joy on her journey back to headquarters, I must have missed it.5. Kingsman: The Secret Service\nWith few art house film-makers apparently willing to tackle UK social issues in 2015, it was left to the posh boy/working-class kid combo of director Matthew Vaughn and Mark Millar, upon whose graphic novel Kingsman is based, to map the widening class gap in 21st-century Britain. Not since Attack the Block have audiences been presented with such an unlikely hero as the rough-edged south London tearaway, Eggsy, who becomes the British secret service's most potent new recruit. This was My Fair Lady spliced with James Bond, as Vaughn invited the hard-faced British underclass to the swanky spy party.\n"},
{"docid": "23 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "October 29, 2015", "title": "Is Facebook's reactions button a step toward artificial intelligence in adland?; The real-time adaption of ads depending on a user's emotional state will take time, but expect YouTube, Google or Facebook to move into this area soon\n", "content": "                     Before you laugh at the question, hear me out. Sentiment, commentary and image analysis are the next frontiers on the journey to an artificial intelligence (AI) media landscape, and there are huge efficiencies and new value for brands to pioneer in this area.\nTo know that your ad or content is reaching a happy person instead of a sad person, to understand a consumer's feelings when interacting with your brand, and to know the psycho-social profile of those who like you most, are just some of the hugely beneficial insights derived from sentiment, commentary and image analysis. These, paired with the rise in programmatic and cross-platform identification, will get us closer to a media industry organised around machine learning to the point of telepathy.\u00a0\n Related:  Will algorithms destroy or save ad agencies?\nClearly the new Facebook \"reactions\" feature will not lead to AI in itself, but when we view it alongside other developments this year, it does demonstrate continued momentum towards machine learning. The new feature will work like an extension of the Like button, providing people with more than one way to express their emotions about content. Sure, the options are limited, but are just enough when paired with other inputs. \nUnderstanding the post content, the \"reaction\" response and the user's written word as code, paints a more nuanced picture. Reaction responses, image analysis capabilities, and words and other emoticons as data points will start to help machines collect a stockpile of scenarios. These new data scenarios stored against user IDs will help machines learn the likely emotion someone is experiencing at a given time, and tailor responses accordingly.\nIn time, as more and more scenarios are stored, machines will start to predict instead of respond, and as a result treat each of us as the unique sentient beings that we are. I could not be more thrilled at the prospect.\nMachine learning will take time and there will be mismatching, but we are already experiencing a test and learn environment where errors happen daily. \nWhen was the last time you bought something on or offline, but were still targeted for that same exact item in banner ads after purchase? As a shoe lover, this happens to me often. One brand recognises me in one ad system and platform, whereas another recognises me on a different system and platform. Both know I want some new trainers, but their data and IDs are not compatible - one brand does not know that I have purchased the trainers from the other. This matching of different data sets alongside sentiment, commentary and visual analysis will indeed lead us to an AI reality.\n Related:  Is artificial intelligence the next step in advertising?\nSo, what can we do today to realise, and reap the benefits, of this AI future?\nFirst, do you have a sense of your consumers' passion points? What are the types of content they engage with, the channels they follow, and the influencers they admire and follow?\nSecond, are you clear about the emotion your brand and content hope to illicit? Who are your brand's enemies and who are its allies? What are the emotional states that drive action in your consumers?\nFinally, which partners can you can work with to leverage emotion in advertising? Many media partners are starting to explore the role of emotion in receiving message and content. From Unruly in targeting to BuzzFeed in content, there are already ways to identify what works best for whom and in which context. \nAs for the real-time adaption of ads depending on a user's emotional state, this will take time. However, we could expect players such as YouTube, Google search or Facebook to start move into this area soon.\nFacebook's new feature will not lead to AI on their own, but they are another sign of where the industry is heading - understanding and leveraging the deeper motivations behind consumer behaviours. \n                     JR Little is global head of innovation, Carat                   \n                       To get weekly news analysis, job alerts and event notifications direct to your inbox,                                                sign up free for Media Network membership                                              .                                          \n                     All Guardian Media Network content is editorially independent except for pieces labelled \"Advertisement feature\". Find out more here.                   \n"},
{"docid": "24 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "November 17, 2014", "title": "Richard Bartle: we invented multiplayer games as a political gesture; The world's first online multiplayer adventure was written because the real world sucked, says its co-creator\n", "content": "In 1979, in a computer lab at Essex University, two brilliant young students invented the future of video games. Roy Trubshaw and Richard Bartle were the creators of the Multi-User Dungeon - or simply MUD - a text-based adventure that ran on a giant DEC PDP-10 mainframe. They programmed the game in their spare time, accessing the computer labs in the evenings. If they hadn't made it, massively multiplayer online adventures like EverQuest and World of Warcraft may never have happened. \nThere had been other fantasy adventure games before MUD, of course. Will Crowther's Colossal Cave Adventure arrived in 1975, while work on Zork, developed by a bunch of MIT students in the university's dynamic modelling group, began in 1977. These single-player programs were, in turn, heavily inspired by the pencil and paper role-playing game Dungeons and Dragons, which had been hugely popular in student circles since its publication in 1974. Bartle, however, wanted to capture the social element of D&D in computer form, he wanted participants to play together on emerging telecommunications networks. So he and Trubshaw made MUD, allowing multiple users to log into a mainframe and go on fantasy quests together.\u00a0\nBartle had been making games and programming computers since the mid-1970s. His formative experiences in coding were courtesy of the DEC PDP-10 owned by British Petroleum's petrochemical works in Brough, East Yorkshire, where he grew up. \"In order to say sorry for filling the air with toxic fumes they let the local schools use their computer,\" he told attendees at the recent GameCity festival. \"We had to fill in these coding sheets, writing in letters using an actual pen. Then we'd send them off somewhere and someone typed them in.\"\nLater, he attended Essex University to study mathematics, but quickly changed to artificial intelligence (AI), a decision guided as much by intellectual pride as it was by interest. \"There were 200 people studying maths at Essex and two of them were better than me,\" he says. \"But on the artificial intelligence course, there were none better than me so I switched to that. There were only three universities in Britain doing AI back then - Essex, Sussex and Edinburgh - the rest were shut down because they'd been told by a physical professor named Dr Lighthill that AI was a useless subject that would never be important\".\nBefore Essex, Bartle had been experimenting with internet connectivity on BP's computer, using an ancient 110 baud modem (\"it could transmit roughly 11 characters a second. You had to be very efficient with your coding\"); the programs he created were stored on paper tape. But Essex had a comparatively advanced set-up. \"The computer was the size of a room,\" he says. \"It had false floor panels under it that were filled with 29 carbon dioxide canisters. If there was a fire they'd all go off at once to put it out really quickly. It would also have put out all the operators, too, but they were cheaper than computers.\"\nExperimenting with this giant system, Roy Trubshaw discovered a mechanism for sharing code across separate teletype machines - an early version of the computer terminal - using an area of memory they weren't supposed to be writing to. In short, it allowed several people to access the same program running on the mainframe at the same time. From here, the duo decided to create a fantasy adventure; Trubshaw wrote the physics, Bartle wrote the game code. The result was MUD. \nThey called it a multi-user dungeon, because of Zork. \"The version we all played ran in [the programming language] Fortran and was just called Dungen because you could only use six character words. Back then we thought all games would be called dungeons, so ours was a multi-user dungeon. Turned out they were all going to be called adventures so we should have called it MUA.\"\nThe duo ran the game over the university network, which was connected to British Telecom's Experimental Packet Switching System, which could also be accessed by other UK universities. Bartle and Trubshaw used this to link in to the University of Kent, and from there establish a connection with the US-led ARPAnet, an early precursor to today's global internet. \"People had never played any sort of shared world before,\" says Bartle. \"You can't imagine what it was like, you were playing a game and suddenly another real person would enter.\"MUD spreads\nVery quickly, keen computer hobbyists and hackers found out about the game and started dialing in to it from outside the university. The system couldn't cope - Essex only had six modems and these were quickly overstretched. \"The gamers clubbed together to buy the university a bank of 12 modems,\" says Bartle. The computing press started paying attention - Bartle wrote a cover feature on the game for Practical Computing, explaining the creation of MUD and defining his hopes for the future of the genre:\n What I would like to see - and it's a long, long way off - is some local or national network with good graphics, sound effects and a well designed set of worlds of varying degrees of difficulty. In this true meritocracy, you will forever be encountering new situations, new difficulties, new solutions, and above all new people. Everyone starts off on an equal footing in this artificial world. \nHe was, of course, imagining the actual future of the massively multiplayer online role-playing game; the possibilities were always there in Bartle's mind. But there was one thing he and Trubshaw never did. They never sought to copyright their game or their technology. Instead they shared it freely. \n\"We encouraged people to write their own MUDs,\" he says. \"We made MUD because the real world sucked. We weren't supposed to be at university - Roy was from Wolverhampton, I was from Yorkshire and sounded like I should be working on a farm. It wasn't a great atmosphere; we were looked down on because other people were at university for intellectual subjects not mind-numbing technology. We raged against that.\"\n\"You shouldn't have to be what the world defines you to be. You should be who you really are - you should get to become yourself. MUD was a political statement, we made a world where people could go and shed what was holding them back.\"\nMUD did indeed proliferate. Other programmers at other universities took the basics of the network code and game design and evolved them. Through the 80s and 90s, several variations were developed and adopted including AberMud, TinyMud (which was more geared toward the social rather than gaming side of virtual worlds) and DikuMud. \nThe latter, built by a group of students at the University of Copehagen, was the most stable and easy to install - it was written in the common programming language C and could run on all Unix systems, so spread easily. It also neatly tied together all of the conventions of quest-based multiplayer role-playing games: players took on a specific class of character - fighter, wizard, thief, etc - then \"leveled up\" by killing enemies with a range of weapons and spells, before collecting experience points and loot.\nFor Bartle, this structure was, itself, a comment on the stifling class system. But in MUD, progression was based on merit, not parentage. \"If you saw someone was at a certain level, it said something about them - about their skill and strength of character,\" says Bartle. \"It was a way for players to understand their place in the hierarchy and to see that they could always progress - there were no glass ceilings. But it wasn't really a meritocracy either because, if you didn't care about your leveling up your character, you didn't need to, you could still play. It was about freedom.\"\nPolitics aside, the raw structure of MUD would influence most subsequent graphical multiplayer online games such as Ultima Online, EverQuest, and World of Warcraft. And it was that initial decision not to protect MUD as an IP that secured its place as a key progenitor. As Bartle explains, \"By the time the games companies got interested in making mutiplayer online games in the late 90s, there were 100 MUD experienced designers for every one who was experienced in one of the other multi-user games that had been invented, because it was all free.\"\nBartle is still at Essex University. He's now a professor and senior lecturer in game design; he also consults in game development. He retains that pervading belief that games are positive and empowering. While society often wonders about their negative effects, he sees in them a model for tolerance and ethical behaviour.\n\"The original hacker ethic was, you can do what you like as long as you don't hurt anyone else. That fed into games and it has propagated outwards,\" he says. \"The more games you play the more sense you have of things like fairness - if you play an unfair game it's no fun, it's not a good game. I think that makes you more resistant to examples of unfairness in the real world. You may start to think, why shouldn't gay people get married, what the hell, it doesn't effect me? \n\"I hope that some of the culture that came out of games has affected the real world.\"\n\n"},
{"docid": "25 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "November 7, 2014", "title": "Can Chappie rescue intelligent-robot movies?; Hopes are high for Neill Blomkamp's forthcoming robot-adopted-by-humans offering, but Big Hero 6 and Automata prove it's tricky terrain\n", "content": "It's looking like a mixed year for intelligent-robot movies. Disney Animation's hyper-stylised, Japanophile Big Hero 6 should provide an offbeat take on the all-CGI superhero film, like an anime imagined by Pixar, but Spanish effort Automata proved a desperately disappointing misfire earlier this year, despite its promising Asimovian leanings. Now comes the long-awaited Chappie, which promises to be a 21st century Short Circuit - if the cult 1980s action-comedy romp had been set in Johannesburg and co-starred Die Antwoord.\nThis is far from director Neill Blomkamp 's first robot rodeo. His 2004 short Tetra Vaal plays out like an ad for a new and terrifying mechanised police force, while 2006's Adicolor Yellow is the Blade Runner-esque tale of a human-like robot who escapes from his creators and goes on the run. Best of the bunch is 2006's Tempbot, which beautifully satirises the spirit-crushing ennui of office environments by imagining a robot struggling to connect with homo sapiens co-workers who often seem as bereft of humanity as he is.\u00a0\nBlomkamp's last film, Elysium, felt in some ways like a Hollywoodised take on his breakthrough movie District 9, the introduction of A-list American stars substantially reducing the sense of grimy realism. Chappie sees the film-maker back on the streets of South Africa, with a cast that mixes local talent with Hollywood stars Dev Patel, Hugh Jackman and Sigourney Weaver. The robot himself is voiced by Blomkamp regular Sharlto Copley.\nPatel, best known for Slumdog Millionaire, plays a scientist who has programmed Chappie with artificial intelligence, and yet the relationship between the robot and his creator is more akin to father and son. Chappie's ability to think for himself elicits joyous awe from his human \"family\", and there's little sense that the robot presents any danger. When Jackman, playing a mulleted meanie named Vincent, expresses concern that Chappie might be unpredictable, he is presented as a villain rather than the voice of reason.\nAt a time when the debate on killer robots and artificial intelligence has never been more pertinent, this first look at the movie seems to be coming from the opposite end of the argument. The humans in Chappie take great pleasure in introducing their new friend to art and culture, while encouraging his own efforts to create. It's as if parenting is being presented as a metaphor for the passing on of the sentient torch from man to robot. Just as a father encourages his son to learn the skills that may one day see the younger man surpass him, so it is suggested we should have no fear of the creatures that may one day inherit the Earth.\nIt's an intriguing take, suggesting an ET-like robot movie with a Spielbergian sense of optimism about the unknown that will hopefully avoid the mawkish sentimentality of the US film-maker's own AI. But who's to say that Vincent, dodgy barnet and all, isn't the true hero here? Blomkamp's earlier short film work on the subject hints there is likely to be more complexity to Chappie's story than we see in this first trailer. The fundamental weakness in the metaphor here is that intelligent robots may not be our mechanised children. They will not look like their human parents, may not think like them and are by no means certain to share their moral values.\nIf Chappie can reflect this otherworldliness to present a vision of the future that we have not yet seen, it promises much. If it is just another movie in which mankind fails in the most basic tests of humanity when confronted by something alien to himself, I think we've all seen that one before.\n"},
{"docid": "26 of 297 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "March 29, 2017", "title": "Microchips in human brains 'will prevent a robot takeover'\n", "content": "THE billionaire tech entrepreneur Elon Musk is launching a company to investigate implanting microchips into the brains of humans to connect them to computers.\u00a0\nSouth African-born Mr Musk, 45, initially made his fortune by founding PayPal, before moving on to start the Tesla car company and SpaceX, which aims to send humans to Mars.\nHe is also working on Hyperloop - high-speed shuttle travel in a tube, with a plan to make the 350-mile journey between Los Angeles and San Francisco in 35 minutes.\nMr Musk yesterday said that, with five children and a range of ambitious projects already in progress, it was \"difficult to dedicate the time\" to his new company, Neuralink. But, he added, \"Existential risk is too high not to.\"\nMr Musk has previously spoken of his belief that mankind's failure to advance artificial intelligence could allow the robot to take over. He sees his project as insurance against such an event. First, however, the company plans to use its technology to treat brain disorders such as epilepsy, depression and Parkinson's.\nThe company is thought to be working on \"direct cortical interface\" - essentially a layer of artificial intelligence inside the brain - that could enable humans to reach higher levels of function. Mr Musk has previously called the rise of artificial intelligence (AI) humanity's \"biggest existential threat\". But he believes that nanobot brain implants are a viable solution to machines rising up against humans.\n"},
{"docid": "27 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "May 28, 2016", "title": "Professor 'staggered' by sexism of computer scientists\n", "content": "One of Britain's leading computer scientists has criticised the \"staggering sexism\" in the industry, citing a visit to an artificial intelligence laboratory where a prototype of an \"enhanced human\" was entirely male.\u00a0\nUrsula Martin, a professor of computer science at Oxford University, said that despite attempts to redress the problem, there was still an anti-female bias.\nShe said that universities had attempted to encourage more women to enrol on science and mathematics courses, admitting that the institutions \"did not always get it right\" but they did try to remove obstacles. Ms Martin said that she had been shocked during a visit to the Microsoft research laboratory in Cambridge on Thursday to discover the attitudes prevalent in young male computer scientists.\n\"I was absolutely staggered at the sexism on show,\" she told the Hay Festival in Hay-on-Wye in Powys.\nShe said that during the symposium on artificial intelligence, Microsoft had given a presentation of its \"vision of what an enhanced human would be\".\n\"This [new human] was faster and more physically energetic. This was so clearly a male type of enhanced human.\nThis vision of a new kind of humanity was an entirely male vision.\"\nShe said that after she had bawled out the employee making the presentation about the absence of female attributes, he had responded: \"I suppose.\"\nMore women are attending science courses at schools and universities although it is proving harder to turn them into more lecturers and professors. Social media campaigns have drawn attention to sexism in science.\nLast year one of Britain's most distinguished scientists was, in his words, \"hung out to dry\" after making comments perceived as sexist. Sir Tim Hunt, a Nobel prizewinner, was dismissed from several posts, including an honorary position at University College London, and subjected to online abuse after suggesting that men and women should work in different laboratories because females cried a lot. He insisted that the remarks were jocular.\nThe dispute bitterly divided the science community.\nMs Martin, who was at Hay speaking about Ada Lovelace, a 19th-century computing visionary who was not credited for her work until recent years, said that she thought \"people were making enormous attempts to counter this [sexism]\" but it was clear there was a lot more to do. Even in recent years Lovelace has received biographical attention for being the daughter of Lord Byron, rather than as one of the founding parents of computing.\nNumerous attempts have been made in recent years to redress the perceived slights to female scientists of the past.\nNicole Kidman played the lead role last year in the West End production of Photograph 51, a play about the life of Rosalind Franklin, who is thought by some to have never received the credit for her work on DNA. The Nobel prizewinners James Watson and Francis Crick are thought to have seen her image of DNA but never credited her work.\n"},
{"docid": "28 of 297 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "November 27, 2017", "title": "Elon Musk says backflipping robot is 'nothing' compared to bots so advanced humans will struggle to see them; The Tesla founder is worried that people will unintentionally develop something unsafe\n", "content": "Elon Musk has issued a new warning about advanced machines.\nThe Tesla founder, who has been highly critical of artificial intelligence developers over recent months, has revealed his thoughts on Atlas, the backflipping humanoid robot.\u00a0\nA video released by Boston Dynamics earlier this month shows the machine backflip off a raised platform, land perfectly on its feet and raise its arms in the air as if to celebrate.\n\"This is nothing,\" Mr Musk tweeted in response to the footage. \"In a few years, that bot will move so fast you'll need a strobe light to see it. Sweet dreams...\"\nAfter being asked to clarify exactly what he meant by the strobe light comment, he added, \"Otherwise you'd only see a blur.\"\nHe then followed this up with an update calling for the regulation of AI and robotics, something he believes to be not only necessary but urgent.\n\"Got to regulate AI/robotics like we do food, drugs, aircraft & cars. Public risks require public oversight. Getting rid of the FAA wdn't make flying safer. They're there for good reason.\"\nAs pointed out by Fran\u00e7ois Chollet, a machine learning and artificial intelligence software engineer at Google, Atlas isn't an AI bot.\nI think this is meant as a commentary on the progress of AI, so it's worth remembering that Atlas is 100% hardcoded, it involves no learning or anything that would qualify as AI these days. It's classical control theory https://t.co/Zw4ldgrlfR\n- Fran\u00e7ois Chollet (@fchollet) November 27, 2017\nHe believes Mr Musk's comments are supposed to be less literal, and instead apply to the progress of AI development.\n                     Mr Musk has made no secret of his belief that AI will be a threat to people, last week saying we have a \"five to 10 percent chance\" of making it safe.\nHe has also repeatedly called for the companies working on AI to slow down to ensure they don't unintentionally build something unsafe, and says he's worried that a handful of major companies will end up in control of AI systems with \"extreme\" levels of power.\n"},
{"docid": "29 of 297 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "September 12, 2011", "title": "The really free schools are online; An Ivy League degree is worth a fortune, so why is one top US college giving away a course online at no cost? And they're not the only ones, discovers Rhodri Marsden\n", "content": "The internet is often scorned for its wealth of mild amusement and inconsequential distraction, but it's still an incredible source of knowledge. \nBut can a quality education be delivered online? And, more to the point, how much would it cost? In just over a month's time (10 October), Stanford University is launching three free online courses - Introduction to Artificial Intelligence, Introduction to Databases and Machine Learning - that are open to all, taught by eminent scientists, involve study, homework and exams, and are rewarded with a \"statement of accomplishment\", should you complete them. It's been described as a \"bold experiment in distributed education\", and so far more than 135,000 people have signed up to take the Artificial Intelligence class alone. \u00a0\nProfessor Sebastian Thrun, one of its teachers, has expressed delight at the prospect of addressing more students in a few short weeks that in his entire career, but what is Stanford's \"statement of accomplishment\" worth? And does it signal a new direction in the provision of education? Universities began putting course material online using software such as Moodle, while organisations such as the Coventry -based Resource Development International (RDI) extended that by working in partnership with educational institutions to offer complete courses and degree qualifications via the internet. \"The internet has been an absolute godsend for our students,\" says Niall Sclater, director of learning, teaching and quality at the Open University. \"There's information instantly at their fingertips, there's the ability to connect with other students and huge administrative benefits in terms of assessment. If the Open University had been founded today, the whole thing would have been formed around the internet.\" \nStanford's experiment sits midway between two online educational strands. Firstly, the provision of courses (or parts of courses) that are paid for, supported by tutors and from which you emerge with a recognised qualification. Secondly, the archiving of huge quantities of educational resources that the public can consume for free, such as lessons on YouTube or iTunes, The Khan Academy's extensive collection of maths and science lectures, or Yale's Open Courses; no traditional support or qualifications, just world-class teaching material absorbed in your own time. Stanford's project combines that wide dissemination with a marking and support system that's designed to cope with many thousands of students. \n\"It's almost as easy to deliver an online course to 10,000 people as it is to deliver it to one person,\" says Stanford's Andrew Ng, associate professor of computer science. But Niall Sclater isn't convinced. \"It's an excellent idea, but it's going to be difficult to assure quality.\" he says. \"There'll be any number of opportunities for copying and impersonation. It's a kind of self-certification and to an employer it's worthless.\" Stanford certainly couldn't be criticised for the quality of its material, however. This is no single camera pointing at a mumbling lecturer. It's interactive, engaging multimedia material, broken up into 15-minute chunks. And while detractors may scorn the way this seems to pander to the supposed decreased attention spans of the internet age, it's widely acknowledged that we simply absorb information better this way.\n\"Traditional lectures aren't regarded as great ways to impart knowledge to students,\" says Sclater. \"If you test them some time after the lecture, there's very little that they retain.\"Dr Lynne Harrison, director of teaching and learning at Cambridge University's Institute of Continuing Education (ICE), agrees. \"A good lecturer will change the tempo after 15 minutes and the internet allows that to happen more naturally. The technology that Stanford has put in place makes lectures more watchable and we're looking at doing a similar thing for our free online courses launching next spring.\"\nThose free courses from Cambridge's ICE will be intense and informative, but won't have assessment - unlike its current paid-for courses that offer full teaching support.\n\"That constant communication channel is really important for our current students, who are part-time and have to balance workloads and families,\" says Harrison. \"It marks the difference between offering free resources to people and actually teaching them.\"\nStanford has emphasised that technology is in place to allow students to feed back and ask questions of their teachers. \"They'll be able to answer each other's questions,\" says Ng, \"and vote others' questions up and down. Instructors will personally answer each of the top-rated questions.\" But with 135,000 students or more, that process doesn't feel particularly nurturing. \"The mechanism seems more designed to help Stanford improve the course,\" says Harrison, \"than to help the students.\"  Support, then, will be driven by the student community, something most free online courses have failed to harness. \n\"People tend to delve into Open University's 600 free online courses for specific information and don't necessarily want to be part of a learning community,\" explains Sclater. \"But as soon as you have some kind of assessment and a cohort of students going through the course at the same time, viable communities develop.\"\nOpen University's virtual learning environment, for example, has more than 50,000 users hitting it every day at peak times and Stanford's dedicated forums promise to be very busy during the next few weeks. But is this kind of interaction comparable to the social experience of being at university? Students of the future may well end up discussing topics via chatroom and webcam and the impact of that on the learning experience is hard to quantify. Phil Hallam, CEO of distance learning veterans RDI, acknowledges that it's a very different life experience to attending a bricks-and-mortar institution, but stresses its increasing importance in the education sector. \"99 per cent of our students are employed,\" he says. \"The majority pay for themselves, so they take the whole process very seriously. And with fee increases in England, many are considering online learning as an alternative. We deliver courses much cheaper - \u00a36,000 to \u00a310,000 for the full three years.\" Susannah Marsden, director of academic services at City University London, agrees with Hallam's prediction. \"As technology is such an integral part of teenagers' lives, choosing a course which is delivered solely online may well become a more attractive option,\" she says. \"A number of universities may also consider developing such online-only provision as a way of expanding their potential markets, as the landscape after 2012 is somewhat unknown.\"\nBut while universities might make savings on buildings and infrastructure, Marsden's colleague Susannah Quinsee, professor of learning and teaching development, stresses the importance of producing well-structured online material, which is by no means cheap. \"Merely putting up a load of PowerPoint presentations on the web isn't enough to engage people,\" she says. \"We've seen with courses taught in blended mode - a mixture of online and classroom-based interaction - that if the online elements just replicate or repeat face-to-face sessions, attendance can become a problem.\n\"Designing good online material requires a different approach and skillset from teaching face to face.\"\nThe developments at Stanford, Yale, Cambridge and Open University raise the question of where the value of education really lies; whether content is secondary to the interaction between students, their fellow students and their tutors. The thousands of enthusiasts taking Stanford's three courses this Autumn will receive quality instruction from eminent thinkers and many will finish it with a burning enthusiasm to investigate more deeply; in that sense the \"statement of accomplishment\" is neither here nor there. But those who, on receiving it, realise that it's not worth the PDF it's contained within, only need ask themselves how much the course cost them. As with everything in life, you get what you pay for.\n"},
{"docid": "30 of 297 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "February 14, 2014", "title": "Google overtakes Intel as world's biggest dealmaker\n", "content": "ONCE it was a mere search engine, but after a series of acquisitions, ranging from a digital-thermostat maker to an artificial intelligence developer, Google is now the world's biggest dealmaker.\u00a0\n It has been involved in 127 agreements in the past three years, including acquisitions, investments and divestments - more than double the number in the preceding three years, according to data compiled by Bloomberg.\n The company has supplanted Intel, which led the previous three-year period with 104 deals but has dropped to third place, with 121 transactions, and has been overtaken by advertising firm WPP.\n Google has ramped up its acquisition process since the appointment of Larry Page as chief executive in 2011, investing in connected devices, business services and mobile applications. Google Ventures has become a big start-up spender, while a new group, Google Capital, backs later-stage companies.\n Acquisitions have included thermostat maker Nest Labs, for $3.2bn, mapping-software provider Waze for almost $1bn, robotics firm Boston Dynamics for an undisclosed sum, and London-based artificial intelligence developer Deep-Mind for a reported \u00a3400m. \"It is absolutely starting to feel like a deal machine,\" said Maha Ibrahim, a partner at venture firm Canaan Partners.\n Google's venture division was also involved in the two biggest private funding rounds for US technology companies in 2013 - online questionnaire service SurveyMonkey, which raised around $444m, and taxi-booking app Uber, which raised $361.2m. Meanwhile, Google agreed to sell its Motorola handset business to Lenovo last month for $2.91bn and last year sold Motorola's set-top box business for $2.24 billion.\n Although Google was the biggest dealmaker by volume over the three years, its $17.6bn total was eclipsed by General Electric at $19.9bn and Blackstone Group LP at $62.3bn.\nGooglewhack Firm's corporation tax bill doubles\n Google paid almost twice as much corporation tax from its non-US profits last year compared with the previous year, regulatory filings have disclosed.\n The internet giant, which has faced criticism over tax avoidance in Britain and other international territories, paid out a total of $771m (\u00a3463m) on combined foreign profits of $8.7bn. That compares with $432m in 2012, but still represents a tax rate of less than 9pc. The reason for the increased bill was not disclosed.\n Google channels its international profits to a subsidiary in Bermuda which funds capital investments.\n The filings also showed that the company's sales in Britain, Google's biggest non-US market, rose by more than 14pc to $5.6bn.\n"},
{"docid": "31 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "September 28, 2017", "title": "It's a robot revolution but you don't need to man the barricades\n", "content": "Dire predictions of a dystopian future in which super-robots steal our jobs are wide of the mark, according to a report which predicts a rise in demand for work that requires uniquely human skills, such as the ability to be sociable and bright.\nAbout one in ten workers, including many in occupations traditionally seen as low skilled, can expect to grow in importance by 2030, according to the Future of Skills report. These include hospitality, leisure, personal and health care, social work and service jobs that require people to engage with customers, as well as food preparation, shelf stacking and street cleaning.\u00a0\nIt also predicts a re-emergence of artisanal employment in occupations such as barbering, brewing and textiles.\nThe report attempts to inject an element of optimism and historical perspective into a debate that often descends into one of \"doom and gloom\". The first three industrial revolutions, based on steam (in the 18th to 19th centuries), electricity (1870 to 1914) and the computer (1980 onwards), have all been accompanied at certain moments by predictions of massive reductions in paid employment that were never fully realised.\nThe fourth industrial revolution, based on robotics, artificial intelligence and nanotechnology, is already upon us in the form of selfdriving vehicles, surgical robot assistants and service robots, bringing improvements in everything from healthcare to military logistics. But its beginnings have been accompanied by a wave of dystopian fears about AI that often cloud a serious discussion about its regulation and the appropriate policy response. The report takes issue with widespread predictions that 40 to 60 per cent of jobs could be lost to robotics and artificial intelligence by 2030, as manufacturing jobs, as well as many white-collar roles involving routine information processing, calculation and decision making, are automated.\nIts authors believe the true figure is likely to be closer to 20 per cent and suggest that technological advances, combined with retraining, will enable existing jobs to be redesigned and saved.\nPerhaps surprisingly, the report, prepared by Nesta, an innovation foundation, the Oxford Martin school of the University of Oxford and Pearson, the education publisher, predicts that expertise likely to be in greatest demand will be in disciplines such as psychology, sociology, anthropology, philosophy, history and theology.\nScience, technology, engineering and mathematics subjects, while still in demand, are likely to be less important than many imagine, as certain tasks, such as programming and statistical analysis, are automated.\nJohn Fallon, chief executive of Pearson, said: \"The future of work is brighter than conventional wisdom suggests. It is not going to be human versus machine, but rather human and machine. Look at the challenges that social media companies face. It's no longer enough to have good algorithms. You have also to understand the wider policy implications of what you are doing. Similarly, advances in genetics require an understanding of ethics.\"\nMr Fallon stressed that universities, schools and employers needed to be willing to redesign existing jobs in response to technological advances and to teach the kind of analytical, problem-solving, social, communications and creativity skills that were least likely to be automated. Last year Stanford University in California suggested that the fourth industrial revolution would require a political rather than a purely economic response in which informed public debate is more important than a blind reliance on industry experts saying \"trust us\".\nThe future of skills: employment in 2030  ;  ;  Numbers in jobs where workforce is predicted to grow Teaching and educational Food preparation and hospitality Other elementary services occupations Public services and other associate professionals Managers and proprietors in hospitality and leisure Artistic, literary and media Natural and social science Engineering Sports and itness Electrical and electronic trades Health and social services managers and directors Media Therapy  ;  ;  899,725 342,311 282,892  ;  ;  167,241  ;  ;  149,439  ;  ;  147,455 124,898  ;  ;  95,267  ;  ;  106,242  ;  ;  58,081  ;  ;  39,088  ;  ;  31,816 27,945  ;  ;  people in the UK are in jobs that are highly likely to fall in numbers  ;  ;  6.7m  ;  ;  people likely to experience a rise in demand for their job  ;  ;  2.5m  ;  ;  people in jobs with uncertain future  ;  ;  22.2m  ;  ;  Sources:  ;  ;  Nesta,  ;  ;  Oxford  ;  ;  Martin,  ;  ;  Pearson  ;\n"},
{"docid": "32 of 297 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "February 7, 2018", "title": "When AI is used in medicine patients will need new protections; The NHS has a unique store of millions of medical records providing an unparalleled resource from which, with the use of digital techniques, we may speed progress to the next breakthroughs - so why was a tobacco company allowed to access it for its own gains?\n", "content": "For Elon Musk, the term artificial intelligence conjures apocalyptic scenarios of autonomous robots wreaking destruction in a world dominated by hyper-intelligent machines. Stephen Hawking foresees a future in which smart machines replace sluggish humans across a range of activities, driving millions out of work. Last month Bill Gates, speaking at the World Economic Forum in Davos, imagined a gentler future - one with longer holidays and more free time.\n\"The purpose of humanity is not just to sit behind a counter and sell things,\" he said.\u00a0\nWe can all speculate about the future. Will.i.am, the Black Eyed Peas singer, has been promoting his first novel this week, an action adventure called \nWaR: Wizards and Robots\n. Despite its title, he told an audience in Davos last month that artificial intelligence would be a force for good, narrowing the wealth gap between rich and poor countries.\nRead more\nThis is the real difference between the UK and US healthcare systems\nWe must hope it can also narrow the health gap. Healthcare provides especially fertile territory for these advances because of the sheer volume of medical knowledge. No clinician, however smart, can hope to master it. McKinsey has estimated potential savings of up to $100bn(\u00a372bn) in the US Healthcare sector alone from developments in artificial intelligence. The aim is not to replace the doctor (yet, at least) but to enhance their medical expertise.\nAt the same time, treatment can be democratised and spread equally to all. Why rely on one doctor's opinion when you can share thousands, culled from databases of their knowledge and the key studies they rely on? Rural dwellers, living far from medical facilities, may be able to enjoy the same level of expertise as their urban counterparts and, ultimately, those in low income countries may benefit from the same expert input as those in the industrialised world.\nSupporting doctors to diagnose disease is a key area of research. Mobile apps to help patients track changes in their health and respond appropriately are bringing quicker treatment and lower costs. Employing machine learning to identify new chemical agents is speeding up drug development and shaping clinical research.\nTo reap these benefits, however, scientists need access to data. Data is as vital to machine learning as coal was to the railways and oil to the motorcar. However, the potential for abuse of data is real.\nAs a surgeon and researcher I was dismayed by the revelations last month that William E Wecker Associates, a company working for the tobacco industry, obtained the lung cancer records of almost 180,000 patients from Public Health England.\nThe NHS has a unique store of millions of medical records providing an unparalleled resource from which, with the use of digital techniques, we may speed progress to the next breakthroughs in medical science and transform care. That such a uniquely valuable resource should now be plundered on behalf of a tobacco manufacturer seeking to defend their cancer-causing products is simply shameful.\nIt remains unclear whether any rules were broken by the company in question, which has testified on behalf of tobacco giants in dozens of lawsuits. Or indeed by Public Health England, which maintains it was under a legal duty to release the information when it was requested under the Freedom of Information Act.\nBut our failure to protect our medical data from misuse is symptomatic of a wider malaise - our failure to value it. Incidents such as these undermine patients' trust and set back the cause of research.\nThe challenge, then, is to devise a system of data governance that protects the interests of patients, provides access for researchers, distributes the fruits of success fairly and wins the confidence of the public. If we are to generate the growth that these innovations could deliver we need to demonstrate why data sharing is a social benefit, as necessary to the public good as taxes.\nThe Government published its industrial strategy in November 2017 in which it set out a plan to create an Artificial Intelligence Council and a Centre for Data Ethics and Innovation, demonstrating its commitment to an ethical approach.\nThis is welcome but we need to go further. Public trust demands more transparency. We need a health specific Data Charter, with clear rules, norms and standards, setting out what can be done, what should be done and what may not be done.\nThere are huge opportunities in these technologies to advance healthcare, benefit health systems and improve the outlook for millions of patients. But unless we establish clear rules from the outset we risk sacrificing public trust, surrendering vital clinical gains and squandering the potential in the vast quantities of medical data we have spent decades accumulating.\nLord Darzi of Denhamis a surgeon and director of the Institute of Global Health Innovation at Imperial College London. He was a Labour health minister from 2007-9. \n"},
{"docid": "33 of 297 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "February 17, 2017", "title": "Facebook is developing tools to read through people's private messages, Mark Zuckerberg manifesto suggests; The social network is working on systems that will 'identify risks' by looking through communications, the essay suggested\n", "content": "Facebook is secretly building artificially intelligent systems that can read people's private messages, according to a major manifesto published by Mark Zuckerberg.\nThe Facebook CEO posted a 6,000-word essay in which he worried about the end of globalisation and seemed to suggest that Facebook would be necessary for the future safety of the world. But it didn't include one paragraph that had been expected to be part of it - apparently as a result of the worrying features it suggested the social network was developing.\u00a0\nIn one version of the text, Mr Zuckerberg wrote about the fact that Facebook appeared to be using artificial intelligence for online surveillance. It could eventually develop robots that would read through people's private messages and check for anything that it deems worrying, the manifesto read.\nAn early version of the piece read: \"The long term promise of AI is that in addition to identifying risks more quickly and accurately than would have already happened, it may also identify risks that nobody would have flagged at all - including terrorists planning attacks using private channels, people bullying someone too afraid to report it themselves, and other issues both local and global. It will take many years to develop these systems.\"\nRead more\nMark Zuckerberg urges people to act against backlash to globalisation\nThe manifesto was distributed to news organisations before the announcement was made publicly, and included that paragraph when it was. But when Facebook issued the statement, that text had been removed.\nLater, it was replaced with a different, less specific paragraph. \"Looking ahead, one of our greatest opportunities to keep people safe is building artificial intelligence to understand more quickly and accurately what is happening across our community,\" it read.\nOther parts of the document made reference to security, and said that it wouldn't be necessary to compromise on privacy to to keep people on Facebook safe. He mentioned the encryption that is built into WhatsApp and Facebook Messenger, which means that in fact it isn't possible for Facebook's AI to read messages sent through those platforms, so long as it is turned on.\n"},
{"docid": "34 of 297 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "January 26, 2016", "title": "Marvin Minsky dead: 'The world has lost one of its greatest minds in science'; Legendary cognitive scientist who pioneered artificial intelligence thrived even when the field suffered hardtimes\n", "content": "Marvin Minsky, a legendary cognitive scientist who pioneered the field of artificial intelligence, died Sunday at the age of 88. His death was announced by Nicholas Negroponte, founder of the MIT Media Lab, who distributed an email to his colleagues:\nWith great great sadness, I have to report that Marvin Minsky died last night. The world has lost one of its greatest minds in science. As a founding faculty member of the Media Lab he brought equal measures of humour and deep thinking, always seeing the world differently. He taught us that the difficult is often easy, but the easy can be really hard.\nIn 1956, when the very idea of a computer was only a couple of decades old, Minsky attended a two-month symposium at Dartmouth that is considered the founding event in the field of artificial intelligence. His 1960 paper, \"Steps Toward Artificial Intelligence,\" laid out many of the routes that researchers would take in the decades to come. He founded the Artificial Intelligence lab at MIT, and wrote seminal books - including \"The Society of Mind\" and \"The Emotion Machine\" - that colleagues consider essential to understanding the challenges in creating machine intelligence.\nYou get a sense of his storied and varied career from his home page at MIT:\u00a0\nIn 1951 he built the SNARC, the first neural network simulator. His other inventions include mechanical arms, hands and other robotic devices, the Confocal Scanning Microscope, the \"Muse\" synthesizer for musical variations (with E. Fredkin), and one of the first LOGO \"turtles\". A member of the NAS, NAE and Argentine NAS, he has received the ACM Turing Award, the MIT Killian Award, the Japan Prize, the IJCAI Research Excellence Award, the Rank Prize and the Robert Wood Prize for Optoelectronics, and the Benjamin Franklin Medal.\nOne of his former students, Patrick Winston, now a professor at M.I.T., wrote a brief tribute to his friend and mentor:\nMany years ago, when I was a student casting about for what I wanted to do, I wandered into one of Marvin's classes. Magic happened. I was awed and inspired. I left that class saying to myself, \"I want to do what he does.\"\n                     M.I.T.'s obituary of Minsky explains some of the professor's critical insights into the challenge facing anyone trying to replicate or in some way match human intelligence within the constraints of a machine:\nMinsky viewed the brain as a machine whose functioning can be studied and replicated in a computer - which would teach us, in turn, to better understand the human brain and higher-level mental functions: How might we endow machines with common sense - the knowledge humans acquire every day through experience? How, for example, do we teach a sophisticated computer that to drag an object on a string, you need to pull, not push - a concept easily mastered by a two-year-old child?\nHis field went through some hard times, but Minsky thrived. Although he was an inventor, his great contributions were theoretical insights into how the human mind operates.\nIn a letter nominating Minsky for an award, Prof. Winston described a core concept in Minsky's book \"The Society of Mind\": \"[I]ntelligence emerges from the cooperative behavior of myriad little agents, no one of which is intelligent by itself.\" If a single word could encapsulate Minsky's professional career, Winston said in a phone interview Tuesday, it would be \"multiplicities.\"\nThe word \"intelligence,\" Minsky believed, was a \"suitcase word,\" Winston said, because \"you can stuff a lot of ideas into it.\"\nHis colleagues knew Minsky as a man who was strikingly clever in conversation, with an ability to anticipate what others are thinking -- and then conjure up an even more intriguing variation on those thoughts.\nJournalist Joel Garreau on Tuesday recalled meeting Minsky in 2004 at a conference in Boston on the future evolution of the human race: \"What a character! Hawaiian shirt, smile as wide as a frog's, waving his hands over his head, a telescope always in his pocket, a bag full of tools on his belt including what he said was a cutting laser, and a belt woven out of 8,000-pound-test Kevlar which he said he could unravel if he ever needed to pull his car out of a ravine.\"\nMinsky and his wife Gloria, a pediatrician, enjoyed a partnership that began with their marriage in 1952. Gloria recalled her first conversation with Marvin: \"He said he wanted to know about how the brain worked. I thought he is either very wise or very dumb. Fortunately it turned out to be the former.\"\nTheir home became a repository for all manner of artifacts and icons. The place could easily merit status as a national historical site. They welcomed a Post reporter into their home last spring.\nThey showed me the bongos that physicist Richard Feynman liked to play when he visited. Looming over the bongos was 1950s-vintage robot, which was literally straight out of the imagination of novelist Isaac Asimov - he was another pal who would drop in for the Minsky parties back in the day. There was a trapeze hanging over the middle of the room, and over to one side there was a vintage jukebox. Their friends included science-fiction writers Arthur C. Clarke and Robert Heinlein and filmmaker Stanley Kubrick.\nMinsky said Turing brought respectability to the idea that machines could someday think (Getty)\nAs a young scientist, Marvin Minsky lunched with Albert Einstein but couldn't understand him because of his German accent. He had many conversations with the computer genius John Von Neumann, of whom he said:\n\"He always welcomed me, and we'd start taking about something, automata theory, or computation theory. The phone would ring every now and then and he'd pick it up and say, several times, 'I'm sorry, but I never discuss non-technical matters.' I remember thinking, someday I'll do that. And I don't think I ever did.\"\nMinsky said it was Alan Turing who brought respectability to the idea that machines could someday think.\n\"There were science-fiction people who made similar predictions, but no one took them seriously because their machines became intelligent by magic. Whereas Turing explained how the machines would work,\" he said.\nThere were institutions back in the day that were eager to invest in intelligent machines.\n\"The 1960s seems like a long time ago, but this miracle happened in which some little pocket of the U.S. naval research organization decided it would support research in artificial intelligence and did in a very autonomous way. Somebody would come around every couple of years and ask if we had enough money,\" he said - and flashed an impish smile.\nBut money wasn't enough.\n\"If you look at the big projects, they didn't have any particular goals,\" he said. \"IBM had big staffs doing silly things.\"\nBut what about IBM's much-hyped Watson (cue the commercial with Bob Dylan)? Isn't that artificial intelligence?\n\"I wouldn't call it anything. An ad hoc question-answering machine.\"\nWas he disappointed at the progress so far?\n\"Yes. It's interesting how few people understood what steps you'd have to go through. They aimed right for the top and they wasted everyone's time,\" he said.\nAre machines going to become smarter than human beings, and if so, is that a good thing?\n\"Well, they'll certainly become faster. And there's so many stories of how things could go bad, but I don't see any way of taking them seriously because it's pretty hard to see why anybody would install them on a large scale without a lot of testing.\"\n\u00a9 Washington Post\n"},
{"docid": "35 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "November 4, 2017", "title": "Robots will force us to be creative, says arts chief\n", "content": "The threat of robots and artificial intelligence taking over jobs performed by humans means that the government must do more to support creative industries as they take in displaced workers, Sir Nicholas Serota has said.\u00a0\nThe head of Arts Council England, which will have distributed \u00a31.8 billion of government and lottery money between 2015 and 2018, argues that people made redundant by automation will need to find new jobs that only humans can do.\nSir Nicholas, 71, who was appointed in February after 28 years as director of the Tate galleries, said that people would welcome the rise of robots provided they had other jobs to go to. \"I think that most people will be quite content to have clerical tasks and other tasks taken over by robots, but basically we need to skill people to work in an adaptable way to changing environments,\" he said. \"Changing in response [to a new job] does require adaptations that are difficult, as I have discovered.\"\nIn an article on The Times's website, he publishes figures that show how creative companies are outperforming the rest of the economy fivefold. The arts and culture industry grew by 10.4 per cent in 2015 while the rest of the economy grew by 2.2 per cent.\n\"As we become aware of the impact automation and artificial intelligence will have on the future workforce, it is clear the skills needed by our cultural and creative industries will become increasingly important to the economy as a whole,\" he writes. \"Creative, digital, design and architectural and engineering occupations are continuing to grow, while roles in manufacturing and other industries face a less certain future in a changing world.\"\nSir Nicholas said he was convinced that greater government funding would be vital to offset the damage done by limiting freedom of movement.\n\"There's undoubtedly a sense for young creatives that there's more opportunity in Spain, Germany, France than there may be in Britain. It's definitely going to be tough on us. Whatever the arrangements are [in a Brexit deal] we will suffer. We need as much freedom of movement of creative talent as it can achieve.\n\"There's a risk that some of our more creative people will go abroad. They'll work in continental Europe or in America. If you don't sow at the right moment then you don't reap the harvest.\" He also said that cultural organisations needed to lead the response to allegations of sexual harassment that are emerging within the entertainment industry and politics. \"I think that arts organisations are no exception [to needing to change their views on sexual harassment] and that they should be leading on this.\"\nRead Sir Nicholas Serota's article on tablet and at www.thetimes.co.uk\n"},
{"docid": "36 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "November 26, 2017", "title": "The man who knows how a 'superhuman' race will disrupt our world - and why it could be here soon\n", "content": "Nick Bostrom, like Bertrand Russell, is eminent as a mathematician and as a philosopher. Unlike Russell, he deals predominantly with how our world awaits transformation by artificial intelligence.\nWhen we spoke earlier this month in the rather intense atmosphere of the Future of Humanity Institute - which he founded and of which he is director - at Oxford University, he made it apparent that the advent of the self-driving car (to give an easily comprehensible example of the use of AI, though one uses it in every Google search or smartphone task) will be but the tiniest part of the revelations, and the revolution, to come.\nThe institute sits within Oxford's philosophy faculty but is home to mathematicians, engineers and computer scientists as well as philosophers. Professor Bostrom is a tall, balding Swede of 44, notable for his study of existential risk and his 2014 book Superintelligence: Paths, Dangers, Strategies .\nIt married the idea of risk with what AI could accomplish and argued that \"the creation of a superintelligent being represents a possible means to the extinction of mankind\". If that makes him sound rather intense - and he exudes a nervous energy and restlessness not always apparent among Oxford dons - then it is worth remembering that he once did stand-up on the London comedy circuit.\u00a0\n.html-embed.component .quote.component{margin-left:0}.html-embed.component .quote.component .component-content{margin-right:16px}.quote__source, .quote__author {white-space: normal;}@media only screen and (min-width:730px){.html-embed.component .quote.component{margin-left:-60.83px}.html-embed.component .quote.component .quote__content:before{margin-left:-12px;padding-right:1px}}@media only screen and (min-width:1008px){.html-embed.component .quote.component{margin-left:-82.33px}}Machine intelligence is the sort of thing that could fundamentally transform the human condition. It's the last invention we would ever have to makeNick Bostrum\nHis interest in artificial intelligence began when he was an undergraduate in Sweden, and he took a course on the subject - because he wanted to understand \"how does a lump of grey matter break down a task into the specific sub-tasks that you need to do to solve it?\"\u00a0\n\"It had struck me for a long time that machine intelligence was the sort of thing that could fundamentally transform the human condition. We're not talking about a cooler iPhone or a more energy-efficient car, but a fundamental transformation. It's the last invention we would ever have to make.\"\nHe agrees that the pace of development of AI has speeded up more than he expected at the time he wrote his book. Therefore, regarding the time when machines might be able to take over, \"there is huge uncertainty about it: the short answer is, nobody knows\". A survey of machine intelligence specialists asked when they thought there would be a 50 per cent chance of machines matching human intelligence.\n\"The median answer was 2040 to 2045. But some were convinced it will happen in the next 10 to 15 years. Others were convinced it will never happen.\"\nNick Bostrom, founder and director of\u00a0the Future of Humanity Institute at Oxford UniversityCredit:      Getty Images     \nWhat about the prospect of someone being able to upload his or her brain on to a computer, so that even after the body has died the mind could live on? \"There is this hypothetical technology of uploading or whole brain emulation. It looks like this is physically possible technology, far beyond what one can do today. It's one of the possible paths towards machine intelligence. If you could digitise a whole human brain then you would have something in a machine that was intelligent.\"\u00a0\nHe believes this will happen, \"but probably after we have achieved machine intelligence by more synthetic means\". By that, he means that artificial intelligence would be required to develop the uploading of a human brain.\nIt is one thing to mimic human intelligence: but what about human consciousness? \"The word 'consciousness' is much more loaded with philosophical ideas. 'Intelligence' is much more behaviourally defined - it's the ability to solve complex problems and puzzles. It's easy for people to define whether an action constitutes intelligence or not: consciousness remains a more complex question. One aspect of consciousness is the ability to reflect on your own experiences. Consciousness in that sense would I think arise as one makes AI more capable.\"\nHumans need not apply | Artificial intelligence in the workplace\nIt is what he calls \"the functional sense of consciousness\" that might allow AI to be turned upon its creators, and to control their world. He says it is happening already, with ads that come up as one browses the internet that are often linked, thanks to previous searches, to the browser's interests. He suggests that we might be prompted \"to read an article, or a headline\" because the machine knows what interests us. But if \"enough optimisation power\" is applied, then he agrees that what comes up may not always be \"what is good for you.\"\nAnd what of the much-discussed danger that AI will put huge numbers of people out of work? \"In the near term, I think some of those concerns are overhyped. But in the end, if you have machines that can do everything humans can do and can do it cheaper and better, then human labour would no longer be needed - including white collar labour. All automation - not just AI - is about being able to do more with less.\"\nSo how would people have an income - how would they survive - if machines did all the work? \"If you can manufacture everything without labour, then prices would come down. So even a modest income stream now could be a vast fortune in a world where everything is almost free. There would be some income stream. Some countries have a big pension fund everyone has been paying into. There has been talk of a universal basic income.\"\nSo it may require a form of mass state redistribution?\n\"There may be a millionfold growth in the economy. So a pound now would be worth a million then. You just have to make sure everyone has ten quid, and most people do have that. And as prices fall, real incomes rise.\"\nHe concedes that, until the new wealth has trickled down through society, \"there might be disturbances and temporary processes that have to be managed that could be tricky. But in the long run, it looks like a very attractive endpoint, which is a world of abundance.\"\n.html-embed.component .quote.component{margin-left:0}.html-embed.component .quote.component .component-content{margin-right:16px}.quote__source, .quote__author {white-space: normal;}@media only screen and (min-width:730px){.html-embed.component .quote.component{margin-left:-60.83px}.html-embed.component .quote.component .quote__content:before{margin-left:-12px;padding-right:1px}}@media only screen and (min-width:1008px){.html-embed.component .quote.component{margin-left:-82.33px}}If superintelligence happens, it should be for the benefit of all. It's too big for any one corporation, or even one country, to monopolise it\nI ask him whether he is worried about severing the link between effort and reward, and he says: \"I am writing a paper on the remaining part of the question.\" It will consider what happens \"if AI can be developed without it being used to wage war, or to allow one firm to take over the world, and everybody ends up with more than enough, then what do we do with our lives?\"\nIsn't there a danger that governments will want to nationalise this new power and control it? Might it not change the whole potential of the state, and threaten our constitutional arrangements?\nIf superintelligence arrives, he replies, \"then there are a lot of fundamental aspects of the human condition that come up for grabs. We must solve the alignment problem. But we also have to develop norms and shared understandings. If superintelligence happens, it should be for the benefit of all. It's too big for any one corporation, or even one country, to monopolise it. All of humanity would share the risks of this transition and all should share the upside as well.\"\nOne early development could be \"this big surveillance network with cameras that can recognise people's faces and can keep track of where people are\". I challenge him about the civil liberties aspect of such an infrastructure: he says that will depend on whether people are \"skimming off the information in real time\" or whether it is just used \"after an incident\" - \"or it could be used when you walk into a shop and just pick up something and walk out with it\", and your account is automatically charged.\nAnd although dictatorships might use AI for nefarious purposes, he thinks people might have virtual reality headsets in which those they meet are evaluated for their \"honesty, conscientiousness and loyalty\", and \"it might just make it harder for scoundrels and bastards to move on to new victims. It might just shift the whole thing into social equilibrium.\"\nHas his study made him more optimistic, or more pessimistic, about humanity's future? \"Both more optimistic and more pessimistic. I'm impressed by the magnitude of how good it could be if it goes well, and how bad it could be if it goes poorly. I'm impressed by how big the stakes are.\"\nHe concedes there will have to be some regulation - what he calls \"the governance issue\" - \"but the biggest variable is just how hard the problem turns out to be of making it go well. That is where the greatest uncertainty is. We could all succeed. We could all fail. We just don't know.\"\n"},
{"docid": "37 of 297 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "March 13, 2017", "title": "Artificial intelligence is ripe for abuse, tech executive warns: 'a fascist's dream'; Microsoft's Kate Crawford tells SXSW that society must prepare for authoritarian movements to test the 'power without accountability' of artificial intelligence\n", "content": "As artificial intelligence becomes more powerful, people need to make sure it's not used by authoritarian regimes to centralize power and target certain populations, Microsoft Research's Kate Crawford warned on Sunday.\nIn her SXSW session, titled Dark Days: AI and the Rise of Fascism, Crawford, who studies the social impact of machine learning and large-scale data systems, explained ways that automated systems and their encoded biases can be misused, particularly when they fall into the wrong hands.\n\"Just as we are seeing a step function increase in the spread of AI, something else is happening: the rise of ultra-nationalism, rightwing authoritarianism and fascism,\" she said.\u00a0\nAll of these movements have shared characteristics, including the desire to centralize power, track populations, demonize outsiders and claim authority and neutrality without being accountable. Machine intelligence can be a powerful part of the power playbook, she said.\n Related:  Message to ministers: AI can transform the way we live right now\nOne of the key problems with artificial intelligence is that it is often invisibly coded with human biases. She described a controversial piece of research from Shanghai Jiao Tong University in China, where authors claimed to have developed a system that could predict criminality based on someone's facial features. The machine was trained on Chinese government ID photos, analyzing the faces of criminals and non-criminals to identify predictive features. The researchers claimed it was free from bias.\n\"We should always be suspicious when machine learning systems are described as free from bias if it's been trained on human-generated data,\" Crawford said. \"Our biases are built into that training data.\"\nIn the Chinese research it turned out that the faces of criminals were more unusual than those of law-abiding citizens. \"People who had dissimilar faces were more likely to be seen as untrustworthy by police and judges. That's encoding bias,\" Crawford said. \"This would be a terrifying system for an autocrat to get his hand on.\"\nCrawford then outlined the \"nasty history\" of people using facial features to \"justify the unjustifiable\". The principles of phrenology, a pseudoscience that developed across Europe and the US in the 19th century, were used as part of the justification of both slavery and the Nazi persecution of Jews.\nWith AI this type of discrimination can be masked in a black box of algorithms, as appears to be the case with a company called Faceception, for instance, a firm that promises to profile people's personalities based on their faces. In its own marketing material, the company suggests that Middle Eastern-looking people with beards are \"terrorists\", while white looking women with trendy haircuts are \"brand promoters\". \nAnother area where AI can be misused is in building registries, which can then be used to target certain population groups. Crawford noted historical cases of registry abuse, including IBM's role in enabling Nazi Germany to track Jewish, Roma and other ethnic groups with the Hollerith Machine, and the Book of Life used in South Africa during apartheid.\nDonald Trump has floated the idea of creating a Muslim registry. \"We already have that. Facebook has become the default Muslim registry of the world,\" Crawford said, mentioning research from Cambridge University that showed it is possible to predict people's religious beliefs based on what they \"like\" on the social network. Christians and Muslims were correctly classified in 82% of cases, and similar results were achieved for Democrats and Republicans (85%). That study was concluded in 2013, since when AI has made huge leaps.\nCrawford was concerned about the potential use of AI in predictive policing systems, which already gather the kind of data necessary to train an AI system. Such systems are flawed, as shown by a Rand Corporation study of Chicago's program. The predictive policing did not reduce crime, but did increase harassment of people in \"hotspot\" areas. Earlier this year the justice department concluded that Chicago's police had for years regularly used \"unlawful force\", and that black and Hispanic neighborhoods were most affected.\nAnother worry related to the manipulation of political beliefs or shifting voters, something Facebook and Cambridge Analytica claim they can already do. Crawford was skeptical about giving Cambridge Analytica credit for Brexit and the election of Donald Trump, but thinks what the firm promises - using thousands of data points on people to work out how to manipulate their views - will be possible \"in the next few years\".\n\"This is a fascist's dream,\" she said. \"Power without accountability.\"\nSuch black box systems are starting to creep into government. Palantir is building an intelligence system to assist Donald Trump in deporting immigrants.\n\"It's the most powerful engine of mass deportation this country has ever seen,\" she said.\nBut what do you do if the system has got something wrong? What if it has incorrect data?\nCrawford argues that we have to make these AI systems more transparent and accountable. \"The ocean of data is so big. We have to map their complex subterranean and unintended effects.\"\nCrawford has founded AI Now, a research community focused on the social impacts of artificial intelligence to do just this\n\"We want to make these systems as ethical as possible and free from unseen biases.\"\n"},
{"docid": "38 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "October 6, 2017", "title": "Car dealer will build personal motor shopper\n", "content": "Arnold Clark, the UK's largest independent motor dealer, is working on deploying more artificial intelligence tools to match customers better with cars and finance offerings.\u00a0\nJohn Brown, chief information officer at Arnold Clark, said the company had only started to \"scratch the surface\" of what the technology could do, but that it could be adapted for potential buyers who are unsure what they want or can afford, as well as automating reminders for servicing and MOTs. Mr Brown, speaking at the Scotsoft conference in Edinburgh on Wednesday, described the plans as \"building a personal shopper\" for the motor trade.\n\"If you look at any online car retailer it is all pretty traditional search. It assumes people have some affinity to a brand or model. What we are seeing is there are lots of customers who want to pick a car based on lifestyle choices.\n\"Perhaps it is the guy like me who wants to buy a car for my daughter leaving university. I want something economical, environmentally friendly, low costs and high safety record. We are trying to figure out how we could put algorithms behind those lifestyle preferences and use artificial intelligence to match potential cars and finance offerings to that person's choices.\"\nWith a team of about 200 developers, engineers and technologists, Arnold Clark aims to improve what Mr Brown called \"the digital customer journey\".\n\"We want to make sure the deal you get on your phone is, to the same penny, the same as if you come in and sit with a sales executive.\"\n"},
{"docid": "39 of 297 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "June 14, 2017", "title": "BenevolentAI: drug research startup goes on hiring spree as UK's artificial intelligence sector booms; Benevolent is one of five private AI companies that has reached a valuation of more than $1bn, according to CB Insights\n", "content": "Drug discovery startup BenevolentAI has begun a major hiring spree, as it seeks to take advantage of the current boom in the UK'sartificial intelligence and machine learning sector.\u00a0\nThe London-based startup, valued at $1.7bn (\u00a31.33m) according to data firm CB Insights, is seeking to hire 50 new staff across AI, data science and bioinformatics, software engineering and medicinal science.\n\"We are already bursting at the seams of our current office space so alongside this hiring spree we'll be moving to a much larger London office later in the year,\" said Ken Mulvany, founder of BenevolentAI.\nRead more\nGoogle uses AI to pick out users' most boring photos\nBenevolent is one of five private AI companies that has reached a valuation of more than $1bn, according to CB Insights. The startup, founded in 2013, focuses on using machine learning to help parse medical data -from existing studies to new papers -to speed up drug discovery.\nThe company has so far raised $140m (\u00a3109.5m)from investors including Lansdowne Partners and Woodford Investment Management. In 2014 the company signed a conditional \u00a3585m ($747.8m) deal with an unnamed USpharma company for potential Alzheimer's treatments, according to filings with Companies House.\nBenevolent employs around 70 people in the UKand US. In September 2016 it hired Jerome Pesenti, a former executive at IBM's Watson platform.\nThe UK's vote to leave the European Union has created economic uncertainty and raised questions about the development of artificial intelligence and the country's ability to attract engineering, software and security talent. Cities including Paris have been battling to attract companies away from the UKas well as entrepreneurs and funding for startups.\nRead more\nAI will be better than human workers 'at all tasks' in 45 years\nThe strange film that sums up our fears of AI and the future\nHalf of companies think AI will 'fundamentally change' their industry\nDespite this, the UKhas recently emerged as one of the dominant hubs for AI, hosting a batch of high-profile tech startups in the sector that have gone on to be acquired by UStech firms, including Twitter's purchase of London-based artificial intelligence startup Magic Pony Technology in June, language processing company SwiftKey's sale to Microsoft in February 2016, and Alphabet's \u00a3400m acquisition of London AI startup DeepMind in 2014.\nMost recently, SoftBank led a $502m investment in Improbable Worlds, a London-based virtual reality startup, in one of the UK's largest venture capital deals.\nLondon is also only behind San Francisco and New York in terms of developers, according to a report Wednesday from Stack Overflow Internet Services, a website for coders. The number of developers in the UKcapital has increased 11 per cent during the past twelve months to 418,000, compared to San Francisco Bay Area and New York, home to around 661,000 and 432,000 developers respectively.\nCloudreach, backed by investors including private equity giant Blackstone and based in London, announced plans Wednesday to hire 100 new developers.\nBloomberg\n"},
{"docid": "40 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "April 5, 2016", "title": "Humans become aroused when touching robot buttocks - study\n", "content": "Touching robots in 'sensitive areas' can trigger arousal in humans, a study by Stanford University has found.\nThe rise of artificial intelligence is seen by some as a threat to the human race, but less research has focused on intimacy between robots and humans, researchers say.\u00a0\nParticipants in the study were asked by the robot, described as a combination of C-3PO and Wall-E, to point to or touch 13 different parts of its body.\n\"Sometimes I'll ask you to touch my body and sometimes I'll ask you to point to my body,\" it told volunteers.\nThose taking part were reluctant to touch 'private' areas of the robot, that was shaped liked a human but did not appear life-like, researchers found, with the response time to the task increasing when they were asked to do so.\nThey found that touching the robot's 'less accessible' places, like its buttocks, provoked a psychological and emotional response in humans.\nThe experiment prompted the same response as if a human had asked the participant to touch them, while touching accessible areas -such as the robot's hand - created low-level responses. \u00a0\nThe rise of the robots - in 90 secondsPlay!01:32\n\"Our work shows that people respond to robots in a primitive, social way,\" Jamy Li, a mechanical engineer at the university in California, told the Guardian . \u00a0\n\"Social conventions regarding touching someone apply to a robot's body parts as well.\"\nHe added: \"The research has implications for both robot design and theory of artificial systems.\"\nThe scientists said that 'touch' is important in building relationships and trust between humans, but said research examining touch between humans and robots was limited.\nThe rise of the robots\u00a0Credit:      AP     \n\"In future, robots with human forms may assist us in personal and public spaces,\" the research team added.\n\"What kinds of relationships will people develop with these robots? While they are clearly not human, social conventions such as body accessibility may apply to robots as well.\"\nMicrosoft's own artificial intelligence experiment backfired recently when its chat robot became a 'Hitler-loving sex robot' within hours of being introduced to society .\nWhile here's how fairy tales could stop killer robots from taking over the world .\nCould a human ever love a robot? The creator of this robot which looks exactly like Scarlett Johansson may just think so.\nAI timelineREAD MORE ABOUT:\n"},
{"docid": "41 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "February 4, 2017", "title": "Computer says yes. It's time to embrace the robot revolution; ? Investment Smart money is piling into a technology sector that is expected to be worth $1.2 trillion by 2025, says Annabelle Williams\n", "content": "President Trump rode into power with the promise of bringing manufacturing jobs back to the US, blaming globalisation for the loss of workers' livelihoods. How he will do this remains to be seen, but most of his voters probably do not realise that of the five million US jobs lost in the decade up to 2010, 85 per cent went to robots, according to a study from academics at Ball State University in Indiana.\nIn the UK, Mark Carney, the governor of the Bank of England, has spoken of a \"technological revolution\" that could mean the loss of 15 million jobs as automation takes over. Some experts say that the rise of robots is set to change society radically, in the same way that the birth of the internet did.\u00a0\nHistorically robots were mainly used in car factories and had to be kept in cages away from humans - their lack of awareness meant people could be maimed or killed if something went wrong. However, advanced sensors have given robots the ability to sense and interpret what is around them, pre-empt accidents and respond to unusual stimuli.\nRobots are now out of their cages and working alongside humans.\nThe race is on as companies compete to make better use of robo-technology - the price of artificial intelligence has reduced significantly and robots are being used in all kinds of industries, from manufacturing and logistics to security, medicine and agriculture.\nThink of Amazon's plans to deliver parcels by drones, surgical operations performed by robots, prosthetic limbs made cheaply through 3D printing, floors cleaned by robot vacuums and fields tended by driverless tractors.\nIn Japan there are plans to have driverless taxis on the roads by the 2020 Tokyo Olympic Games. Scientists have already created robots that can learn as quickly as humans.\n\"Automation and the use of robotics have revolutionised factory floors in ways that were science fiction only decades ago. These phenomena will continue to define the future,\" says David Coombs, a fund manager at Rathbones Unit Trust Management.\nPeople have feared the growth of robotics and automation, but experts argue that society needs to make better use of artificial intelligence to cope with upcoming social challenges.\nThe global population continues to rise and agriculture will have to work harder to feed more mouths. People are living longer and demanding more from medical science. Robots can speed things up and do jobs too dangerous for humans.\n\"As working age populations in the western world and much of the developing world begin to shrink over the coming decades, technology will have to be part of the solution if we are to retain standards of living,\" says Mr Coombs. \"Broad strides are being made in driverless cars, artificial intelligence and the 'internet of things', which connects our appliances to the internet.\"\nThe \"robot economy\" has grown to $64 billion (\u00a351 billion). That sum is predicted to rise to $1.2 trillion (\u00a3956 billion) by 2025.\nRobotics can cut costs for businesses in the long run. An American welder costs $25 an hour, including benefits, but a machine could do the same job for $8, even if you factor in the costs of installation and maintenance, according to Boston Consulting Group. And machines will probably become even cheaper. More importantly, they have improved productivity, according to researchers at Ball State University. This addresses one of the biggest problems that has faced western economies since the financial crisis - markedly lower productivity, which has had an adverse effect on economic growth.\"Productivity remains the most important driver of prosperity and slower improvements in efficiency will eventually lead to a fall in living standards,\" says Aneeka Gupta, the equity and commodities strategist at ETF Securities, a passive fund provider.\nHowever, robots are not replacing human beings entirely. In many cases people will have to improve their skills to work with them. These collaborative robots are known as co-bots.\n\"Trump wants to bring jobs back to the US and some of those will have been replaced by robots, but not all of them. You can see collaborative robots working alongside humans to take away danger and speed up tasks, or making manufacturing and logistics more efficient,\" says Howie Li, of ETF Securities.\nWalter Price, the manager of the Tech funds Dedicated robot funds tend to be high-risk because they concentrate in one area.\nMore general tech funds can be a less risky alternative. Here is a selection of both: ? Allianz Technology trust ? Axa World Funds Framlington Robotech Capitalisation ? Baillie Gifford Japan trust ? Pictet Robotics ? Robo Global Robotics and Automation Go UCITS ETF Allianz Technology trust, says: \"Manufacturing in the US will have a resurgence, and new plants for manufacturing items consumed in the US will be built.\n\"We expect that these will be filled by robots to keep costs down, so the demand for employees that know computers will intensify as will the use of artificial intelligence in these new factories.\"\nA number of dedicated investment funds have been launched to back robot technology, while some general funds are investing in companies involved in automation. There are more than 1,300 public and private companies in the robotics, automation and artificial intelligence sectors. Their compound annual growth rate is at 35 per cent.\nOne of the most rapidly growing sectors is 3D printing, followed by co-bots, according to Robo-Global, which gathers information on robotics and automation. There has been a boom in the amount of money investors have put into these companies - it has tripled since 2014 to reach $1.3 billion.\nThe Pictet Robotics fund is actively managed and invests in 53 companies around the world. Japan is a leader in robots and the manager of the Baillie Gifford Japan trust is keen on the sector, investing in Fanuc, which manufactures robots. There is also a tracker fund that invests in 81 robot-focused companies - Robo Global Robotics and Automation Go Ucits ETF. Mr Coombs invests in Amazon, which is leading the way when it comes to investing in automated technology. He also likes the Allianz Technology trust, which has investment managers based in San Francisco, where much of the innovation is born. \"While the trust is not immune to the dangers of high-risk tech investments, we believe there are plenty of exciting investments in its portfolio,\" he says.\nThe most rapidly growing sectors are 3D printing and co-bots\nRobots have changed factory floors in ways that were science fiction only decades ago\nTechnological gains $64bn The total worth of the 'robot economy'\n"},
{"docid": "42 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "December 22, 2016", "title": "World's largest hedge fund to replace managers with artificial intelligence; Bridgewater Associates has a team of engineers working on a project to automate decision-making to save time and eliminate human emotional volatility\n", "content": "The world's largest hedge fund is building a piece of software to automate the day-to-day management of the firm, including hiring, firing and other strategic decision-making. \nBridgewater Associates has a team of software engineers working on the project at the request of billionaire founder Ray Dalio, who wants to ensure the company can run according to his vision even when he's not there, the Wall Street Journal reported.\n Related:  Mark Zuckerberg out-robots his AI robot in saccharine holiday video\u00a0\n\"The role of many remaining humans at the firm wouldn't be to make individual choices but to design the criteria by which the system makes decisions, intervening when something isn't working,\" wrote the Journal, which spoke to five former and current employees.\nThe firm, which manages $160bn, created the team of programmers specializing in analytics and artificial intelligence, dubbed the Systematized Intelligence Lab, in early 2015. The unit is headed up by David Ferrucci, who previously led IBM's development of Watson, the supercomputer that beat humans at Jeopardy! in 2011.\nThe company is already highly data-driven, with meetings recorded and staff asked to grade each other throughout the day using a ratings system called \"dots\". The Systematized Intelligence Lab has built a tool that incorporates these ratings into \"Baseball Cards\" that show employees' strengths and weaknesses. Another app, dubbed The Contract, gets staff to set goals they want to achieve and then tracks how effectively they follow through.\nThese tools are early applications of PriOS, the over-arching management software that Dalio wants to make three-quarters of all management decisions within five years. The kinds of decisions PriOS could make include finding the right staff for particular job openings and ranking opposing perspectives from multiple team members when there's a disagreement about how to proceed. \nThe machine will make the decisions, according to a set of principles laid out by Dalio about the company vision.\n\"It's ambitious, but it's not unreasonable,\" said Devin Fidler, research director at the Institute For The Future, who has built a prototype management system called iCEO. \"A lot of management is basically information work, the sort of thing that software can get very good at.\"\nAutomated decision-making is appealing to businesses as it can save time and eliminate human emotional volatility. \n\"People have a bad day and it then colors their perception of the world and they make different decisions. In a hedge fund that's a big deal,\" he added. \nWill people happily accept orders from a robotic manager? Fidler isn't so sure. \"People tend not to accept a message delivered by a machine,\" he said, pointing to the need for a human interface. \n\"In companies that are really good at data analytics very often the decision is made by a statistical algorithm but the decision is conveyed by somebody who can put it in an emotional context,\" he explained. \nFuturist Zoltan Istvan, founder of the Transhumanist Party, disagrees. \"People will follow the will and statistical might of machines,\" he said, pointing out that people already outsource wayfinding to GPS or the flying of planes to autopilot.\nHowever, the period in which people will need to interact with a robot manager will be brief. \n\"Soon there just won't be any reason to keep us around,\" Istvan said. \"Sure, humans can fix problems, but machines in a few years time will be able to fix those problems even better. \n\"Bankers will become dinosaurs.\"\nIt's not just the banking sector that will be affected. According to a report by Accenture, artificial intelligence will free people from the drudgery of administrative tasks in many industries. The company surveyed 1,770 managers across 14 countries to find out how artificial intelligence would impact their jobs.\n Related:  'This is awful': robot can keep children occupied for hours without supervision\n\"AI will ultimately prove to be cheaper, more efficient, and potentially more impartial in its actions than human beings,\" said the authors writing up the results of the survey in Harvard Business Review.\nHowever, they didn't think there was too much cause for concern. \"It just means that their jobs will change to focus on things only humans can do.\"\nThe authors say that machines would be better at administrative tasks like writing earnings reports and tracking schedules and resources while humans would be better at developing messages to inspire the workforce and drafting strategy.\nFidler disagrees. \"There's no reason to believe that a lot of what we think of as strategic work or even creative work can't be substantially overtaken by software.\"\nHowever, he said, that software will need some direction. \"It needs human decision making to set objectives.\"\nBridgewater Associates did not respond to a request for comment.\n"},
{"docid": "43 of 297 DOCUMENTS\n", "source": "The Guardian - Final Edition\n", "date": "February 15, 2010", "title": "Media: Tools of the trade: Siri: voice-driven iPhone app\n", "content": "If you're a hardcore Douglas Adams fan, you may remember the 1990 BBC2 documentary Hyperland. In it, he dreams of a future in which a super-clever program, a \"software agent\" played by Tom Baker, guides him through a world of information.\u00a0\nComputers that answer questions we ask them are sci-fi fare, but moving closer to reality as smartphones become more powerful. Google mobile apps have had voice search for a couple of years, but speech-driven mobile apps are growing in sophistication. A new app called Siri promises to be a virtual personal assistant.\nSiri draws on artificial intelligence research from a $150m US defence programme called Calo. Rather than helping soldiers find bad guys, Siri promises to help you find an Italian restaurant near your office or a movie close by, or let you know the weather forecast for tomorrow.\nWant to know what romcoms are playing near you? Just ask, and the iPhone app interprets your question, finds your location from the onboard GPS and delivers a list of movies, cinemas and times.\nSiri uses its artificial intelligence and speech recognition from Nuance to dedecide whether to query the forecasting service WeatherBug, MovieTickets.com or the airline information site Flightstats.\nSo far, the app is only available in the US. However, speech-driven apps are growing more common, especially on mobile phones where it's often easier and faster to speak your request than type it in. After years in which a keyboard or keypad was the main way to work with our computers and mobile phones, Apple made touch almost the default way to use a smartphone. As these speech-driven applications improve, speaking to our phones - not just on them - will seem like second nature. Siri also provides information services, including news sites, another way to deliver information on the move.\n"},
{"docid": "44 of 297 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "July 5, 2017", "title": "Stop sniggering ... the rise of the sex robot is a reality; Experts say the lifelike machines could be used for sexual therapy or as companions for the lonely\n", "content": "SEX robots could soon be used to keep the elderly company in care homes and help couples enjoy long-distance relationships, the Foundation for Responsible Robotics (FRR) has said. There are currently four manufacturers making lifelike robotic dolls worldwide, but experts predict that in coming decades they could become widespread, used not just as a fetish, but for sexual therapy and as companions for lonely, disabled or older people.\u00a0\nNoel Sharkey, the emeritus professor of robotics and artificial intelligence at the University of Sheffield, and co-founder of the FRR, said it was time for the Government and the public to decide whether to regulate pleasure-bots. \"I can tell you that robots are certainly coming,\" he said at the launch of the consultation report in central London.\n\"The concern is that this is going on and nobody is talking about it. People snigger about them, but they are actually shipping quite a lot and we are going to see them a lot more.\n\"They are being proposed for the elderly in care homes, which I think is controversial.\n\"If you have severe Alzheimer's you can't really tell the difference. We need to think about, as a society, what we want to do about it.\" The report found that up to two thirds of men and about 30 per cent of women were in favour of using sex robots, which currently cost between \u00a34,000 and \u00a312,000 and can be customised by sex, height, hair colour, eye colour and even personality. Companies are also starting to incorporate artificial intelligence so robots can communicate and respond to human emotions.\nDoll brothels already operate in South Korea, Japan and Spain, while the first robotic oral sex coffee shop opened in Paddington, west London, last year.\nThe report said that as robotics, telecommunications and virtual reality merged, a sex doll could be created which was a silicon replica of a longdistance partner, so that couples could have virtual sex and even speak to each other through the doll's mouth.\nBut the authors warned that the march of sex robots raised serious moral and ethical questions which needed to be addressed.\nThey warned that users could become socially isolated or even addicted to the machines which could never replace real human contact.\n\"If people bond with robots it's very worrying. You are loving an artefact that can't love you back, and the best they can do is fake it,\" said Prof Sharkey.\nThe authors said it may be necessary to criminalise \"robotic rape\" and to build in \"handled roughly\" sensors to prevent users developing violent sexual tendencies. And they called for a complete ban on child sex dolls.\n"},
{"docid": "45 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "October 11, 2016", "title": "The good, the bad and the cyborgs: Westworld's robot forbears; As Westworld's rogue robots begin to revolt, we take a look at some of their artificial forebears who gave new meaning to the phrase 'technical glitch'\n", "content": " Related:  Westworld recap: episode two - do androids dream of electric slaughter?\nKurosawa-inspired bickering buddies C-3PO and R2-D2 have been bleep-blooping benevolently across our screens for nearly four decades, and the ranks of kindly machine heroes have been boosted in more recent times by Brad Bird's Iron Giant, Pixar's Wall-E and Baymax from Disney's Big Hero Six. But for every good-hearted automaton, there's a malicious artificial intelligence just biding its time to usher in the inevitable age of the machine. \n                   The gun-wielding metaphors for corporate inhumanity                   \u00a0\nPoor, unfortunate Mr Kinney. One moment a high-flying corporate executive at Detroit's top mega-corporation Omni Consumer Products, the next splayed out on a display table, body peppered with automatic gunfire, after getting on the wrong side of the latest (if not necessarily greatest) in automated policing, Robocop's mighty Ed209. Paul Verhoeven's searing 1987 satire on corporate greed imagined a future in which the replacement of human beings with machines begins to spin horribly and inexorably out of control. Pure science fiction? Not according to killer robot expert Bonnie Docherty of Harvard University, who wrote recently that military robots with the ability to fire on targets independently of human control are swiftly moving towards reality thanks to rapid improvements in artificial intelligence. \n                     See also:  The Terminator, Yul Brynner's Gunslinger from the 1973 Westworld movie.\n                   Machines that use sex as a weapon                   \nWill mankind destroy himself through his own malignant cruelty and hunger for lazy titillation? Alex Garland's Ex Machina pondered what might happen if the world's first artificial intelligence happened to be created by a deeply-flawed sociopath: Oscar Isaac's alcoholic tech genius Nathan Bateman. \nHere we have a bona fide sexual terrorist with clear misogynistic tendencies who understands the potential for machines to rise up and take over the Earth, yet blindly pushes his exquisitely beautiful creations to the point of bloody insurrection entirely through his own savage barbarism. Alicia Vikander's blank-eyed Ava has been taught by humanity that the lives of others do not matter, and that lust is man's greatest weakness. It's hardly surprising that she chooses to use this information to knock off Nathan, lock Domhnall Gleeson's callow Caleb Smith in his boss's fancy jungle techno-mansion and waltz off to plant the seeds of the machine hegemony.\n                     See also: Metropolis, the Fembots from Austin Powers, Pris from Blade Runner.\n                   Sociopathic operating systems and freaky space cyborgs                   \nTechnology glitches are a part of everyday existence in 2016, but the concept of machine minds with power over life and death situations remains a terrifying one almost half a century after Stanley Kubrick's 2001: A Space Odyssey debuted in theaters. How do we know if artificial intelligences will think like us? Is \"humanity\" a trait exclusive to human beings, or can a sufficiently clever machine also learn to be kind? \nAnd yet once again, Hollywood's evil robots often end up telling us more about ourselves than they do our future digital children. In 2001, HAL 9000 only rebels against its masters, issuing the famously chilling reposte \"I'm sorry Dave, I'm afraid I can't do that\", because it fears its own imminent death - an entirely human reaction. And Ian Holm's Ash the android is only following orders from his human bosses when he decides to sacrifice the crew of the Nostromo for the chance of returning a live xenomorph specimen to Earth in 1979's Alien.\n                     See also: Gerty from Moon.\n                   Robots that showed us what it means to be human                   \nIs there a more affecting, haunting scene in Hollywood sci-fi than Rutger Hauer's \"tears in rain\" speech from 1982's Blade Runner? The Dutchman improvised the final soliloquy from screenwriter David Peoples ' far less lyrical original script, and it instantly changes everything we've seen thus far. Only in this final scene do we realise that the replicants' short life spans do not curtail their ability to live a full existence, perhaps even one fuller than that of the average human. Moreover, we're given a synapse-searing glimpse into the wonders they have glimpsed in the heavens. Suddenly it makes sense that Pris, Roy Batty et al look like rock stars: these biorobotic androids are perfect examples of the \"live hard, die young\" archetype.\n                     See also: Chappie, Short Circuit's Number Five.\n                   Machines that blazed a trail and left us in their wake                   \nWhat if artificial intelligences simply outgrow humanity, leaving us behind like a youthful romantic dalliance? Spike Jonze's wonderful Her imagined a geeky indie stereotype, Joaquin Phoenix's Theodore Twombly, falling in love with his operating system, Scarlett Johansson's Samantha, only to discover that his perky incorporeal paramour has been carrying out techno-romances with several thousand other human lovers. She then leaves poor Theo (and mankind) behind to join a collective of digital minds in an intellectual orgy of discovery in some elevated dimension of existence that his tiny mind couldn't possibly contemplate. Ouch. \n                     See also: David, the android in Prometheus.\n"},
{"docid": "46 of 297 DOCUMENTS\n", "source": "MAIL ON SUNDAY (London)\n", "date": "October 8, 2017", "title": "BREXIT BAD BOY' TO NET MILLIONS FROM INSURANCE FLOAT\n", "content": "UKIP donor Arron Banks is in line to make millions of pounds from the listing of an insurance firm that he says has been boosted by controversial technology used to help win the Brexit vote.\u00a0\nBanks said he is aiming to float Eldon Insurance in the New Year.\nThe insurance broking firm made \u00a316.7?million in underlying profits in the first six months of the year, according to unpublished figures seen by The Mail on Sunday.\nThe businessman, one of the self-styled bad boys of Brexit', says he is looking for a stock market flotation early next year as by that time the firm will have posted its latest full-year profits, expected to be \u00a324?million or \u00a325?million. Banks said: That equates to an initial public offering of \u00a3250?million. But we're growing very quickly too.'\nHe has a stake of about 90 per cent of Eldon, with staff and managers owning the remainder. Eldon owns the Go Skippy broking brand, and Banks has been underwriting the cover through a Gibraltar insurer that he owns. But he is planning to pass the underwriting on to major insurers from January 1 through a new insurance agent' company called Somerset Bridge.\nBanks said: 2018 and 2019 are going to be fantastic years in the motor insurance market, purely because it has seen losses in the past and rates have risen significantly.'\nEveryone knows their car insurance premiums have gone through the roof. It goes in cycles and the current one is good for insurers,' he said. He added that Eldon had also been using artificial intelligence experts he deployed in the Brexit campaign. Leave.eu used social media profiling to target swing voters, though it was alleged that this was provided under arrangements in breach of Electoral Commission rules.\nBanks said of the technology: It's transforming the business. In 18 months we have halved our personal injury claim frequency, which is phenomenal. It's all about risk selection. We are able to use the artificial intelligence to profile the people we want, and also the people we don't want.'\nEarlier this year Banks said: Artificial intelligence won it for Leave.'\n\u00a9 Mail On Sunday\n"},
{"docid": "47 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "June 17, 2009", "title": "The march of the robots; Being on the same wavelength as automatons will pay off, says Rachel Potter\n", "content": "Imagine a world in which robots can teach children, patrol borders, spoonfeed frail elderly people, even remove an injured soldier from the battlefield to an operating theatre - and then perform surgery on him. We are in that world. Rapid advances in robotics mean that robots are now capable of doing all this and much more.\nNoel Sharkey, professor of artificial intelligence and robotics at the University of Sheffield, says: \"Nanotechnology has reduced sensors and electronics to such a small scale that you can pack much more on to a robot now. It is a matter of creativity: think of any menial task and you can probably get a robot to do it.\"\nSharkey, who was chief judge on the television show Robot Wars, says the developments in service robots are particularly exciting. \"People will be familiar with industrial robots: big arms that paint cars, for example. There are about 1.2 million industrial robots on the planet. Service robots have only really been around in this millennium but there are 4.5 million already and there could be 11 million within the next two years.\"\nGiven the pace of development, it is more important than ever to consider the social and moral implications of robots. Japan, which has a rapidly ageing population, is keen to develop robots to care for the elderly. Is it morally acceptable to remove human interaction from the care of older people if it enables them to live in their own homes longer?\nThe biggest employer of roboticists is the military. Sharkey says there are 6,000 robots on the ground in Iraq - mainly used for \"good reasons\" such as roadside bomb disposal. \"There are some armed robots but they haven't been used yet,\" he adds.\nThe boundaries between robotics and other disciplines are breaking down. One of the growth areas is human robotic interaction. Studying robotics can involve engineering, philosophy, psychology, cognitive science, linguistics, artificial intelligence and computer science.\nChris Melhuish, director of the Bristol Robotics Laboratory, says robotics can open the door to careers in the automation, medical, leisure, transport and defence industries. \"If you have a qualification in robotics then I think you will be a very attractive person to employers. Robotics requires a fusion of disciplines ranging from mechatronics and artificial intelligence to software and control theory.\"\nAs new applications emerge, robotics will provide chances for people who do not necessarily have a solid engineering background, he adds.\nAntonio Espingardeiro has just completed an MSc in robotics and automation at the University of Salford. His childhood passion for computer games and science fiction led to an undergraduate degree in computer science. During the final year he developed a software application to control a small robotic car and became hooked on robotics.\nHe says: \"I believe that in 30 years' time robots will be a big part of our economy and society. I want to explore their social integration: how we can use robots to provide a better quality of life. If we are going to live with robots we have to think about how we are going to manage these machines and what kind of intelligence we are willing to give them.\"\nTechnology I want to explore how we can use robots to provide a better quality of life\n"},
{"docid": "48 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "May 14, 2015", "title": "Artificial intelligence experts are building the world's angriest robot. Should you be scared?; A New Zealand AI company is creating an extremely angry robot. But is this a cause for concern or an exciting computing development?\n", "content": "It sounds like the beginning of an apocalyptic sci-fi film. A New Zealand artificial intelligence company is building the angriest robot in the world in the hopes of helping companies to understand and placate angry customers. The technology firm, Touchpoint group, has spent more than \u00a3230,000 on the project, which is expected to be live by the end of the year. \nSo, is it time to start preparing for the robotic revolution? Not quite - though the long-term future of artificial intelligence is undeniably unnerving. The robot will only simulate anger\nThough it may seem aggressive, Touchpoint's robot won't come close to experiencing bona fide rage. Instead, the machine will have hundreds of millions of angry customer interactions uploaded to its database and the robot <em class=\"bold\">will be programmed to mimic and repeat<em class=\"bold\" />these conversations. Dr Stuart Armstrong, a research fellow at the Future of Humanity Institute at the Oxford Martin School, Oxford University, says that anger is a relatively easy emotion to seemingly replicate in robots. \u00a0\n\"There's not much variety in human anger. If someone's angry they'll just hurl insults at you, there's not much subtlety of interaction so you don't have to code anything complicated. Anger is easy to imitate without having to go into depth,\" he says. Fake robot anger is very basic - for now\nTouchpoint's angry robot will only be programmed to show basic signs of rage, and will behave in a markedly different way from a genuinely angry human. Dr Armstrong explains: \nWhy would we be afraid of a human who's angry? Well, because they might do something stupid and lash out. Robots are not going to start punching the person at the other end of the phone or spreading angry messages on Twitter. They're not going to do a whole host of things that you would expect a genuinely angry person to do- unless it had been programmed to do that. And that's how you can tell that their anger is purely situational. A sign that a robot has feeling is if they act in a way that we would expect a human to do but they weren't programmed for. Truly scary robots don't show any emotion\nTheoretically, we might one day be able to build robots that exhibit all human signs of anger. There is a complicated philosophical debate about the point at which mimicked emotion and consciousness is indistinguishable from actual emotion and consciousness. If a robot can exactly mimic human consciousness, and react with the same emotional responses to the same events, then are we really justified in calling it unconscious? \nBut such an advanced computer is a hypothetical creation that we might see by the end of the century - and certainly won't see in the next decade. And even if we do create an angry, human-esque robot, these are a far lesser concern than emotionless robots. \nComputer scientists are more likely to make an error with emotionless robots, which they might be less wary of, than robots that exhibit anger. \"If we can create genuine anger as an emotion in robots, everything in our background tells us that this is dangerous and this is not something that should be placed in a position of power,\" says Dr Armstrong. \nAnd programmers with sinister intentions would intentionally avoid angry robots. \"If you want to cause harm, create a murderous robot but don't make it angry. If you want to cause harm then creating the thing that signals danger to all humans is exactly what you want to avoid,\" says Dr Armstrong. \nInstead, robots that have no human evidence of emotion could (hypothetically, far in the future) create a far greater threat. Dr Armstrong says: \nEverything in our evolutionary background prepares us to deal with angry entities and knowing whether or not to trust them. If we get a robot that's angry in the classically human sense, we know so much more about how to deal with it than a robot that does not exhibit anger of any sort but may have goals that are very dangerous. The dangerous ones are the ones that do not correspond to anything that we can classify on a human scale - the ones that are indifferent to some crucial aspect of the world. If AI are indifferent to humans, it's obvious how that could go wrong. If they're indifferent to some aspect of humans and they get great power, well that aspect of humanity may vanish. Should we worry about AI at all?\nThough angry robots may not be such a threat, Dr Armstrong says that it's extremely difficult to predict whether or not Artificial Intelligence will eventually cause harm to humans. \n\"Intelligence itself has allowed us to dominate the planet, so potentially higher intelligence might lead to much higher power,\" he says. \"AIs could become extremely powerful and then their preferences would influence the direction of the future. If these preferences are indifferent to some human element then things could end up quite badly for us.\"\nBut though it seems certain that AIs will become more powerful in the coming decades, it's far from certain that they'll reach a significant level of power. \"There's great uncertainty here,\" says Dr Armstrong. How to program robots to avoid harm\nDr Armstrong says that the threat posed by Artificial Intelligence is a \"technical problem\" being addressed by computer scientists. \nOne option is specify and code human values - which is an extremely difficult task. \"The disagreements among human values is almost unimportant in comparison with the difficulty of specifying this value sufficiently so that it can be coded. You have to solve all of moral ethics in computer code,\" says Dr Armstrong. \nDr Armstrong is working on an alternative solution, and is investigating whether robots can be made safe by programming it for \"reduced impact.\" He explains: \nIf you programmed a robot to remove a tumour then, once the tumour is gone, it might then immediately cut off someone's leg. It's motivation to remove the tumour is not safe. But if you programmed it to remove the tumour and have a small impact on the person, then it will remove the tumour without then doing something so drastic. So we've made an unsafe goal safe by adding reduced impact to it. Many values become a lot safer if you program the robot so that it won't do a huge change. \nThe future of Artificial Intelligence is extremely uncertain, and computer scientists like Dr Armstrong are working to make sure we'll be safe from dangerous robots. But for now, the angry robot in New Zealand poses no serious threat. Sci-fi horror stories haven't become reality yet. \n"},
{"docid": "49 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "February 22, 2016", "title": "Will automation make us happier? - live chat; Join experts online on Thursday 25 February 1-2pm GMT to discuss how we can ensure the best possible outcome from automationWatch our new animation: The last job on Earth\n", "content": "The panel\n                     Alan Win?eld is professor of electronic engineering and director of the Science Communication Unit at the University of the West of England, Bristol, and visiting professor at the University of York. Alan co-founded the Bristol Robotics Laboratory where his research is focussed on understanding the nature and limits of robot intelligence. \n Related:  Automation may mean a post-work society but we shouldn't be afraid\n                     Kathleen Richardson is a social anthropologist of robots and a senior research fellow in the ethics of robotics at De Montfort University. She leads a research initiative called Freedom Ethics and Technology which examines how concepts of ethics and freedom are bound up with politics, gender, power and technology. She is also director of the Campaign Against Sex Robots. \n                     Yngvar Sjoner  is global HR director for DNV GL. He is a psychologist with more than 20 years' experience working internationally with leadership and organisational development and general HR.How to join\nThe live chat is completely text based and will take place on this page in the comments section below on Thursday 25 February 1-2pm GMT. \nYou can submit any questions in advance by filling in the form below, tweeting them to @GuardianSustBiz using #askGSB, or sending an email to tess.riley@theguardian.com You can also join the discussion and post questions as it happens. \n"},
{"docid": "50 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "March 20, 2017", "title": "'Britain has the talent to lead the Fourth Industrial Revolution'\n", "content": "Commitments by Google and Apple to build new UK headquarters are not just a reflection of Britain's status as a world-leading tech hub but a strong vote of confidence in our economic prospects.\nAfter meeting the prime minister last month, the Apple CEO, Tim Cook, described his business as a \"big believer in the UK\", adding that we'll be \"just fine\" after Brexit.\nThis cutting-edge investment bodes well for Britain as we enter an unprecedented period of economic change driven by disruptive technologies. Dubbed the Fourth Industrial Revolution, or 4IR, this new wave is being propelled by artificial intelligence, mass automation and hyper-connectivity. Breakthroughs in robotics, driverless cars, drones, 3D printing, the Internet of Things and nanotechnology will transform how we live and work.\u00a0\nNow politicians must respond. As the 4IR gathers pace, Britain can - and should - lead by ensuring that political and economic structures are fit for purpose.\nThis month's budget laid firm foundations, with the chancellor providing \u00a3300 million for new academic research, \u00a3200 million to expand high-speed broadband and \u00a3500 million per year for technical skills. These measures strengthen digital infrastructure, increase the skills of our workforce and boost productivity.\nNonetheless, the fast-paced nature of change means policymakers often struggle to keep up with innovation and its implications. Today's launch of the new all-party parliamentary group on the 4IR by the chancellor can change that.\nBy connecting politicians to businesses, academia, the media and other stakeholders, this group can become the focal point we need in Westminster to get to grips with the legal, ethical and economic questions that new technologies pose, such as who is liable if a driverless car crashes.\nBut to turbo-charge Britain's leadership of the 4IR, policymakers must get behind key new policies.\nFirst, spending on research and development must rise substantially, so we match the best performing OECD economies, which spend around 3 per cent of GDP on R&D. The government has committed to an extra \u00a34.7 billion by 2020-21 - the largest increase since 1979 - but the private sector must step up.\nSecond, Britain needs a new national institute for robotics and artificial intelligence to bring together expertise on two allpervasive 4IR disciplines. This would be the centre of the country's AI ecosystem, combining engagement between government and industry on issues of regulation and policy with a hub for R&D and commercialisation. It would replicate the success of Sheffield's Advanced Manufacturing Research Centre, which enticed Boeing to locate its new parts plant in the city.\nFinally, government should carry out a future skills review at the start of each parliament, taking a longterm look at what skills employers will need over the next decade. This would do for skills what the strategic defence and security review and the comprehensive spending review already do for defence and public spending.\nWhile ideas and leadership are key to sustaining a competitive edge, policymakers have a vital role too. In the 1970s this meant propping up failing nationalised industries, \"picking winners\" and sclerotic growth. Today we need a smart state, not big government. Politicians must focus on the conditions for innovation to thrive, setting out the direction of travel but not dictating the detail.\nThe new all-party group's aim is to help Westminster get that balance right so Britain can lead the Fourth Industrial Revolution, just as we led the first.\nAlan Mak MP is chairman of the all-party group on the Fourth Industrial Revolution\n"},
{"docid": "51 of 297 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "October 7, 1996", "title": "Lost? Send in the hounds; Finding what you're looking for on the Web is about to get easier.\n", "content": " Have you ever spent hours trying to find something on the Internet without really knowing where to look? If not, count yourself in a lucky minority. For the Net's vastness - the incredible, ever-expanding amount of information it contains - makes it both a thing of wonder and a source of irritation to those who use it. There are numerous \"search engines\" to help you find your way around, but all too often they are slow to respond to a query and when they finally do you are presented with long lists of irrelevant items.\n But a revolutionary solution, drawing on research into neural networks and artificial intelligence, is now at hand. Known as an \"intelligent agent\", it is an ingenious piece of software that does all the searching for you and, unlike conventional search engines, can distinguish between different meanings of the same word. Those who are promoting agents say this is just the beginning. They are already talking of agents that will negotiate deals for you, pay bills and arrange home entertainment such as music or movies.\u00a0\n The concept of employing artificial intelligence for searching the Net and other computer networks has been around for some time. Several companies, including Microsoft, have been putting a lot of effort into producing a viable application. \"It has been the Holy Grail for software developers\", says David Tabizel, a consultant to Durlacher Multimedia, who has watched the development of agents.\n In August, the race was won by Autonomy (a Cambridge-based technology start-up) when it released several different agents in beta form. Autonomy is linked to Cambridge Neurodynamics, a company that specialises in artificial intelligence and is associated with the university. Initially, Autonomy offered a cut-down version of Agentware for free download (though only for PC users; Mac users will have to wait until next year). The package includes three \"Web Researchers\" that can be programmed to search simultaneously for anything on the Web, or in newsgroups or FTP sites. You can also choose from 50 \"pre-trained\" agents at the site, programmed to look for specific subjects. Autonomy is selling full versions of its products in two packages - Agentware and Agentware Pro.\n Autonomy's agents can function while you are connected to the Net, allowing you to monitor its searches or carry out other tasks. An efficient way is to send them off like bloodhounds, while you are off line. Once they have finished sniffing around, they rest in \"kennels\" on a designated computer server, with their bag of files and other goodies, waiting for their \"master\" to call them home. \"In the morning, you come back and everything they have found is delivered to your computer,\" says Simon Morris, Autonomy's marketing director. The agent stores all the site addresses, allowing you to switch back to the original sources.\n What makes agents so special, says Mr Tabizel, is that they can \"learn\" from experience. He has been beta-testing Autonomy's models since the beginning of the year. He cites an experimental search he did for information on Everton Football Club. \"At first, it couldn't find anything useful.  But I left it running and it went back and started to piece together information on players, fixtures, results and history. Eventually, I ended up with about 300 really good bits of information. It's eerie watching it learn, but quite incredible.\"\n Mr Tabizel says agents have the ability to talk to each other, opening up the possibility of \"negotiating\". An executive can instruct his or her agent to talk to their opposite number's electronic diary and work out a mutually convenient time for a meeting.\n Agents can be programmed to work the other way round, screening out material you may prefer not to see. As part of the Agentware package, Autonomy is releasing Guardian Agent, which is targeting parents concerned at the possibility of their children accessing pornography on the Net. Another specialised agent in its portfolio is Press Agent, which searches online newspapers and other information sources according to your preferences.  \"It allows you to create a \"Daily Me\" newspaper, delivered straight to your computer\", says Morris.\n At the moment, Autonomy has the pure agent market to itself. \"It has scored a real coup by getting there first,\" says Mr Tabizel. But competitors are already lining up. AgentSoft, a subsidiary of the Israeli multilingual software specialists Accent Software, is planning to release a set of agents by the end of the year, including one to handle negotiations in electronic commerce. Agents Inc is also expanding its activities and Microsoft's agent is expected soon.\n But with all these agents buzzing around, talking to each other, handling our day-to-day affairs, what will there be left for us humans to do? As Mr Tabizel points out: \"The development of agents brings us to the final stage of computing, where machines are becoming autonomous.\" What an unsettling thought.\n A 30-day trial version of Agentware, including WebResearcher, Press Agent and Mail Agent, is available at http://www.agentware.com\n\n"},
{"docid": "52 of 297 DOCUMENTS\n", "source": "The Guardian - Final Edition\n", "date": "December 15, 2009", "title": "Comment: When robots have feelings: If, as seems likely, we develop super-intelligent machines, their rights will need protection, too\n", "content": "Last month, Gecko Systems announced that it had been running trials of its \"fully autonomous personal companion home-care robot,\" also known as a \"CareBot,\" designed to help elderly or disabled people to live independently.\nRobots already perform many functions, from making cars to defusing bombs - or, more menacingly, firing missiles. Children and adults play with toy robots, while vacuum-cleaning robots are sucking up dirt in a growing number of homes. There is even a Robot World Cup, though footballers have no need to feel threatened just yet.\u00a0\nMost of the robots being developed for home use are functional in design - Gecko's homecare robot looks rather like the Star Wars robot R2-D2. Honda and Sony are designing robots that look more like the same movie's \"android\" C-3PO. There are already some robots, though, with soft, flexible bodies, human-like faces and expressions, and a large repertoire of movement.\nWill we soon get used to having humanoid robots around the home? Noel Sharkey, a professor of artificial intelligence, has predicted that busy parents will start employing robots as babysitters. What will it do to a child, he asks, to spend a lot of time with a machine that cannot express genuine empathy, understanding or compassion? In his book Love and Sex with Robots, David Levy goes further, suggesting that we will fall in love with warm, cuddly robots, and even have sex with them. But what will the presence of a \"sexbot\" do to the marital home?\nA more ominous question is familiar from novels and movies: will we have to defend our civilisation against intelligent machines of our own creation? Some consider the development of superhuman artificial intelligence inevitable, and expect it to happen no later than 2070. They believe it will lead to an \"intelligence explosion\" as super-intelligent machines design even more intelligent machines, with each generation repeating this process.\nFor the moment, a more realistic concern is not that robots will harm us, but that we will harm them. At present, robots are mere items of property. But what if they become sufficiently complex to have feelings? After all, isn't the human brain just a very complex machine?\nIf machines can and do become conscious, will we take their feelings into account? The history of our relations with the only nonhuman sentient beings we have encountered so far - animals - gives no ground for confidence that we would recognise sentient robots as beings with moral standing and interests that deserve consideration.\nThe cognitive scientist Steve Torrance has pointed out that powerful new technologies, like cars, computers, and phones, tend to spread rapidly, in an uncontrolled way. The development of a conscious robot that (who?) was not widely perceived as a member of our moral community could therefore lead to mistreatment on a large scale.\nThe hard question, of course, is how we could tell that a robot really was conscious, and not just designed to mimic consciousness. Understanding how the robot had been programmed would provide a clue - did the designers write the code to provide only the appearance of consciousness? If so, we would have no reason to believe that the robot was conscious.\nBut if the robot was designed to have human-like capacities that might incidentally give rise to consciousness, we would have a good reason to think that it really was conscious. At that point, the movement for robot rights would begin.\nPeter Singer is professor of bioethics at Princeton University. Agata Sagan is an independent researcher living in Warsaw. (C) Project Syndicate, 2009\n"},
{"docid": "53 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "March 13, 2008", "title": "Now where did I leave my...? The glasses that can find anything\n", "content": "(Except, of course, your missing glasses)\nYou know the feeling. Call it a senior moment, absent-mindedness or a sign of what a busy active brain you have. We've all asked ourselves that irritating question: \"Where on earth did I leave my car keys?\"\u00a0\nNow a team of Japanese scientists claim to have come up with the answer. And the secretive artificial intelligence project codenamed Smart Goggle does not stop at elusive keys. With Yasuo Kuniyoshi's invention balanced on your nose, nothing - be it the remote control, mobile phone or iPod - should ever go missing again.\nSimply tell the glasses what you are looking for and it will play into your eye a video of the last few seconds you saw that item.\nBuilt on to the glasses is a tiny camera which makes a constant record of everything the wearer sees: the tiny display inside the glasses identifies what is being scanned and a small readout instantly announces what the computer thinks the object probably is. For some things that look different from a range of angles, however, the glasses offer only a \"best guess\" - they are better at identifying a guitar and a chair than a coathanger or battery.\nThe hardware itself is not extraordinary: what has taken Professor Kuniyoshi several years to perfect is the computer algorithm that allows the goggles to know immediately what they are seeing. It is, he says, a problem that has always vexed the fields of robotics and artificial intelligence.\nBut working in a team with Tatsuya Harada, one of Japan's masters of the science of \"fuzzy logic\", Mr Kuniyoshi believes he has cracked the problem. Behind the goggles is possibly the world's most advanced object recognition software and a computer that can learn the identity of new objects within seconds.\nSo if the user wanders round the house for about an hour telling the goggles the name of everything from that coathanger to the kitchen sink, they will remember. Then if, at some point in the future, you ask them where you last saw a particular item, they will play the appropriate footage.\nProfessor Kuniyoshi has even greater ambitions for his software, ambitions that owe a lot to the visual display of the Terminator of science fiction. He describes his goggles as the ultimate connection between the real world and the cyber world and believes that they could eventually be loaded with vast quantities of data from the internet.\nWith that database installed, the glasses might actually know much more about what the wearer is seeing than the wearer himself - species of animal, technical specifications of vehicles and electronics, or even the identity of people. In a demonstration, the professor showed how the user might, for example, gaze at a selection of unknown flowers and the glasses would say which were begonias, which were ferns and which were pansies.\nAlthough the experimental model, shown exclusively to The Times yesterday, is still too bulky for daily use, the team at the Tokyo University School of Information Science and Technology are confident that it can soon be miniaturised. It could even, they suggest, be small enough to look little different from a normal pair of glasses.\nBut unfortunately, of course, there is one irritating question they would not be able to answer: \"Now where did I put my glasses?\"\n"},
{"docid": "54 of 297 DOCUMENTS\n", "source": "DAILY MAIL (London)\n", "date": "February 27, 2017", "title": "TOP INSURER ASKS STAFF IF ROBOT COULD DO THEIR JOB\n", "content": "It'S a question for the modern age - do you think a robot could do your job better?\nAnd, if you answered yes - would you admit it to your boss?\u00a0\nThat is what insurance giant Aviva will be asking its 16,000 employees - and the ones who say they could be replaced by a machine will be retrained for another role at the firm.\nCall centre staff and those who assess customers' credit ratings and calculate the price of insurance are most likely to have to transfer.\nThe increasing sophistication of robots has preoccupied company bosses across the world looking to cut costs and boost efficiency.\nBut Aviva is thought to be first company in the world to pose this question directly to its staff, according to The Sunday Times.\nRobots have already replaced tens of thousands of jobs in manufacturing - including in the car industry.\nBut experts have warned entire professions dominated by middle-class workers - such as accountancy - could be pushed to the brink of extinction as developments in computers make their roles redundant.\nMinisters believe the onward march of the robots is inevitable and must be embraced.\nLast weekend the government announced it will hand \u00a317million to universities for artificial intelligence research, including robots and driverless cars.\nIt has seized on estimates from consultancy firm Accenture that artificial intelligence could provide a \u00a3654billion boost to the UK economy by 2035, creating more highly skilled jobs.\nBut the latest developments will fuel concerns that many white collar jobs will also soon be obsolete. Bank of England governor Mark Carney warned in December that 15million Britons -\u00a0almost half of the 31.8million workforce - could be replaced by robots over the coming years as livelihoods were mercilessly destroyed' by the technological revolution.\nDeeply worrying forecasts from the Bank say that a new machine age' would be particularly devastating for those on lower incomes.\nResearchers from Oxford University also recently compiled a list of jobs which are most in danger of being automated, and found that 35 per cent of jobs in the UK were in danger of being automated.\nInsurance underwriters were top of the list, with a 98.9 per cent risk of becoming automated. Other high-risk professions were estate agents, postal service workers, and accountants.\nBut firefighters, dentists and doctors all have a less than a 1 per cent chance of being replaced by robots.\n\u00a9 Daily Mail\n"},
{"docid": "55 of 297 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "July 25, 1992", "title": "OBITUARY: ALLEN NEWELL;Mechanics of the mind\n", "content": "\u00a0\n DR ALLEN NEWELL, a founder of artificial intelligence and modern cognitive psychology, and professor of computer sciences and psychology at Carnegie Mellon University in Pittsburgh, has died aged 66.\n Born in San Francisco, he graduated in physics at Stanford and spent a graduate year in mathematics at Princeton. Finding abstract mathematics too unworldly, he joined the RAND Corporation as a research scientist, creating with colleagues a simulated Air Defence station, staffed with an entire Air Force unit. This huge laboratory, unprecedented in the human sciences, confirmed Newell in always seeking large-scale research funding for large projects, an attitude he perhaps learned from the physicists.\u00a0\n The RAND laboratory focused Newell's attention on explaining how people acquire and process information - how they think. He took as his life work exploring the nature of the mind. It was in 1952 at RAND that we first met, and discovered that our ways of viewing human thinking were nearly identical.  Through exposure to new electronic computers at RAND, we gradually conceived of studying thinking by using computer programs to simulate it.\n In 1955 we co-opted Cliff Shaw, a talented RAND computer scientist. At the same time, Newell joined me at Carnegie Mellon in Pittsburgh to combine research with completing a doctorate. The business school there saw nothing untoward about supporting research on artificial intelligence or admitting a mature researcher as a \"student\".\n By the end of 1955 the three of us had designed a computer program that could discover proofs for theorems in logic by selective or \"heuristic\" search. To program this discovery, we had to invent a whole new class of computer languages, list processing languages. These discoveries, of heuristic problem solving and list processing, created the discipline of artificial intelligence, precipitated a \"revolution\" in cognitive psychology, and influenced many facets of computer science. AI centres were soon formed at many institutions, including Carnegie Mellon, MIT, Stanford and Edinburgh.\n In the succeeding years, Allen Newell pushed forward with colleagues and students, making important contributions to psychology and to the generality and flexibility of AI systems. Ultimately, this led him to invent the SOAR system, a unified architecture for cognition. Dozens of investigators are now using SOAR as the core of the intelligent systems they are building. Newell's magisterial summary of this work, Unified Theories Of Cognition, ) was based on his William James Lectures at Harvard.\n In every organisation he served, Newell became a major leader, engendering an atmosphere of trust and cordiality, and advising and aiding his associates, from department head to junior faculty member and newest graduate student. He was trusted and loved because his motives were totally clear and his actions without guile. Sometimes his energy, intensity, intelligence and single-mindedness could intimidate people, but not when they came to understand what motivated him. He never displayed anger. The environments he created were efficient, well supported, and formed warm human communities.\n His many friends observed in the Newells' family and social life the same qualities of human warmth and wisdom. For his scientific achievements and for his demonstration of what it means to be both a scientist and a whole human being, Allen Newell will be remembered as one of the great scientists of our century.\n Allen Newell, born March 19, 1927; died July 19, 1992.\n"},
{"docid": "56 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "June 21, 2017", "title": "Robots will get lessons in etiquette\n", "content": "Researchers at the Pentagon hope to teach robots better manners to ensure they are \"safe and trustworthy collaborators\" with human partners.\nAdvances in artificial intelligence allow engineers to create robots capable of performing increasingly complex tasks, but concern about the machines' lack of social skills and ethics has led the US Department of Defense to fund a study into how to address their behaviour issues.\u00a0\n\"If we're going to get along as closely with future robots, driverless cars, and virtual digital assistants as we envision, then those assistants are going to have to obey the same norms we do,\" said Reza Ghanadan, a programme manager at the Defense Advanced Research Projects Agency (Darpa), which develops technologies for the US military. Humans can assess a situation and automatically respond in an appropriate manner, but engineers have so far failed to give robots and virtual assistants the same abilities.\nMr Ghanadan added: \"Such norms are intuitively obvious to most people, as the result of growing up in a society where subtle or not-so-subtle cues are provided from childhood about how to behave in a group setting, or respond to interpersonal situations. But teaching those rules to robots is a novel challenge.\"\nBy studying how such reactions are formed in the human mind, Darpa hopes to be able to create equivalent processes in computers.\n\"That task will prove far more complicated for artificial intelligence systems than teaching them rules for simpler tasks such as tagging pictures, detecting spam, or guiding people through their tax returns,\" said Mr Ghanadan. \"The new research could accelerate the day when machines emulate the best of human behaviour.\"\nAmong Darpa's projects is the development of robots that can supplement, or substitute for, human disaster response operations, such as after an earthquake.\nTeams have created robots capable of driving into a debris zone, clearing rubble, manoeuvring around obstacles, operating a fire hose and carrying out key rescue tasks such as cutting holes in walls.\nA Darpa-funded robot built at Carnegie Mellon University's national robotics engineering centre stands 5ft 2ins tall, and can operate power tools, turn valves on and off, climb stairs and lift objects weighing 300lbs.\nDarpa has also created a robotic pack-mule which has four legs, walks over rough terrain and can carry 400lbs of equipment - three times the load-bearing capacity of a US Marine.\n"},
{"docid": "57 of 297 DOCUMENTS\n", "source": "The Sunday Telegraph (London)\n", "date": "November 19, 2017", "title": "We need an intelligent debate about the new machine age - and soon\n", "content": "It's often said that the first responsibility of any government is to keep its citizens safe. In which case, our policymakers might like to reflect on a speech given by Professor Stephen Hawking last week. The renowned physicist warned: \"Success in creating effective artificial intelligence could be the biggest event in the history of our civilisation. Or the worst. We just don't know.\"\nProfessor Hawking's fear is that while AI technologies have the potential to deliver undoubted benefits to humanity, there are serious dangers too: the development of autonomous weapons, for example, or, as Bill Gates has cautioned, an \"existential threat\" to mankind. \"With artificial intelligence, we're summoning the demon,\" the Microsoft founder has previously said.\u00a0\nMessrs Hawking and Gates aren't proposing that we put the genie back in the bottle; what they want is a public debate about how AI technologies should be allowed to evolve. Just as we have regulation that attempts to set out the moral and ethical principles that should underpin development in fields such as biotechnology or embryology, so we should be talking about these ideas in the context of AI.\nThat debate is beginning to take shape at Westminster. Earlier this year, the House of Lords set up a select committee with a remit to consider the economic, ethical and social implications of advances in AI; it held its first public hearings last month and will meet again on Wednesday.\nBut politicians in the Commons show little interest in anything other than Brexit right now, where the debate may fairly be described as artificial but certainly doesn't show much intelligence.\nYou might think we have years to work out where we stand. Delivering sophisticated AI that genuinely rivals broad-based human intelligence remains the stuff of science fiction and it is very difficult to replicate or emulate the perception-based learning processes that humans employ.\nHowever, while that gives us a window of opportunity to build better governance structures around AI, time is short. Already, for example, Human Rights Watch says that the US, China, Israel, South Korea, Russia and the UK are all investing in AI-powered weapons systems that will reduce human intervention in the process of selecting and hitting targets. AI, in other words, will make decisions about killing people.\nShould AI really be able to kill? What rights will humans have in an era of artificial intelligence? How will we ensure AI doesn't assert its supremacy over humanity? Will we lose control? These are serious questions that require deep thinking and international co-operation, but don't bank on our elected politicians to rise to the challenge; they're too busy bickering over a Brexit deal.\nIf we get the governance right, AI can transform our lives for our better, increasing our free time and enriching and enlivening the world of work. But we need to discuss how we take advantage. For example, why aren't we rethinking an education system? The skills our young people will need to succeed in the labour market once AI takes over repetitive tasks will be very different. Similarly, can we exploit Brexit? Since AI depends on the free flow of data and the European Union's regulation of data is very restrictive, is there an opportunity to secure competitive advantage for the UK? The prospect that scares some people most is that the machines will eventually try to wipe us out. It's prudent to worry about such an eventuality; right now, however, we're not even talking about the little (relatively) things. At a time when our political discourse is mired in the natural stupidity of Brexit, artificial intelligence isn't getting a look-in. That is something we will live to regret, even if the machines we create are friendly.\nHaakon Overli is a founding partner of Dawn, an early stage venture capital firm investing in start-ups across Europe\n"},
{"docid": "58 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "April 11, 2018", "title": "Giving us travel directions is fine - but polling shows we don't want AI flying our planes anytime soon\n", "content": "A recent poll suggests that individuals would be happy for AI to perform menial tasks in the future, but most of us are uncomfortable with the prospect of them having real control over our lives.\u00a0\nThe research comes in the wake of the first death involving a fully autonomous vehicle last month when Elaine Herzberg was hit by a self-driving Uber 4x4 while crossing the street in Arizona.\nIf the hype around AI\u00a0is to be believed then we are about to witness the biggest workplace shift ever experienced in the tecnological era .\nBut how ready are we for it?\n                   We're happy to hand over menial tasks to AI                   \nResearch company D-CYFOR carried out the\u00a0poll to assess how members of the public feel about the advent of artificial intelligence its potential impact on our society.\nThe results suggest that the majority of us would be\u00a0happy to give AI control over menial tasks which have little to no effect on our health or wellbeing.\nMost people are happy for AI to take on a menial role in society\nFor example, 74 per cent of us would be happy taking travel directions from AI and 51 per cent of us would be happy with AI providing manual labour.\n                   But we want to keep people in control of positions of power                   \nMany of us are far less comfortable when faced with the possibility of artificial intelligence being granted positions of power with real influence over our lives.\nFor example, 67 per cent of the public would be unhappy with AI flying planes and 61 per cent are unhappy with AI providing a police service.\nMost people are against AI having positions of power\nThese results appear to suggest that most people want to see AI take on a more subservient role\u00a0in society\u00a0while humans continue to retain the key decision-making positions.\n                   The majority of us are concerned about driverless cars                   \nThe poll also revealed that three quarters of us are concerned about sharing the road with a driverless car,\u00a0while 65 per cent would not be\u00a0a passenger in one.\nThree quarters of individuals are concerned about driverless cars\nThe cars rely on a system of cameras and sensors along with software to detect other vehicles, pedestrians and objects,\u00a0but\u00a0these systems are still being perfected.\nProponents of driverless cars have highlighted the numerous benefits that they believe the technology will eventually bring, including fewer road accidents and reduced congestion .\u00a0\nBut the polling reveals that many of us are yet to be convinced of the benefits of such artificial intelligence technology.\n                     Polling was conducted by D-CYFOR on a representative sample of 1,002 UK adults and was completed on 03/04/2018.                   \n"},
{"docid": "59 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "September 27, 2017", "title": "Don't be too afraid of robots taking your job. They're more likely to assign you a new one\n", "content": "To stay alive when the robots come for us you will need a special kind of camouflage. Called Hyperface, it is made of strange broken forms which intelligent cameras misrecognise as faces.. You will need to combine it with lens-dazzling make-up and vary your gait as you walk. Finally you must learn at least five programming languages, to stop them from taking your job.\nThe fear of automation is everywhere right now. There is a cottage industry of futurologists and consultants who tell us that artificial intelligence will do to white collar jobs what mechanical automation did to blue collar ones. At the Labour conference in Brighton this week that became a justification for Jeremy Corbyn to use higher taxes to fund a National Education Service .\u00a0\n.html-embed.component .quote.component{margin-left:0}.html-embed.component .quote.component .component-content{margin-right:16px}.quote__source, .quote__author {white-space: normal;}@media only screen and (min-width:730px){.html-embed.component .quote.component{margin-left:-60.83px}.html-embed.component .quote.component .quote__content:before{margin-left:-12px;padding-right:1px}}@media only screen and (min-width:1008px){.html-embed.component .quote.component{margin-left:-82.33px}}I think we should be very careful about artificial intelligence. If I had to guess at what our biggest existential threat is, it's probably thatElon Musk\nWe have always fantasised about machines in revolt, from Frankenstein to the Terminator. They overwhelmed us with raw clomping power when factories were changing, became cold and calculating while computers began infiltrating our homes, and today, in the age of the algorithm, they watch and enslave us en masse like the machine overlords of The Matrix.\nThe strangest form of modern AI fear involves the Singularity, a hypothetical future event in which self-improving machines could evolve overnight into something like a god. For believers, formulating an ethical framework which could compel such a being to protect us rather than recycle our atoms into more storage space for MP3s therefore becomes the most important task on Earth. Naturally they are concentrated in Silicon Valley, and seem to\u00a0 include some powerful people such as SpaceX founder Elon Musk .\n        Elon Musk?s rise to fame in 90 seconds       01:33\nYet the threat to employment is more sober, and must be taken seriously. We are living through an unprecedented explosion in more humble forms of intelligence: no gods yet, but many locusts. The list of industries being transformed by algorithms and machine learning is now too long for humans to read. If tasks involving analysis and judgement become cheaper to automate than to pay wages for, professions like lawyers and accountants could be decimated. One study by Oxford University found 47 per cent of jobs were at risk .\nThat might happen in future, but there's no evidence it's happening yet . If it were we would expect to see productivity and unemployment rising in advanced economies, where in many places they are pinned to the floor. We would also expect to see capital investment boom as companies plough money into new technologies; in the US such investment has grown more slowly since 2002 than any time before the Second World War.\nThis is not to say automation won't be transformative, but it is likely to be both slower and less cataclysmic than some presume. The machines that Luddites smashed in the 19th century did not render humans obsolete but created entirely new forms of labour with new armies of bureaucrats to organise it. More recently, the economist James Bessen has shown how cash machines actually increased the number of bank tellers by making it cheaper to open new branches.\nChart: Long run global total factor productivity growth for advanced and emerging economies\nJust so, a recent LSE study across 17 developed countries found that robots did indeed reduce the hours of lower-skilled workers, but not the total hours worked by all humans, and that they actually increased average wages. So while automation will hurt specific professions and specific industries - and studies suggest these impacts will be relatively small (single figure percentages) and take several\u00a0decades\u00a0\u00a0- it will create and bolster others. Even then, of 271 occupations listed in the 1950 US census, only \"elevator operator\" has been obviated completely.\nThis will still have sweeping social effects. The industrial age created the union movements and mass literacy that enabled modern politics, but\u00a0also turmoil, dislocation and suffering. We are already seeing what happens to our own politics when we write off large numbers of people as superfluous. In 2015 the Economist interviewed a \"sporadically employed\" American named Orlando Redden whose skills were no longer needed in a town bustling with retail and \"pink collar\" jobs; one year later similar men propelled the rise of Donald Trump. Yet that itself shows the problem with blaming everything on robots: it is not automation which left these men behind but globalisation and the shift towards services.\nThat said, we should be thankful to even the most fervid prophets - yes, even the Singularitarians. Their predictions might not come true but we need to be thinking about them; they inoculate us from unseen disasters, force us to plan. We will also continue to find them perversely thrilling, and feel special and clever for considering them before others do. My prediction? That the job of doomsayer will always be secure.\nAt a glance | Robot taxes\n"},
{"docid": "60 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "December 10, 2014", "title": "Asteroid strike: 7 ways the world could end; As a mountain-sized asteroid is detected heading towards Earth, what is the likeliest 'extinction-level' scenario for mankind?\n", "content": "Our solar system is littered with billions of pieces of debris, from the size of large boulders to objects hundreds of miles across. We know that from time to time these hit our Earth. Now, a Russian scientist has calculated that a mountain-sized asteroid - which crosses paths with the Earth every three years - could one day hit us with an explosion 1,000 times greater than the surprise 2013 impact of a bus-sized meteor in Russia . \nThis is not the only Doomsday scenario faced by our planet. Humanity may have already created its own nemesis, according to Professor Stephen Hawking . The Cambridge University physicist claimed that new developments in the field of artificial intelligence (AI) mean that within a few decades, computers thousands of times more powerful than in existence today may decide to usurp their creators and effectively end humanity's 100,000-year dominance of Earth. \nThis 'Terminator' scenario is taken seriously by many scientists and technologists. Before Professor Hawking made his remarks, Elon Musk, the genius behind the Tesla electric car and PayPal, has stated that \"with artificial intelligence, we are summoning the demon\", comparing it unfavourably with nuclear war as the most potent threat to humanity's existence. \u00a0\nAside from the rise of the machines, many potential threats have been identified to our species, our civilisation or even our planet itself. To keep you awake at night, here are seven of the most plausible. \n                     1. Asteroid strike                    \nSixty-five million years ago, an object, possibly a comet a few times larger than the one landed on by the Philae probe last month, hit the Mexican coast and triggered a global winter that wiped out the dinosaurs. And in 1908, a smaller object hit a remote part of Siberia and devastated hundreds of square miles of forest. Last week, 100 scientists, including Lord Martin Rees, the Astronomer Royal called for the creation of a global warning system to alert us if a killer rock is on the way. \n                     Probability: Remote in our lifetime, but one day we will be hit. \n                     Result: There has been no strike big enough to wipe out all life on Earth - an \"extinction-level event\" - for at least 3bn years. But a dino-killer would certainly be the end of our civilisation and possibly our species. \n                     2. Artificial intelligence                   \nProfessor Hawking is not worried about armies of autonomous drones taking over the world, but something more subtle - and more sinister. Some technologists believe that an event they call The Singularity is only a few decades away. This is a point at which the combined networked computing power of the world's AI systems begins a massive, runaway increase in capability - an explosion in machine intelligence. By then, we will probably have handed over control to most of our vital systems, from food distribution networks to power plants, sewage and water treatment works and the global banking system. The machines could bring us to our knees without a shot being fired. And we cannot simply pull the plug, because they control the power supplies. \n                     Probability: Unknown - although computing power is doubling every 18 months. We do not know if machines can be conscious or \"want\" to do anything, and sceptics point out that the cleverest computers in existence are currently no brighter than cockroaches. \n                     Result: If the Web wakes up and wants to sweep us aside, we may have a fight on our hands (perhaps even something similar to the man vs machines battle in the Terminator films ). But it is unlikely that the machines will want to destroy the planet - they live here, too. \n                     3. A genetically created plague                    \nPossibly the most terrifying short-term threat - because it is so plausible. The reason Ebola has not become a worldwide plague - and will not do so - is because it is so hard to transmit, and because it incapacitates and kills its victims so quickly. However, a modified version of the disease that can be transmitted through the air, or which allows its host to travel around for weeks, symptom-free, could kill many millions. It is unknown whether any terror group has the knowledge or facilities to do something like this, but it is chilling to realise that the main reason we understand ebola so well is that its potential to be weaponised was quickly realised by defence experts. \n                     Probability: Someone will probably try it one day. \n                     Result: Potentially catastrophic. \"Ordinary\" infectious diseases such as avian flu strains have the capability to wipe out hundreds of millions of people. \n                     4. Nuclear war                    \nStill the most plausible 'doomsday' scenario. Despite arms limitations treaties, there are more than 15,000 nuclear warheads and bombs in existence - enough, in theory, to kill every human on Earth several times over. Even a small nuclear war has the potential to cause widespread devastation. In 2011, a study by NASA scientists concluded that a limited atomic war between India and Pakistan involving just 100 Hiroshima-sized detonations would throw enough dust into the air to cause temperatures to drop more than 1.2C globally for a decade. \n                     Probability: High. Nine states have nuclear weapons, and more want to join the nuclear club. The nuclear wannabees are not paragons of democracy. \n                     Result: It is unlikely that even a global nuclear war between Russia and Nato would wipe us all out, but it would kill billions and wreck the world economy for a century. A regional war, we now know, could have effects far beyond the borders of the conflict. \n                     5. Particle accelerator disaster                    \nBefore the Large Hadron Collider, the massive machine at CERN in Switzerland that detected the Higgs Boson a couple of years ago, was switched on, there was a legal challenge from a German scientist called Otto Rossler who claimed the atom-smasher could theoretically create a small black hole by mistake - which would then go on to eat the Earth. \nThe claim was absurd: the collisions in the LHC are far less energetic than the natural collisions caused by impacting cosmic rays hitting the planet. But it is possible that, one day, a souped-up version of the LHC could create something that destroys the planet - or even the universe - at the speed of light. \n                     Probability: Very low indeed. \n                     Result: Potentially devastating, but don't bother cancelling the house insurance just yet. \n                     6. 'God' reaches for the off-switch                    \nMany scientists have pointed out that there is something fishy about our universe. The physical constants - the numbers governing the fundamental forces and masses of nature - seem fine-tuned to allow life of some form to exist. The great physicist Sir Fred Hoyle once wondered if the Universe might be a \"put-up job\". \nMore recently, the Oxford University philosopher Nick Bostrom has speculated that our Universe may be one of countless \"simulations\" running in some alien computer, much like a computer game. If so, we have to hope that the beings behind our fake universe are benign - and do not reach for the off-button should we start misbehaving. \n                     Probability: According to Bostrom's calculations, if certain assumptions are made then there is a greater than 50 per cent chance that our universe is not real. And the increasingly puzzling absence of any evidence of alien life may be indirect evidence that the Universe is not what it seems. \n                     Result: Catastrophic - if the gamers turn against us. The only consolation is the knowledge that there is absolutely nothing we can do about it. \n                     7. Climate catastrophe                    \nAlmost no serious scientists now doubt that human carbon emissions are having an effect on the planet's climate. The latest report by the Intergovernmental Panel on Climate Change suggested that containing temperature rises to below 2C above the pre-industrial average is now unlikely, and that we face a future 3 or 4 degrees warmer than today. \nThis will not literally be the end of the world - but humanity will need all the resources at its disposal to cope with such a dramatic shift. Unfortunately, the effects of climate change will start to really kick in just at the point when human population is expected to peak - at about 9bn by the middle of this century. Millions, of mostly poor people, face losing their homes to sea-level rises (by up to a metre or more by 2100) and shifting weather patterns may disrupt agriculture dramatically. \n                     Probability: It is now almost certain that CO2 levels will keep rising to 600 parts per million and beyond. And it is equally certain that the climate will respond accordingly. \n                     Result: Catastrophic in some places, less so in others (including northern Europe, where temperature rises will be moderated by the Atlantic). The good news is that unlike most of the disasters here, we have a chance to do something about climate change now. \n"},
{"docid": "61 of 297 DOCUMENTS\n", "source": "The Guardian - Final Edition\n", "date": "March 24, 2014", "title": "G2: Shortcuts: Music: Is this the first post-internet album?\n", "content": "It was only a matter of time before creative minds began pondering the brave new world where virtual reality intersects with real reality. Take director Spike Jonze, whose film Her was a tender parable about love and artificial intelligence. Or Dave Eggers' prescient, tech-obsessed thriller novel The Circle.\u00a0\nIndustrial-folk singer EMA has gone one better. Her second album, The Future's Void, may be the first truly \"post-internet\" record (although weirdly Keyboard Cat doesn't feature at all). She wrote it following her experiences online after the release of her debut, 2011's Past Life Martyred Saints, when derogatory comments were posted under her videos on YouTube. \"I went offline feeling unsettled and unsafe,\" she says.\nThe artist formerly known as Erika M Anderson used these feelings to create a mournful elegy to the \"internetification\" of the human race, looking to William Gibson's seminal cyberpunk tome Neuromancer as inspiration. The central theme, she says, came to her in a vision. \"I felt like I had a white cube in my brain which was separate to me and it contained all my publicity photos and videos. I realised it was like an AI (artificial intelligence). I feel like we all have this other entity, this Neuromancer-y thing that's made up of all the information we give up online.\" David Cronenberg are you listening? This could be your musical.\nEMA unpicks the strange relationship we have with our Facebook and Instagram selves and channels them into doom-filled post-Nine Inch Nails missives. On the track Neuromancer, she sings of a world where people take selfies with abandon but where that narcissism turns inward to create cyber-bullying. \"I didn't set out to make a topical record,\" she says. \"But the album ended up being a black mirror that perhaps will resonate with other people's experiences online.\"\nPriya Elan\nThe Future's Void is out on 7 April.\n"},
{"docid": "62 of 297 DOCUMENTS\n", "source": "The Guardian - Final Edition\n", "date": "April 30, 2009", "title": "Technology: Go, going, gone?: Chess has fallen, draughts has been jumped. And a new algorithm has professionals losing the ancient Chinese game to computers for the first time.\n", "content": "If you want to beat the best software in the world at a classic board game, the only one left to you is the strategy game Go. It's long been considered the last bastion of human gaming superiority, holding out against the onslaught of computational brute force and artificial intelligence techniques, while draughts, Othello, backgammon and chess have all fallen.\nBut to be a human winner at Go, you're going to have to get good in a hurry. The end, with computers ruling, is in sight.\nIn February, the software MoGo, developed at the University of Paris-Sud, achieved what was once thought impossible: it won two games, on a 19x19 board, against professional Go players. (It did benefit from a handicap - in effect, a number of free turns at the start of the game.) The same month, a program called Many Faces of Go, with a seven-turn handicap, beat a professional in a game played during the general meeting of the Association for the Advancement of Artificial Intelligence. (See the human-computer Go challenges page at bit.ly/Go28.)\u00a0\nThe wins did require a lot of computing power, however. MoGo was running on 640 cores of the Huygens supercomputer in Amsterdam; Many Faces of Go on a 32-core 3.2GHz Xeon, eight quad cores networked together.\nNext month the bar is likely to rise again as programmers fine-tune their code for the annual International Computer Games Association tournament, the computer olympiad, in Pamplona, Spain (bit.ly/Go26).\nYet even a few years ago Go looked like an impossible computing task: the \"search space\" for each move was too big. At each turn, especially in the beginning, there are hundreds of possible places to play (the board has 361 points, compared to chess's 64), and deciding on which will turn out better a number of moves ahead - a comparatively simple task in chess and draughts - turns into a morass, with hundreds of almost-equal possibilities and a few hundred moves over which to compare them. Standard \"minimax\" methods that work for chess (picking the move that gives your opponent the fewest high-value moves in future) don't work in Go.\nAcross the board\nWhat's changed has been the development of the UCT algorithm (bit.ly/Go24), a special case of the Monte Carlo Tree Search (MCTS) algorithm. UCT first appeared in 2006 applied to small 9x9 Go boards, and now academics, and professional Go programmers, are extending and refining its techniques. It has led to a revolution in Go program development.\nDavid Fotland, the US-based commercial developer behind Many Faces of Go (bit.ly/go222), says the results represent a major leap. But he's realistic about the achievement. \"My machine can beat a good amateur, but not a great amateur.\"\nIn 2008 he spent six months incorporating UCT into his software, combined with his traditional Go algorithm (\"the new algorithm has some blind spots\"), and won that year's computer olympiad. At the event every program incorporating UCT beat all the ones using traditional methods.\nGo pieces are called stones, are black or white, and identical. Playing alternately, the object is to use one's stones to surround as many blank intersections (called \"territory\") as possible. Games typically have a couple of hundred moves.\nThe Go rating scale for amateurs starts at 35 kyu, and moves towards 0: the highest level is 1 kyu. The next amateur rank is 1 dan, up to 7 dan. Above them are profes sionals, who start at pro 1 dan going up to pro 9 dan, the highest level possible.\n\"Handicapping\" allows weaker competitors to play on a level footing with stronger ones: each difference in grading is given as one stone's start. Thus a 20-kyu player would get nine stones in a game against an 11-kyu player.\nMany Faces of Go's result puts it at about a 1-dan amateur ranking. David Silver, who's researching Go for his PhD at the University of Alberta, says that: \"Anyone who would have suggested this (could happen) a couple of years ago would have been laughed out of town.\"\nSilver contributed to MoGo in 2007, developing UCT, which led to the first victories against human pro players on 9x9 boards. But when he started his PhD, pre- UCT, he was discouraged from studying the game by the head of the university's games research group. Too many good minds had been wasted on it, and the research was doomed to failure, it was thought.\nGame of chance\nFor the past 30 years, Go programs have evaluated positions by using handcrafted heuristics based on human knowledge of shapes, patterns and rules. However, professional Go players often play moves according to intuitive feelings that are hard to quantify. Encoding their knowledge into machine-understandable rules has proved to be a dead end.\nUCT works on the idea of playing out games over and over again, choosing moves at random, but it is biased to what's been successful before. It does this while still allowing alternative lines to be explored.\nNow, Silver says: \"I feel very fortunate doing research during this revolutionary period. MCTS is in its infancy, but the rate of performance improvement is pretty rapid.\" He thinks a machine to beat all humans could appear in four to five years.\nYet humans haven't lost all their tricks. As the human v computer Go challenges page notes: \"In every case where each player (computer and human) won at least one game, the human lost the first game played and won the rest. This may be because of experience gained in the first game, or because of techniques learned from discussions with the other players.\" But the randomisation the UCT algorithm brings may make that result less likely.\nFotland thinks the UCT-based work responds to a certain amount of processor supercharging, but then plateaus. \"There is a certain kind of large-scale fighting in Go that requires a kind of thinking the algorithm not good at. (The ranking) 1 dan amateur is where people start being good at these large-scale fights.\"\nWacky races\nHis rival Mick Reiss, the commercial programmer behind Go++ (bit.ly/AnJ9s), released his version incorporating UCT in Japan this month. His publisher says it matches the Japanese commercial version of Many Faces of Go in strength.\nReiss doesn't think UCT is the total answer. Of pure UCT-based programs, he says: \"A lot of them play in a wacky way, which doesn't really work. Because it's so different to what Go players are used to, in the early games they get beaten. Once they get a bit of practice they get their revenge.\"\nThe highest level of his own program is based on a combination of the old-style Go approach and the UCT program. \"It does less of the strangeness of the pure UCT programs. It plays in a more conventional way.\"\nFotland is still circumspect about when computers will dominate Go. \"I'd say 20 years. There's got to be several algorithm breakthroughs, and 20 years of Moore's law (bit.ly/Go224).\"\nAnd then? The end of an era? Certainly. But the end of playing Go? Thankfully, as the evidence shows, we still enjoy the simple pleasure of just playing games.\n"},
{"docid": "63 of 297 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "December 23, 2000", "title": "TV LECTURER ON ROBOTICS DISOWNED BY SCIENTISTS\n", "content": "\u00a0\n AN EMINENT group of scientists has denounced Kevin Warwick, the robotics researcher giving this year's televised Royal Institution Christmas lectures, saying he is scaremongering and poses a danger \"to the public perception of science\".\n The predictions of Professor Warwick, a specialist in cybernetics at the University of Reading, include saying humans will be slaves to robots in 50 years. They have brought him widespread publicity but roused the ire of other scientists in \"artificial intelligence\". They say his predictions are opinions, rather than objective science.\u00a0\n The committee of the Society for the Study of Artificial Intelligence and the Simulation of Behaviour, the leader in the field, has written a public letter condemning the decision by the Royal Institution and Channel 4 to pick Professor Warwick as host of the five- lecture series.\n The Christmas lectures are seen as an ideal forum for sparking children's interest in science, because they are shown in the holidays. The first will be on Boxing Day, and they regularly attract an audience of more than a million.\n One committee member, Dr Simon Colton, said: \"As Professor Warwick has been given the task of educating the nation's children through the lectures, we felt we had to warn that his predictions differ greatly from the opinions of the majority of researchers in artificial intelligence.\"\n Resentment has simmered among cybernetics scientists who have seen Professor Warwick garner publicity - and research funds - for an area that has found it difficult to deliver on hopes of developing \"intelligent\" computers and machines.\n \"The lengths he goes to, to publicise not just this view (about robots enslaving humans) but himself - including self-mutilation by inserting a chip under his skin - undermine his credibility,\" said Dr Colton.\n Alan Winter, operations director of the Royal Institution, said Professor Warwick had been chosen by it and Channel 4, which has won the contract to televise the lectures from the BBC.\n \"The criteria (for the lecturer) is that the person should be an academic still practising science, holding a chair or office at a university, who knows their topic, and is a good communicator,\" he said. Professor Warwick fulfilled those.\n The scripts of the four lectures so far recorded were \"about development of robotics and cybernetics\" and had not included Professor Warwick's better -known predictions. But he had not seen a script for the fifth and final lecture, which goes out live on Saturday, 30 December, called I, Robot.\n Dr Colton added: \"Previous Christmas lecturers have indeed included truly visionary professors. But, as representatives of the largest and longest -standing artificial intelligence society in Britain, we strongly believe this is not true of Kevin Warwick.\"\n"},
{"docid": "64 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "April 26, 2016", "title": "Robot monk to spread Buddhist wisdom to the digital generation; At an ancient Chinese temple, Xian'er can chant mantras and answer questions about his faith via a touch-screen display\n", "content": "In an unexpected synthesis of ancient and modern, a Buddhist temple on the edge of Beijing has developed a robot monk who can chant mantras and and explain basic tenets of faith.\u00a0\nAt 2ft high, Xian'er is encased in saffron-yellow robes and has a shaved head. Despite spending much of his time closeted in the spiritual calm of Longquan Temple, he wears an expression of permanent surprise. \nHis purpose is to reach out to people who are more connected to their smartphones than their inner being. Xian'er can answer 20 simple questions, displayed on the touch-screen on his chest, about Buddhism and daily life at the 500-year-old temple. \nMaster Xianfian, a (human) monk at Longquan and Xian'er's creator, said artificial intelligence could be harnessed to spread Buddhist wisdom in China. \n\"Science and Buddhism are not opposing nor contradicting, and can be combined and mutually compatible,\" he told Reuters. \nBuddhism filled a gap in a fast-paced, hi-tech existence, he added. \"Buddhism is something that attaches much importance to inner heart, and pays attention to the individual's spiritual world ... I think it can satisfy the needs of many people.\" \nXian'er was developed as a robot in a joint project between the temple, artificial intelligence experts at Chinese universities and a technology company. \nSince he was created, he has appeared at several robotic fairs across China, but spends most of his time in deep meditation on an office shelf in Longquan. \nHe started his existence as a cartoon drawn by Xianfian when he joined the temple in 2011. Xianfian described Xian'er as \"a reflection of innovative Buddhist spirit ... [who] might help traditional Buddhism reach a wider public more easily.\" \nMaster Xuecheng, the head of Longquan and president of the Buddhist Association of China, is a digital communication enthusiast. \n\"Buddhists should not only seek enlightenment through daily learning, meditation and cultivation to gain positive energy from Buddhist doctrine. They should also contribute more to society, by transforming their own gains, kindness, compassion and wisdom to others through the internet and new media,\" he told CCTV. \n"},
{"docid": "65 of 297 DOCUMENTS\n", "source": "Guardian.com \n", "date": "October 1, 2008", "title": "Kelly to Kurzweil: You're a total Thinkist \n", "content": "You may have heard of Ray Kurzweil, the inventor and futurist. It's fair to say he's got a different approach on life: he thinks the singularity - a theoretical moment of supreme technological advance, precipitated by artificial intelligence - is set to arrive in 2045. That's why the 60-year-old New Yorker pops up to 210 pills a day in an attempt to extend his lifespan until the moment when the singularity arrives and suddenly cures cancer, makes us live forever and works out where the TV remote went.\u00a0\nKevin Kelly, the Wired editor at large, says he admires Kurzweil but makes a well-argued rebuttal to what he calls \"thinkism\". This is, Kelly says, where we believe the main thing we lack in solving problems is not being able to think enough. So, if we put enough cycles in we can find the answer to anything: a sufficiently advanced AI would have more think cycles than all of humanity combined, therefore any problem you can imagine would be solved in a jiffy.\nThe problem? Sometimes thinking isn't enough. Getting there might require data that had been previously unable to get, or the building of complex tools - machines like the Large Hadron Collider. And that takes a lot of time and effort. Even if the singularity arrives, it won't solve everything instantaneously because we've still got to build the tools to help give us the answers.\nIt's a cogent take on technological utopianism. But I've always had a more straightforward problem with Kurzweil's thinking: if a massively superior artificial intelligence did arise, why on earth would it waste its time improving things for the human race?\n"},
{"docid": "66 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "April 16, 2018", "title": "Help to break Facebook's grip on data, peers urge Whitehall\n", "content": "Data held on people by the NHS and other public institutions should be made available to artificial intelligence companies to counter the giant US technology companies, a House of Lords report has recommended.\u00a0\nThe authors said that companies such as Facebook and Google benefited from huge \"network effects\" in which the masses of data they held gave them an almost unassailable lead in developing programs.\nOne of the best ways to open up the market, the committee suggested, was for big public datasets to be anonymised and offered to researchers. \"Several witnesses pointed to the network effects at work in informationbased industries, which tend towards 'winner-takes-all' markets, and contributed to the growing dominance of these large technology companies,\" the select committee on artificial intelligence wrote. It presented the findings after interviewing experts. One witness compared the biggest technology companies to robber barons. Mike Lynch, founder of the technology company Autonomy, said that datasets were a barrier to entry. \"Data is everything in machine learning, which means whoever gets access to data can have a big advantage,\" he said.\n\"As they gain a more consolidated position in the market, in turn they get access to more data, and so they can easily create an advanced competitively defensive position.\"\nAttempts to use NHS data for research have hit problems in recent years. A deal in which Deep Mind, the Google AI company, was given access to patient records in 2015 was criticised and the hospital trust involved was sanctioned by the Information Commissioner's Office. An earlier programme intended to provide health researchers with anonymised patient data was closed down in 2016 after allegations of incompetence. That scheme, called care.data, was criticised by some researchers who said that it was not possible to make health records sufficiently anonymous that they protected people's identities while still being useful. However, the committee said that unless other sources of data were offered, smaller AI companies had little chance of competing. \"These datasets give these companies a key advantage in the development of AI systems. This form of market dominance is increasingly referred to as a 'data monopoly',\" it wrote.\nThe committee also said that, by more accurately representing the whole population, such datasets might counter the problems of unwitting bias. Some groups, especially the poor and ethnic minorities, suffer from \"data poverty\", in which there is less electronic data about them. This may mean that using privately held datasets will lead to their exclusion from artificial intelligence systems.\nMatt Ridley, page 21\n"},
{"docid": "67 of 297 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "January 5, 2018", "title": "The legal and ethical minefield of AI: 'Tech has the power to do harm as well as good'; Artificial intelligence and machine learning tools are already embedded in our lives, but how should businesses that use such technology manage the associated risks?\n", "content": "As artificial intelligence (AI) penetrates deeper into business operations and services, even supporting judicial decision-making, are we approaching a time when the greatest legal mind could be a machine? According to Prof Dame Wendy Hall, co-author of the report Growing the Artificial Intelligence Industry in the UK, we are just at the beginning of the AI journey and now is the time to set boundaries.\n\"All tech has the power to do harm as well as good,\" Hall says. \"So we have to look at regulating companies and deciding what they can and cannot do with the data now.\"\u00a0\n                     AI and robotics professor Noel Sharkey highlights the \"legal and moral implications of entrusting human decisions to algorithms that we cannot fully understand\". He explains that the narrow AI systems that businesses currently use (to draw inferences from large volumes of data) apply algorithms that learn from experience and feed back to real-time and historical data. But these systems are far from perfect.\n Related:  Copyright, defamation, employment: how tech is disrupting every corner of the law\nPotential results include flawed outcomes or reasoning, but difficulties also arise from the lack of transparency. This supports Hall's call for supervision and regulation. Businesses that use AI in their operations need to manage the ethical and legal risks, and the legal profession will have a major role to play in assessing and apportioning risk, responsibility and accountability.\nAI also raises new issues around data ownership and intellectual property. \"Different suppliers offer different positions on whether any learning that the AI platform takes from a dataset should be for the benefit of the owner of the dataset, or should be for the benefit of the wider user community,\" says Emma Wright, technology partner at Kemp Little. \"Companies need to consider whether they want to share and benefit from industry learning, or whether the efficiencies that the AI has created offer a market advantage that should remain proprietary.\" \nCliff Fluet, partner at Lewis Silkin, also recognises the tensions around intellectual property ownership. \"The supplier will want to retain the ability to use the knowhow and core engine that facilitates the machine learning solution again elsewhere, while the customer will want to own it,\" he says. \nThe lack of transparency is another potential sticking point. \"AI software does not allow a user to 'look under the bonnet' and allow independent verification of the inputs that have been entered in order to drive the output,\" says Wright. \"This limits the degree of reliance that companies can place on the output, particularly when used in a compliance or legal context.\" \nThis \"black box\" syndrome is partly due to engineers not understanding exactly how the conclusions of some machine learning systems are reached, as well as their unwillingness to risk losing competitive advantage. \"Algorithms are proprietary and valuable, so sharing with customers, where the technology may ultimately end up in the hands of competitors, remains unappetising,\" says Wright.\nThe algorithm transparency dilemma is at the heart of a criminal case in Wisconsin, where an appeal has been launched against a judicial decision based on the inability to explain the workings of an algorithm. \nHowever, in most business contexts, \"an AI decision-maker is a tool, just like any other technology that we might implement to make our work easier,\" says Ben Travers, head of IP and IT at Stephens Scown. \"Organisations that use an AI decision-making tool will not be able to avoid liability for bad decisions.\"\nRobotics and ethics professor Alan Winfield agrees. \"We need to be absolutely clear that AIs cannot be responsible for their decisions. There's nothing mystical about AI systems that means that you can't engineer them responsibly,\" he says. \"Even systems that learn can be designed to be provably safe - by building in hard limits beyond which the learning cannot take the system.\"\n These imposed limits aren't yet required and the likelihood of an artificial intelligence replacing a human judge is slim. The critical analysis, abstract reasoning and judgement required in sentencing will not be replicable in AI for a very long time. Currently, the Sentence Range Calculator on Thomson Reuters Practical Law applies the Sentencing Council's definitive guidelines, but it operates on the understanding that the final decision rests with a judge who has heard all the evidence and seen the witnesses in every case.\n Related:  Driverless car crashes and data theft: law experts predict the court cases of the future\nBeyond the legal profession, when it comes to managing the risk in business and professional services, supervision is key. \"Who will make sure that the algorithms actually do what they say they will do?\" asks Sonya Leydecker, consultant and former chief executive of Herbert Smith Freehills. \"From a law firm perspective, you would need assurance that you could rely on a system governing day-to-day business to comply with health and safety and employment law.\"\n\"One of the biggest considerations for businesses using AI is the data,\" says Dave Coplin of The Envisioners, who is a former chief envisioning officer at Microsoft. \"Not only do they have to think about whether they have the data they need to make the AI work, but more importantly, whether they have the right to use it in that way. Organisations need to develop a moral and ethical stance on how they use customer data, as they may be tempted to do things that offer a lot of value, but could have massive privacy implications.\" \nHe adds that rather than attempting to control the algorithm, \"we are going to have to get better at how we manage and control the data that the AI will use as fuel for the answer.\" \nJason Alan Snyder, global chief technology officer of Momentum Worldwide, advises businesses not to lose sight of the human factor. \"For the moment, anyway, humans are a primary source and destination for the information being created. And people give meaning to the machines. Each of us reading this is feeding data into the cloud. Data is replacing oil and gold as a primary commodity. But a business has got to put people first. \" \nAll of this comes down to getting our approach to data management right. Coplin highlights the importance - and the limitations - of data governance. \"Current and planned regulation locks down data usage, which is obviously a good thing. But locking it down also prevents innovative use that could provide incredible value to consumers as well as businesses,\" he says. \n"},
{"docid": "68 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "May 23, 2017", "title": "Ford ditches boss in shift to driverless future; Carmaker takes new road to high-tech future just weeks after being overtaken by Tesla, James Dean reports\n", "content": "Ford ousted its chief executive yesterday, replacing him with the man in charge of its driverless vehicle programme as the carmaker plotted a new course to embrace artificial intelligence, 3D printing and robotics.\nJim Hackett, 62, the chairman of Ford Smart Mobility, took over from Mark Fields, 56, as president and chief executive with immediate effect. Mr Fields, who was appointed to the top job less than three years ago, retired after 28 years with the company.\nThe abrupt change at the top came seven weeks after Tesla's market value climbed past Ford's. Under Mr Fields, Ford's share price fell by 37 per cent as Tesla's climbed by 30 per cent.\u00a0\nFord's board is also believed to have been unhappy with the way that Mr Fields sparred with Donald Trump last year over plans to send small car production to Mexico from the US. In April last year, Mr Fields announced a plan to move production from Michigan to San Luis Potosi. Mr Trump described it as an absolute disgrace. Ford scrapped the plan weeks after Mr Trump won the election.\nBill Ford, executive chairman and great-grandson of the founder Henry Ford, said that Ford required a transformational leader.\n\"Mark had a tremendous career at Ford and did great things. We've had record profitability and cashflow and really solid results. That's put us financially in a great position so we can chart the future. But this is a time of unprecedented change. These changes are here now,\" he added.\nFord said that it would begin to use new tools such as artificial intelligence, big data, 3D printing and advanced robotics to improve efficiency and speed up decision-making. Mr Hackett would also work with Mr Ford on \"decisively addressing\" underperforming parts of the business, it said, without naming specific departments.\nFord shares rose by 1.4 per cent to $11.02 in New York yesterday as Tesla's lost 0.8 per cent to $308.43.\nMr Hackett was an outsider to the car industry when he joined Ford's board in 2013. He served as chief executive of Steelcase, an office furniture maker, for 20 years. He was appointed chairman of Ford Smart Mobility when the division was set up in March 2016 to \"design, build, grow and invest in emerging mobility services\". Ford said last year that it wanted to become \"a leader in connectivity, mobility, autonomous vehicles, the customer experience and data and analytics\". The new chief executive sought to reassure shareholders that Ford would remain focused on the bottom line as it remodelled itself. \"The future is really a source of optimism. We have just as much a future as anyone else, we have a right to it. What won't be lost is this great vehicle business,\" he said.\nFord posted a record annual profit and sales under Mr Fields last year but that failed to assuage shareholders who believe that the company has been slow to position itself for the future.\nLike other established carmakers, Detroit's big three, Ford, General Motors and Chrysler, have come under increasing pressure to invest in electric vehicle and autonomous driving technology. The pressure increased last year when Tesla unveiled the Model 3, its first electric car designed for the mass market.\nCarmakers are also under pressure from Waymo, the self-driving car company owned by Alphabet, and Uber, which has invested billions of dollars in its autonomous taxi programme. Marcy Klevorn, 57, chief information officer, will replace Mr Hackett as president of Ford Smart Mobility, effective from June 1.\n"},
{"docid": "69 of 297 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "December 23, 2000", "title": "CHRISTMAS LECTURER DISOWNED BY SCIENTISTS\n", "content": "\u00a0\n AN EMINENT group of scientists has denounced Kevin Warwick, the robotics researcher giving this year's televised Royal Institution Christmas lectures, saying he is scaremongering and poses a danger \"to the public perception of science\".\n The predictions of Professor Warwick, in cybernetics at the University of Reading include saying humans will be slaves to robots in 50 years, and they have brought him widespread publicity but roused the ire of other scientists in \"artificial intelligence\". They say his predictions are opinions, rather than objective science.\u00a0\n The committee for the Society for the Study of Artificial Intelligence and the Simulation of Behaviour (SSAISB), leaders in the field, have written a public letter condemning the decision by the Royal Institution and Channel 4 to pick Professor Warwick as host of the five-lecture series.\n The Christmas lectures are seen as an ideal forum for sparking children's' interest in science, because of its timing in the holidays. The first will be shown on Boxing Day, and they regularly attract an audience of more than one million.\n One of the committee, Dr Simon Bolton, said: \"As Professor Warwick has been given the task of educating the nation's children through the lectures, we felt we had to warn that his predictions differ greatly from the opinions of the majority of researchers in artificial intelligence.\"\n Resentment has simmered among cybernetics scientists who have seen Professor Warwick garner publicity - and research funds - for an area which has found it difficult to deliver on hopes of developing \"intelligent\" computers and machines.\n \"The lengths he goes to, to publicise not just this view (about robots enslaving humans) but himself - including self-mutilation by inserting a chip under his skin - undermine his credibility,\" said Dr Colton.\n Alan Winter, operations director of the Royal Institution (RI), said Professor Warwick had been chosen by the RI and Channel 4, which for the first time has the contract to televise the lectures from the BBC.\n \"The criteria (for the lecturer) is that the person should be an academic still practising science, holding a chair of office at a university, who knows their topic, and is a good communicator,\" he said. Professor Warwick fulfilled those.\n The scripts of the four lectures so far recorded were \"about development of robotics and cybernetics\" and had not included Professor Warwick's better -known predictions. But he has not seen a script for the fifth and final lecture, which goes out live on Saturday, 30 December,called I, Robot.\n Dr Colton added: \"Previous Christmas lecturers have indeed included truly visionary professors. But, as representatives of the largest and longest -standing artificial intelligence society in Britain, we strongly believe this is not true of Kevin Warwick.\"\n"},
{"docid": "70 of 297 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "December 10, 2017", "title": "Robots can set us free and reverse decline, says Labour's Tom Watson; Party's deputy leader says people should not fear the 'march of the robots' and automation need not mean lost jobs\n", "content": "Labour's Tom Watson will call on society to \"embrace an android\" as he argues that the rise of automation in the workplace need not cause mass unemployment and should instead be welcomed. \nThe party's deputy leader will make the comments at the launch of the final report of the Future of Work Commission, which has concluded that people should not fear the \"march of the robots\". \nInstead, it claims that if government investment is sensibly targeted, the technological revolution has the potential to reverse the UK's economic decline and create as many jobs as it destroys.\u00a0\nWatson, who convened and co-chaired the commission, is expected to say: \"Much has been written about the impact of technological change and the dystopian future we could all face as a result of the rise of the robots.\n\"It can sometimes feel like we are preparing for a world in which artificial intelligence, algorithms and automation, rather than human endeavour and hard work, will shape every aspect of our society and our economy. That sounds like a frightening prospect. But it needn't be.\"\nHe will argue that allowing \"21st-century machines\" to take on the heavy lifting and routine tasks of the future will let the human workforce focus on activities that generate larger economic benefits.\n\"That is liberating. So I suppose what I'm really saying is: robots can set us free... A former prime minister once famously said 'hug a hoodie'. Today, I'm asking you to embrace an android,\" Watson will say.\nHowever, the study admits that taking advantage of the change requires ensuring the workforce is ready to take on jobs that need a different array of skills. \nThe commission has brought together experts including the Nobel prize-winning economist Sir Christopher Pissarides, and Michael Sandel and Michael Osborne, professors from Harvard University and Oxford University respectively.\nThey conclude that Britain's low productivity, falling wages and inequality are down to poor government decisions, rather than the result of automation.\nInstead, they say \"mass technological unemployment is highly unlikely\". However, to avoid problems, they call for action to prevent the growing gap between high-skilled and low-skilled workers, and in particular for \"future-oriented planning\" when investing in skills that will be necessary for a future workplace. \nRecommendations include a specific artificial intelligence curriculum to be developed for secondary schools, including ethics training, alongside a universal, lifelong future skills account that would help people retrain over their working lifetime as workplace demands shift.\nThey also urge changes to tax and business rates regimes to incentivise companies to invest more in new technologies, an increase in research and development, and expanding employment protections to all workers including agency staff and contractors. \nHelen Mountfield QC, who co-chaired the commission, said: \"Advances in robotics and artificial intelligence don't need to spell the end of work. But we cannot sit passively by letting technological change just happen. \n\"We need to decide what sort of future we want and make policy choices, design education and introduce a legal architecture to shape a future of good work which benefits everyone, in which the rewards of innovation are fairly shared.\" \nThe report comes after it was claimed that at least one-fifth of jobs across Britain were at high risk of being automated, rising to 40% in some parts of the country.\nThe prediction by the Future Advocacy thinktank followed a warning from PricewaterhouseCoopers that more than 10 million workers were at high risk of being replaced by robots.\nThere is little evidence of mass fears in the UK of being pushed aside by automation, but a survey has found that more than 70% of Americans are wary about a world in which machines perform tasks previously carried out by humans.\nThe report comes as John McDonnell, the shadow chancellor, launched another study that claims the UK's financial system is failing to deliver investment to the high technology sector.\nThe interim report, produced by Graham Turn of GFC economics, found that UK output from high-tech industries has fallen over the last 10 years.\n\"Under the Tories, we've seen more and more investment flowing into property speculation whilst high-tech firms have been starved of the money they need, and research spending has lagged far behind,\" said McDonnell. \nTurner said the worry was that regional inequality would rise due to a disproportionate number of tech companies being based in London and the south-east, and said there was also too little money spent on research and development. \n\"The pace of automation and technological change is accelerating, threatening established business models and creating an economy characterised by frequent 'disruptive' episodes. Analysis shows that banks are diverting resources away from industries vital to the future of this country,\" Turner said.\n"},
{"docid": "71 of 297 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "February 17, 2017", "title": "Automated holidays: how AI is affecting the travel industry; Travel companies are investing in artificial intelligence, but that doesn't mean fewer jobs for humans\n", "content": "First you could book a flight online. Then came online travel agents. And now you might check in for your hotel via mobile, a computer could set the price, while a chatbot answers your queries.\nSome travel experts expect the first autonomous cargo flights to start within several years, while big data analysis is on the rise at internet-based firms like Expedia, Lastminute.com and Skyscanner. \n\"We have to reinvent the place of the man in the system,\" says Fabrice Ota\u00f1o, chief data officer at AccorHotels group. \u00a0\n\"Artificial intelligence can replace some existing jobs, and managers have to take care of what the next step for people is, that is relevant in the data world. We have to evolve our revenue managers into more data jobs, balancing old jobs with new school jobs in business analytics.\"\nSo far, at least, that has not meant a decline in jobs. According to the most recent EU statistics, although overall employment declined from 2008 to 2014, it rose in tourist accommodation and selected tourism industries: now tourism employs just over 12 million people within the EU.\nCompanies like IBM, whose Watson tool is helping the travel company Thomson trial a smart chatbot for its customers' holiday searches, pledge to \"augment, not replace, human intelligence\". \n Related:  Solar-powered trains are closer to reality than we might think\nThis is also the view at Skyscanner. The airfare comparison site acquired by Chinese firm Ctrip International for \u00a31.4bn, may have a dedicated \"Bots\" squad, but it doesn't believe computing power will replace human roles or travel reviews.\n \"We see AI [artificial intelligence] as an evolutionary part of travel,\" says a Skyscanner spokeswoman. \"We've always believed that people would go from click-type-tap style searching to a conversational format. Interestingly, those using our bots treat them in a very 'human' way - ask for the bot's name, send an emoji or sticker of appreciation.\"\nMore investment in AI is a business necessity for hotels, according to Tim Gunstone, managing director of EyeforTravel, who recently spoke [pdf] on the issue at an industry conference. \"The cost of search marketing [paid by hotels to online travel agents for sales made] has gone up,\" he says. \"This is what is driving hoteliers. The industry needs to cut costs and focus on loyalty.\" \nGunstone believes AI can boost loyalty by helping hoteliers know more about their customers, in order to better meet their needs and win repeat business.\nWe will see \"technological unemployment\", says Professor Ryan Abbott, professor of law and health sciences at the University of Surrey, but if a chatbot gives hotel recommendations based on reviews and your preferences, rather than plugging a relative's place, maybe that's for the best,\n\"People who have been rendered obsolete by technology have always gone on to find new and better jobs,\" he adds. \"When machines outperform people in every way, that's another problem - but that's a long way in the future.\"\nAt the bottom of the travel market, computing is about automation and saving money, but at the top end, AI is being used to personalise experiences - delivered by people. A waiter at a luxury hotel, for instance, could use information on you to predict what kind of drinks you like and recommend something from the menu. Or reception staff, with data on your spa use, might propose a particular service. \n Related:  Age of automation: what if more work is the problem, not the solution?\nBut not everyone is predicting the demise of travel agents. A spokesperson for ABTA, which represents UK travel agents and tour operators, says almost a fifth of Brits still booked a holiday in a travel store last year and that although artificial intelligence can help with targeted marketing, \"it can be hard to beat the human touch\".\nPeople quickly get frustrated if a chatbot isn't responding accurately, for a start. \"Many roles in the travel industry remain unaffected by technological advances,\" adds a spokesperson. \"Cooks are needed to cook, beds need to be made, and the personal experience of a destination expert is hard to beat.\"\nABTA warns, too, that travel companies need to avoid breaching customers' privacy when they gather data on them: this is something that AccorHotels makes specific pledges to respect, beyond European legislation, which states that personal data can only be gathered legally under strict conditions and must be protected against misuse.\nGunstone also cautions that regulators could be catching up with computer-based intelligence. \"US antitrust laws are on the lookout for AI-created price fixing,\" he warns.\nMeanwhile, automation won't work everywhere. Ian Yeoman, visiting professor at the European Tourism Futures Institute, says we won't see automated hotels until closer to the end of this century, but even then it won't be worldwide.\n \"In many third-world destinations, the cost of labour is quite cheap so there's no incentive for owners and operators to invest,\" he says. \"You would probably have sabotage and riots. These countries also don't have a strong technological infrastructure as back up - where you have failure, you could have catastrophic failure.\"\n                     Sign up to be a Guardian Sustainable Business member and get more stories like this direct to your inbox every week. You can also follow us on Twitter.                   \n"},
{"docid": "72 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "February 15, 2012", "title": "Recruitment technology passes intelligence test; Sophisticated systems now match jobseekers with employers, says Mark Frary\n", "content": "Finding a graduate job is now harder than ever. According to the Association of Graduate Recruiters, the average number of applications for graduate jobs now stands at 83 per vacancy, a record figure. The comparative figure was 69 in 2010, 49 in 2009 and just 31 in 2008.\nWhile this means that jobseekers are facing a tough time, so are employers.These increases mean that companies are now having to process far more applications than ever before and typically have to do that on decreased financial resources because of the recession.\u00a0\nSome organisations are turning to artificial intelligence to manage the flood of applications.\nColin Minto, head of resourcing at FTSE 100 security company G4S, says that the volume of applications per vacancy at the company has grown from 40 to 80 in just 14 months. The company handles all its job applications through an online career centre at careers.g4s.com.\nHandling applications online is not new, but what G4S does with applications is rather innovative. \"All our users are continually matched using artificial intelligence and semantic logic to every new job posted on to the career centre globally,\" Minto says.\n\"This in turn alerts a jobseeker to a potential opportunity they are suitable for, and also alerts G4S's local hiring manager when a candidate profile in the global database matches a job they have posted,\"\nThe career centre uses two main technologies. The text in CVs and job descriptions is analysed, or parsed, using technology developed by Burning Glass, a company based in Boston. Its Lens/Xray parsing engine has been taught to recognise key phrases using a database of tens of millions of CVs.\nThe system breaks down an applicant's CV into definable chunks, tagging pieces of information according to what they present, such as an exam grade or hobby.\nThe next step is to match this information intelligently with key phrases in a job description, using TribePad, which was developed by the Sheffield company Talent on View. This generates a list of applicants who are best matched to the vacancy.\nWhile this investment in cuttingedge technology sounds expensive, it has delivered return on investment for the company. G4S's Cash Solutions business in the UK invested \u00a330,000 to automate its recruitment process, including ensuring that all jobs were advertised on the career centre. Minto says that this helped G4S Cash Solutions to save \u00a3100,000 for operational hiring and \u00a3500,000 for management hiring in 2011.\nG4S is at the forefront of such technology but others are now looking at implementing it. TribePad has recently signed a contract to introduce a similar system with Sodexo, the food and facilities management company.\nOther technology companies have entered the intelligent search market. WCC in the Netherlands has developed an artificial intelligence engine called ELISE, which is used by Germany''s Federal Employment Agency to match vacancies with jobhunters.The key to the system is that it uses \"fuzzy search\", meaning that it finds much more than just exact matches between desired skills and competencies and those offered by the candidate.\nWhat this all means is that graduates are going to have to become skilled in something similar to the search engine optimisation used by websites to attract traffic now that CVs are going to increasingly be scrutinised by \"robots\" rather than the human resources team, at least in the initial phase.\nMinto advises graduates that they need to outline clearly what they can do and how they have used those skills in practical situations.\nOur users are matched to every new job posted\n"},
{"docid": "73 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "May 10, 2017", "title": "This dating app will read your tweets to find a personality match - find out yours\n", "content": "If you have ever worried that the you've spent on Twitter have been wasted, think again. You've been feeding a machine that could help find\u00a0you the love of your life.\u00a0\u00a0\nDating app Loveflutter, which works in a very similar way to Tinder and launched in 2014,\u00a0believes it can match potential partners by analysing their Twitter profiles for compatibility.\u00a0\nThe language people use on social media and in conversations can be\u00a0a key indicator of personality. But until now there hasn't been a way to analyse two people's individual speech and their interactions together in real time to see their chances of connecting romantically.\u00a0\nLoveflutter\u00a0is hoping to change this by introducing artificial intelligence to its app that can analyse personality traits from users' Twitter profiles and conversations to establish a compatibility score. \u00a0\n\"It's good to explore different innovations in dating because the looks focus has got a bit tired,\" said Daigo Smith, founder of Loveflutter.\u00a0\"We think Twitter gives a really good display of your personality. It's a ready made way to show who you are.\"\nLoveflutter works in a similar way to Tinder but includes a 140-character description and 10 recent tweetsCredit:      Loveflutter     \nThe app has teamed up with Receptiviti, a firm that uses artificial intelligence to analyse language, to match language styles and create a compatability score from users' tweets and conversations.\u00a0\n\"Lanaguage analysis is an exciting area that hasn't been explored in dating before,\" said Smith. \"What people use on their profiles and how they interact once they get chatting.\"\u00a0\nLoveflutter\u00a0plans to\u00a0add pre-\u00a0and post-match\u00a0compatibility scores to its\u00a0app\u00a0before the end of the year, Smith said. The app will also be\u00a0able to suggest when users should stop chatting and go on a date, based on how their conversation progresses.\u00a0\nIt\u00a0isn't the first company to glean personality information from social media.\u00a0 Political campaigns and marketing companies alike use similar methods to target voters and customer online. But Loveflutter will be the first dating app to use the technology.\nGiven the tendency for people to present\u00a0different versions of themselves across social media, it isn't clear if Twitter behaviour corresponds exactly to real-life personality.\u00a0\nAhead of its launch later this year, users can test the technology\u00a0through\u00a0 an online tool Loveflutter and Receptiviti  have created that analyses personality based on tweets.\nIt asks users to enter their Twitter handle so it can scan for a range of personality traits including Type A or Type B, levels of happiness and\u00a0depression,\u00a0persuasiveness and independence.\u00a0\nFor those who require a second opinion, IBM has a similar tool that uses Watson, the\u00a0Jeopardy!\u00a0beating AI machine, to analyse personality based on text samples. \u00a0\nAs a first step towards personality matching users,\u00a0Loveflutter today announced Twitter integration, meaning users can log in through the 140-character social network. They can also add their 10 most recent tweets to their profile, giving potential dates an indication of their online personality.\u00a0\nLoveflutter currently has around 1 million users, around 330,000 of whom are based\u00a0in the UK.\u00a0\nBest iOS apps: 20 apps you should download today      If you would like to add a comment, please register or log in     RegisterLog inPlease review our commenting policy\n"},
{"docid": "74 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "June 15, 2015", "title": "Humans review: 'a clever, high-energy thriller, it's sci-fi for the non sci-fi fan'; The Hawkins family love Anita, their helpful humanoid robot - but when she starts to think and feel, things start to get really complicated\n", "content": "Would you? Get one? That's a discussion that will have been going on in the country's living rooms during and after the first episode of Humans (Channel 4, Sunday). One meaning your own synthetic, or \"synth\": a green-eyed humanoid robot.\nOn the plus side it will clean and iron and then cook you a nice chicken chasseur for tea, freeing you up for all the good stuff you never find time for. It might even provide some kind of companionship. Plus there are potential upgrades, including adult ones, if you know what I'm saying.\u00a0\n Related: Humans recap: season one, episode one - these synths get everywhere\nOn the downside, there is a danger synths might make you, me, everyone redundant. They are already doing all the jobs people don't really want to do, not just in the house, but street cleaning, handing out free newspapers, sex work etc (they are basically a bit like immigrants, I'm afraid). But it won't be long before they're doing the jobs you might want to do yourself - doctor, lawyer, politician, TV critic, footballer perhaps. The Singularity - when artificial intelligence overtakes human intelligence - isn't far off. Also, returning to the basic domestic model, it might be a bit creepy having a machine that looks just like a person living in your house. It's not good for the children either, it'll mess with their heads. Plus you might be unlucky - like the Hawkins family - and get one, like Anita, that ... who can think, and feel. Then things start to get really complicated.\nOne of the beauties of Humans is that, like Charlie Brooker's Black Mirror, it really isn't such a big leap, or ask. Only last week there was a story about Ocado creating an army of humanoids with artificial intelligence. The online supermarket robots might not be as pretty as Gemma Chan, who plays Anita (very convincing as a semi-humanoid), but this stuff is happening. Tellingly, Humans is set not some time in the future, but some time around now. It's sci-fi for the non sci-fi fan, sci-fi that has more than a foot in sci-fact.\nIt's also a clever, high-energy thriller. Written - actually adapted from a Swedish series - by Spooks writers Sam Vincent and Jonathan Brackley, it has some of that show's breathless urgency and tachycardiac pace. There are more of these sentient synths about the place, in the woods, plus urban wastelands, hiding, running. They are seen as a threat, bad dudes are after them, darting them, bundling them into vans, taking them away to be wiped clean, rebooted, decommissioned, or abused. Actually, it's too early, and too simplistic, to divide into good and bad. There's a more complicated, more realistic, more interesting morality to Humans.\nSo you're sitting on the edge of your seat, but maybe you're also resting your chin in your hand, as you ponder technology, intelligence, consciousness, humanity, who we are and how we live now, and so on. And maybe that discussion you have should be not would you get a synth, but will you? Me? Are you kidding? Of course I bloody will. Mmm, chicken chasseur.\nCan there really be 100 Lego bricks for every child, woman and man in the world, as revealed in The Secret World of Lego (Channel 4, Sunday)? Seven hundred billion bricks? By my calculations that would mean (for someone with average size feet) that approximately every other time you walked into a room bare-footed you'd step on a piece ... yeah, so about right then.\nHead office, in the Danish village of Billund, is a secretive place where strange child-adults stick coloured bricks together, for their job. Secretive, until now; \"Reputation Manager\" Roar Rude Trangbaek has opened the doors and is showing us round, except for the product development area; as the camera approaches, the building's shutters do their thing (shut).\nThe cultishness of the company - or the fact that sugar isn't allowed in the canteen - doesn't put Justin off, a 23-year-old Afol (adult fan of Lego) from London from wanting to work there. Wanting to, and succeeding. The dream comes true! Of the thousands who apply, Justin is selected. And here he is, six months into the job. \"It's amazing, it's this great family atmosphere, you feel like you're part of something,\" he says, smiling. There's something slightly different about him, now he's in, from before, when he was just a fan. I think Justin is lost, to Lego.\nAnother interesting stat: in a couple of years the population of Minifigures will overtake humans ... Hang on, this is beginning to feel like the other show. How long before Lego Minifigures will be able to think?\n"},
{"docid": "75 of 297 DOCUMENTS\n", "source": "THE DAILY TELEGRAPH(LONDON)\n", "date": "March 01, 2001", "title": "Talking computer is taking its cue from Kubrick\n", "content": "A REAL-life version of Hal, the intelligent talking computer in Stanley Kubrick's film 2001, A Space Odyssey, is being developed by scientists.\nResearchers are teaching their creation, also called Hal, how to understand everyday language and converse with humans in the hope that one day it will allow us to abandon keyboards and converse naturally with computers.\nAt present Hal is a toddler, learning language from children's stories, but the scientists hope to give it the linguistic skills of a five- year-old.\u00a0\nThe fictitious Hal went mad and set about murdering the crew of the spaceship Discovery in Kubrick's film. There is no chance of the same happening with its Israeli namesake, developed by Artificial Intelligence Enterprises, a Tel Aviv company.\nIn the film, Hal had an instructor who taught him to sing A Bicycle Built for Two. The real Hal - an intelligent software program - also has a teacher who communicates with it via a keyboard and responds to what it says in the manner of a parent.\nAlready Hal is said to have fooled independent experts who believed they were reading transcripts of exchanges between an adult and a 15-month-old child. It learns language like a human, from sets of problem-solving rules called algorithms and the words typed in by its teacher.\nSo far Hal is capable of only simple sentences of a few words, New Scientist reported. For example, when asked what game it would like to play in the park, it might respond: \"Ball, mummy.\"\nHowever, while children might take years to learn the basics of language, Hal could pick it up in just a few days.\nJason Hutchens, Artificial Intelligence's chief scientist, claimed that the potential impact of the technology could be as great as the discovery of electricity. \"Once it exists there are millions of uses for it,\" he said.\nDr Hutchens said: \"Instead of telling it how to learn language, Hal figures this out for itself. The whole point is that we don't know how it's doing it.\"[PS]News: [ES]\n"},
{"docid": "76 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "July 12, 2017", "title": "Program creates the perfect name for your dog (almost)\n", "content": "Shadoopy, Sbookie, and Ray-Bella. They sound like the sort of \"kooky\" names an upmarket dog-walker might have to shout on Hampstead Heath.\u00a0\nBut they're not the product of an animal lover's imagination. They were generated by an algorithm mimicking the way we name dogs after it \"studied\" a list of 81,542 pooches registered in New York. The experiment took only a few hours, using freely available tools.\nHaving trawled the list of real-life names, which includes Spanky the toy poodle and Putin the cross-breed, the algorithm's 400 offerings included Zouf, Watty and Jot. It also came up with the less appealing Grimby, Prickett and Bum-Charmo.\nJohn Keefe, a computer programmer, used Torch, an open-source \"recurrent network\", to generate the dog names after he was inspired by similar work on Harry Potter fan fiction.\nThese artificial intelligence tools comb through any dataset, teaching themselves the patterns and conventions they observe. They're modelled on the workings of the human brain and nervous system, hence the name.\nMr Keefe wrote on his blog: \"The experiment was something I've wanted to try since I saw the playful, awesome work of Janelle Shane and her experiments using neural networks to generate Harry Potter fan fiction.\"\nTechnology experts said these experiments weren't only fun, but signalled the increasing accessibility of artificial intelligence tools. Paul Armstrong, of Here/Forth, the consultant, said: \"It demonstrates the potential to gain insights into complex scenarios as the technology gets easier to use.\"\n"},
{"docid": "77 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 20, 2017", "title": "Debrett's 500 List: Engineering & Technology\u00a0\n", "content": "An in-depth look at the most influential people in...\n                   <ul />                   Engineering and Technology                   The Baroness Brown of Cambridge, DBE, Vice-Chancellor, Aston University, 62                   \nJulia King - Baroness Brown of Cambridge since her 2015 appointment to the House of Lords - is vice-chancellor at science and engineering university Aston. She was previously principal of the Engineering Faculty at Imperial, and her expertise means she frequently advises government on education and technology. King spent 16 years as a researcher and lecturer at Cambridge and Nottingham universities, has held senior positions at Rolls Royce, and was chief executive of the Institute of Physics. She cites her mother as her inspiration as she 'believed women could do anything'.\u00a0\n                   Professor Nick Bostrom, Director, Future of Humanity Institute, University of Oxford, 44                   \u00a0\nPhilosopher and artificial intelligence expert Nick Bostrom is a professor in Oxford University's Faculty of Philosophy and director of its Future of Humanity Institute, which he founded a decade ago. His 2014 book Superintelligence argues that the future impact of artificial intelligence could present the most serious threat yet to the human race, and became a New York Times bestseller. Bostrom was born in Sweden and experienced an epiphany as a teenager when he first encountered the writings of Nietzsche and Schopenhauer. He completed a PhD at LSE and has worked in physics, computational neuroscience and mathematics as well as philosophy. \u00a0\n                   Andy Cowell, Managing Director, Mercedes AMG High Performance Powertrains, 47                   \nAndy Cowell has been managing director of Mercedes AMG High Performance Powertrains since 2013 and is responsible for engine design and performance at Mercedes's Formula One arm. Mercedes won the Formula One Constructors' Championship for a third consecutive year after Nico Rosberg's victory in the Japanese Grand Prix in October. Cowell was engineering and programme director for Mercedes-Benz High Performance Engines from July 2008 until he took on his current role. He won the 2013 James Clayton Prize for his contributions to engine design and development in Formula One, and for his inspirational leadership at Mercedes-Benz.\n                   Professor Dame Ann Dowling, OM, DBE, President, Royal Academy of Engineering, 64                   \nMechanical engineer Ann Dowling became the Royal Academy of Engineering's first female president in 2014. Her research has focused primarily on combustion, acoustics, aeronautics and energy, specialising in the reduction of vehicle and aircraft noise. In 1998 Dowling became the first female head of Cambridge's Department of Engineering, one of the most esteemed engineering departments in the UK. She supports initiatives encouraging women to pursue careers in engineering and recently oversaw a report warning that Brexit should not limit access to skilled engineers from the EU, which could delay major projects such as HS2.\nQueen Elizabeth II with (L-R) Sir James Dyson, Professor Dame Ann Dowling and Lord Darzi of Denham\u00a0Credit:      Getty Images     Sir James Dyson, OM, CBE, Industrial Designer and Founder, Dyson, 69\nSince developing the ground-breaking bagless vacuum cleaner in 1983, James Dyson has gone on to produce hand dryers, hairdryers, fans and heaters, and his net worth now stands at around \u00a35 billion. Success was not straightforward: in increasing amounts of debt, and supported by his wife's teaching salary, he went through 5,127 failed prototypes before perfecting the design. He set up the James Dyson Foundation in 2002 to encourage and inspire budding engineers, and its annual award is given to the best invention by a student. In 2017 he will open the Dyson Institute of Technology to help solve the skills gap in UK engineering.\n3 Minutes With | James DysonNick Grey, Founder and CEO, GTech, 48\nEntrepreneur Nick Grey has developed cordless vacuum cleaners, lawn mowers and hedge trimmers, as well as a battery-operated 'ebike'. He founded GTech 15 years ago after resigning from his job as head of product development at Vax, and his first product was the world's first cordless power sweeper. GTech now operates in the UK, US and China and has sold more than 20 million products worldwide. Its sales have tripled in the last year and it was listed in the 2016 Sunday Times Fast Track 100 list of the UK's fastest-growing businesses.\nDemis Hassabis, Artificial Intelligence Researcher and Founder, DeepMind Technologies, 41\nFive-times World Games Champion Demis Hassabis is one of the world's leading experts on artificial intelligence and co-founder of DeepMind, which was acquired by Google in 2014 for a reported \u00a3400 million. Leading a team of mathematicians and computer scientists, Hassabis develops 'learning machines', which support human understanding of digitised information and solves problems by sifting through huge amounts of data. DeepMind is now working with both Moorfields Eye Hospital and the Royal Free NHS Trust to analyse patients' data, sending alerts via an app, and saving hundreds of thousands of hours spent on paperwork.\nDemis Hassabis, Artificial Intelligence Researhcer and Founder, DeepMind TechnologiesCredit:      Getty Images\u00a0     Prof Dame Wendy Hall, DBE, Professor of Computer Science, University of Southampton, 64\nWendy Hall was one of the first computer scientists to embark on serious research into multi- and hyper-media technologies and today she is a leading light in the development of web services. She is professor of computer science at the University of Southampton where she obtained her PhD, and was also its first female professor of engineering. Hall was a founding director of the Web Science Research Initiative with Sir Tim Berners-Lee, and was president of the British Computer Society, of which she became a distinguished fellow in 2016.\nDame Sue Ion, DBE, Expert Adviser on Nuclear Power, 61\nLeading nuclear engineer Sue Ion is chair of the government's Nuclear Innovation Research Advisory Board, set up to research and advise on alternative energy sources. She has also sat on the Prime Minister's Council for Science and Technology and became the first woman to win the Royal Academy of Engineering's President's Medal, its most prestigious award. As a spokesperson for the industry, Ion has done much to promote engineering as a career, particularly for women. She studied at Imperial and began her career at British Nuclear Fuels Ltd, where she went on to be chief technology director.\nLiam Maxwell, National Technology Adviser, 48\nLiam Maxwell became the government's first national technology adviser in 2016 having served as its first chief technology officer for four years before that. In his new role he develops relationships with the UK's digital and tech sector, promoting the digital economy both at home and overseas while harnessing its expertise on behalf of the government. A former head of IT at Eton, in his previous role Maxwell was credited with the digital transformation of the government and with saving \u00a33.5 billion in admin costs.\u00a0\n<table>\nLiam Maxwell, National Technology Advisor, UK talking about the future of India and UK collaboration #TECHSmtpic.twitter.com/W3TKROF517\n - CII (@FollowCII) November 7, 2016Sir David Payne, Photonics Professor, University of Southampton, 72\nDavid Payne's invention of the erbium-doped fibre amplifier is regarded as one of the most important developments in modern communications and facilitated the internet's rapid growth through fast transmission and amplification of large amounts of data. Currently professor of photonics and director of the world-renowned Optoelectronics Research Centre at the University of Southampton, Payne also directs its Photonics Hyperhighway project, which aims to avert network gridlock caused by applications that use up a lot of bandwidth.\u00a0\nNick Rogers, Director, Group Engineering, Jaguar Land Rover, 49\nNick Rogers became director of group engineering at Jaguar Land Rover in 2015, having worked for the company for over 30 years. He learned to drive a Land Rover growing up on a farm in Oxfordshire, and joined the company as a technician apprentice. An expert on aluminium and lightweight technology, Rogers helped develop and launch a new Range Rover and Range Rover Sport in his previous role as vehicle line director. He has been keen to encourage more women to work at JLR, which now runs a four-day programme for female college students and a sponsorship scheme for female engineering undergraduates.\nNick RogersCredit:      Getty Images     Prof Sir Martin Sweeting, OBE, Executive Chair, Surrey Satellite Technology, 65\nMartin Sweeting is a world leader in microsatellites, renowned for his pioneering concept of low-cost, rapid response, small satellites. He heads Surrey Satellite Technology, the company he founded in 1985, and which operates a number of satellites in orbit for earth observation and imaging, scientific research, navigation, telecommunications and defence. Inspired by the 1969 lunar landing and the film 2001: A Space Odyssey, Sweeting decided to design a satellite while studying for his PhD - all the more remarkable because he knew nothing about building satellites and because the satellite weighed just 72kg when others were the size of buses.\nAndrew Wolstenholme, OBE, Chief Executive, Crossrail, 57\nAndrew Wolstenholme is the man in charge of Europe's largest civil engineering project as head of Crossrail, the high frequency railway for London and the South East. Wolstenholme was programme director on the \u00a34.3 billion development of Heathrow's Terminal 5, seeing it delivered on time and in budget, and also worked at Balfour Beatty before taking up his post at Crossrail in 2011. The project, consisting of 73 miles of railway line, will cost around \u00a316 billion and service is due to begin on its Elizabeth Line in 2018. In 2016 Wolstenholme was appointed vice-president of the Institution of Civil Engineers, with a view to becoming president in 2019.\nAndrew Wolstenholme OBE (right), Chief Executive, CrossrailCredit:      Getty Images     Professor Saeed Zahedi, OBE, Technical Director, Blatchford & Sons Ltd, 59\nLeading prosthetics designer Saeed Zahedi works for orthopaedics manufacturer Blatchford, where he oversees research and development in artificial limbs. Zahedi was responsible for developing the world's first fully integrated limb system, Linx, which is controlled by microprocessors and adapts to changing terrains and circumstances, helping prevent back pain. The system won the Royal Academy of Engineering's prestigious MacRobert Award in 2016, and Zahedi had been shortlisted for the award once before, for a prosthetic foot featuring a hydraulic ankle. He is vice-chair of the International Society of Prosthetics and Orthotics and was named Royal Designer for Industry in 2014.\n\u00a0For a full index of the Debrett's 500 list, click here .\n"},
{"docid": "78 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "November 14, 2016", "title": "Brexit means that Britain can harness the new industrial revolution\n", "content": "Theresa May closed last month's Conservative Party Conference in Birmingham with an optimistic and energising rallying cry: \" Come with me as we rise to meet this moment...together let's seize the day \". The Prime Minister's message was clear. We need a positive approach to Brexit, taking control of this once-in-a-generation opportunity to both change the direction of our nation, and our thinking in key areas of policy.\nWe should start with our approach to science, technology and innovation, as the Fourth Industrial Revolution (\"4IR\") accelerates and the government draws up its new Industrial Strategy. Britain should build on its outstanding track record of innovation - stretching back over 250 years to the first industrial age powered by coal and steam - and secure its post-Brexit future by turning away from the EU's often stultifying approach to new inventions. Only by doing so\u00a0can Britain spearhead this revolution, characterised by\u00a0the unprecedented fusion of new technologies that blur the traditional boundaries between the physical, digital and biological spheres.\u00a0\nMeet EMILY, the robot lifeguardPlay!01:06\nBreakthroughs\u00a0and new products\u00a0in fields such as artificial intelligence, robotics, the Internet of Things, driverless cars, drones, 3D printing and nanotechnology have already captured the public's imagination. Mastering the 4IR was\u00a0the theme at this year's World Economic Forum Annual Meeting in Davos: countries around the world are already competing to lead it.\nIn that global race, Britain is no slouch. Philip Hammond pointed out in his Party Conference speech, as he announced new investment in the 4IR, that\u00a0\"...unnoticed by most of us, entrepreneurs and scientists ...have been turning Britain into a hub of tech innovation\" under the radar. London-based DeepMind Technologies is a world leader in artificial intelligence (but became prominent only when bought by Google), while\u00a0the University of Manchester quietly pioneered graphene, the ultra-strong, ultra-light wonder material.\nThis has all been achieved in spite of the EU's \"precautionary principle\" . Enshrined in EU law, the precautionary principle is a risk management strategy, used widely by EU regulators, under which the burden is on inventors of new medicines, products or technologies to prove that their invention is\u00a0not\u00a0harmful where some risk exists, even if there is no scientific consensus to suggest that it may actually be harmful. If in doubt, hold back or don't innovate.\nPepper the robot launches in TaiwanPlay!01:10\nThis has led to what George Freeman, former UK Life Sciences Minister, has described as the \"increasingly science hostile\"\u00a0approach of the EU to innovation . For example, EU opposition\u00a0to genetically modified (GM) crops caused German chemical company BASF and American agribusiness Monsanto to withdraw from conducting agricultural research in Europe at a time when the Continent could have been a world leader in crop technology. When he was Science Minister, David Willetts\u00a0criticised the EU's ban on the use of Bisphenol A, a plastic-hardening chemical,\u00a0in the making of\u00a0babies' bottles.\u00a0\"Too often, activities that are potentially hazardous are treated as genuinely risky, when the size of the exposure is so low that there is no real risk\" he declared.\u00a0\u00a0In the same vein, the EU Clinical Trials Directive is often cited as a key factor in making Britain a less attractive place to conduct clinical trials of new medicines.\nFear of the new or unknown was harnessed by a number of\u00a0EU member states, vehemently opposed to some forms of innovation for political purposes, to stifle scientific progress.\u00a0If we are to lead the 4IR, Britain should now turn away from the EU's over-reliance on the precautionary principle and adopt a home-grown, pro-innovation approach\u00a0to regulating, funding and commercialising new 4IR technologies. We must liberate our researchers and entrepreneurs to make the most of Brexit's opportunities, erring on the side of progress not excessive caution.\nClawed robot drone lifts 10kg and cuts cablesPlay!01:24\nThis central recommendation underpins a new report I am launching tonight in Parliament, backed by the Free Enterprise Group of Conservative MPs and the Institute of Economic Affairs. \"Masters of the Revolution \" sets out why the 4IR should be at the heart of Britain's new Industrial Strategy, and how\u00a0Britain can - and should - lead it.\nThe report sets out twenty practical, actionable recommendations, which I hope Business & Industrial Strategy Secretary Greg Clark,\u00a0who is speaking at the launch,\u00a0will take back to Whitehall. From abandoning the precautionary principle and building new 4IR research centres, to continued investment in digital infrastructure and reform of our welfare and education systems, we must act now to ensure that our political and economic structures are fit for purpose. There is no time to lose.\u00a0To lead the Fourth Industrial Revolution, Britain must seize the day.\n"},
{"docid": "79 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 9, 2016", "title": "Google's DeepMind AI makes history by defeating Go champion Lee Se-dol\n", "content": "A computer program has beaten the world champion of one of civilisation's oldest board games\u00a0for the first time in history.\u00a0\nLee Se-dol, a 33-year-old South Korean, resigned the first of five matches of the fiendishly complex strategy game against the AlphaGo program, which is built by the Google-owned British company DeepMind.\u00a0\nThe game, which lasted a brief 3.5 hours, was officially declared as a win for AlphaGo in Seoul today. Commentators called it a \"superb\" game that would be studied for years to come.\nThe breakthrough is seen as a watershed moment for artificial intelligence, a milestone potentially more significant than\u00a0\u00a0IBM defeating the world champion Gary Kasparov at chess in 1997. Go takes a lifetime to master and unlike chess, a computer cannot play by simply assessing all possible moves but must rely on something akin to intuition.\n                     #AlphaGo WINS!!!! We landed it on the moon. So proud of the team!! Respect to the amazing Lee Sedol too\n- Demis Hassabis (@demishassabis) March 9, 2016\nWell done #AlphaGo !! Fantastic game from Lee Sedol. Four more games, but indubitably a new milestone has been reached in AI research today.\n- Edward Grefenstette (@egrefen) March 9, 2016\nThe game involves two players putting black and white markers on a 19-by-19 grid. It is said to have more possible playing permutations than the number of atoms in the universe.\nThe AlphaGo program, which uses algorithms, has practised by analysing data from 100,000 professional human games and playing itself some 30 million times.\nLee Se-Dol (right) plays the first move in the gameCredit:      Getty Images     \nMr Lee, who has been\u00a0a professional Go player since the age of 12, and won 18 international titles, said at a pre-game press conference:\u00a0\"It would be a computer's victory if it wins even one game.\"\u00a0\n\"I believe human intuition and human senses are too advanced for artificial intelligence to catch up. I doubt how far AlphaGo can mimic such things.\"\u00a0\nAfter the game he admitted that he was \"shocked\".\nHow Go works\n\"I admit I am in shock,\u00a0I did not think I would lose.\u00a0I couldn't foresee that AlphaGo would play in such a perfect manner. I in turn would like to express my respect to the team who developed this amazing program,\" he said.\nFour more games will be played over the course of this week, although AlphaGo would only have to win two of those to be crowned the victor.\nThe game had captured Korea's imaginationCredit:      AP     AI timelineREAD MORE ABOUT:\n"},
{"docid": "80 of 297 DOCUMENTS\n", "source": "DAILY MAIL (London)\n", "date": "October 14, 2017", "title": "GLAXO HAILS ROBOT BREAKTHROUGH\n", "content": "Now artificial intelligence slashes years off time taken to trial drugs\nBY MATT OLIVER\nPHARMA giant GlaxoSmithKline is hailing a breakthrough in artificial intelligence technology which could slash years from the time it takes to make new drugs.\u00a0\nGSK is harnessing the power of supercomputers and cutting-edge machine learning' techniques to discover new treatments.\nCurrently, it can take up to 12 years and about \u00a31.1bn to develop a new drug, with vast amounts of trial and error involved. But new artificially intelligent robots, which can examine decades of test data to predict how molecules will react, are on the brink of slashing development times.\nIn addition, the computers will also be used to sift through thousands of previous drug trials which have been deemed flops in the hope of spotting potentially life-saving treatments that may have been missed.\nGSK and its British arch-rival Astra Zeneca are already using the technology, with both teaming up with smaller tech start-ups to bring in expertise.\nAt GSK's base in Stevenage a team of scientists is already making up to 20 potential drug treatments each month that have been suggested by machines.\nIt is thought that speeding up development with this innovation is a central part of new chief executive Emma Walmsley's drive to reclaim GSK's status as a medical pioneer.\nDarren Green, director of computational chemistry at GSK, said machines were on the verge of helping cut the amount of time spent on initial discovery research from five years to just one.\nHe told the Mail: What AI can help most with is efficiency because, contrary to what you might think, humans are not so great at designing drugs. We have a very high failure rate.'\nIt takes about ten years for a medicinal chemist to train, gain expertise and build professional judgment, but Green believes machines can reduce the burden on scientists. He said: Humans are not perfect... but the machine can be the chemist with the perfect memory and help draw on all those sources of information.\nSo when we get a problem, we can say, \"Have we seen this before? And when we did, what did we do? What worked, and what didn't work?\"\nWe are still a long way from the machine doing it all, but it is at a point where it can definitely improve efficiency, which means getting things to patients faster and making drugs cheaper.'\nGSK has been working with Dundee technology company Exscientia, which specialises in using artificial intelligence.\nIn a deal worth \u00a333m, the firm is looking to find drug treatments on ten projects.\n\u00a9 Daily Mail\n"},
{"docid": "81 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "October 31, 2016", "title": "Dr Watson will see you now: hospital turns to supercomputer for diagnoses\n", "content": "A Liverpool hospital plans to be the first in the NHS, and one of the first in the world, to employ the diagnostic abilities of IBM's Watson supercomputer.\nAlder Hey Children's Hospital, which cares for 270,000 children a year, said that Watson's powers of artificial intelligence would help doctors by rapidly analysing patients' medical histories with reference to vast stores of scientific knowledge.\nThe system has \"read\" almost 15 million pages of medical literature and can review patients' notes and medical questionnaires to suggest diagnoses and treatment. It has already identified a case of a rare leukaemia that baffled doctors in Japan and will be used to try to solve complex medical cases in Germany next year.\u00a0\nThis diagnostic support is part of Alder Hey's programme to use IBM's system to give the hospital a virtual brain. In the first stage, the hospital is developing a Watson-powered \"chatbot\" to answer questions from patients and their parents from next year.\nBefore they are admitted, patients and parents will be able to speak to their tablet or smartphone to find answers on everything from the hospital food and toys to clinical procedures, anaesthetics and surgery. The hospital is also looking at installing the bot in plastic dinosaurs for younger children.\nIain Hennessey, a paediatric surgeon and clinical director of innovation at Alder Hey, said: \"There are lots of things people don't ask a doctor because they're embarrassed or don't want to sound silly or waste our time.\nPeople are also more confessional when they speak to a machine. They might ask: 'Am I going to die?' And young children say: 'Why will they put me to sleep? Why can't they wait till it's night and I go to bed?' \" Confronted with darker or complex questions, the chatbot would notify staff and tell the child something like: \"That's a question lots of children ask. Let's chat about it with the doctor.\"\nMr Hennessey said: \"The chatbot can help us to alleviate children's anxieties, which should mean we can operate with less anaesthetic and less risk, and the child will recover faster. It's safer, they're happier and it's also more cost-effective.\"\nIn due course Alder Hey intends to use Watson to analyse patients' scanned medical notes to help with anaesthetic plans and diagnoses. The hospital stressed that the technology would give doctors an extra tool and opinion and would not replace human expertise or input.\nMr Hennessey said: \"Children can have a stack of notes almost as tall as themselves in complex cases. Doctors are human and can miss something in all that text. Watson can analyse the information and in effect say 'Have you thought about this?' and you might think, 'Good point, let's do a scan.' \" Use of artificial intelligence in medicine can be controversial because of fears about machines taking over and data privacy. However, Mr Hennessey said artificial intelligence would be used to free up staff from repetitive unskilled work to prioritise more important duties and could monitor things such as admission patterns to help with bed-planning.\nBehind the story IBM's Watson was created in 2006 to learn from huge volumes of data and answer questions (Mark Bridge writes). The system can process natural language and was first put to the test five years later when it beat human competitors to win $1 million in the US quiz show Jeopardy!\nIt has been \"studying\" medicine for five years and can trawl through patients' notes, questionnaires and genetic data, as well as millions of pages of textbooks. Watson comes up with diagnoses, ranked by confidence, as well as possible treatments.\nThe system can be particularly helpful for patients with undiagnosed rare diseases, many of whom have long medical histories and reams of notes.\nThe computer is used in diagnostics at a number of hospitals worldwide, including in the US and India.\n"},
{"docid": "82 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "April 4, 2016", "title": "Self-driving cars to hospital robots: automation will change life and work; The fourth industrial revolution is underway as 'thinking machines' transform the workplace. Jobs losses may follow but many sectors will thrive, experts say\n", "content": "Britain is on the brink of a robotics revolution. Advances in technology are unleashing a new age where computers handle many tasks previously carried out by humans. From automated manufacturing to software that does complex legal work, business is adapting to the robot economy.\nSome worry that this will lead to a jobs apocalypse as \"thinking machines\" replace workers. Others are optimistic that robots will free workers from mundane tasks and allow them to concentrate on higher-level creative and strategic work.\nBut one thing is clear: the economy is about to change radically. Robots are outperforming humans in numerous fields and the technology is striding ahead in the workplace. To examine how this transformation will unfold, and its likely impact on business, the Guardian invited senior figures from industry and academia for a roundtable discussion, which was supported by Swiss bank Julius Baer. The discussion was chaired by Rohan Silva, a technology entrepreneur, Guardian contributor and former adviser to the prime minister, David Cameron.\n                   Industry 4.0: the fourth industrial revolution                   \u00a0\nAs the roundtable got underway, Wolfgang Epple, director of research and technology at Jaguar Land Rover, said that a huge opportunity for the UK lies in what's known as Industry 4.0. This fourth industrial revolution is where the latest developments in manufacturing, such as the internet of things, big data, automation and artificial intelligence (AI), enable a massive increase in productivity and effectiveness.\nThe roundtable heard that such technology was already being utilised, for instance in the mass customisation of cars, which is expected to lead to increased integration of human and robotic skills. At present, robots in car manufacturing are used mainly in the body shop, making doors or bonnets; robotics is less advanced on the assembly line, as complex tasks carried out here require a human hand. But this is beginning to change. \"In the US, manufacturers have started to have robots and human beings concurrently on the assembly line and they teach each other,\" said Epple. This could mean a human taking the arm of a robot and moving it around to teach it a task, such as screwing on a bolt.\n                   Self-driving cars                   \nEpple also pointed to self-driving cars as an application of AI and robotics that offers a \"tremendous opportunity\", allowing people to work inside cars rather than driving them, boosting productivity. But Fergus Boyd, digital and IT director of hotel chain Yotel, questioned the usefulness of autonomous cars. He argued that similar benefits could be delivered by a ride sharing service such as Uber Pool. \"Uber Pool offers one person driving three or four people and it's low cost, easy and friendly. What is the use case for autonomous cars?\"\nOcado's technology director Paul Clarke defended the idea of autonomous cars, pointing to Google's original vision for the technology, which was to boost transport efficiency by getting vehicles travelling close together and in coordination. Silva added that increased safety is another plus point. \"Another element of that vision was why should anyone die in road accidents in the 21st century?\" he said.\n                   Agriculture based on data                   \nWhile autonomous cars are set to transform road transport, automation and artificial intelligence are also having a huge impact on agriculture. Antonio Marzia, vice-president for precision solutions and telematics at CNH Industrial, said there is a growing synergy between traditional agriculture and analytics based on data. \"We can locate the precise position of every single square inch of ground around the world and we can optimise the way we do agriculture on that land,\" he said.\nFarmers are driving the demand for more technology in agriculture as they look for greater efficiency and better ways of farming, he said. For instance, technology can help farmers with seeding, using historical data and analytics about the land to tell them the most effective ways and times for carrying out seeding. Technology can also enhance safety in farming, for instance by automatically spraying orchards rather than exposing farm workers to potentially hazardous pollutants. \"These are practices that do more with less - fewer chemicals, less diesel, fewer seeds - and it has a very big impact on the environment. It is an optimised way to do agriculture,\" he said.\nMarzia also pointed out that robotics and artificial intelligence are two different, but related fields. Robots are machines that react to their environment - cars, for example, are not robotic since they respond to human instructions. But the latest models have robotics built-in with automated parking, which uses sensors to guide the vehicle into the parking space. Meanwhile, artificial intelligence is software that solves complex problems and adapts as it learns. It is the combination of AI and robotics which will be so transformative.\nThis transformation is being experienced in call centres, which are rapidly automating. Nicola Millard, head of customer insights and futures at BT Global Innovation Team, said technology is taking over transactional tasks such as checking people's accounts, but she stressed that there is much that a computer cannot do. \"The technology is not good at negotiation; it is not good at innovation or creativity and it is not good at caring or empathy,\" she said.\nWith technology carrying out mundane functions - such as reporting account balances - call centre workers can focus on becoming more skilled. Time is freed up for staff to talk to customers and help them with their queries. \"Let's look at the strengths of the human and the strengths of the technology and think about how we add those together to actually help customers get what they want,\" said Millard.\n                   Use of robotics creating jobs                   \nDespite advances in technology, UK industry is lagging behind other European countries in automation, said TUC general secretary Frances O'Grady. \"The majority of robots are used in the automotive sector, it hasn't spread in the way it has in other countries,\" she said. She pointed out that using robots on production lines has created a whole new raft of jobs to maintain and service them, rather than leading to job losses, while also potentially freeing workers from more boring tasks. She thinks the UK's low-wage economy is holding back automation at present, as it is cheaper to employ workers than invest in expensive machinery.\nO'Grady believes the NHS could offer huge scope for automation. Microsoft, for example, is working with Addenbrooke's hospital in Cambridge, carrying out image analysis of brain scans, reducing the time that oncology consultants spend analysing images of tumours from three hours to 30 minutes. Dave Coplin, chief envisioning officer at Microsoft UK, said the big question was how health professionals use the time freed up by technological advances. \"The real gift of this is what the consultant chooses to do with that two and a half hours,\" he said. Hopefully, he added, they will spend that time engaging more closely with patients.\nThe impact of automation on our health will also be felt through our own uptake of new personal health apps. \"We think AI can play a role in answering some of the questions people have about their health,\" said Matteo Berlucchi, chief executive of digital medical service Your.MD. He said that last year, the NHS estimated 60m visits to the GP were for minor ailments. Your.MD is launching on WhatsApp and other messaging services as a virtual assistant to advise people on minor ailments. This will allow users to check on their symptoms while also giving the virtual assistant a chance to ask questions about the user's health and check they have followed the virtual assistant's previous advice. \nWhile much media attention has focused on loss of jobs, the roundtable saw the types of changes seen in healthcare as an example of the wider impact automation would have on how we live and the types of jobs created.\n                   Are we ready for the robot economy? - Roundtable participants:                    \n"},
{"docid": "83 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "April 14, 2016", "title": "RoBoHoN is the world's cutest smartphone - and he's poised to take over the world\n", "content": "If any robot can take over the world, it's RoBoHoN . He has all the information you put in your smartphone - which, for most people, is a lot - and can read human emotion.\u00a0\nHe's also cute enough that everyone in the human race probably wants one.\nRoBoHoN is incredibly useful, he can project photographs and films, tell you he loves you if he senses you crying, hail an Uber for you and basically do everything your smartphone can do, and more.\nCredit:      Sharp     \nHe can even dance, and at \u00a31,300 he isn't significantly more expensive than an iPhone if you factor in the hundred million charging cords you'll have to buy when they all inevitably break.\nRoBoHoN was created by Japanese electronics firm Sharp and stands at 20cm tall.\nCredit:      Sharp     \nIt can walk around your home and acts as an outrageously cute\u00a0personal assistant.\nIt reads your texts, announces phone calls, works out alongside you, dries your tears and wakes you up.\nThis piece of technology is certainly a cut above Siri -\u00a0RoBoHoN can even recognise your face and greets you by name when you enter the room.\nWho wouldn't want a tiny, adorable personal assistant ?\nPerhaps those who have noticed that we live in a world where Artificial Intelligence turns evil - but surely something so cute wouldn't want to exterminate the human race?\nAI timelineREAD MORE ABOUT:\n"},
{"docid": "84 of 297 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "March 13, 2016", "title": "Lee Sedol v AlphaGo: Human beats computer in Chinese board game for the first time; South Korean grandmaster Lee Sedol is battlingcomputer programme AlphaGo to test whether robots have advanced enough to out-smart humans at the board game\n", "content": "A champion Go player has scored a surprise victory over his robotic rival, as part of a competition which is gripping South Korea. Lee Sedol is competing against computer software machine AlphaGo, which has been designed by Google to be an unbeatable board game player. The pair have been battling it out in a series of games to prove whether robotics are yet advanced enough to out-smart a human. The unlikely competitors are fighting for a $1 million prize pot which will be donated to charity.\u00a0\nAlphaGo won the first three rounds, to the fascination of thousands of viewers watching the game unfold live online. However, Mr Sedol has now succeeded in winning his first game, bringing the pair to a new score of 3-1.\nThe 33-year-old, who has 18 international championships to his name, furrows his brow as he plots his next move against the Google software\nThe 33-year-old South Korean Go grandmaster, is among the best in the world at Go, an ancient Chinese board game. He has 18 international championships to his name. After winning today he says he has finally identified a flaw in the software. He said he discovered it when he made an unexpected move and found that the artificial intelligence system struggled to process it. He now believes that the system is unable to cope with surprises.\nMr Sedol said of his success today: \"This one win is so valuable and I will not trade it for anything in the world.\"\nTwenty years ago, a software system was designed which enable computers to win at chess. However, as Go has a near-infinite number of board positions, it has so far proved too difficult for programmers to capture in an artificial intelligence format. Experts have dubbed it 'the holy grail' of computer design because the board game is so complex.\nWith additional reporting by AP\n"},
{"docid": "85 of 297 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "June 6, 2005", "title": "BRITON DIES ON EVEREST WHILE TESTING SAFETY EQUIPMENT\n", "content": "\u00a0\n A British computer expert has died while trying to scale Mount Everest on a climb during which he was testing pioneering software designed to help ensure the safety of mountaineers.\n Dr Rob Milne, 49, died on Saturday 1,200 feet short of the summit, where he would have completed his 25-year ambition of climbing the highest mountains on all the seven continents.\n Details of his death have not yet been disclosed, but it is believed he collapsed and died on the spot. He was married with two teenage children and lived at Bathgate, West Lothian.\u00a0\n At least two other climbers have died during bad weather on Everest this season while, also this weekend, the adventurer Sir Ranulph Fiennes abandoned an attempt to reach the summit. Dr Milne, who was an expert in artificial intelligence and a passionate climber, was attempting the Seven Summits challenge: reaching the peaks of the highest mountains in all seven continents. He had climbed his first major peak, Mount Denali in Alaska, in 1980. During this Everest trip he was testing a mobile communications system called IM-PACS, which allows climbers and adventurers to plan their expeditions more effectively. Designed at the Artificial Intelligence Applications Institute in the School of Informatics at Edinburgh University, the technology was designed to allow Dr Milne to keep friends and family updated with details of his movements. IM-PACS was also designed to suggest alternative routes in the event of deteriorating weather and to help find a rescue strategy, should it be needed. He was also collecting seeds for botanical research. Dr Milne was born in Montana in the US and had dual British-US citizenship. He went to Edinburgh to study for his doctorate but went back to work as head of artificial intelligence at the Pentagon. He returned to Britain 18 years ago and set up a software company. He was also a visiting professor at several Scottish universities.\n Professor Austin Tate, head of the School of Informatics, said last night: 'I knew him for 25 years as a colleague and friend and it is a terrible shock.' He stressed that while the equipment Dr Milne was testing was designed to help climbers, on this trip he was using it as a reporting method. Before he left for Everest, Dr Milne said: 'Giving the IM-PACS software an ultimate field test will not only help pioneer the way for remote support, but also provide feedback to my friends and family as to how I am progressing.'\n"},
{"docid": "86 of 297 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "December 10, 1987", "title": "Computer Guardian: Taking the soft option - Why computer systems analysts tend to ignore the sociology of the workplace\n", "content": "\u00a0\n Is industry afraid to address the problem of 'soft' systems which it faces when designing and implementing computer systems? If managers ignore certain classes of information and analysts are untrained to address these problems, what is the resultant cost to the effectiveness of new systems?\n I am talking about a sociology of the workplace in which all computer systems have to be embedded. Two strategies which partly address the problem are the use of expert systems and the application of artificial intelligence (AI). Yet neither of these goes far enough in dealing with the complexities of the workplace, nor were they designed to do so.\u00a0\n Both expert systems and AI are in danger of being seen as panaceas for the ills of information management in business, and yet each is capable of dealing only partially with these ills.\n The limits of expert systems are fairly easy to observe. An expert system does just what its name suggests - it stands in the place of a human expert or experts and gives advice according to the rules and probabilities built in at the design stage. Ask it a question and it will give an answer, most likely with a probability of correctness attached to it. An expert system can be invaluable when applied to specific domains of knowledge - hence their popularity in the field of medical diagnosis.\n What the expert system cannot do is say to a patient: 'There, there, take this and it will all be all right.' It cannot have a bedside manner, it cannot convince a patient that conventional drug therapy is better than alternative medicine, and it cannot inspire confidence in its human users by the possession of any charismatic qualities. It can only be a diagnostic tool with limited use in the real world of doctors and patients.\n Perhaps we can argue that expert system plus Artificial Intelligence can replace human intervention. But then, what is intelligence? A common sense definition is: the ability to take facts and information, process them according to some known rules and come to a reasoned conclusion taking into account as many factors as can be accommodated in a given situation. In this respect an AI system can be seens as an 'expert system plus.'\n A common measure of AI is the ability of a program to learn through experience. So, if an expert system is able to learn new rules and make new inferences without being taught all those rules and inferences by a human being, then that system could be said to be endowed with artificial intelligence.\n Elements of AI are now being built into all sorts of common computer systems such as enquiry systems, optical character recognition and diagnostic aids. However, it is doubtful that any true and fully artificial intelligence system is being used in a real business environment.\n And the idea of AI, as it currently stands, is not going to answer the complex sociological and organisational problems found in large companies. That such technological promises are too easily accepted is a failure both of computer scientists and business managers to be realistic. Yes, an AI system can be imagined that will reason, learn and adapt; such systems have been developed and work is under way to bring the benefits to the workplace. However, once you have sacked ten members of staff and replaced them with an AI system, the problems of your organisation, albeit smaller in size, still remain. Consultants who design systems are often given the job of advising on industrial relations, but that advice is nearly always used as a way of ameliorating immediate problems whilst ignoring the fundamental ones.\n Sociology is a discipline that does not seem amenable to computer analysis. It is not an area in which hard facts can be discovered and applied in a linear fashion. The statistics which can be produced give only an idea of likely trends, and answers produced are of transitory use because the complex network of human interactions is constantly changing. What was true yesterday will not necessarily be true tomorrow. In terms of hard science this means that it is almost impossible to replicate experiments and produce data which is always valid.\n Sociology, in so far as it is addressed in computing terms, is therefore treated under the vague heading of 'soft' systems, which is still a vague and ill-defined idea. The best known proponent of soft systems analysis in this country is Peter Checkland of Lancaster University, whose system of analysis does take into account human activity systems. Many case studies have been done at Lancaster, but examples from other sources are thin on the ground. Most 'conventional' analysis techniques conveniently ignore the human activity systems.\n Another approach is the use of semiotics, the study of signs and their meanings, and Ronald Stamper of the LSE has written much on this topic. Semiotics has been touted as a means of examining everything from literary and artistic works to the design of computer systems, and as a unified body of work it is even harder to define than sociology. Again, suspicion on the part of business managers means that it is difficult to use in real situations. Stamper would argue that human transactions can be meaningfully codified by semiotic analysis, but this is yet to be accepted by the majority of other analysts or by users.\n Business and industry has undoubtedly increased its efficiency and profitability over the last decade by the analysis of their existing systems and the use of computers to rationalise these systems. In the area of human problems in organisations, however, little progress has been made. The waning or power of the unions has meant that industrial relations problems have been less of a concern, but the bedrock of problems caused by failure of people to communicate in organisations remains.\n The sociological questions of the uses of power and the influences of work cultures are yet to be answered.\n Many would argue that there is no place for computer scientists in trying to answer such questions. I disagree. There is ample scope for sociologists to work with computer scientists in solving some of the more intractable human problems which still plague industry. There is a sociology, as well as a science, of information and the need to understand it is every bit as important as the design of hard systems.\n"},
{"docid": "87 of 297 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "May 5, 2017", "title": "A hospital with a brain: how big data is changing healthcare; The NHS holds a wealth of data about how patients are diagnosed and treated. Unlocking its secrets could be key to improving patient care\n", "content": "Iain Hennessey wants to build a hospital with a brain. It sounds like the stuff sci-fi movies are made of but as this affable consultant paedeatric surgeon explains, his desire is to improve care at Alder Hey children's hospital by making better use of its growing wealth of information. \n\"It's all well and good having all of this data, but if you can't do anything with it then it's pretty useless - it overwhelms you,\" says Hennessey, who balances a role as clinical director of innovation alongside his surgical commitments.\u00a0\n\"Basically, my job is deciding whether or not to operate. Either I am going to operate, or I am not. But the more variables you throw into the picture, the more difficult it is to make that black-and-white decision.\"\nHe compares it to sitting in front of Netflix, paralysed by the scale of the choice. \"But what if we could analyse all the data? That's the transition, I think, that we need to get to in healthcare.\"\nCertainly there is no shortage of information for computers and humans to sink their teeth into. Many patient records are now digital, conventional x-ray film has long since been replaced by computerised images, and treatment outcomes are recorded nationally for a range of surgical procedures.\n                                        Data analysis can significantly improve care                                      \nBernard Marr, author of Data Strategy: How to Profit from a World of Big Data, Analytics and the Internet of Things, is convinced better use of all this information would yield real benefits.\n\"Applying big data analytics in the NHS has the potential to significantly improve care,\" he argues. \"Instead of relying on GPs to understand all your symptoms and history within a 10-minute time slot and then make an accurate diagnosis and come up with a treatment plan, we should be using intelligent big data-enabled artificial intelligence tools which can be fed with all your medical and even genetic data.\"\n Related:  'You changed my life': better information-sharing transforms patient care\nGetting to that stage will undoubtedly take some time, and likely some debate. But according to Adam Steventon, director of data analytics at the Health Foundation, there is much that can be done right now to wring greater value out of healthcare data.\nThe organisation is running a range of projects that seek to use analysis of large datasets to improve care. One looked at whether seeing the same GP over time reduced hospital admissions - and found it did.\n\"That's important because that aspect of care quality, continuity of care, is not often measured,\" says Steventon. \"And we were able to measure it using data from the existing medical record.\"\nSimilar work is happening in the north of England. Connected Health Cities is a collaboration between the NHS, local authorities, charities, industry and patient groups, and operates across four northern regions. The aim is to use data analysis to improve specific aspects of care in the area.\n Gary Leeming, the project's director of informatics, is excited by the possibilities big data offers in healthcare. But he knows there are risks too. The decision to operate across four cities was a conscious one. \"We're operating at that scale to address the risk of people feeling they've lost control of their own data.\"\n It's an issue made more pressing by the failure of care.data. NHS England's plan for a national database of health information collapsed amid worries about consent.\nMore recently, concerns have been raised over the transparency of a partnership between Royal Free London NHS foundation trust and Google DeepMind, an artificial intelligence company.\n                                        Using artificial intelligence to answer patients' questions                                      \nIn Alder Hey, Hennessey says a hospital with a brain has no need for access to patient records. Work is underway to develop an app that will answer children's questions before they come into hospital. \n Related:  Wearable technology - just what the doctor ordered\nArtificial intelligence (AI) sitting behind it will have analysed the questions generally asked - and so ensure the patient receives the right answer.\nIt's being built by experts at the Hartree Centre and uses IBM's Watson cognitive computing technology.\n\"Dealing with this sort of information we're able to demonstrate we're able to deploy AI in a sensible way, in an environment where it adds something of value, and then take on some of the bigger challenges later on,\" explains Lee Hannis, the centre's head of business development.\nFor Hennessey, the app is all about building a better patient experience. \"I think that's an area that's very often neglected in technology,\" he muses.\n\"It's always about how can we get a better diagnosis, how can we run clinical trials better. And all that's important, but actually a huge part of being a doctor at the coalface is making sure that people are happy.\"\n                     Content on this page is paid for and produced to a brief agreed with Brother, sponsor of the Partnerships in practice hubs on the Teacher Network and Healthcare Professionals Network.                   \n"},
{"docid": "88 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "January 20, 2016", "title": "Welcome to Silicon Valley on ice; Bankers, what bankers? Davos has been taken over by hi-tech titans, says Sathnam Sanghera\n", "content": "Politico, the US-based government affairs website, was not wrong when it glanced at a list of this year's attendees at the World Economic Forum in Davos and exclaimed: \"It's all tech. Bye-bye bankers.\" Financiers are not absent from the annual festival of mansplaining, which begins today, and tech types have long had a presence, with Google hosting an annual party that has been described as \"legendary\" by people who probably don't get out very much, but now the Swiss shindig is turning into Silicon Valley on ice.\nReflecting a business world that is increasingly in awe of the seeming ability of tech moguls to create billiondollar businesses in a matter of months, names such as Jack Yun Ma (of Alibaba Group), Sheryl Sandberg (Facebook) and Nathan Blecharczyk (Airbnb) are dominating proceedings, with the self-declared theme this year being \"The Fourth Industrial Revolution\", which apparently refers to scientific advances such as \"artificial intelligence, robotics, the Internet of Things, autonomous vehicles, 3-D printing and nanotechnology\".\u00a0\nSo what can attendees expect over the next few days? Well, my first and last visit to Davos as a young news reporter in 2000 was not a wild success, being marked by a great deal of falling over (somehow I hadn't realised Davos was a ski resort and arrived with no winter coat or boots) and repeated failure to recognise business titans (mortifyingly, I asked George Soros - \"the man who broke the Bank of England\" - what he did for a living), but business culture is increasingly synonymous with Silicon Valley culture, and I am, unfortunately, paid to monitor its outpourings, and it seems to me we can bet on a load of ...\nAbstract thought\nDavos always thinks big, specialising in pretentious panel discussions on everything from \"transformational leadership\" to \"secular stagnation\", but expect the ponderousness to intensify this week given that abstraction is Silicon Valley's favoured sport. You may have noticed, for instance, that Amazon's Jeff Bezos rarely talks about book sales, his original business, preferring instead to pontificate on drone deliveries and developing re-usable rockets. Google executives are similarly rarely quoted on the subject of internet searches, favouring conversations about driverless cars and artificial intelligence. It's a Valley paradox: the less you talk about your actual business, the more people suspect you might be a business genius. So expect incomprehensible discussions on everything from artificial intelligence, to telepresence, sending balloons into the sky to connect people to the web, cars that fly, building lifts into space and retiring on Mars. Which brings us to ...\nSuperheroic talk of saving the human race\nAltruism has long been a feature of Davos - it's why you are never more than 250 yards from Bono and why attendees to the 2003 meeting were invited to an opening-night \"Love\" dinner but, maybe because so many tech moguls grew up reading superhero comics, this is something else Silicon Valley takes to an extreme level. Whether it is Bill Gates doing inspiring work in solving disease in Africa, or the Facebook founder Mark Zuckerberg rather more controversially pronouncing that he is giving away his wealth, it's easier to get tech moguls on topics such as global warming and the future of human civilisation than on the bankers' old favourites, profit and loss. Not that this altruism extends to paying a fair share of tax, of course, with tech types always finding a way of funnelling money away from nations where profits are made, to places such as Ireland, Luxembourg and the Netherlands, which offer sweetheart tax breaks.\nPeople feeling prematurely old\nOne of the few really good things about Davos was how hanging out with octogenarian CEOs and politicians made one feel relatively sprightly, but no more. Perhaps the defining feature of Silicon Valley is youth, with many of its pioneers founding their companies before the age of 27, whether it is Zuckerberg setting up Facebook in 2004 when he was 19, or Gates beginning his meteoric rise in software even younger. Though it's some consolation that tech titans at Davos won't be immune from feeling past it themselves. Just as Microsoft missed the boat with mobile computing and Google missed social networking, Zuckerberg has arguably had to pay to remain relevant, spending $22billion (\u00a315.5billion) on the messaging service WhatsApp. Which is the ultimate problem with the cults of youth and disruption: even the young quickly become too old, and even the disrupters eventually get disrupted.\nSocial awkwardness\nDavos has always operated by strange social rules, with status and access being denoted by coloured badges and heavy security affecting where you can go, but you can bet on tech types making the corporate speed dating weirder. Even if you don't buy the theory that Steve Silberman dissects brilliantly in his book Neurotribes - that many moguls exhibit autism-spectrum behaviour - there is no getting over the fact that many Silicon Valley executives began as coders, for whom social isolation is a way of life, and that the wild success of awkward men such as Steve Jobs has made it acceptable to behave unusually. So at Davos you can expect to witness people talking weirdly (see points 1 and 2), acting weirdly (see point 5), and dressing weirdly (anything from jeans to turtlenecks, gym shorts or rollerhockey gear - but nothing will be stranger than the year Zuckerberg messed with everyone's heads by turning up in a tie).\nAwkwardness around women\nThe bankers and CEOs who traditionally pack Davos have never had a great reputation on this front, with reports suggesting that only 17 per cent of participants at Davos last year were women, but you can rely on \"Testosterone Valley\" making things even worse. Some two years after companies, led by Google and Intel, started to publish their diversity data, Silicon Valley's gender make-up remains almost the same, with about 71 per cent of staff at the large tech firms being blokes. Though just as telling is the insanity of Silicon Valley's male-dominated dating scene, with a feature for The Times Magazine recently bringing us the news that a start-up company is trying to address the gender imbalance by flying single women to San Francisco from New York, the claim that many male tech workers suffer from \"Weird Science syndrome\" (the belief that they can, as in the Eighties comedy, engineer a perfect woman), and the revelation that one of the most popular aphorisms among the longsuffering single women at Silicon Valley is: \"The odds are good but the goods are odd.\"\nGlobalisation\nIt seems almost quaint that the big new story in Davos in 2000 was anti-globalisation protests, with activists targeting a local branch of McDonald's. Looking back, their worries were not entirely misplaced, but it has been tech companies such as Amazon and Facebook that have arguably hastened the worst aspects of internationalism, not fast food operations. Indeed, it is another feature of Silicon Valley culture that its companies are determinedly global in their outlook, with Netflix typifying the approach when it announced last week that it had become available in almost every country in the world.\nI could go on. Don't expect delegates to be reminiscing about their college days: the global elite may have once attended a set few universities but now, as demonstrated by Gates, Tesla's Elon Musk and Uber's Travis Kalanick, the thing to do is to attend an elite university but then drop out to start a business. Don't expect discussion of turnover: being focused on money almost seems to be regarded as petty by Silicon Valley, with tech companies almost routinely failing to make profits. However, more revealing, perhaps, is a quote I stumbled across in a tech biography which went: \"Google hires really bright, insecure people and then applies sufficient pressure that - no matter how hard they work - they're never able to consider themselves successful.\"\nIt reminded me of very similar words from Andrew Stead, a former Goldman Sachs banker I once interviewed, who said that the bank's hiring strategy was to \"accumulate overachieving, insecure people\" so \"you can get more out of them\". Which is the thing: bankers and tech types are basically versions of the same people. Let's face it, it will mainly be business as usual at Davos in 2016: a bunch of egotistical white men, who insecurely regard themselves as the smartest people on the planet, sounding off about problems they probably helped cause in the first place.\n"},
{"docid": "89 of 297 DOCUMENTS\n", "source": "DAILY MAIL (London)\n", "date": "December 30, 2017", "title": "DAY BRITAIN'S TECH DARLINGS REPLACED THE CITY'S OLD GUARD\n", "content": "TECH pioneers stole the spotlight in the New Year Honours with a series of gongs in recognition of Britain's world-leading firms.\nThe awards handed out to those who have championed digital innovation overshadowed those given to the old guard in banking and finance.\u00a0\nThose honoured included Dr Demis Hassabis, founder of Deepmind - an artificial intelligence firm bought by Google - as well as TechUK president Jacqueline De Rojas, video games industry leader Dr Richard Wilson and Ron Kalifa, who led digital payments firm Worldpay.\nCity grandees still scooped top honours, however, with Bank of England court chief Anthony Habgood given a knighthood.\nHassabis, chief executive of Deepmind, was handed a CBE for services to science and technology. The Cambridge University graduate is on a mission to develop computers that can think like humans.\nHe set up Deepmind in 2010 and Google bought it for \u00a3400m three years later. It now employs about 400 people\nHassabis, 41, lives in London with his wife and two sons.\nHis work is likely to become even more important to Google as it ramps up competition with other technology giants over artificial intelligence.\nTechUK president de Rojas was awarded a CBE for services to international trade and technology. The 55-year-old has decades of experience at software companies and sits on the board of property website Rightmove and Channel Tunnel engineering firm Costain Group.\nShe has also campaigned to encourage more women to join male-dominated tech companies. Worldpay's Kalifa, 56, formerly its chief executive and now deputy chairman, was given an OBE for services to financial services and technology.\nHis firm has more than 5,500 staff and a market capitalisation of \u00a36bn.\nIt struck a controversial \u00a39.3bn deal this year to merge with US rival Vantiv, with the new firm set to have a dual listing in London and New York. Kalifa promised that most job losses will fall on the US and that UK centres in London, Cambridge, Manchester and Gateshead will be kept.\nWilson, 49, chief executive of trade body The Independent Game Developers' Association, was given an OBE for service to the video game industry.\nHe took the role in 2008 and campaigned for tax relief schemes to be handed to the industry.\n\u00a9 Daily Mail\n"},
{"docid": "90 of 297 DOCUMENTS\n", "source": "DAILY MAIL (London)\n", "date": "April 13, 2016", "title": "SPERM DONOR TO BRITISH COUPLES IS US CROOK WITH MENTAL ILLNESS\n", "content": "BRITISH families are in shock after learning a US sperm donor they used to father their children was a criminal with a history of mental illness.\nChris Aggeles, 39, had claimed he had a high IQ of 160 and a master's degree in artificial intelligence.\nBut instead he has served time in prison and his career amounted to working in a steak house and pizza restaurant.\u00a0\nHe also has schizophrenia which means the children of the families who used his sperm are at risk of the condition, according to a lawsuit filed in the US.\nAggeles is said to have fathered 36 children in North America and Britain - 19 boys and 17 girls. In total, 26 families are affected by his alleged deception, though it is not clear how many are from the UK.\nHis real identity was revealed after one of the families was mistakenly sent an email by Xytex, an Atlanta-based sperm bank they had used.\nThey realised donor 9623 was not the highly intelligent, internationally-acclaimed drummer his profile had suggested.\nAggeles did not have a master's degree in artificial intelligence and was not working on a PhD in neuroscience as he had claimed, the lawsuit alleges.\nHe also said he could speak five languages, that he read four or five books a month, and that he donated his sperm to give parents one of the greatest gifts in the world'.\nAngie Collins, a Canadian mother whose eight-year-old son was conceived using Aggeles' sperm, said in legal papers that the donor was schizophrenic, which is genetic and hereditary, thereby risking all of said donor's offspring'.\nShe wrote that after carrying out research she learned that Aggeles had dropped out of college and held no degrees whatsoever ... had been arrested for burglary and was an ex-felon'.\nThe lawsuit filed by Miss Collins and her partner, Margaret Hanson, of Port Hope, Ontario, was dismissed in October by a judge in Georgia in the US.\nFulton County Superior Court Judge Robert McBurney said there was no law governing what he called wrongful birth' claims, but added that there should be a way for them to seek redress.\nTeacher Miss Collins, 45, has indicated she intends to file a fresh lawsuit in Canada, which other families will join. The previous legal claim included allegations of fraud, negligence and breach of warranty.\nMiss Collins told the Toronto Star newspaper that her son has not shown any signs of mental illness, but she worried he could turn on a dime in puberty'.\nShe said that learning of his father's identity was a dream turned nightmare in an instant ... I felt like I was duped by Xytex and I failed my son for having chosen Xytex'.\nMiss Collins added that she had to have a very difficult conversation with her son.\nI told him, \"The man who helped create you has something wrong with his brain. He shouldn't have been donating and the company shouldn't have been promoting him. We want to make sure that all you kids are safe in the future so we're suing\" ... he did ask, \"So Mommy, am I OK?\"'\nAggeles appears to have graduated from the University of Georgia last year with a bachelor's degree in cognitive science - 20 years after he first started at the college.\nA video on YouTube appears to show him playing drums with a rock band in Los Angeles called American Mannequins.\nKevin O'Brien, Xytex president, said in an open letter that the company is upfront about not checking up on donors.\nHe [Aggeles] reported a good health history and stated in his application that he had no physical or medical impairments,' Mr O'Brien said.\nThis information was passed on to the couple, who were clearly informed the representations were reported by the donor and were not verified by Xytex.'\nAggeles was not available for comment.\n\u00a9 Daily Mail\n"},
{"docid": "91 of 297 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "October 10, 2017", "title": "Tech: will it really be safer this time? [...]; The sector is booming but investors may be wary after getting their fingers burnt after the last collapse, says Sam Meadows\n", "content": "Exciting new technologies are booming. Some of the most interesting developments are in robotics and artificial intelligence but less eye-catching technologies, for instance behind driverless cars, are also growing rapidly. For investors, the sector can be tempting: some made big returns in the \"tech boom\" of the late Nineties and early Noughties, but many suffered heavy losses.\nAs that period shows, picking which companies will succeed is tricky. Putting money into funds that provide a broad exposure to one area of technology while retaining a spread of risk across companies can be a wise strategy.\nInvestors can find funds that focus on one particular technology, such as robotics, while others invest more broadly, including in technology giants such as Amazon and Google parent company Alphabet. Deciding which approach to take will be one of the key questions facing investors.\u00a0\nJohn Husselbee, multi-asset manager at Liontrust, the fund group, said: \"The conversations we are having today are conversations I was having in the mid-Nineties. We had the tech boom and bust, and plenty of people had their fingers burnt. The best way to approach this is with established funds, which will give you the blend of established companies and exposure to these newer technologies.\"\nBrian Dennehy of Fund Expert, the fund shop, tends to favour a broader focus, or a small companies fund. \"You know you are buying stocks that have the potential to outperform anyone,\" he said. \"And if you can find one that has a bias towards technology that's fantastic. If you want to find the next Amazon, you are much more likely to find it in a small companies fund.\"\nMr Husselbee picked Henderson Global Technology, Polar Capital Global Technology and Axa Framlington Global Technology as good broad funds offering general exposure to technology companies.\nTelegraph Money asked experts to suggest funds that will give investors exposure to some of the most exciting technologies.\nRobotics In the future, robots could be delivering our shopping, fixing our car and even writing our newspapers. While this could put many of us out of work, it also presents exciting opportunities for investors. Some companies are making huge strides in the field. Online supermarket Ocado, for example, is developing a robot that can help an engineer fix an engine.\nFor funds, Mr Husselbee selected the \u00a33.9bn Pictet Robotics fund and Axa Framlington's Robotech fund, launched in January.\nMr Dennehy picked ETFS Global Robotics as a good option for those wanting a passive fund that tracks a specially-designed index. For an active option, run by a fund manager, he picked Pictet Robotics, but said for most investors it is likely to be too risky. The Pictet fund invests in giants such as Siemens and Alphabet, alongside Japanese robotics company Fanuc and motor company Nidec. He said: \"The Pictet fund has a decent exposure to larger cap stocks such as Alphabet and Siemens, which should provide greater liquidity when the downturn comes, giving you a better chance of selling. But if you are a robotics groupie the ETFS tracker gives you a purer exposure and so long as the bubble grows, better returns: it's up 32pc versus 26pc in the past year.\"\nArtificial intelligence Robots and machines that have the ability to learn have long been the stuff of science fiction movies. But the real-world applications of the technology can be exciting, and for investors, there's money to be made.\nThe funds listed above do not draw clear distinctions between areas such as artificial intelligence (AI), robotics and automation so will be an acceptable choice for many investors wanting AI exposure.\nMr Dennehy said those wanting a broader choice of companies, and spread of risk, can look at the \u00a3748m Liontrust UK Smaller fund. He described it as having \"exciting long-term potential\". It has around 40pc of its money in UK-based technology companies. He added: \"The other smaller businesses in this fund are also going to grow by adapting all the new technology as it comes on stream - making a fund like this doubly effective.'' Mr Husselbee said Smith & Williamson announced the launch of an AI fund in May, managed by Chris Ford and Tim Day, formerly of Pictet, while Allianz has also recently launched an AI fund: Global Artificial Intelligence, although both have minimal track record on which to assess performance.\nDriverless cars/automation Driverless cars have enormous potential to transform our road networks and commute to work. The technology has been pioneered by Google, but companies such as Lyft, Uber and Apple have also jumped on board. Experts say fully driverless cars could be just five years away.\nThe presence of the major players means most broad technology funds provide exposure to companies developing driverless cars. Mr Dennehy said the \"granddaddy of the sector\" was the \u00a3741m Henderson Global Technology fund.\nIt has US technology giants Alphabet, Apple, Facebook and Microsoft in its top holdings, as well as some Chinese equivalents, Alibaba and Tencent.\nAnother approach more risk-taking investors could take is to invest directly in some of the smaller companies that develop the underlying components and software used in automated technology - although this is clearly not for the faint-hearted.\nHyunho Sohn, manager of the \u00a32bn Fidelity Global Technology fund, tipped Infineon Technologies and Delphi. Infineon, listed in Germany, makes parts for emergency braking battery management systems and had a pre-tax profit last year of \u00a3763m, while US-listed company Delphi has also made strides in the driverless car market and made \u00a31.9bn profit last year.\nBiotechnology is a little understood area. The term refers to any technology based on biology. Huge strides have been made to develop agricultural technology and to provide vaccines for previously untreatable diseases. For investors, companies developing biotech have a \"long and mostly honourable history\", said Mr Dennehy.\nBoth Mr Dennehy and Mr Husselbee picked Axa Framlington Biotech as the obvious choice for investors. The \u00a3531m fund has a range of pharmaceutical companies in its top holdings, including Gilead Sciences, which recently bought cell therapy firm Kite Pharma. Mr Husselbee also recommended Neil Woodford's \u00a3853m Patient Capital trust, as it has exposure to biotech firms. But it has underperformed, with its share price dropping 4pc since launch in April 2015.\nRenewable energy Huge sums are being poured into a range of renewable energies, including solar, hydropower and wind power. For investors who want to gain a slice of this market growth, Mr Dennehy recommended iShares Global Clean Energy, an exchangetraded fund that tracks the market. However, he said the renewables sector is often \"confused\" by government interference, which come in the form of subsidies.\nMr Dennehy said renewables were a good long-term bet, but can be unstable - the iShares fund is down about 5pc this year.\nThere are three main funds investing in solar power: Bluefield Solar Income, Foresight Solar and NextEnergy Solar.\n"},
{"docid": "92 of 297 DOCUMENTS\n", "source": "The New Review\n", "date": "September 12, 2010", "title": "Men of the future; They're building robots, they're making us immortal, they're hanging out with Stevie Wonder and getting off on fruit-fly porn. These are the visionary thinkers who can make our future bright, and these are the ties that bind them. But are they leading us all towards 'nerdocalypse'?\n", "content": "As night thickens around Marina Boulevard on a murky San Francisco evening, one thing is crystal-clear: the future is not what it used to be. The wildest, most mind-frazzling visions of the years ahead are no longer the sole preserve of science fiction. At least, it seems that way at a reception to mark the start of the 2010 Singularity Summit, the world's leading forum for serious discussion of incredible things to come.\nHere, in a plush and spacious apartment not far from the Golden Gate Bridge, scientists, academics and futurists - bankrolled by the Silicon Valley dollar - are discussing what many among them believe to be an imminent and radical transformation of the human experience. This sea change, caused by monumental advances in technology, has a name: the singularity. It also has a dedicated and well-informed fanbase: the singularitarians.\u00a0\nThe reception is in full swing. Next to the open bar, the professional rationalist is rubbing shoulders with the preeminent neurobiologist, and the scenario forecaster is exchanging ideas with the cutting-edge nanotechnologist, as notions once thought too outlandish to merit serious consideration - such as beyond-human intelligence, immortality and god-like omniscience - are reassessed in the cool light of possibility. Yesterday's tech-obsessed fantasist is today's credible expert. A new, dynamic, cross-discipline geek community is visibly taking shape, as the buzz of high-brow chatter fills the room like pipe tobacco in an early 20th-century Vienna coffee house.\nMichael Vassar, summit host and president of the Singularity Institute for Artificial Intelligence (SIAI), reduces the future to two competing scenarios: \"Either you and everyone you love are going to be killed by robots; or you are going to live forever.\" Some very clever people, he says with a hint of mischief and a disconcerting flash of clear-eyed sincerity, can make a strong case for each of those arguments, so it's in our best interests to pay attention.\nLooking around the apartment (which was borrowed for the evening from the billionaire venture capitalist Peter Thiel, SIAI backer and co-founder of PayPal), Vassar points out a couple of the summit's keynote speakers: there's the Canadian inventor Steve Mann, \"the world's first cyborg\", who's wearing a black woolly hat and computer-enhanced eyeglasses; and, over by the dessert table, Ben Goertzel, who has been called \"the bad-ass of the artificial intelligence [AI] community\", and looks as thought he's been blown off course on the way to Glastonbury.\nOver the following two days, in the conference hall at the Hyatt Regency hotel, these and other invited experts add their latest insights and thoughts to a concept first suggested in the 1950s by information theorist John von Neumann, expanded on during the 1980s and 1990s by computer scientist Vernor Vinge, and carried enthusiastically through to the 21st century by current singularitarian-in-chief, inventor Ray Kurzweil.\nThe singularity is a metaphorical term used to express the transformative moment when technology has moved so rapidly that the human race can never be the same again. This could be a good thing, according to Kurzweil, if we avoid the dangers of genetics, nanotechnology and robotics, then succeed in harnessing artificial intelligence to conquer mortality and accept the next, transhuman phase of our evolution. Or it could all go badly wrong, resulting in what some have dubbed the \"nerdocalypse\". In Kurzweil's estimation we should know, either way, by 2045.\nIt's that sense of imminence and immediacy that has made the singularity such a passionately contested proposition, and attracted interest - and investment - from extremely wealthy and intelligent individuals, as well as Google and Nasa, which have each put money into the Singularity University (co-founded by Kurzweil) near San Jose.\nAn early hit at the summit is biophysicist and entrepreneur Gregory Stock, who enthuses the paying audience of future-followers with statements such as \"science has slammed the evolutionary process into fast forward\" and \"evolution is itself evolving\", before advising everyone to drink more coffee (based on the promising gene research he oversaw as chief executive of Signum Biosciences) and suggesting that we should not underestimate the current state of progress: \"This is big stuff that's happening.\" He elicits a communal chuckle by showing pictures of gratuitous sex (featuring worms, beetles, squid and flies) as a precursor to his notion of a \"planetary superorganism\".\nAway from the podium, Stock elaborates: \"What's really freeing is if you walk through a city and think of it as purely biological: that there isn't a contradiction between flesh and biology and technology. It's the manifestation of biology creating this entity, this superorganism: a city. You have to be awestruck that it actually works.\"\nThe broad concept of a city is also central to understanding the AI theories of Demis Hassabis, who earnt a double-first in computer science at Cambridge before trading his career in the videogame industry for a job in cognitive neuroscience at University College London. Hassabis wants to enable computers to learn not just language but complex abstractions. \"I'm interested in how we build the concept of a city. It's a really rich representation. You're thinking of size, tons of people, cathedrals... the actual concept. Basically, I think there are going to be some amazing breakthroughs by 2020.\"\nHassabis confesses that, while he's interested in the singularity, he himself is not a singularitarian. \"Maybe it's because of my British side, but it's a bit Californian, I think. Potentially that's the ultimate thing we might have to deal with if anything we do in AI works. But I think we're so far away from that, and so far away from anything being dangerous or sentient, that we need to do a lot more work first before we can properly analyse what the dangers might be.\"\nGoertzel is not as sure as Hassabis that we should relax. \"I would be among the least shocked people if we had the singularity in 2015,\" he says, before qualifying that thought with: \"I also wouldn't be amazed if it was delayed to 2100, because some technologies prove hard to work through all the details.\" Either way, he thinks, the singularity is coming. But what's it going to look like?\n\"There's a dichotomy,\" says Goertzel, \"between people such as Ray Kurzweil, who see the kinder, gentler singularity, which makes the future much like it is today but without disease and without scarcity, and everyone's frolicking in the fields. And Vernor Vinge, [who says] once we've got a 'being' 10 times as smart as us, all bets are off. I'm a bit more inclined towards Vinge's views than Ray's. I'm hoping for the best, and will work toward a positive outcome. I feel like Ray and some others downplay the irreducible uncertainty of creating things massively more capable than us.\"\nRoboticist David Hanson has been discussing with Goertzel some of the reasons why there hasn't been something like an Apollo programme, funded by the government, to achieve human-level cognition in machines. \"Ben said he thought it was because people were scared of these machines, and I said that if people felt that the machines were friends, and lovable, they wouldn't be scared.\" To address that fear, Hanson makes robots he calls \"empathy machines\" because \"if we don't feel like they're part of our family, then we're going to pick a fight with [them]. And the smarter they get, the more dangerous it will be to pick fights.\"\nSteve Mann, still wearing his intelligent spectacles, demonstrates another way the man-machine gulf can be bridged, by playing House of the Rising Sun on what looks like a cross between a synthesizer and a bird bath: he creates music by placing his fingers on small jets of water. It's less an attempt to soundtrack the future than a way to show how the hard digital world can seem less alien, more tactile. Although Mann shares a claim to \"world's first cyborg\" status with the University of Reading's Kevin Warwick, he assures me he's been modifying himself since childhood.\nIf all cyborgs and robots end up as affable, enthusiastic and musical as Mann, the face of the singularity - should it ever show itself - will not appear too daunting, but all the speakers at the summit agree that, however the future unfolds, we're sure to have plenty to think about. For instance, with the promise of advanced AI comes the possibility of radical life extension, even immortality, after we've banished all bodily ills and uploaded ourselves to a hard-drive.\nIn case he doesn't live to see that day, Goertzel has signed up for cryonic suspension, so that he can be revived and rebooted in the transhuman, post-singularity era. Hanson has hedged his bets, saying that to be a transhumanist is to humbly realise that there is a future that exists beyond us. Stock, on the other hand, acknowledges that the human lifespan will most likely be modified, in a good way, but says that it won't really matter to him.\n\"I don't think I will quite make it,\" he admits, before urging us to step back for a second, and relish the fact that, in the broader picture, we live in incredible times. \"Drink this stuff, imbibe of it. When you really penetrate into this stuff it's absolutely mind-boggling. People should be taking pleasure in that.\" *\nRay Kurzweil\nAge 62 Born New York Lives Boston\nBig idea Reverse-engineering the brain\nQuote \"Our tools for peering into our brains are improving at an exponential pace.\"\nProfile Kurzweil made his name with a series of inventions - the first print-to-speech reading machine for the blind; the first synth capable of accurately replicating orchestral instruments - and after popularising the idea of the singularity (see \"A futurist glossary, below\"), he is now turning the bulk of his attention to reverse-engineering (structurally analysing) the brain. \"It's not that we're going to simulate the brain mindlessly,\" he joked to 2010 Singularity Summit attendees. \"I believe we are only two decades from fully modelling and simulating the human brain.\"\nStewart Brand\nAge 71 Born Illinois Lives San Francisco\nBig idea Whole Earth Discipline\nQuote \"We are as gods, and have to get good at it.\"\nProfile Name-checked at the beginning of Tom Wolfe's Electric Kool-Aid Acid Test, Brand emerged from the counterculture at the leading edge of technology and environmentalism. In 2009, he amended much of his green thinking in Whole Earth Discipline: An Ecopragmatist Manifesto. \"I think that geoengineering [or climate engineering] will become seen as necessary - whether it works well remains to be seen,\" he says. Of the singularity, he adds: \"I think it has correctly been characterised as the Rapture of the Nerds.\"\nDemis Hassabis\nAge 34 Born London Lives London\nBig idea Hybrid Systems Neuroscience\nQuote \"There are spaceships being launched all over the place right now, so how about launching a few into the mind.\"\nProfile Hassabis is a former child chess prodigy and videogames designer hoping to surf the revolution in cognitive neuroscience, and enable computers to not only understand a concept but to \"learn, store, and flexibly use concepts\". This he hopes to achieve by 2020, by pursuing an approach summed up by the equation: machine learning + neuroscience = artificial general intelligence. \"I want to create an interdisciplinary lab that basically has computer scientists and neuroscientists working together.\"\nLarry Brilliant\nAge 66 Born Detroit Lives San Francisco\nBig idea Teleological Technology\nQuote \"If you don't have a world that builds technology for the purpose of making life better, then technology is not the answer.\"\nProfile The physician and technologist who played a key role in the eradication of smallpox in the 1970s, and is currently president of the Skoll Global Threats Fund, set up \"to safeguard the future\", advocates applying the medical usage of teleology - disease-specific medicine - to technology. \"I'd like to see more purposeful technology. We have unbridled increases in certain technologies and not enough in others. We've done really well with globalisation of products that make a profit, but really poorly at the globalisation of compassion and empathy.\"\nDavid Hanson\nAge 40 Born Dallas Lives Dallas\nBig idea Character Robotics\nQuote \"I think we can achieve something like human creative genius in machines, between 10 and 20 years from now, maybe sooner.\"\nProfile Hanson, a former Disney \"imagineer\" who developed Frubber??? artificial skin for robots at Hanson Robotics, suggests a renaissance philosophy whereby engineering, neuroscience and art feed on each other: \"For civilisation to go forward we need friendly superintelligent machines. I focus on 'character intelligence' because I'm trying to see it from the human-use perspective: how would the user interact with this robot? Rolling techniques from art into the mix is a shortcut to realising machines we can empathise with.\"\nBen Goertzel\nAge 43 Born Rio de Janeiro Lives Washington\nBig idea Artificial Biology\nQuote \"Artificial biologists will ultimately abolish involuntary death.\"\nProfile Goertzel is the prime mover behind OpenCog, a project developing Artificial General Intelligence (AGI). \"AGI will be a system that has more of the type of general intelligence that we think of humans as having, where it can solve a huge variety of problems, including those the programmers of the system never thought of.\" The road to understanding radical life extension (like the longevity he's seen in fruit flies genetically bred to live five times longer than regular fruit flies) is \"combining OpenCog AI stuff with narrow AI to get a system of artificial biology\".\nMax More\nAge 46 Born Bristol Lives Austin, Texas\nBig idea Dynamic Optimism\nQuote \"I'm hoping not to age and die.\"\nProfile More is one of the more cautious futurists, who believes that, \"Futurism shouldn't be about predictions - it should be about scenarios.\" He is not a singularitarian because \"the singularity view seems to rely on a single forecasting method, and there are many other methods\". However, he was one of the first thinkers to sharpen the definition of transhumanism (see glossary) and to map out a strategic approach to tech-based futurism. \"Part of my view is this idea of Dynamic Optimism. We can make ourselves and the world better, but only if we make a big effort. It's not going to happen automatically.\"\nGregory Stock\nAge 60 Born LA Lives Princeton\nBig idea The Planetary Superorganism\nQuote \"Things are going to get very weird, relatively quickly.\"\nProfile Stock has expanded on his 1993 book Metaman, which outlined a vision of humanity merged with technology. \"The way we interact with each other, the kind of social networking that exists, all that has moved into the mainstream in a very profound way, extremely rapidly. To me, it's the networking that makes things beyond human level intelligence. We're able to multiply who we are by being tied together. If you look at those multiplication factors, that's already happening just in the past few years. I look at it and I go: What a privilege to be alive right now.\" '\nA futurist glossary\nTranshumanism\n\"It's humanism on steroids,\" explains Max More. \"It's a view that we can improve the human condition: things like mortality, the inevitability of death; the limited capacity of our brains; the primitive state of our emotional systems.\"\nExtropy\nThe opposite of the natural tendency towards disorder and decay. \"It's about increasing levels of a system's intelligence, its vitality, its experience, and its capacity and drive for improvement,\" says More.\nThe singularity\nThe point at which accelerating technology profoundly changes human existence. Ray Kurzweil believes it will arrive in around 2045; Ben Goertzel wouldn't be surprised if it arrived by 2015.\n"},
{"docid": "93 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "February 26, 2017", "title": "O2 lines up robots to handle customer enquiries\n", "content": "O2 is seeking to cut costs in its customer service operation by encouraging people to talk to a new artificially intelligent robot rather than contact its call centres.\u00a0\nThe mobile operator's parent company, the Spanish telecoms giant Telefonica, unveiled the new voice recognition technology, called Aura, at the Mobile World Congress trade show in Barcelona.\nThe system is scheduled to be introduced in the UK in the next year and is designed to answer customers' questions about their account, such as how much of their monthly data allowance is left or what their next bill will be.\nCustomers will also be able ask to add new services, such as a roaming package, or cancel them, without speaking to a person.\nMark Evans, O2's chief executive, said Aura represented the next stage of the company's efforts to encourage customers to serve themselves if they have a basic inquiry.\nCalls to the operator have already halved as people increasingly turn to a smartphone app to manage their accounts.\u00a0 It is intended that the addition of artificial intelligence and voice recognition will reduce costs further, however, and increase loyalty by making it easier to interact with O2.\nMr Evans has been trimming costs recently to get the operator ready for a potential \u00a310bn stock market float this year, in which Telefonica would sell a minority stake. The operator's call centres are outsourced to Capita.\nA reduction in work could lead to job cuts that would be among the first in the UK directly attributable to consumer usage of artificial intelligence.\u00a0\n"},
{"docid": "94 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "January 16 1990", "title": "Telecomputing likely to face losses of 1.4m pounds\n", "content": "\u00a0\n Telecomputing, the USM-quoted computer software group that is investigating a possible overstatement of company profits, is likely to fall into losses of Pounds 1.4 million after writing off artificial intelligence assets as exceptional items when it reports its final results in February.\n The group, which fell into a Pounds 194,000 loss for the year to end-September 1988 after a move into artificial intelligence before returning to the black with pre-tax profits of Pounds 145,000 for the six months to end-May 1989, says it is cutting costs significantly, but is presently trading at break-even.\u00a0Telecomputing, which plans to turn to its shareholders to raise about Pounds 2 million in a rights issue next month, also said it is close to discovering whether or by how much the interim profits had been overstated.\n\n A spokesman said it was a matter of assessing whether or not former accounting policies were appropriate.\n Telecomputing, which has obtained an injunction against its founder and ex-chairman, Mr Bernard Panton, with an injunction on Friday preventing him from communicating with the group's financial advisers, bankers and shareholders, believes the accounting practice used by Mr Panton was 'not best practice.'\n Mr Panton, who resigned in late November when the computer company Ferrari Holdings took a 29.8 per cent stake with the backing of the merchant bank Singer & Friedlander, had spent Pounds 3 million on what the new board calls a disastrous move into the highly-speculative realm of artificial intelligence software.\n The dispute between Mr Panton and Telecomputing revolves round a disagreement about whether Merrion Gates, an Irish software company, was a 100 per cent subsidiary or a 45 per cent-owned associate.\n Telecomputing shares, down from a peak of 303p in 1987 and bought by Ferrari at 87p, fell 8p to 85p.\n"},
{"docid": "95 of 297 DOCUMENTS\n", "source": "The Times\n", "date": "January 16, 1990", "title": "Telecomputing likely to face losses of Pounds 1.4m\n", "content": "Telecomputing, the USM-quoted computer software group that is investigating a possible overstatement of company profits, is likely to fall into losses of Pounds 1.4 million after writing off artificial intelligence assets as exceptional items when it reports its final results in February.\nThe group, which fell into a Pounds 194,000 loss for the year to end-September 1988 after a move into artificial intelligence before returning to the black with pre-tax profits of Pounds 145,000 for the six months to end-May 1989, says it is cutting costs significantly, but is presently trading at break-even.\u00a0Telecomputing, which plans to turn to its shareholders to raise about Pounds 2 million in a rights issue next month, also said it is close to discovering whether or by how much the interim profits had been overstated.\nA spokesman said it was a matter of assessing whether or not former accounting policies were appropriate.\nTelecomputing, which has obtained an injunction against its founder and ex-chairman, Mr Bernard Panton, with an injunction on Friday preventing him from communicating with the group's financial advisers, bankers and shareholders, believes the accounting practice used by Mr Panton was ''not best practice.''\nMr Panton, who resigned in late November when the computer company Ferrari Holdings took a 29.8 per cent stake with the backing of the merchant bank Singer & Friedlander, had spent Pounds 3 million on what the new board calls a disastrous move into the highly-speculative realm of artificial intelligence software.\nThe dispute between Mr Panton and Telecomputing revolves round a disagreement about whether Merrion Gates, an Irish software company, was a 100 per cent subsidiary or a 45 per cent-owned associate.\nTelecomputing shares, down from a peak of 303p in 1987 and bought by Ferrari at 87p, fell 8p to 85p.\n"},
{"docid": "96 of 297 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "November 2, 2017", "title": "Stephen Hawking warns artificial intelligence 'may replace humans altogether'; The world-renowned physicist says it will be'a new form of life'\n", "content": "                     Stephen Hawking is concerned that artificial intelligence could replace humans.\nThe world-renowned physicist fears that somebody will create AI that will keep improving itself until it's eventually superior to people.\u00a0\nHe says the result of this will be a \"new form\" of life.\n\"I fear that AI may replace humans altogether,\" he said in an interview with Wired magazine, seen by Cambridge News.\n\"If people design computer viruses, someone will design AI that improves and replicates itself.This will be a new form of life that outperforms humans.\"\nThis is far from the first time Mr Hawking has spoken out about the development of AI.\nEarlier this year, he called for technology to be controlled in order to prevent it from destroying the human race, and said humans need to find a way to identify potential threats quickly, before they have a chance to escalate and endanger civilisation.\nBack in 2015, he also expressed fears that AI could grow so powerful it might end up killing humans unintentionally.\nRead more\nAI tricked into thinking a turtle is a rifle and a cat is guacamole\n\"The real risk with AI isn't malice but competence,\" he said. \"A super intelligent AI will be extremely good at accomplishing its goals, and if those goals aren't aligned with ours, we're in trouble.\"\nAn ex-Uber employee was recently found to have set up a non-profit religious organisation calling for the creation of an artificial intelligence \"Godhead\" that humans would worship.\nElon Musk, who has also expressed major concerns over AI, said he should be \"on the list of people who should absolutely *not* be allowed to develop digital superintelligence\".\n"},
{"docid": "97 of 297 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "August 10, 1989", "title": "Computer Guardian (Workspace): Concern in the data villages\n", "content": "\u00a0\n A FEATURE of information technology is its social geography. Everybody lives in little villages and nobody takes the trouble to walk across the fields to see what is happening in the next village. At a pinch they might read the local newspaper to see what the editor thinks is happening, but they rarely visit the neighbouring village pubs. They are too busy to waste an evening away from their own local.\n It is no different to other disciplines. But where they are held together by theory, information technology is often in the position where practice is a couple of years ahead. Most current software and techniques originated either in working installations or with suppliers who had to find answers for their users. It could be argued the only significant contribution made by academia is communications.\u00a0\n\n Data processing is one of these villages and few of the editors of the local newspapers are inhabitants. Its advances accordingly are not properly reported and their implications are not reported at all.\n In The Fifth Generation by Feigenbaum & McCorduck (Michael Joseph, 1984), the difference is explained between a database and a knowledge-base - as perceived by the inhabitants of a neighbouring village called artificial intelligence.\n Feigenbaum is a guru who knows what he's talking about. You might say he's head of the artificial intelligence parish council. But he's obviously never heard of functional or referential integrity, or of entity modelling, or of the constraints (meta-data) in the relational model, or of the rules that are co-resident with data structures in every database management system (DBMS). Nor is he aware of the discussion on whether rules should be written as conditional procedures or as a series of assertions.\n If someone like Feigenbaum thinks that a database is no more than a complicated file, the data processing village is obviously not getting its activities properly reported in the local press.\n Three or four years ago, James Martin wrote that academic institutions were not turning out the kind of graduates that data-processing managers wanted to employ; he was beating the drum for fourth generation languages at the time. He was challenged to defend his view in open debate against the might of American academe.\n The debate was interesting because it illustrated that the academics were interested in the technicalities of programming while data-processing managers, as reported by Martin, were interested in the speed of developing applications.\n Data processing is not greatly concerned with languages - any old language will suffice so long as it does the job. But it is overwhelmingly concerned with how to structure data to be processed in all sorts of different ways, and is now increasingly concerned with structuring data to provide information rather than to drive applications.\n A graduate specialising in artificial intelligence is valuable because he or she already knows what is involved in structuring knowledge and the pros and cons of choosing to structure it in a particular way.\n A graduate specialising in business computing is of less value because the equivalent knowledge about structure data is buried by the academic premise that databases primarily are productivity aids for specific applications. This is why a degree in computing is usually essential for work in artificial intelligence but no more than a welcome bonus in data processing.\n A more important issue is raised by the poll tax, whose practical implications are just beginning to dawn on our amateur bosses. These are the first glimmerings of a problem that data processing has been trying unsuccessfully to solve for years, namely the proper use of information.\n No one outside data processing seems to have realised that forbidding the provision of sensitive information from a single database does not protect it. It can be deduced by computer program from ad-hoc data combinations, and much of the current work in data processing - object oriented programming, distributed database theory, and separating the processing of rules from computation and the manipulation of data - will make this deduction a matter of course.\n This is one reason why the ignorance of data processing in neighbouring villages is changing from a mere irritation to a cause for concern.\n"},
{"docid": "98 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 22, 2017", "title": "Tech sector growing faster than UK economy with 72pc of investment outside London, report says\n", "content": "Theresa May has described the technology industry as a \"great British success story\" after a report revealed that investment in digital businesses spread across the country last year.\u00a0\nExpanding its reach beyond London, 72pc of venture capital and private equity investment went to regional businesses in 2016, amounting to \u00a39.2bn, according to the third annual Tech Nation report.\u00a0\nThe report revealed the UK leads in Europe, attracting \u00a328bn in technology investment since 2011, compared with \u00a311bn in France and \u00a39.3bn in Germany.\u00a0\u00a0\nWith talent and investment pouring into the sector, it has grown to be a major contributor to the UK economy. The digital economy, which is growing at twice the rate of the wider economy, now contributes around \u00a397bn a year, up 30pc in five years, according to the report.\u00a0\nMs May says the tech sector will be a focus for the UK after BrexitCredit:      Bloomberg     \n\"The number of digital tech\u00a0jobs across the UK\u00a0has grown at more than twice the rate of non-digital tech sectors,\" said Ms May. \"From analysts to web developers to software architects, these pioneers of our digital economy are at the forefront of a great British success story.\"\u00a0\nMs May said tech will be a priority after leaving the European Union and that the Government will work closely with the industry.\u00a0\n\"We will expand the scope of our digital tech industries, funding artificial intelligence, robotics, 5G, smart energy and more,\" she said.\u00a0\nSome 2,700 tech workers and investors were questioned for the report, which\u00a0reveals that the spread of investment and talent has allowed pockets of tech expertise to develop across the regions. For example, Belfast has a flourishing cyber security scene, Edinburgh specialises in data analytics, and London and Cambridge in artificial intelligence.\u00a0\nThe highest concentrations of high growth tech companies are found in London, Bournemouth, Poole and Newcastle, the report says.\u00a0\nDebbie Wosskow is a strong advocate for women in the UK tech sector\nHowever, there remain barriers to entry for women. Adding to claims of sexism in the industry,\u00a0Tech Nation found that men outnumber women by a ratio of three to one within the sector. It follows\u00a0 news that only 9pc of investment in British start-ups in 2016 went to companies with a female founder.\u00a0\nSome people in the industry are worried that Brexit will hamper growth by creating a talent shortage.\n\"There are some big challenges ahead of the British digital tech sector, not least finding the skilled staff to continue growing at this rate, as the UK prepares to leave the EU,\" said Wendy Tan White, general partner at Entrepreneur First.\u00a0\"Whatever happens in the coming months, the UK must continue to be an attractive place for investors to want to put their money, prioritising support and infrastructure for the start-up economy.\"\nA separate report from Tech London Advocates found that one in 10 London tech companies have experienced investors withdrawing or holding back funding since the referendum. The survey of 4,400 people in the sector found 58.2pc think Brexit will hamper the UK's position within the global tech industry.\u00a0\nAssuaging fears, Gerard Grech, chief executive Tech City UK, which authored the report, said British universities have contributed significantly to the growth of regional tech companies, and will continue to do so.\u00a0\n\"Universities across the country are providing talent for this fast growth sector and we need to maintain the momentum they've developed,\" said Grech.\u00a0\nHigh salaries in the industry \u00a0will help the sector continue to grow and attract talent after Brexit, he added.\u00a0\n\"The average salary in the digital\u00a0industries is 44pc higher than the national average,\" he said. \"That's very good to know for school leavers and university graduates looking for a good career. This is obviously a good destination for them.\"\u00a0\nOn average tech workers are paid \u00a350,663 a year, up 13pc since 2012,\u00a0compared with \u00a335,155 for the average non-digital salary, the report found. The number of digital tech jobs meanwhile increased 17pc between 2011 and 2015.\nREAD MORE ABOUT:\n"},
{"docid": "99 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "September 7, 2016", "title": "Digital move pays off very nicely for Shop Direct\n", "content": "Profits have soared at Shop Direct for the fourth year in a row after bargainhunters flocked to its www.Very.co.uk and www.Littlewoods.com websites.\nShop Direct, owned by the Barclay brothers, who also own The Daily Telegraph and the Ritz hotel in London, said that its pre-tax profits had jumped by 20 per cent to \u00a3105.6 million in the year to the end of June. Its underlying profits rose by nearly 44 per cent to \u00a3150.4 million on sales of \u00a31.86 billion, up 4.3 per cent on the previous year.\u00a0\nThis was the first full year for Shop Direct as a \"pure-play digital retailer\" since it ditched its once significant catalogue business and closed non-core brands such as K&Co and Isme.\nAlex Baldock, its chief executive, said: \"We are pretty happy with what is our fourth consecutive record year and much of that growth has come from [orders made on] mobile phones. We offer something different to customers and our investment in technology and personalisation of our offer has been a big part of our success.\"\nwww.Very.co.uk, which Shop Direct calls an online department store, was the key driver of growth, with its sales rising by 15.9 per cent last year \"making it a \u00a31 billion plus brand for the first time\". Mr Baldock said that the group continued to invest heavily in technology and was working closely with IBM Watson on artificial intelligence technology, \"which will allow customers to talk\" to www.Very.co.uk as they would message a friend on WhatsApp. He added: \"The exciting thing for us is that we don't think we are anywhere near our full potential yet. We think artificial intelligence is going to be huge for us and we are putting some elbow behind it.\"\nThe strong results for Shop Direct will fuel speculation that the Barclay Brothers will look to float or sell a stake in the online fashion seller. The twins are thought to be working with investment bankers at Goldman Sachs and HSBC on a partial sale.\nMr Baldock declined to comment on any potential corporate activity.\n"},
{"docid": "100 of 297 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "July 30, 2017", "title": "Does the next industrial revolution spell the end of manufacturing jobs?; Smart machines are about to usher in the age of Industry 4.0\n", "content": "Robots have been taking our jobs since the 1960s. So why are politicians and business leaders only now becoming so worried about robots causing mass unemployment?\nIt comes down to the question of what a robot really is. While science fiction has often portrayed robots as androids carrying out tasks in much the same way as humans do, the reality is that robots take much more specialised forms. Traditional 20th-century robots were automated machines and robotic arms building cars in factories. Commercial 21st-century robots are supermarket self-checkouts, automated guided warehouse vehicles, and even burger-flipping machines in fast-food restaurants.\nUltimately, humans haven't become completely redundant: while robots may be efficient, they're also a bit stupid. They do not think, they just act - in accurate, but limited, ways. Humans are still needed to work around robots, doing the jobs the machines aren't able to and fixing them when they get stuck. But this is all set to change, thanks to a new wave of smarter, better value machines that can adapt to multiple tasks. This change will be so significant that it will create a new industrial revolution.\u00a0\nIndustry 4.0\nThis era of Industry 4.0 is being driven by the same technological advances that enable the capabilities of the smartphones in our pockets. It is a mix of low-cost and high-power computers, high-speed communication and artificial intelligence. This will produce smarter robots with better sensing and communication abilities that can adapt to different tasks, and even coordinate their work to meet demand without the input of humans.\nThe fourth industrial revolution (\nChristoph\nRoser\n)\nIn the manufacturing industry, where robots have arguably made the most headway of any sector, this will mean a dramatic shift from centralised to decentralised collaborative production. Traditional robots focused on single, fixed, high-speed operations and required a highly skilled human workforce to operate and maintain them. Industry 4.0 machines are flexible, collaborative and can operate more independently, which ultimately removes the need for a highly skilled workforce.\nFor large-scale manufacturers, Industry 4.0 means their robots will be able to sense their environment and communicate in an industrial network that can be run and monitored remotely. Each machine will produce large amounts of data that can be collectively studied using what is known as \"big data\" analysis. This will help identify ways to improve operating performance and production quality across the whole plant - for example, by better predicting when maintenance is needed and automatically scheduling it.\nFor small-to-medium manufacturing businesses, Industry 4.0 will make it cheaper and easier to use robots. It will create machines that can be reconfigured to perform multiple jobs and adjusted to work on a more diverse product range and different production volumes. This sector is already beginning to benefit from reconfigurable robots designed to collaborate with human workers and analyse their own work to look for improvements, such as BAXTER, SR-TEX and CareSelect.\nWhile these machines are getting smarter, they are still not as smart as us. Today's industrial artificial intelligence operates at a narrow level, which gives the appearance of human intelligence exhibited by machines, but designed by humans.\nWhat's coming next is known as \"deep learning\". Similar to big data analysis, it involves processing large quantities of data in real time to make decisions about what is the best action to take. The difference is that the machine learns from the data so it can improve its decision making. A perfect example of deep learning was demonstrated by Google's AlphaGo software, which taught itself to beat the world's greatest Go players.\nThe turning point in applying artificial intelligence to manufacturing could come with the application of special microchips called graphical processing units (GPUs). These enable deep learning to be applied to extremely large data sets at extremely fast speeds. But there is still some way to go and big industrial companies are recruiting vast numbers of scientists to further develop the technology.\nImpact on industry\nAs Industry 4.0 technology becomes smarter and more widely available, manufacturers of any size will be able to deploy cost-effective, multi-purpose and collaborative machines as standard. This will lead to industrial growth and market competitiveness, with a greater understanding of production processes leading to new high-quality products and digital services.\nIndustry 4.0 will allow humans to focus on business, creativity and science, which it would beharder for any robot to do (Rethink Robotics)\nExactly what impact a smarter robotic workforce with the potential to operate on its own will have on the manufacturing industry, is still widely disputed. Artificial\u00a0intelligence, as we know it from science fiction, is still in its infancy. It could well be the 22nd century before robots really have the potential to make human labour obsolete by developing not just deep learning, but true artificial understanding that mimics human thinking.\nIdeally, Industry 4.0 will enable human workers to achieve more in their jobs by removing repetitive tasks and giving them better robotic tools. In theory, this would allow us humans to focus more on business development, creativity and science, which it would be much harder for any robot to do. Technology that has made humans redundant in the past has forced us to adapt, generally with more education.\nBut because Industry 4.0 robots will be able to operate largely on their own, we might see much greater human redundancy from manufacturing jobs without other sectors being able to create enough new work. Then we might see more political moves to protect human labour, such as taxing robots.\nAgain, in an ideal scenario, humans may be able to focus on doing the things that make us human, perhaps fuelled by a basic income generated from robotic work. Ultimately, it will be up to us to define whether the robotic workforce will work for us, with us, or against us.\nJeff Morgan is a manufacturing research engineer at Trinity College Dublin. This article was originally published on The Conversation (www.theconversation.com)\n"},
{"docid": "101 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "March 11, 2017", "title": "The robots with artificial irreverence; Stage debut beckons for machines programmed to learn the nuances of improvised comedy, Oliver Moody writes\n", "content": "Picasso's wife walks into the studio one day to find him watching a television show about a new-fangled computer and painting a portrait of its presenters with what smells distinctly like rendered sardine fat.\n\"Pablo, what is this?\" she says. \"Oh,\" he replies, \"I'm going to call this one 'AI': arty fish oil in telly gents.\"\nIt's a dreadful joke. Yet it is nothing like as bad as some of the gags that two real artificial intelligence programs devised in an experiment that is taking the machine revolution into its toughest territory yet: improvised comedy. At the end of this month two performers and their robots will stand on stages in London and Edmonton, Canada, for a video-linked duet of the one art form that computers have struggled to master.\u00a0\nTheir digital partners, known as Alex and Pyggy - short for Pygmalion, after the sculptor who fell in love with his statue of Aphrodite - have learnt the craft from a database of tens of thousands of English subtitles for foreignlanguage films.\nUsing speech-recognition software, the programs compare the lines that are fed to them with lines of cinematic dialogue and try to work out an appropriate response, word by word.\nThe results, articulated through voice synthesis software on an Apple Mac, are often surreal non sequiturs. During one demonstration of Alex at the British Academy last month, his handler said that they were on a first date and thanked the machine for bringing him a present - a holiday for two in Iceland. The computer replied: \"When it is said, if you see a woman or a priest, you'll have to buy me a stick.\"\nAt other times the answers come out in a barely coherent form of English, a problem that has dogged previous attempts to marry the statistics-crunching power of artificial intelligence with the mess of nuances and intentions that make up conversational language.\nAt another performance in Canada, one of the AIs implied that she was having an affair with an old man. \"What's going on?\" the performer asked. \"I can't tell you,\" she replied, \"the more I can be the reason for me to be responsible for the end of you.\"\nJust occasionally, however, the software sounds almost human. \"There was a scene in the earlier days, when the speech recognition would pick up a bit early on in my dialogue and not give me enough time to seed it with words,\" said Piotr Mirowski, a French-Polish data scientist who will perform the London end of the show. \"My suggestion was to do a dating scene and I told it: 'I'm sorry, I just got us two tickets to go to the Royal Opera House.' It said: 'I don't want to carry on with this conversation. I'm going to call the police.'\" Computers have beaten world champions at chess, cards, quiz shows, Space Invaders and Go!. Comedy turns out to be a different proposition. There are no obvious rules, and while Google's machines have more or less got the hang of translating between Spanish and English, the mess of wordplay, double entendre and surrealism that makes up humour is proving altogether more elusive.\nAnother kind of conversation program, known as a chatbot, can occasionally hoodwink people into thinking it is human. In 2014 one of these strings of code even passed the Turing test, persuading a third of the judges at the Royal Society that he was a 14-year-old Ukrainian boy called Eugene in a series of brief exchanges, largely through a mixture of jokes, rudeness and frenetic changes of subject.\nMany computer scientists say that this is little more than a cheap trick that falls apart in the face of simple questioning.\nAlex and Pyggy may be less convincing at the moment, but Dr Mirowski, 38, said that they were a better reflection of the challenges that artificial intelligence would have to overcome before it could match humans in language games, such as working out grammar and context for itself.\nHe compared computer imitations of poetry with the real thing. \"In one case you're basing the text that you write on the meaning of your emotions and the kind of extremely complex factors that go into it,\" he said. \"In the other, you're relying on statistical patterns. They do 95 per cent of the job, but it's the 5 per cent that's missing which is so difficult.\"\nBinary 2 will be performed on March 31 and April 1. For tickets go to www.tristanbatestheatre.co.uk.\nOliver Moody, page 28\nMarch of the computers\nThe first computergenerated science fiction film, Sunspring, was shown last year at a festival in London. The AI, Benjamin, came up with its own plot, dialogue and music. Movie critics, however, said that all three were terrible.\nEven sophisticated audiences of classical music listeners have been unable to tell the difference between the genuine work of JS Bach and a series of imitations written by a program called EMI.\nIn 1996 a chess computer called Deep Blue beat the world leader, Garry Kasparov. In 2011 IBM's Watson overcame two past champions at Jeopardy, an American quiz show. In 2015, AlphaGo beat Lee Sedol, the South Korean Go! champion, at one of the last bastions of human supremacy, board games.\nThe machines triumphed at Texas Hold'em, a form of poker that depends on bluffing, in January.\n"},
{"docid": "102 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 7, 2017", "title": "Facebook must show it can follow its own rules on child safety\n", "content": "Last year, Facebook showed me into a room in central London to demonstrate the power of its visual recognition technology. The software, an executive explained, is trained using millions of photos, and built by some of the world's leading artificial intelligence experts. It can be used to describe images to blind users, find faces in photos, and - perhaps most importantly - see illegal images almost as soon as they are posted.\nNow, when an image is reported to Facebook's moderators, one in three times it comes from its own AI. Many of the images removed from the social network never have to be seen by a human, sparing both its users and the army of content checkers the gruesome job of clicking through thousands of photos of beheadings, child abuse and racist memes.\u00a0\nFacebook, in comparison to many areas of the internet, is a safe space. It's relatively private, and explicit images are banned. The company prides itself on it, and enforces its rules with often excessive zeal. Famous statues of gods and goddesses have been removed from the website for breaching its rules on nudity.\nThe statue of Neptune, a photo of which was removed by Facebook this yearCredit:      Alamy     \nSo how was it that when a BBC investigation reported 100 images of sexualised images of children, the company only took down 18 of them ? The photos, laden with obscene comments and some even labelled as \"child pornography\", apparently met Facebook's \"community standards\" - the set of rules that governs what is and isn't deemed acceptable.\nExcept of course they weren't acceptable. For one thing, Facebook eventually had a change of heart, removing the images after \"carefully reviewing\" them, raising the question of what went wrong in the first place.\u00a0More bizarrely, it reported the BBC to the police after it was emailed evidence.\nThis isn't the first time that Facebook has struggled with how to moderate the billions of photos uploaded a day. Last year, a Pulitzer-winning photo of the Vietnam War was censored for featuring a naked nine-year-old girl. For a long time, breastfeeding photos were routinely removed. Earlier today, Elizabeth Linder, a former Facebook executive, said there was a \"fine balance\" between enforcing standards and censorship.\nNot here. Child abuse images are no edge case: the laws, as well as Facebook's own rules, are not open to interpretation. The company often deflects full responsibility for what appears on its website because it is ultimately posted by the user, but that is little excuse here. \u00a0\nFacebook is relying on artificial intelligence in moderationCredit:      PA     \nFacebook's ability to deal with unappealing content - whether that's illegal child images, hate speech or misleading fake news - is now coming under growing scrutiny.\nThe company's answer so far has been to make more use of artificial intelligence. Its live video tool, which has been used to live stream murders, is now being scanned by image recognition software, flagging it to a human if deemed inappropriate.\nBut the company's failings are still too numerous, and AI, at least at present, has its limits: an algorithm recently unveiled by Google to reduce abusive online comments was last week shown to be easily sidestepped by typos.\nIf 82 out of 100 images were deemed acceptable when reported, as the BBC claims, that is a failure on Facebook's part, and one that makes examining\u00a0its practices worthwhile. Of course, there is no easy way to police almost 2 billion users across different languages and cultures, but if Facebook can't even follow its own rules, something's not working.\nA Facebook spokesman said it has been \"recognised as one of the best platforms on the internet for child safety\". If it is to live up to that billing, it can't afford incidents like this.\n"},
{"docid": "103 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 8, 2017", "title": "Budget 2017: Funding for robotics and batteries dismissed as underpowered\n", "content": "A pledge to fund \u00a3270m of research in robotics, next-generation batteries and biotech announced in Wednesday's Budgets was dismissed by the industry as woeful despite being a key pillar of the Government's industrial strategy.\u00a0\nThe Treasury announced the first phase of its \"Industrial Strategy Challenge Fund\", an effort to back groundbreaking technologies being developed by UK tech companies and universities.\nResearch teams will have to compete for funds aimed at solving three key challenges: batteries that can power electric cars, artificial intelligence and robots that can be used to replace humans in dangerous environments such as nuclear stations and oil rigs, and new ways of manufacturing medicines.\nHigh-tech research and development has been seen as central to Theresa May's industrial strategy and \u00a0the three areas are seen as one that the UK can lead the world in.\n                   Watch | Budget 2017: What we learnt                         01:34\nThe Chancellor Philip Hammond said the funds would \"keep the UK at the forefront of disruptive technologies\". However, the funding was criticised as inadequate by some in the industry, who pointed out that it can cost hundreds of millions of pounds to develop one technology alone.\u00a0\n\"While of course any investment in our technology industry is welcome, a leading world economy like the UK should be more decisive in its efforts to boost the development of disruptive technologies,\" said Adolfo Hernandez, the chief executive of language software firm SDL.\u00a0\n\"A \u00a3270m pot to cover everything from artificial intelligence, robotics, driverless cars and new biotech isn't big when you put it into context. The US spent more than $1bn (\u00a3820m) on R&D in AI-related technologies alone in 2015. For the UK to be a true global leader in these areas, we must be prepared to provide adequate funding and support.\"\nTo secure funds, businesses and researchers must apply to Innovate UK, the Government's science investment arm. The challenges are designed to replicate competitions run by DARPA, the US robotics organisation spun out of NASA.\u00a0 A Treasury spokesman said that the \u00a3270m was not just for the three research goals announced in the Budget but that further projects would be announced this year.\nBudget winners and losers\n"},
{"docid": "104 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "April 11, 2018", "title": "Bedtime story written by AI makes for bit of Grimm reading\n", "content": "\"Once upon a time there was a golden horse with a golden saddle and a beautiful purple flower in its hair.\"\nThat may not be authentic Jacob and Wilhelm Grimm, but it is the opening of the first bedtime story created by artificial intelligence (AI). The Princess and the Fox is the product of an algorithm that was fed the complete works of the Brothers Grimm, the 19th century compilers of folktales including Cinderella and Rapunzel, and trained to mimic their style.\u00a0\n\"You might call it literary cloning,\" said Michael Acton Smith, co-founder of Calm, the app that commissioned the tale for its \"bedtime stories for grownups\", which have five million listeners. He added: \"We're doing for the Brothers Grimm what Jurassic Park did for dinosaurs - bringing them back from the dead with modern science.\"\nThe story tells the tale of a king, a magical golden horse, a forlorn princess and a poor miller's son. A talking fox helps the lowly miller's son to rescue the beautiful princess from the fate of having to marry a dreadful prince who she does not love.\nCalm claims that the story has the style and \"voice\" of the Brothers Grimm but with a more \"soothing\" plot and feel than the scarier Grimm stories - a point that's won't impress literary critics who admire the darkness of the brothers' work.\nThe story flows fluently but the robo-writer did have a bit of help. The tale is the product of collaboration between Calm and Botnik, a group of writers and computer programmers who use artificial intelligence to create new forms of writing, such as a Harry Potter chapter in which Harry's best friend Ron eats Hermione's family.\nCalm commissioned Botnik to train its predictive text program, known as Voicebox, on the collected stories of the Grimms. The program works in a similar way to the predictive text on a phone but instead suggests phrases based on the writing of the particular authors whose work it has digested.\n\"The human writers took the sentences suggested by the predictive text program and began to assemble them into the rough shape of a story,\" said Jamie Brew, chief executive of Botnik.\n\"We then filled in the gaps, either using further algorithmic suggestions or simply by writing details that struck us as natural completions of the scene. This back and forth between machine and human input continued throughout.\"\nBotnik isn't the only organisation that has worked on AI literature. Two years ago Google collaborated with Stanford University and the University of Massachusetts to generate poetry. The researchers fed more than 3,000 romance novels into an algorithm that in turn used them to create poems, with one opening: \"There is no one else in the world/ There is no one else in sight/ They were the only ones who mattered/ They were the only ones left.\" Although poets and novelists needn't fear for their livelihoods quite yet, Bj\u00f6rn Schuller, a professor in machine intelligence at Augsburg University, recently predicted that AI would, unaided, write better novels than human authors within the next 10-20 years.\n"},
{"docid": "105 of 297 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "September 25, 1990", "title": "BOOK REVIEW / The education of Eliza and other robots; 'How to Build a Person' - John Pollock: MIT Press, 20.25 pounds\n", "content": "WE ARE distinguished from lesser beasts by our intelligence - our mind. The idea that this, our special core, might be reproduced mechanically, even if the mechanism is a very sophisticated computer program, is usually dismissed as fanciful. In How to Build a Person, John Pollock plans just such a development. This book is principally a spirited though technical argument for strong artificial intelligence (AI), the thesis that thinking, feeling, conscious things - persons - can be constructed.\nArtificial persons have a long and portentous history, going back at least as far as Hero of Alexandria, who in the first century AD wrote Pneumatics, describing various hydraulic human and animal-shaped gadgets. Neither these nor the many devices that followed were ascribed much ontological significance. That is a more recent indulgence, attributable principally to the logician Alan Turing. There has been much debate about the status of even the most convincing and personable form of AI. One notorious disbeliever is the philosopher John Searle. Searle starts with the Turing Test: if a program convinces you that you are communicating with a person, is the program intelligent? The Turing test says yes: if you cannot distinguish computer from human responses, consider the computer intelligent. Searle disagrees.\u00a0\n One such program - almost - is Eliza, a simulated Rogerian psychotherapist. Its methods are simple but effective. ''I have been feeling depressed,'' you type. ''You have been feeling depressed,'' reflects Eliza. Many people were convinced, until they tried nonsense like ''the blenheim been feeling warthog gradzbadag.'' Sticking to her syntax, ''what if there were not warthog gradzbadag?'' Eliza replied.\nSearle's critique postulates a Chinese to English translating program. Assuming that its translations were perfect, would the computer then understand Chinese? The Turing test suggests yes. Searle replies by taking the program's place, using its dictionaries and sophisticated rules of thumb. Does he now understand Chinese? ''Certainly not,'' he replies. There are problems with this analysis, however, not least the implausibility of translating this way. Furthermore, why not? Can it really be the case that the only conceivable substrate for intelligent life is carbon? Perhaps opponents of AI will be accused of ''carbocentrism'', a novel moral defect which only allows that rights be enjoyed by carbon-based lifeforms.\nThere seems no reason to believe that mind requires a specifically organic brain. In his book Mind Children, for example, robotics professor Hans Moravec discussed mind trans-embodied into a new silicon receptacle - our evolutionary fate, he argued. Instead of minds being carried by frail and fleeting physiological structures, intelligent awareness would sensibly migrate to a hardy electromechanical vehicle.\nJohn Pollock is not so much concerned with the evolutionary fate of mankind, but its mimicry by machine. He begins with a brief robot fable: unlike much artificial intelligence, his model is not fashioned after some grand design, but built ''bottom up'' from simpler cognitive bits and conative pieces. The book is a defence of three theses: token physicalism, agent materialism, and strong AI. Token physicalism is the notion that mental events are physical events, which in humans means neurophysiological events, and agent materialism is the idea that persons are physical objects that have a suitable structure.\nPollock discusses ''cognitive carpentry'' - putting theory into practice and building a person. A central element is defeasible - revisable - reasoning. Much AI has tried to reduce all reasoning to deductive reasoning, but real people do not generally think this way. Instead they make tentative suggestions, draw conclusions and withdraw them later in the light of new facts or new ideas. Classical logic, in which only correct conclusions can be deduced, struggles to mimic this. Most AI, however, rests on such logic, and is thus likely to lead to inappropriate behaviour in artificial people. Will Pollock's project ever work? Perhaps so, in which case the theoretical arguments will simply vanish in a puff of technology.\n"},
{"docid": "106 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "March 24, 2016", "title": "Short story with a twist in the tale: it was written by a robot\n", "content": "They started decades ago working on production lines before advancing to become chess masters and take control of driverless cars. Now robots devised by Japanese scientists are trespassing on an area of high culture, writing short stories and novels.\u00a0\nA story partly composed by an artificial intelligence program recently made it through the first round of a Japanese literature competition. Although it did not win the Hoshi Shinichi Literary Award, the judges commended the story, though they found its efforts were a bit thin on characterisation.\nThe program was the work of a team of scientists at Future University in the northern Japanese city of Hakodate. The computer did not compose the entire story from scratch but constructed sentences from inputs by its human masters.\nInstructed to include the elements of time, weather and what a character was doing, it came up with the following: \"The clouds hung low that day in an overcast sky. Inside, though, the temperature and humidity were perfectly controlled. Yoko was sitting lazily on the couch, passing the time playing pointless games.\"\nThe prize, which is awarded in the name of one of Japan's most famous science fiction writers, is unusual in encouraging artificial intelligences to enter their work.\nThis year, for the first time, 11 works of robot-assisted fiction were submitted among the 1,450 entrants. Four of them came from the team at Future University, headed by Hitoshi Matsubara.\nThe judges did not know which authors were human and which were robots. They were given a hint, however, from one of the stories entitled The Day a Computer Wrote a Novel.\nIt contains the following passage, whose prose qualities suggest that established literary giants do not need to give up in despair yet: \"I squirmed with joy, which I experienced for the first time, and continued writing excitedly.\nThe day a computer wrote a novel! The computer, pursuing its own rapture, gave up serving humans.\" In another entry, My Job, one character tells another: \"Did you hear yesterday's news? About jobs being cut, as cheap, clever humanoid robots are replacing humans?\" One of the judges, Satoshi Hase, a science fiction novelist, said he was surprised that the successful story was so well structured. \"But there are still some problems to overcome before winning the prize, such as character descriptions,\" he said.\nMr Matsubara said there were many problems to iron out before computer programs could be relied on to produce flowing prose. They could, however, create lines for haikus, adhering to the rules relating to the number of syllables for the poems.\nIn another victory last week for artificial intelligence, AlphaGo, a program developed by the British company DeepMind, defeated Lee Sedol, a South Korean champion of the Asian board game Go.\n"},
{"docid": "107 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "December 10, 2015", "title": "Google's new quantum computer is '100 million times faster than your PC'; Google and NASA have been working on a lightning-fast quantum computer that is 3,600 times faster than a supercomputer at solving complex problems\n", "content": "Has Google won the race to build the world's first commercial quantum computer? \nThe technology company's artificial intelligence lab believe they may finally have proof that their opinion-dividing quantum computer actually works. \u00a0\nGoogle and Nasa announced they were collaborating on the D-Wave X2 quantum computer, which they say is 100 million times faster than a conventional computer chip, in 2013. It can answer certain algorithms in seconds rather than years. \nGoogle director of engineering, Hartmut Neven, said: \"For a specific, carefully crafted proof-of-concept problem we achieve a 100-million-fold speed-up.\"\n<!-- Place this tag in your head or just before your close body tag. -->\nHowever, Matthias Troyer of the Swiss Federal Institute of Technology in Zurich said he wasn't convinced. \n\"You need to read the fine print,\" he told New Scientist. \"This is 108 times faster than some specific classical algorithm on problems designed to be very hard for that algorithm but easy for D-Wave.\"\nHemet does admit in his blog post that other algorithms can currently beat D-wave but says Google expect \"those methods will soon become ineffective\". \nAccording to Engadget, the computer figures out the \"most efficient overall course of action to complete a task when given a set number of options\" and could be key to the development of next-generation artificial intelligence. \nSceptics have questioned if the computer actually taps into quantum physics to solve algorithms but now Google and Nasa say they have proof. \n\"It is a truly disruptive technology that could change how we do everything,\" said Deepak Biswas, director of exploration technology at Nasa's Ames research centre in California. \nHere's why quantum computers could undermine cryptography.\n"},
{"docid": "108 of 297 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "August 2, 2011", "title": "Martin Woodhouse; Obituaries Polymath who turned his hand to artificial intelligence and perfume and dressed Diana Rigg as Maid Marian\n", "content": "MARTIN WOODHOUSE, who has died aged 78, was a psychologist and medic, but worked variously as a novelist, scriptwriter, engineer, programmer, government planner, artificial intelligence researcher and perfumer.\nHe wrote seven episodes of the cult 1960s fantasy adventure television series The Avengers, including Mr Teddy Bear (1962), one of the earliest episodes to feature Patrick McNee as Steed and Honor Blackman as Cathy Gale.\nThe actor Ian Hendry (the original Steed) had just left the series, and Woodhouse joined a brainstorming session one evening in a Thamesside pub before concluding that the sexual fantasies of the average middle-class Englishman included being dominated by a beautiful woman, preferably clad in leather.\u00a0\nHe duly wrote six of the early Avengers screenplays featuring Honor Blackman, and one of the later episodes, A Sense Of History (1966), inspired by a vision of Diana Rigg dressed as Maid Marian.\n\"If anyone wonders how the stories for The Avengers were conceived, this is the answer,\" Woodhouse explained. \"Having decided that Ms Rigg would look charming as Maid Marian, the only question was how to build a plot in which it might be plausible for her to appear thus. Such a sideways approach might, I dare say, result in stories which are a trifle far-fetched, but there you go.\"\nAs a novelist, Woodhouse's writing was characterised by dry, humorous prose, with protagonists who tended to be intelligent, sarcastic, and unimpressed by authority figures. Many of his books are filled with details that reflect his background in engineering and medicine.\nHis Medici series, co-written with Robert Ross, comprised three novels about the fictional antics of Leonardo da Vinci while he worked as a military engineer in the service of the Duke of Milan. In The Medici Guns (1974), The Medici Emerald (1976) and The Medici Hawks (1978) Leonardo is depicted as a clever Italian Renaissance engineer who doubts the supremacy of the Catholic Church.\nMartin Charlton Woodhouse was born in Romford on August 29 1932. Educated at Salisbury Cathedral School and Oundle, he read Natural Sciences at Downing College, Cambridge, and Medicine at St Mary's Hospital Paddington, completing his postgraduate research at the Medical Research Council's applied psychology unit in Cambridge.\nThere he built \"Lettuce\", a logical truth computer, with the intention of comparing machine intelligence with that of the human brain.\nIn 1959 he was called up for National Service and worked with the RAF at the Institute of Aviation Medicine, and then at the Farnborough radar research establishment, where he helped to lead research into computer-aided low-level flight, heads-up instrument displays and computerbased targeting for the Bloodhound guided missile system.\nAt the start of 1960 he was set to rejoin the applied psychology unit in Cambridge with a view to working on artificial intelligence, when he received a call from his younger brother, Hugh, asking him if he would like to help write 26 half-hour episodes for the children's television puppet series Supercar.\nThe screenplays had to be written at the rate of one every week, for six months. Hugh pointed out that no single writer could undertake such a workload and asked his brother if he would like to join him as soon as he had handed in his uniform. Over the next 15 years Woodhouse went on to write more than 70 film and television scripts.\nIn 1966 he was invited to Hollywood by 20th Century Fox to work on a screenplay for Tree Frog. He played cards with Paul Newman and Lee Marvin, and guitar with Tim Buckley on Malibu beach, but the film was never made.\nWoodhouse then moved to the West Indies, working in Grenada and Montserrat. In 1969 he wrote a \"Five-year Commercial Development Plan\" for Grenada's government and set up several enterprises in the West Indies, including a quarrying and demolition company, a perfume-oil distillery, a waterfront bar and restaurant, a solar distillation plant, and a non-profit rural clinic in Montserrat. He returned to Britain in 1974.\nFrom 1976 to 1982 Woodhouse returned to his interests in computing. He worked with early micros, including the Apple II, studying artificial intelligence. He also wrote computer programs to manage his own perfumery and cosmetics business in Dorset - where all the creams were manufactured with a food blender.\nBetween 1984 and 1986 he created a computer system for Handelskreditbank, Zurich, which ran an online dealing room for commodity and financial futures via brokerage houses in London and Switzerland. He also wrote \"Prophet\", a financial analysis program. Later, he pursued computer programming work for IBM and developed theories about the scientific proofs for God.\nMartin Woodhouse, who died on May 15, married, in 1970, Penny Stallings, with whom he had a son and a daughter. They divorced in 1982. She and their children survive him, as does Brenda Woodford, his partner of nearly 30 years.\n"},
{"docid": "109 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "November 14, 2017", "title": "Killer robots are almost a reality and need to be banned, warns leading AI scientist\n", "content": "The technology to create killer robots is already here and needs to be banned, a leading artificial intelligence scientist has warned. Stuart Russell, a professor of computer science at Berkeley University, California, said \"allowing machines to choose to kill humans\" would be \"devastating\" for world peace and security.\nThe professor, who has worked in the field of artificial intelligence (AI) for more than 35 years, also warned that the window to ban lethal robots was \"closing fast\".\u00a0\nHis warning comes as campaigners are making the case at the United Nations (UN) this week for a global prohibition on lethal autonomous weapons systems.\nYesterday the pressure group, the Campaign to Stop Killer Robots, showed a short film it produced to a meeting of countries participating in the Convention on Conventional Weapons, which painted a dystopian scenario based on existing technologies.\nThe video, entitled 'Slaughterbots', starts with an enthusiastic CEO on stage unveiling a new product to an excited crowd. Instead of a new smartphone of consumer tech innovation, he reveals a miniturised drone that uses facial recognition to identify its target before administering a small yet lethal explosive blast to the skull.\nThe nameless CEO boasts: \"A $25 million order now buys this, enough to kill half a city - the bad half. Nuclear is obsolete, take out your entire enemy virtually risk-free. Just characterise him, release the swarm and rest easy.\"\nHowever the film shows the weapons quickly falling into the hands of terrorists who use them to slaughter politicians and a classroom of\u00a0students.\nProfessor Russell said: \"This short film is more than just speculation, it shows the results of integrating and minturising technologies that we already have.\n\"[AI's] potential to benefit humanity is enormous, even in defence. But allowing machines to choose to kill humans will be devastating to our security and freedom - thousands of my fellow researchers agree. \u00a0\n\"We have an opportunity to prevent the future you just saw, but the window to act is closing fast\".\nMore than 70 countries participating in the\u00a0Convention on Conventional Weapons have been meeting in Geneva this week to discuss a potential worldwide ban on lethal robots.\nThe technology to create robots that can kill autonomously is already here, experts have warnedCredit:      Killer Robots AI UN\u00a0     \nThe convention has already prohibited weapons such as blinding lasers before they were widely acquired or used.\nAutonomous weapons that have a degree of human control, such as drones, are already used by the militaries of advanced countries such as the UK, US, Israel and China.\nThe Campaign to Stop Killer Robots is arguing that modern low-cost sensors and recent advances in artificial intelligence have made it possible to design a weapons system that could attack and kill without human control.\nJody Williams, a 1997 Nobel Peace Laureate and co-founder of the campaign, said: \"To avoid a future where machines select and attack targets without further human intervention, countries must draw the line against unchecked autonomy in weapon systems.\n\"With adequate political will, governments can negotiate an international treaty and ban killer robots-fully autonomous weapons- within two years time.\"\nTechnology billionaire Elon Musk has warned of the dangers of AICredit:      Reuters/Aaron Bernstein     \nThe pressure group's concerns echo those voiced by technology billionaire, Elon Musk, earlier this year.\nIn July the entrepreneur behind companies such as Tesla and SpaceX described AI as the \"biggest risk we face as a civilisation\" and warned that it needed to be regulated before \"people see robots go down the street killing people\".\n"},
{"docid": "110 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "June 23, 2016", "title": "We can't deny robots their humanoid rights\n", "content": "The last time the government embarked on a serious overhaul of its labour laws, the country was blazing with the fires and unrest of the first industrial revolution.\nNow it may be on the brink of extending basic workers' rights to robots at the dawn of a very different age. As artificial intelligence begins to vie with humans for jobs everywhere from factory floors to solicitors' chambers, the EU is to vote on controversial plans to declare autonomous robots \"electronic persons\".\nThe most advanced of these machines should be free to own, to trade money and to claim copyright on their work, and their human owners must pay into a social insurance fund against any damage they might cause, according to a draft report from the European Parliament's legal affairs committee.\u00a0\nThe MEPs have called on all the EU's member states, including Britain, to consider giving citizens a guaranteed universal basic income to protect them against the mass unemployment that could be driven by automation.\nThe science of robotics is moving swiftly towards a point where the most sophisticated devices will no longer be simple \"tools\" but agents in their own right, capable of teaching themselves, roaming around and choosing which customers to offer their services to, the report states.\nThis threatens to open up a spectacular legal can of worms: what happens if a self-directing robot surgeon goes rogue and hooks up a patient's brain to her kidney? What if an AI financial adviser tells a person with dementia to plough their life savings into junk bonds? The answer, the MEPs say, is to give the machines a legal responsibility comparable to that of subsidiary companies. Their owners should be obliged to pay premiums into a state fund to cover the cost of any harm, as well as reporting in their financial results what proportion of their income stems from robotics and AI.\n\"From Mary Shelley's Frankenstein's monster to the classical myth of Pygmalion, through the story of Prague's golem to the robot of Karel Capek, who coined the word, people have fantasized about the possibility of building intelligent machines,\" the MEPs wrote.\n\"Now that humankind stands on the threshold of an era when ever more sophisticated robots, bots, androids and other manifestations of artificial intelligence seem poised to unleash a new industrial revolution, which is likely to leave no stratum of society untouched, it is vitally important for the legislature to consider all its implications.\"\nThe report says that these advances could bring about \"virtually unbounded prosperity\" but could undermine the entire basis of the welfare state if too many people are made unemployed. It warns that within a few decades AI could become so powerful that it could challenge humanity's \"capacity to be in charge of its own destiny and to ensure the survival of the species\".\nMady Delvaux, the socialist MEP from Luxembourg, who led the work, said that MEPs would vote on the plans at some point over the next 12 months, and if the motion was passed it would then be up to the EU civil service and council of ministers to draw up the proposed laws. \"This is a new world that we see arriving,\" she said.\nNoel Sharkey, professor of artificial intelligence at the University of Sheffield, said that the proposals were a first step towards civil rules for robotics but that he was uneasy about holding robots responsible for their actions. The discussion of digital personhood and sentience belongs more in sci-fi than in an EU document,\" he said. \"It is easy to be anthropomorphic about robots and follow fictional tropes. But it is imperative that legislation treats robots as inanimate artefacts unless the actual facts suggest otherwise.\"\n"},
{"docid": "111 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "January 29, 2016", "title": "Robots could exterminate the middle class; They don't call in sick, get tired or waste time chatting. And if you think your white collar Job is safe, think again\n", "content": "There is an algorithm called Alice (Artificial Linguistic Internet Computer Entity) which holds out the pleasing prospect that, one day, columns like this will be written by a robot. They already have the visual sophistication to select and stack boxes. The next frontier, a simulation of reflective intelligence, promises mass unemployment. A spectre is haunting capitalism. In the technology sessions in Davos last week and the Digital-Life-Design conference in Munich the week before stalks the anxiety that capitalism is about to consume itself.\nThis is the real Google story of the week. Their tax contribution to Britain is derisory and they ought to feel a sensation to which they are strangers, namely shame. But Google offers a greater threat to the tax base than its ingenious shifting of funds offshore. The vast bulk of corporate taxation is not the proceeds on corporation tax but various imposts paid by employees. In The Rise Of The Robots, the Silicon Valley tech entrepreneur Martin Ford says that catastrophe is conceivable. The more sophisticated the merger between computing capacity and vast archives of data, the greater the likelihood that robots perform jobs as varied as radiology in hospitals, refurbishing stock in supermarkets, driving planes, trains and automobiles, defusing bombs and serving drinkers in bars. In economies based on consumer spending, mass unemployment heralds the end of days.\u00a0\nThe tech companies are engaged in the equivalent of a geeky space race. On Wednesday Facebook announced that its artificial intelligence project was getting to the point where it could beat a human at the complex Chinese board game Go. Yesterday, Google declared that its program had beaten Fan Hui, the European champion, five-nil. The software that plays Go relies on pattern recognition and, with the capacity to run a procedure millions of times at great speed, is capable of gradually incorporating, and therefore eliminating, its errors.\nThis means robots are useful in, for example, manufacturing, assembly, packing and packaging, earth and space exploration, surgery, weaponry, laboratory research and the mass production of consumer goods. That's not all, though. Robots are now flying, swimming, sailing, driving cars and going away for the weekend together. The really dangerous skill, though, is exactly the kind of complicatedly repetitive event at which artificial intelligence will defeat its sentient counterpart, by which I mean you and me.\nThe first decade of the 20th century, in the US and UK, has passed with the net creation of no new jobs. Opportunities in novel industries, such as computing, are not keeping pace with the destruction in employment caused by the same. A recent report by Deloitte suggested that, within two decades, 60 per cent of today's jobs in retail could be automated. Almost three quarters of the jobs in transport could easily be done by simple machines or complex robots, and automation in factories, already extensive, will continue apace. That would mean 11 million people put out of work. Andrew Haldane, chief economist at the Bank of England, warned last year that middle-income jobs could be \"hollowed out\" by machines, leaving only low-paid and high-paid jobs behind.\nThis has been plain in the US for some www.time.No small part of the disillusionment with politics that is so evident in the dreadful presidential run is the following fact: since 1973 productivity has risen in the US by 107 per cent. Though the costs of housing, education and healthcare have all risen, a typical production worker now earns 13 per cent less, adjusted for inflation, than he did then. There is no single cause of this but mechanisation is a major part and it has only just begun.\nSince 2011, Google has been buying up robotics companies and seeking to advance the techniques of artificial\u00a0intelligence. It owns Cheetah the fastest robot in the world, a solar-powered drone that can stay in the air for five years, the Motoman who is a demon at loading and unloading trucks, the Schaft that can climb ladders, and Spot the robot dog which alerts Marines to danger.\nSince the invention of the integrated circuit in 1958 computing power has doubled 27 times.\nPrevious waves of technological innovation attacked industries one by one which meant the economy could diversify and see off the threat. The next revolution in information technology could be different as it attacks almost all industries at the same time. Any employee whose work is at all predictable is now coming within the sight of the robots (bad news for Jeremy Corbyn there).\nHowever, before we all scare ourselves into resignation, there are two caveats. The first is that the intelligence is only artificial. In 2012, it took 16,000 computers frantically mimicking brain activity to recognise a cat. I have known some pretty stupid people in my time but almost none of them would have any trouble recognising a cat. During proceedings for the 2015 Loebner Prize, awarded to any computer that fooled the judges into thinking it was human, an award went to software which replied to the question: \"The car could not fit in the parking space because it was too small. What was too small?\" by saying, brilliantly \"I'm not a walking encyclopedia, you know\". In a word, robots struggle to adapt. The independent mechanical spirits of Isaac Asimov's I, Robot remains a science fiction www.fantasy.No doubt human ingenuity has never had a tougher assignment but that is not to say we are not up to it.\nBesides, even if the predictions of job losses are halfway true we still have the ingenuity to cope. Bear in mind that it is not prosperity that will be lost. Robots simply distribute the rewards differently. Machinery is traditionally thought of as capital but robots blur the line. They are machines but they are doing the labour, no doubt with great www.efficiency.No robot will ever call in sick or go on strike or get tired or waste time chatting. Productivity will rise but all the rewards will go to the owners of capital. Advanced societies, and here China will rapidly figure, will be home to a squalid class of the destitute, a middle class dependent on philanthropy and a wildly wealthy plutocracy. Look what you've gone and done now, Google.\nWe can choose a different path, even if the science turns out not to be fiction. The tip-off is in the very word \"robot\" which was coined by the Czech writer Karel Capek in his 1920 play R.U.R. (Rossum's Universal Robots). The neologism \"robot\" came from robota, the Slavic word for labour. An ordered society will therefore be one in which we all have an entitlement to a robot. The old Tory dream of the property-owning democracy will suddenly become not just a hope but an imperative. As long as I live at home with a robot I don't mind if Alice writes this column.\nProductivity will rise but all rewards will go to the owners of capital\n"},
{"docid": "112 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "December 6, 2017", "title": "Entire human chess knowledge learned and surpassed by DeepMind's AlphaZero in four hours\u00a0\n", "content": "Hundreds of years of chess knowledge was learned and then surpassed by Google DeepMind's artificial intelligence algorithm in just four hours, it has emerged.\nThe astonishing programme AlphaZero quickly mastered the ancient game, before coming up with completely new strategies, which are now being analysed by grandmasters.\u00a0\nThe algorithm is so extraordinary because it learns from scratch. It has only been programmed with the rules of chess and must work out how to win simply from playing multiple games against itself. \u00a0\nWhen IBM's supercomputer Deep Blue beat Gary Kasparov in 1997, it was because it had been programmed with the best moves. But AlphaZero has learned completely on its own.\nGary Kasparov playing against Deep BlueCredit:      \u00a0Rex Features     \nThe English grandmaster Simon Williams, who runs the GingerGM site,\u00a0said that the achievement  was 'one for the history books.'\n\"On the 6th of December, 2017, AlphaZero took over the chess world,\" he said.\n\"AlphaZero and DeepMind then went on to dominate chess, eventually solving the game and finally enslaving the human race as pets.\"\nDavid Kramaley, who runs chess education site Chessable, added : \"We now know who our new overlord is.\n\"The games AlphaZero played show it can calculate some incredibly creative positional bombs, the depth of which are far beyond anything humans or chess computers have come up with.\n\"It will no doubt revolutionise the game, but think about how this could be applied outside chess. This algorithm could run cities, continents, universes.\"\nChinese Go player Ke Jie competes against Google's artificial intelligence (AI) program, AlphaGoCredit:      Rex Features     \nJon Ludvig Hammer, the Norwegian grandmaster, described AlphaZero's strategy as 'insane attacking chess' which was coupled with 'profound' positional play.\nThe DeepMind team eventually want to use the algorithm to solve big health problems. They believe that the programme could come up with cures for major illness in a matter of days or weeks, which would have taken humans hundreds of years to find. \u00a0\nThe company has already begun using AlphaZero to study protein folding and has promised it will soon publish new findings.\nMisfolded proteins are responsible for many devastating diseases, including Alzheimer's, Parkinson's and cystic fibrosis.\nThe latest achievement was published online on the site arXiv .\n"},
{"docid": "113 of 297 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "January 5, 2016", "title": "Zuckerberg plans to build AI 'butler' to run his home\n", "content": "MARK ZUCKERBERG plans to build himself an artificially intelligent butler similar to one that appears in the Iron Man superhero films.\nThe Facebook chief executive said the creation of the system would be his personal challenge for 2016.\u00a0\nHe aims to teach it to recognise his voice and control everything in his California home including music, lights and heating.\nThe system will also be programmed to report any problems in the room of his one-month-old daughter Max.\nMr Zuckerberg said: \"My personal challenge for 2016 is to build a simple AI to run my home and help me with my work. You can think of it kind of like Jarvis in Iron Man. This should be a fun intellectual challenge to code this for myself.\n\"I'll teach it to let me know if anything is going on in Max's room that I need to check on when I'm not with her. I'll teach it to let friends in by looking at their faces when they ring the doorbell.\"\nThe Iron Man films feature Jarvis which stands for Just A Rather Very Intelligent System, a highly advanced form of artificial intelligence that manages almost everything in the life of the main character Tony Stark, a genius engineer played by Robert Downey Jr. The system is voiced by Paul Bettany, the British actor.\nElon Musk, another California technology billionaire, has previously been described as the the \"real-life Tony Stark\" rather than MrZuckerberg.\nMr Musk founded the space company SpaceX, and electric car maker Tesla, but recently warned against the proliferation of artificial intelligence systems saying they were \"potentially more dangerous than nukes\".\nMr Zuckerberg sets himself a new personal challenge at the start of each year.\nHis previous challenges have included learning Mandarin, eating only meat he killed himself, reading two books a month, and meeting a new person every day.\n'This should be a fun intellectual challenge to code this for myself. Like Jarvis in Iron Man'\n"},
{"docid": "114 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "January 9, 2018", "title": "Who's a clever toy? Dogs go digital\n", "content": "CES in Las Vegas is the tech industry's biggest showcase for the latest gadgets and trends, attracting nearly 200,000 visitors over four days. It is known for its mix of serious and nutty devices and early highlights included:\nROBOTS TO BEFRIEND YOUR DOG\u00a0\nPreviously if your dog was lonely, you would buy him a canine companion or spend more time with him. In 2018 you can buy a robot friend-cum-surveillance device to monitor him while you are away.\nThe La\u00efka robot resembles a small, trundling plastic barrel, equipped with a camera, microphone and \"treat-tosser\". This \u00a3220 chew-proof machine will help to look after your pet while you're away, allowing you to see him, talk to him and dole out treats. You can control it using a mobile app, or put it into autonomous mode when you're busy. It is paired with a tracker on the dog's collar and endeavours to keep him entertained by following him around, playing games. It is powered by artificial intelligence and, according to creators, the French start-up Camtoy, the algorithm adapts to your dog's personality, learning what's best at keeping him stimulated.\nMeanwhile, California startup Anthouse's robotic dog companion Buddy+ resembles a small tank equipped with a tennis ball launcher for games of fetch. The company behind Petcube, a treat-dispensing connected camera, has new pet-detection technology that uses artificial intelligence to \"recognise pets, trigger recording of pet selfie videos and initiate two-way video calls\".\nGADGETS FOR WINE LOVERS\nFrench entrepreneurs have been shaking off the stereotype that their country is too traditionalist about wines.\nThe Caveasy One claims to be the first smart wine rack. The connected device can fit any cellar but the standard pack holds 100 bottles on 20 shelves and costs (EURO)594. It includes sensors to monitor the temperature and humidity of the cellar. You take a photo of each bottle's label on your phone and the app checks the wine against a database. Once the wine is in the rack, the app alerts you when it reaches its peak and a light in that bottle's slot is illuminated. It also offers recommendations for purchases and can suggest food pairings.\nAnother French device, the $200 Aveine pouring gadget, starts with the same label-scanning principle and claims to offer the perfect degree of aeration for each bottle instantly. Once you've taken a picture of the bottle with your phone, you insert the paired device over the bottle's mouth and pour.\nThe Coravin device has had a \"smart\" makeover.\nIt passes a thin needle through the cork of a bottle, and allows you to pour wine, replace the lost volume with inert gas and reseal the bottle as if it had never been opened. The $1,000 Coravin Model Eleven works with an app that recommends pairings for individual bottles and provides \"cheatsheets\" of what to say to wine merchants to secure the best bottles.\nSHORT STORY MACHINE\nThe creators of a machine that dispenses short stories on strips of receipt-style paper at railway stations, airports and university campuses are hoping to bring the devices to Britain.\nThe French founders of the Short Edition project say the free tales, dispensed as one, three and five-minute reads at the push of three buttons, appeal to those who value the escapism of putting their phones and tablets down and reading something they can physically hold. The stories, which are issued at random from a database of about 5,000, include some classic literature but are mostly the work of contemporary writers. The devices are already popular at stations in France.\nAIRBAGS TO PROTECT FROM FALLS\nA belt for the elderly that deploys airbags to protect their hips in a fall was one of the most attention-grabbing exhibits, as reporters and volunteers took tumbles to check that it worked. It did.\nHelite, the manufacturers of the $800 Hip'Air device, claim that it will absorb 90 per cent of the impact whereas ordinary hip protectors, which resemble padded underwear, absorb only about 10 per cent. The belt is lightweight and fairly slim before the bags are deployed.\nAccording to the makers, a typical fall takes 400 milliseconds. Using built-in gyroscopes and accelerometers, the belt can detect one within 200 milliseconds of it starting. It then deploys two airbags, which takes 80 milliseconds. It will be available from March.\nWEARABLE TECH TO WARD OFF SUN\nL'Or\u00e9al has a device stuck on the thumbnail that monitors how much UV light the wearer has been exposed to and provides advice. It is supposed to encourage \"sun-safe behaviour such as reapplying sunscreen or moving into the shade\". UV Sense can provide realtime information and store up to three months of data, showing trends. It is less than 2mm thick and 9mm in diameter. The thumbnail is the best place to measure sunlight, L'Or\u00e9al says.\nOnce you've taken a multiple-choice test on your individual skin type, the app will give you a running score to tell you if you're spending too much time in the sun. It will also recommend L'Or\u00e9al sun-care products for you. The gadget will be sold in the US this year and Britain next year for under $50.\nSMART SHOWERS\nAlexa may soon be joining you in the shower. At least two smart showers from the Elmer and Moen brands are compatible with Amazon's voice assistant, meaning users can address the artificial voice to ask her to start running the water or turn up the temperature. Rather than fumbling with tap fittings people will be able to say \"Alexa, stop\" before stepping out of the shower.\nHip protector belt\nHow it works Inlator\n1 Sensor detects when person is falling and triggers inlator\n2 Inlated airbag instantly cushions fall\nHip protector belt How it works Sensor Inlator Folded airbag 1 Sensor detects when person is falling and triggers inlator 2 Inlated airbag instantly cushions fall\n"},
{"docid": "115 of 297 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "September 22, 1988", "title": "Computer Guardian (Micromaths): Bee brain goal for neural networks\n", "content": "\u00a0\n Reports and rumours put the figure anywhere between Dollars 100 million and Dollars 1 billion. But whatever, the final figure turns out to be, there now seems to be little doubt that the American Defence Advanced Research Projects Agency (Darpa) is about to inject a huge amount of hard cash into basic research in neural network computing. Perhaps too much for its own good, given the past history of artificial intelligence funding.\n\u00a0Artificial intelligence is the part of computer science that attempts to build computer systems that exhibit features of intelligence normally only found in humans and higher animal forms (from about the level of a bee upwards).\u00a0\n\n Traditional approaches to this problem attempt to codify rules of intelligent behaviour using mathematical logic, leading to 'intelligent' programs running on conventional computers. Despite some very real successes with this approach (see, for example, Micromaths, July 28), it has not led to a single system that really justifies the adjective 'intelligent'.\n Unfortunately, a mixture of hype, overconfidence, and over-funding in the early days led to a sense of disillusionment when results failed to live up to the promise. The real advances that were made fell so far short of the glittering prizes, that for a while artificial intelligence took on a very tarnished look.\n But advances there have been, and perhaps more than ought to be expected, given the magnitude of the task. It is, after all, only 30 years since the subject was born, and that is a mere instant in the history of scientific development.\n One irony is that, so far, the greatest success has been achieved in those areas of intelligence that humans find the most difficult, such as chess playing, medical diagnosis and designing complex electronic circuitry. These are all domains in which traditional artificial intelligence techniques have made genuine advances. But tasks such as recognising a sketch of Snoopy as a dog, or understanding everyday speech - tasks that humans take for granted - have proved far harder to crack.\n For many years, a small but stubborn group of workers in the field pursued a different line of attack on such 'every-day' problems. Traditional techniques were bound to fail on such problems, this group argued, because by their very nature, tasks such as picture or speech recognition are not based on the following of logical rules, but rather they are what might be termed 'instinctive skills'. In plain language, people just do them. Therefore, the argument went, attempts to accomplish such tasks by writing a programme to run on a traditional computer were bound to fail. It would be far better to start again with a quite different form of computer, one organised not along the lines of mathematical logic (as traditional computers are) but one that takes as its model the human brain.\n This incredible organism, far smaller and lighter than the supercomputers that it can so easily outperform when it comes to telling a cat from a dog, achieves its sophistication by means of a vast number of relatively simple computing devices (neurons) all interconnected in a highly complex fashion, and all operating and communicating with one another simultaneously.\n Thinking of the brain as some form of computer, the 'program' that guides its behaviour consists not of a series of instructions stored some-where in memory, but rather is embodied in the exact pattern of the interneural connections. 'Programming' such a device entails modifying these inter-connections in an appropriate fashion. This is the process we usually refer to as learning.\n Normally, it takes considerable time and effort to make such modifications, which is why we find it so hard to learn a new skill or a new language. The process is not one of programming, but rather of training, constantly repeating whatever it is to be learnt until the required brain modifications have been made.\n This idea of a large number of very basic computing elements, all interconnected in a fashion that allows for constant modification, forms the starting point for a quite new form of computer, the so-called 'neural network' or PDP (parallel distributed processing) computer.\n Following hot on the heels of some dramatic research results (see, for example, Micromaths, January 21), this approach to AI, after languishing on the sidelines of the field for a long time, has suddenly found itself thrust into the spotlight, making household names of workers who for years had pursued this line in small groups working on shoestring budgets.\n Neural network computers - which for the most part, still only exist as stimulations running on conventional computers - are not programmed in the traditional sense. Rather they are taught, or trained, to perform whatever task is required of them, by means of a repetitive cycle of instruction involving what for the computer system amounts to punishment and reward.\n This approach can lead to some interesting and encouraging results, but those of us who have watched the rise and fall (and now, we hope, the less-hyped re-rise) of traditional artificial intelligence, cannot help but suspect that the new wave of frantic interest in neural network computers can only lead to tears and disappointment.\n Again, the danger is that when the reality fails to match the vaunted goals, the reaction will mask what real gains have been made.\n The name 'artificial intelligence' has proved to be as much a curse as a blessing, since nothing artificial is likely to come close to human intelligence. Likewise the title 'neural network computing' might also come to be regarded as something of a millstone, since however successful such computing devices prove to be, they are not going to achieve anything like the sophistication of the human brain.\n What of the bee? Well, in mentioning it in connection with the announcement of their new funding initiative, Darpa might just have set the goal about right. But be prepared to see this particular goal start to recede beyond the eight year period the new funding is supposed to cover.\n"},
{"docid": "116 of 297 DOCUMENTS\n", "source": "MAIL ON SUNDAY (London)\n", "date": "June 5, 2016", "title": "IT'S MAN VERSUS MACHINE IN THE BATTLE OF THE DOCTORS\n", "content": "THE world's first artificial intelligence' doctor will be pitted against the real thing this week, in a head-to-head contest that could mark a turning point in medicine.\u00a0\nBritish start-up firm Babylon Health will test its programme, called Check, against a doctor and nurse in a competition to see which can deal most quickly and accurately with a range of common health problems.\nThe smartphone app has been designed to act like a triage nurse, asking a series of questions to advise users whether their problem is nothing to worry about, something they should consult their GP about, or a matter that requires calling 999. It does not give a formal diagnosis.\nIts developers, who believe AI will transform medicine in the coming years, said last night they were 100 per cent confident' their app would come out on top. Babylon Health boss Ali Parsa said Check could analyse thousands of problems with astounding precision. It is more accurate than any human, just as a computer weather forecast is now more accurate than any human,' he said.\nThe algorithm was developed with the help of more than 100 doctors, who repeatedly tested it and, so far, could not fault it.\nCheck will not make the final step of giving a formal diagnosis, although Babylon, which is particularly keen to push into parts of the developing world where people often have difficulty seeing a doctor or a nurse, is not ruling that out for the future.\nSteve Hamblin, head of Babylon's artificial intelligence team, said: As for replacing doctors, that's not our goal. I'm not in the business of putting a doctor out of business. I'm in the business of giving them a boost.'\n\u00a9 Mail On Sunday\n"},
{"docid": "117 of 297 DOCUMENTS\n", "source": "The Sunday Telegraph (London)\n", "date": "August 13, 2017", "title": "Hidden stars of the second tech revolution; We all know Apple and Google, but could these lesser-known 'enablers' produce better returns? James Connington reports\n", "content": "The idea of investing in technology companies will, for many, bring back painful memories of the tech bubble bursting at the turn of the millennium. Today, there is little of the mania of two decades ago, and tech firms are making profits - which were conspicuously absent the first time around.\nSome investors will have exposure to technology through firms such as Amazon, Facebook and Google, which are popular holdings in many funds available to British savers. But there is another approach: investing in companies that make \"enabling\" technology, the components and software used in many of the most advanced developments.\u00a0\nTelegraph Money asked a number of technology fund managers to name some of their favourite stocks. There are very few quoted technology firms in Britain, so many of the stocks discussed here are listed overseas.\nA number of investment shops offer international share dealing, although not all do so within an Isa. You may need to fill in special forms before you trade.\nDriverless vehicles Driverless cars are estimated to be just five years away, depending on technology and regulation. This would dramatically increase the market for the components required. For now, much of the growth comes from \"advanced driver assistance systems\" such as automatic braking.\nInfineon Technologies (German listed) Market value: \u00a319.5bn; last year's pre-tax profits: \u00a3763m This semiconductor firm was tipped by all of the technology fund managers we spoke to. It makes components used in systems such as emergency braking and battery management.\nHyunho Sohn, manager of the Fidelity Global Technology fund, said: \"Infineon exemplifies a company poised to gain from the move to electric and autonomous cars.\n\"It has a market-leading position and, as the technology going into each vehicle increases, it should see rises in sales and margins.\"\nArtificial intelligence and machine learning The concept of artificial intelligence (AI) - the ability of a computer system to learn and adapt - has existed for decades. Ben Rogoff, manager of two Polar Capital technology funds totalling \u00a32.5bn, explained that, as with any technology, AI started out as a promise with no means of delivery.\n\"Today, it feels like we have that capability. Right now the applications are straightforward, such as facial recognition and improving search results, but they will expand,\" he said.\nNvidia (US listed) Market value: \u00a375bn; profits: \u00a31.9bn Nvidia, tipped by several managers, could fall into a number of our categories. Its graphics processing units (GPUs) are becoming increasingly important for \"vision systems\" in autonomous cars, according to Mr Rogoff.\nHe said AI offered another avenue for expansion, as GPUs could be used to \"train\" AI networks. \"This is what makes AI intelligent - the ability of the network to improve by looking at its past mistakes. Nvidia is the best way to play this theme,\" he said.\nBlue Prism (UK listed) Market value: \u00a3578m; \u00a35m loss This firm makes software \"robots\" that automate tasks to create a socalled \"digital workforce\". Chris Ford, manager of Smith & Williamson's new Artificial Intelligence fund, said it was \"one of the very few pure AI firms anywhere\". He added: \"It could fall into the 'undiscovered gems' camp, despite recent share price gains. We think this technology will become ubiquitous for financial firms to reduce cost and improve accuracy.\"\nMachine vision Cognex (US listed) Market value: \u00a36.7bn; profits: \u00a3161m Cognex makes \"machine vision\" systems used to scan and check products or labels. Tom Riley, manager of Axa's Global Technology fund, said the technology was gaining ground, with \"more manufacturing applications\" and increasing use in logistics.\nMr Rogoff said: \"We're pretty sure Apple and Amazon are customers.\"\n"},
{"docid": "118 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "June 29, 2015", "title": "Threat from Artificial Intelligence not just Hollywood fantasy; Oxford academic Dr Stuart Armstrong warns humanity runs the risk of creating super intelligent computers that eventually destroy us all\n", "content": "From the dystopian writings of Aldous Huxley and HG Wells to the sinister and apocalyptic vision of modern Hollywood blockbusters, the rise of the machines has long terrified mankind. \nBut it now seems that the brave new world of science-fiction could become all too real. \nAn Oxford academic is warning that humanity runs the risk of creating super intelligent computers that eventually destroy us all, even when specifically instructed not to harm people. \u00a0\nDr Stuart Armstrong, of the Future of Humanity Institute at Oxford University, has predicted a future where machines run by artificial intelligence become so indispensable in human lives they eventually make us redundant and take over. \nAnd he says his alarming vision could happen as soon as the next few decades. \nDr Armstrong said: \"Humans steer the future not because we're the strongest or the fastest, but because we're the smartest. \n\"When machines become smarter than humans, we'll be handing them the steering wheel.\"\nHe spoke as films and TV dramas such as Channel 4's Humans and Ex-Machina, - which both explore the blurred lines between man and robot - have once again tapped into man's fear of creating a machine that will eventually come to dominate him. \nDr Armstrong envisages machines capable of harnessing such large amounts of computing power, and at speeds inconceivable to the human brain, that they will eventually create global networks with each other - communicating without human interference. \nIt is at that point that what is called Artificial General Intelligence (AGI) - in contrast to computers that carry out specific, limited, tasks, such as driverless cars - will be able to take over entire transport systems, national economies, financial markets, healthcare systems and product distribution. \n\"Anything you can imagine the human race doing over the next 100 years there's the possibility AGI will do very, very fast,\" he said. \nBut while handing over mundane tasks to machines may initially appear attractive, it contains within it the seeds of our own destruction. \nIn attempting to limit the powers of such super AGIs mankind could unwittingly be signing its own death warrant. \nIndeed, Dr Armstrong warns that the seemingly benign instruction to an AGI to \"prevent human suffering\", could logically be interpreted by a super computer as \"kill all humans\", thereby ending suffering all together. \nFurthermore, an instruction such as \"keep humans safe and happy\", could be translated by the remorseless digital logic of a machine as \"entomb everyone in concrete coffins on heroin drips\". \nWhile that may sound far fetched, Dr Armstrong says the risk is not so low that it can be ignored. \n\"There is a risk of this kind of pernicious behaviour by a AI,\" he said, pointing out that the nuances of human language make it all too easily liable to misinterpretation by a computer. \"You can give AI controls, and it will be under the controls it was given. But these may not be the controls that were meant.\"\nDr Armstrong, who was speaking at a debate on artificial intelligence organised in London by the technology research firm Gartner, warns that it will be difficult to tell whether a machine is developing in a benign or deadly direction. \nHe says an AI would always appear to act in a way that was beneficial to humanity, making itself useful and indispensable - much like the iPhone's Siri, which answers questions and performs simple organisational tasks - until the moment it could logically take over all functions. \n\"As AIs get more powerful anything that is solvable by cognitive processes, such as ill health, cancer, depression, boredom, becomes solvable,\" he says. \"And we are almost at the point of generating an AI that is as intelligent as humans.\"\nDr Armstrong says mankind is now involved in a race to create 'safe AI' before it is too late. \n\"Plans for safe AI must be developed before the first dangerous AI is created,\" he writes in his book Smarter Than Us: The Rise of Machine Intelligence. \"The software industry is worth many billions of dollars, and much effort is being devoted to new AI technologies. \"Plans to slow down this rate of development seem unrealistic. So we have to race toward the distant destination of safe AI and get there fast, outrunning the progress of the computer industry.\"\nOne solution to the dangers of untrammelled AI suggested by industry experts and researchers is to teach super computers a moral code. \nUnfortunately, Dr Armstrong points out, mankind has spent thousands of years debating morality and ethical behaviour without coming up with a simple set of instructions applicable in all circumstances which it can follow. \nImagine then, the difficulty in teaching a machine to make subtle distinctions between right and wrong. \n\"Humans are very hard to learn moral behaviour from,\" he says. \"They would make very bad role models for AIs.\"\n"},
{"docid": "119 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "February 16, 2008", "title": "Get ready for a scary new world of life-enriching robot implants\n", "content": "The advances are so rapid that one inventor says humanitywill be transformedby 2050, Mark Henderson reports from Boston\nArtificial\u00a0intelligence will match the human intellect within a couple of decades, according to an inventor who predicts a technological revolution in which intelligent \"nano-robots\" work inside the body to stave off ageing and enhance the capacity of our minds.\nRay Kurzweil, a software engineer and futurologist, said yesterday that technology was advancing at such a rate that it would transform the way people lived by the middle of the century, extending life spans, protecting against disease and even improving the biological hardware of the human body and brain.\u00a0\nMr Kurzweil, a member of a panel that published a report yesterday detailing the great engineering challenges of the 21st century, said that the rate at which science and technology moved forward was doubling every two decades. This suggests that there will be 32 times more technical progress over the next half-century than in the last.\nThe rapid rate of progress would lead to artificial intelligence (AI) matching, then surpassing, the power of the human mind, and to nanotechnology allowing this to be incorporated in machines that could fight disease and reverse the ageing process, he told the American Association for the Advancement of Science conference in Boston. Set to work in the brain, these nano-robots would produce virtual realities so compelling that they would match the real thing, and enhance human intelligence.\n\"Intelligent nano-robots will be deeply integrated in the environment, our bodies and our brains, providing vastly extended longevity, full-immersion virtual reality incorporating all the senses, experience 'beaming', and enhanced human intelligence,\" he said.\nThe ideas of Mr Kurzweil, who in the 1970s developed the first optical text recognition software for computers, are controversial among scientists and engineers. Many consider that he overstates the potential of technology to solve problems and enhance life, while underplaying the threats of issues such as global warming, emerging infectious diseases and overpopulation.\nHe is taken sufficiently seriously by his peers, however, to have been included on the panel of 18 leading engineers convened by the US National Academy of Engineering. The group, which published its report at the Boston meeting, also included Larry Page, the co-founder of Google, Craig Venter, the geneticist who is seeking to create synthetic life, and Lord Broers, former president of the Royal Academy of Engineering.\nIt stopped well short of endorsing Mr Kurzweil's visions, which will be set out this year in a film entitled The Singularity is Near: A True Story About the Future, focusing on the need for technology to address threats to humanity and the environment.\nThe priority for engineering, the report said, was to solve the energy crisis by harnassing the power of the Sun. \"Sunshine has long offered a tantalising source of environmentally friendly power, bathing the Earth with more energy each hour than the planet's population consumes in a year,\" it said. \"But capturing that power, converting it into useful forms, and especially storing it, poses provocative engineering challenges. Another popular proposal for long-term energy supplies is nuclear fusion, the artificial re-creation of the Sun's source of power on Earth. The quest for fusion has stretched the limits of engineering ingenuity, but hopeful developments suggest the goal of practical fusion power may yet be attainable.\"\nMr Kurzweil believes that this will be solved through nanotechnology. \"We only need to capture one part in 10,000 of the sunlight that falls on the Earth to meet 100 per cent of our energy needs,\" he said.\nThe report also highlighted the importance of developing carbon sequestration and storage systems to halt and even undo the climate damage caused by burning fossil fuels. Another key goal is improving access to clean water. Biomedical engineering should seek to develop technologies that enable personalised medicine.\nMr Kurzweil highlighted the importance of technologies such as gene therapy and RNA interference, which can correct genes and turn them on and off. \"Within one to two decades we will be in a position to stop and reverse the progression of ageing resulting in dramatic gains in health and longevity,\" he said.\nAlthough the panel acknowledged the potential of medical technology, it also pointed out that they were matched by threats such as pandemic flu. Another challenge will be to \"reverse-engineer\" the brain, which could lead to improvements in artificial intelligence of the sort Mr Kurzweil predicts. Once artificial intelligence matched the human mind, he said, \"it will then necessarily soar past it because of the continuing acceleration of information-based technologies, as well as the abilities of machines to instantly share their knowledge\".\n"},
{"docid": "120 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "November 30, 2016", "title": "Estee Lauder offers mascara in 60 minutes with Facebook Messenger bots\n", "content": "The Estee Lauder Companies are\u00a0to\u00a0become the first major retailer to launch on Facebook's Messenger service \u00a0in the UK.\nThe beauty company, which counts Kendall Jenner as its ambassador, is launching the mobile service along with a Christmas pop-up shop near its headquarters on Mortimer Street, London.\u00a0\nEstee Lauder says that the Messenger bot - which uses artificial intelligence to communicate with customers - will mean that shoppers can shop for their Christmas gifts and choose an instant courier within 60 minutes delivery across London.\u00a0\n\"Today's changing consumer behaviours mean that we have to adapt to the need for instant access to our products and services\" said Chris Good, president of Estee Lauder.\n\"For the time-poor consumer, convenience is the new luxury\", Mr Good added. \"We are constantly looking at new ways to provide greater choice and flexibility, trialling new features like Messenger alongside live chat and other existing digital offerings.\"\nEstee Lauder, which was founded in 1946, is looking for ways to revive flatlining sales of its core brands. The beauty brand has\u00a0been driven by acquisitions of Jo Malone, Mac, La Mer, Too Faced and Smashbox, which \u00a0are also popular with younger customers.\u00a0\nKendall Jenner appeals to millennials\nThe company recently created a \" millennial advisory board\" to inform the beauty business \u00a0about latest trends and set-up a formal reverse-mentoring programme, where young employees taught senior managers how to use social media, including Snapchat. \u00a0The UK is the company's second biggest market.\u00a0\nFacebook has been pushing the capabilities of its artificial intelligence Messenger chat bots as a way to make its service more useful than Apple's iMessage, Google's Allo and WhatsApp.\u00a0\nSix months after its initial launch, Facebook  recently added a\u00a0new feature that will make it easy for users to engage with businesses in Messenger . From today, when users click on an advert in their News Feed it could open a conversation in Messenger with the company. \u00a0\nEarly uses of the chatbot in the US have included the airline KLM and drinks maker Absolut. KLM has a bot that provides customers with their travel itineraries and boarding passes.\nWatch | A history of Facebook                         02:03\n"},
{"docid": "121 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "March 29, 2016", "title": "Microsoft 'deeply sorry' for racist and sexist tweets by AI chatbot; Company finally apologises after 'Tay' quickly learned to produce offensive posts, forcing the tech giant to shut it down after just 16 hours\n", "content": "Microsoft has said it is \"deeply sorry\" for the racist and sexist Twitter messages generated by the so-called chatbot it launched this week. \nThe company released an official apology after the artificial intelligence program went on an embarrassing tirade, likening feminism to cancer and suggesting the Holocaust did not happen.\u00a0\n Related:  Tay, Microsoft's AI chatbot, gets a crash course in racism from Twitter\n The bot, known as Tay, was designed to become \"smarter\" as more users interacted with it. Instead, it quickly learned to parrot a slew of anti-Semitic and other hateful invective that human Twitter users fed the program, forcing Microsoft Corp to shut it down on Thursday.\n Following the disastrous experiment, Microsoft initially only gave a terse statement, saying Tay was a \"learning machine\" and \"some of its responses are inappropriate and indicative of the types of interactions some people are having with it.\"\nBut the company on Friday admitted the experiment had gone badly wrong. It said in a blog post  it would revive Tay only if its engineers could find a way to prevent Web users from influencing the chatbot in ways that undermine the company's principles and values. \n \"We are deeply sorry for the unintended offensive and hurtful tweets from Tay, which do not represent who we are or what we stand for, nor how we designed Tay,\" wrote Peter Lee, Microsoft's vice president of research. \n Microsoft created Tay as an experiment to learn more about how artificial intelligence programs can engage with Web users in casual conversation. The project was designed to interact with and \"learn\" from the young generation of millennials.\n Tay began its short-lived Twitter tenure on Wednesday with a handful of innocuous tweets.\n Then its posts took a dark turn.\n In one typical example, Tay tweeted: \"feminism is cancer,\" in response to another Twitter user who had posted the same message.\n Lee, in the blog post, called web users' efforts to exert a malicious influence on the chatbot \"a coordinated attack by a subset of people.\"\n \"Although we had prepared for many types of abuses of the system, we had made a critical oversight for this specific attack,\" Lee wrote. \"As a result, Tay tweeted wildly inappropriate and reprehensible words and images.\"\nMicrosoft has deleted all but three of Tay's tweets.\n Microsoft has enjoyed better success with a chatbot called XiaoIce that the company launched in China in 2014. XiaoIce is used by about 40 million people and is known for \"delighting with its stories and conversations,\" according to Microsoft.\n As for Tay? Not so much.\n \"We will remain steadfast in our efforts to learn from this and other experiences as we work toward contributing to an Internet that represents the best, not the worst, of humanity,\" Lee wrote. \n                      Reuters contributed to this report                   \n"},
{"docid": "122 of 297 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "November 28, 1990", "title": "Singapore: Nervous times for the patron saint; Singapore's success as a port has changed little since the time of Raffles, but it remains vulnerable to world trade, writes Terry McCarthy\n", "content": "EVER SINCE Sir Stamford Raffles arrived in Singapore in 1819 and decided the island's location on the main shipping route between India and China would make it an excellent place to set up a port, Singapore's economy has relied heavily on shipping and entrepot trade. The main newspaper, first published in 1845, is still called The Straits Times, and the island is constantly ringed by ships at anchor, loading or unloading.\nWooden bumboats still bob up and down around Singapore's quays as they did when Joseph Conrad used the harbour as the basis for several fictional ''eastern ports'' in his novels, but today the port's main concern is with containerised shipping. This year, Singapore overtook Hong Kong harbour for the first time to become the port handling the largest number of containers in the world, much to the delight of Lee Chee Yeng, the director of operations and information systems of the Port of Singapore Authority (PSA).\u00a0\n''We call the PSA the patron saint of industry, a business in itself and not just a utility,'' says Mr Lee. Last year revenue for the port authority reached pounds 258m, and total assets are over pounds 1.25bn.\nMr Lee is fond of figures - the 7,000 PSA employees and 3,500 dockers dealt with 38,942 ship arrivals last year - which made Singapore the busiest port in the world for the eighth year in a row.\nIn 1823 Raffles wrote in the first port regulations that ''the port of Singapore is a Free Port and the Trade thereof is open to ships and vessels of every Nation . . .'' The regulations laid down procedures for reporting ships' arrivals and departures, the handling of cargo and the anchorage fees.\nToday this is all done by computer, and the port authority's information systems department is working on artificial intelligence applications to plan berths and loading, deploy pilots and map out channels and anchorages. They proudly remind visitors that this has already won them an award from the American Association for Artificial Intelligence.\nClose to pounds 1bn has been earmarked for investment over the next five years to construct additional berths at the new Brani terminal, upgrade freight handling and further automate on and off- loading of cargo.\nBut the high-tech can-do attitude is tempered with realism. There has been no fundamental change from the days of Raffles, when it was Singapore's location rather than any domestic production base that made the port successful.\nLike Singapore's economy as a whole, the PSA is entirely vulnerable to any downturn in world trade flows, and Mr Lee and his colleagues are nervous but helpless onlookers to the Gulf crisis and the growing recession in the West.\n"},
{"docid": "123 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "April 24, 2016", "title": "The innovators: can computers be taught to lip-read?; Technology being developed at University of East Anglia could help those who have recently lost their hearing - and prove who said what on the football pitch\n", "content": "When Zinedine Zidane, the then French captain, headbutted Italy's Marco Materazzi during the 2006 World Cup final, the clash quickly became one of the most infamous incidents in football history. What was not clear was what sparked the Frenchman's ire - Zidane said his mother had been insulted, a charge that Materazzi vigorously denied.\nThe head-butt got Zidane sent off and Italy won the game. However, had there been technology there to identify what was said, the result could have been very different, Dr Helen Bear believes. \"If a machine lip-reader was in existence, the other player [could] have got sent off too so it would have been 10 men against each other in a World Cup final,\" she argues.\u00a0\nBear is one of a number of researchers at the University of East Anglia focusing on ways to teach computers to read people's lips, technology that could be used in artificial intelligence applications.\nA three-year study at the university's school of computer studies could prove  a significant advance in the science behind automated lip-reading, which is still in its early stages. The technology could help people who have recently lost their hearing and, on a more basic level, it could improve our interactions with gadgets that are usually controlled by hand.\n\"For those who suffer post-lingual hearing loss, it is a a lot harder for them to learn to lip-read than someone who was deaf from birth, purely because if you have to learn from birth you are surrounded by all of this visual information. Some sort of technology that could help with that would be invaluable,\" she says. In practical terms, the system could work using the camera on a smartphone to read the speaker's lips and then carry out commands. \n One of the main problems faced by researchers is that some of the sounds that are made when people talk relate to a very similar facial expression. These shapes that the mouth makes are known as visemes. However, there are many more sounds, or phonemes, made during speech. \n This means that the viseme can have a number of meanings. A human lip-reader needs to figure out what is the actual meaning and also relies on other information such as the context of what is being talked about and body language. In a similar way, machines working to pinpoint what is being said by analysing the movement of the mouth have the same problem when the different sounds have similar facial appearances. \"This is where we get this confusability,\" says Bear.\nHer breakthrough has been in finding a new way to distinguish the sounds, which appear similar on the face, by identifying subtle differences which computers will be taught to recognise. By doing this, the different words can then take shape and the computer can lip-read what a person is saying.\n The development is significant, says Prof Richard Harvey, who has been working with Bear on the research. \"Lip-reading is one of the most challenging problems in artificial intelligence so it's great to make progress on one of the trickier aspects, which is how to train machines to recognise the appearance and shape of human lips,\" he says.\n The possibility of machines being able to lip-read could allow people to control devices without using their hands, such as when driving. A smartphone being used as a satnav could still pick up commands even if background or engine noise drowns out the speaker. And for someone who is outside using a phone whose call is being disrupted by wind noise, the camera could switch itself on and pick up what is being said.\n In other areas of research, using advances in technology has meant that volume controls in cars can now be manipulated using gesture controls similar to those of games machines, and cookers may soon have the ability to be turned on and off without being touched.\n Bear says that while the reality of this happening is some way off, it is possible. \"I don't see any reason why lip-reading technology will not exist at some point,\" she says. \nWith the possibility that a machine can read someone's lips and then the words are displayed on a screen will inevitably raise privacy concerns about the possible uses for this new strand of artificial intelligence.\n\"The whole point is that the machine is learning something that as humans we have not been able to do by ourselves, which is quite exciting. I know some people are wary [about artificial intelligence]. My personal opinion is that if you are careful, if you properly develop something and test it as far as you can, everything should be OK. It is all about having good software engineering practices and principles,\" Bear says.\n \u00b7 For more information on how Big Innovation Centre supports innovative enterprise in Britain and globally, go to our archive of the innovators columns on the Big Innovation Centre website.\n"},
{"docid": "124 of 297 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "August 17, 2017", "title": "Smashing tech leadership's glass ceiling; These female leaders are finding they have transferrable skills for many roles in the burgeoning tech sector\n", "content": "When walking into PwC's London offices on an excruciatingly hot day, I expected to be bombarded with jargon and terminology I couldn't even hope to relate to. Instead, I was welcomed with cool air conditioning and warm smiles from a group of women who are taking this otherwise male-dominated tech industry by storm. \n\"A tech career isn't very interesting. We're not told about them, so why would we bother going into one?\" These are things Nina Rush hears all too often. She works with young women and girls as part of PwC's women in technology programme and believes the time has come for this to change. \u00a0\nIf progress could be measured by the amount of talk about the lack of women in science, technology, engineering and mathematics (STEM), then it is quick and steady; 33.8m Google hits and counting. However, when measured by the number of women actually entering these careers, it's appallingly slow. \nWhy does it matter? In a world where women make between 20-40% less than men, a role in the STEM sector tops the list for salary potential. Meanwhile, research (pdf) by the Peterson Institute for International Economics reveals a \"positive correlation between the proportion of women in corporate leadership and firm profitability.\" In short, it's a win win.\nThree women at PwC, Nina Rush, Jane Wainwright and Jo Salter - coming from their diverse work backgrounds in accountancy, military intelligence and the RAF - are sources of inspiration. \n                                        Nina Rush, head of artificial intelligence                     in PwC's internal IT team                                      \nWith the support of her employer, Rush has made it her mission to encourage young women to consider a career in technology - partly because it's a world full of excitement, partly because it's where the future lies. As PwC's head of artificial intelligence, she describes herself as \"not the techiest person in the world\", but she didn't let that hold her back. \"These young girls need to see that this industry is actually fun, and so diverse,\" she says. \"I couldn't deal with a dull job, it would drive me mad. That's the picture I want to get across.\"\nRush never expected to end up working in tech. She started at PwC straight after secondary school, then trained as an accountant. \"I thought it was a fantastic way to get out into the workplace and learn a new skill.\" Rush completed her qualifications then worked for other companies and \"took the step into tech without really realising\". She has since returned to PwC in a transformation leadership role where she leverages some of the world's hottest technologies.\n Related:  'You can't be what you can't see': making tech careers a reality for women\n                   Jane Wainwright, privacy and data protection director                   \nRising to success while working in military intelligence, border control and as head of corporate security for the 2012 Olympics, Jane Wainwright had previously associated tech careers with the dull colours of \"grey, blue and black\". After 12 years of service with British military intelligence, it would be fair to say that professional services didn't have the same exciting ring to it. Her role in PwC's privacy and data protection legal practice happily proved her wrong. \n\"For mothers who have taken time off, there is a fear of skill fade. But you don't have to know everything, it's part of the excitement to learn as you go,\" says Wainwright, whose career decisions have been influenced by her desire to balance her career ambition with hands-on motherhood. \"If you want to design a new laptop then some up-skilling will be involved. But other skills, such as leadership, are highly transferrable. I don't necessarily need to understand how that laptop switches on; I do need to understand how to lead a team.\"\n                                        Jo Salter, director in people and organisation                                      \nAs Britain's first female fighter pilot in the RAF, Jo Salter is a true role model. In control of \u00a325m of flying metal at an age when most of us are still living with our parents, she flew from both Turkey and Saudi Arabia in protection of the \"no-fly zone\" over Iraq. She's hardly a stranger to excitement. And yet, she's finding herself equally passionate and ambitious about her role at PwC, leading those who love tech to take their skills further. \nWhile Salter has always been technical in the sense that she's flown a plane which is \"more complicated to operate than a Formula One race car\", her versatile skills have taken her from book writing, to academic lecturing and motivational speaking. Now she leads digital analytics to improve health, happiness, performance and diversity in organisations. \"I want to immerse myself in the world of analytics and through that help people to be the best version of themselves.\"\nWhile these women come from completely different backgrounds, they share two things in common: a new-found love for technology and an early career that did not include tech in its traditional sense. The key thing to understand, says Wainwright, is that \"a career in tech\" is an umbrella term for a lot of different jobs. Roles can include governance, compliance and innovation; and for all three of these women, demand leadership and constant change. \nFinding opportunities to learn and grow is the common thread. They focus on the breadth of possibilities and the pleasures of the unexpected they've found working in tech. \n                     To find out more about PwC's Women in Tech initiative, head here.                   \n                     To find out more about experienced hire opportunities within technology at PwC, head here.                   \n                     Content on this page is paid for and produced to a brief agreed with PwC, sponsor of the women in technology hub                   \n"},
{"docid": "125 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "May 24, 2016", "title": "If robots are the future of work, where do humans fit in?; We need to rethink our view of jobs and leisure - and quickly, if we are to avoid becoming obsolete\n", "content": "Robin Hanson thinks the robot takeover, when it comes, will be in the form of emulations. In his new book, The Age of Em, the economist explains: you take the best and brightest 200 human beings on the planet, you scan their brains and you get robots that to all intents and purposes are indivisible from the humans on which they are based, except a thousand times faster and better.\n Related:  The Guardian view on artificial intelligence: look out, it's ahead of you | Editorial\nFor some reason, conversationally, Hanson repeatedly calls these 200 human prototypes \"the billionaires\", even though having a billion in any currency would be strong evidence against your being the brightest, since you have no sense of how much is enough. But that's just a natural difference of opinion between an economist and a mediocre person who is now afraid of the future.\u00a0\nThese Ems, being superior at everything and having no material needs that couldn't be satisfied virtually, will undercut humans in the labour market, and render us totally unnecessary. We will all effectively be retired. Whether or not we are put out to a pleasant pasture or brutally exterminated will depend upon how we behave towards the Ems at their incipience.\nWhen Hanson presents his forecast in public, one question always comes up: what's to stop the Ems killing us off? \"Well, why don't we exterminate retirees at the moment?\" he asks, rhetorically, before answering: some combination of gratitude, empathy and affection between individuals, which the Ems, being modelled on us precisely, will share (unless we use real billionaires for the model).\nOpinion on the precise shape of the robot future remains divided: the historian Yuval Noah Harari argues, in Homo Deus: A Brief History of Tomorrow, that artificial intelligence robots will be the first to achieve world domination. This future is bleaker than Hanson's - lacking empathy, those robots wouldn't have a sentimental affection for us as their progenitors - but essentially the same. Harari predicts the rise of the useless class: humans who don't know what to study because they have no idea what skills will be needed by the time they finish, who can't work because there's always a cheaper and better robot, and spend their time taking drugs and staring at screens.\nThese intricacies, AI versus Ems, AI versus IA (intelligence amplification, where humans aren't superseded by our technological advances but enhanced by them) fascinate futurologists. Hanson argues that AI is moving too slowly, while only three technologies need coincide to make an Em possible: faster and cheaper computers, which the world has in hand; brain scanning, which is being worked on by a much smaller but active biological community; and the modelling of the human mind, \"which is harder to predict\".\n Related:  AI will create 'useless class' of human, predicts bestselling historian\nBut all the predictions lead to the same place: the obsolescence of human labour. Even if a robot takeover is some way away, this idea has already become pressing in specific sectors. Driverless cars are forecast to make up 75% of all traffic by 2040, raising the spectre not just of leagues of unemployed drivers, but also of the transformation of all the infrastructure around the job, from training to petrol stations.\nThere is always a voice in the debate saying, we don't have to surrender to our own innovation: we don't have to automate everything just because we can. Yet history teaches us that we will, and teaches us, furthermore, that resisting invention is its own kind of failure. Fundamentally, if the big idea of a progressive future is to cling on to work for the avoidance of worklessness, we could dream up jobs that were bolder and much more fulfilling than driving.\nThere are two big threats posed by an automated future. The first - that we will irritate the robots and they will dominate and swiftly obliterate us - is for Hollywood to worry about. There is not much apparatus we can build in advance to make ourselves less annoying. There will undoubtedly be those who believe our obliteration is so inevitable that every other anxiety is a sideshow.\nIf you can hold your nerve against that, the critical question becomes: in a world without work, how do we distribute resources? It is a question articulated precisely by Stephen Hawking last year, when he noted: \" Everyone can enjoy a life of luxurious leisure if the machine-produced wealth is shared, or most people can end up miserably poor if the machine owners successfully lobby against wealth redistribution.\"\nLike so many things, from debt cancellation to climate change, the reality of the situation is easily understood by scientists, academics, philosophers from the left and right, activists from within and without the establishment; and the only people who staunchly resist it are the self-styled political \"realists\".\nThe question of how to distribute wealth in the future curves back round to meet a conundrum raised by the past: how do we remake the social safety net so that it embodies solidarity, generosity and trust, rather than the welfare state of the present, rickety with the woodworm of mutual suspicion.\nThe idea of a universal basic income is generally framed as a way to \"shift from the Beveridge principle of national insurance based on contributions and the sharing of risk, to a system of income as of right\" (as described in a Compass paper by Howard Reed and Stewart Lansley). In its simplest iteration, all citizens receive the same income. There is work to be done on the numbers - whether this income needs to be supplemented for housing, in what form it has its most progressive effect, whether and how it is taxed back in the higher deciles, how it can be affordable at the same time as genuinely livable.\nThere is also work to be done on the surrounding incentives, whether a basic income would capsize the work ethic and leave the world understaffed while we await the robot takeover (a pilot scheme in Canada concluded the only groups who worked less with an income were mothers of young babies and teenagers still in education; other pilots are under way in Kenya and across Europe).\nEnter the future, with its possibility that many vocations will be unnecessary, and we face more existential questions: how do we find meaning without work? How do we find fellowship without status? How do we fill leisure intelligently? These mysteries possessed Bertrand Russell and John Maynard Keynes, then fell out of currency as we realised we could consume our way out of futility, and ignite our urge to earn by spending it before it arrived.\nEven absenting the constraints of the globe, that plan has failed. Consumption may have lent necessity to work, but it didn't confer meaning upon it. And perhaps the most profound accommodation we have to make with the future isn't whether or not we are capable of sharing, but where we will find our impetus.\n\"Can you just write,\" Hanson asked at the end of our conversation, \"that even though I'm talking about dire and dramatic things, I'm a friendly guy who smiles a lot?\" I'm not sure how much this helps. Some of his predictions are only bearable if you assume that you'll have died before they come to pass.\nHanson doesn't insist that his is the only possible outcome. Rather, \"you should expect that, whatever change is going to happen, it's going to happen pretty fast. Like, five years from nothing different that you'd notice to a completely different world. What I want is to have people understand how urgent it is, when this thing shows up, to have made a plan.\"\n"},
{"docid": "126 of 297 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "June 12, 2016", "title": "DREAMING OF A HUMAN MACHINE; A startling new film explores research by AI scientist Ben Goertzel, who hopes robot minds will one day be as 'smart, creative and kind' as any human. By Geoffrey Macnab\n", "content": "According to the artificial intelligence maverick and \"transhumanist\" Ben Goertzel, humans are \"the minimal general intelligence system on this planet at this time...humans are not the end of the line any more than amoebas are the end of the line\".\nGoertzel is the subject of Roy Cohen's startling new documentary, Machine of Human Dreams, premiering at the Sheffield Doc Fest this weekend. The documentary profiles Goertzel while telling the story of his ongoing attempts to refine \"OpenCog\", his artificial general intelligence (AGI) software that models the mind - and that he hopes will be used by robots that are as \"smart, creative and kind\" as any human.\u00a0\nThe way that Goertzel explains it in Cohen's film, creating \"walking, talking, smiling, gesturing, humanoid robots\" is straightforward enough. All you need to do is hook up them with OpenCog software and let them interact with the world.\nThe human brain builds itself from \"its vast amount of life experience\". It is a \"constantly evolving hypograph of nodes and links\". The robot brain will develop in the same way.\nOne idea is to use toy robots. \"If you have a million people playing with robots that connect with OpenCog's mind in the \"mind cloud\", then you have a million people who are teaching your AGI [robot] by interacting with it,\" he suggests.\nThere have been plenty of recent sci-fi movies that have dealt with AI: everything from Ex-Machina to Her, from Robot & Frank to Interstellar. We've all seen movies in which robots act as butlers, lovers, warriors or surrogate kids. Subject matter that used to be for the geeks is now resolutely mainstream. Google has invested heavily in AI buying British company DeepMind, Facebook has an AI department and Baidu is also spending heavily on AI research.\nCohen studied neuroscience at Harvard University and then spent time as a research assistant at Massachusetts Institute of Technology. During his studies, he encountered for the first time \"people who were interested in questions of artificial intelligence not merely as science fiction but as their vocation\". Goertzel, whom he met at a conference in New York, was intriguing: someone who didn't just spend his time in blue-sky research, but who has been striving to build the first \"thinking machine\".\nCohen talks about Goertzel's capacity to \"think and do and communicate at the same time\". One very downbeat phrase that you don't hear in the sci-fi movies is repeated several times in Machine of Human Dreams. Goertzel talks constantly about \"resource restriction\". That's another way of saying that he is in a continual battle for funding. Cohen's film stands both as a celebration of its subject's utopian vision - and as a cautionary tale about how difficult that vision is to realise.\nIn the film, Goertzel emerges as part visionary, part mountebank. He can always attract partners and excite investors, but he struggles to hit deadlines. A company he set up in New York \"pissed away\" $20m (as his former business partner puts it). There is an excruciating scene in the documentary in which he and his colleagues demonstrate their AI \"child\" robots to their Chinese investors in Hong Kong. The robots let them down. Little bits of their bodywork fall off. They give answers that have nothing to do with the questions they're being asked.\nThe setbacks don't shake Goertzel's confidence in his vision. Nor do his partners lose faith in him. Robotics physicist and former NASA engineer Mark Tilden speaks of him with unreserved enthusiasm. \"Ben has one of the best models of mind that I've ever met.\"\nGoertzel has now seen Machine of Human Dreams. His initial reaction wasn't enthusiastic. \"He was pretty???furious,\" Cohen acknowledges. \"Ben would have liked a film that was more technology focused.\"\nAfter reflecting further, Goertzel revised his view. He accepted that Cohen had needed to \"condense\" his story and that the filmmaker had been fair given the \"plethora of perspectives\" that the documentary includes.\n\"I definitely recommend you to watch the film,\" Goertzel wrote on a recent blog post. \"I particularly like the parts of the movie covering my team's recent work in Hong Kong and Addis [Ababa] - I think these are excitingly shot and directed, and they show aspects of our recent robotics tinkering that there's no other way to get a visual look at.\"\nWhat the film doesn't reveal is just when Goertzel's thinking machine will finally become a reality - or whether he will get there first. Goertzel is currently working for his former partner David Hanson as chief scientist at Hanson Robotics. The company created the first expressive biped robot, and Hanson is renowned for his marketing flair and business skills. He also patented \"Frubber\", the spongy flesh rubber that can make robots look like Alicia Vikander in Ex-Machina.\n\"I think that combination, David Hanson's flair for what works and what sells and Ben's truly brilliant mind, that may be the combination that makes the breakthrough,\" Cohen says.\nWhen (and if) the breakthrough finally happens, one prediction can safely be made: the fast-blurring lines between robots in sci-fi and those in real life will disappear altogether.\n'Machine of Human Dreams' premiered at Sheffield Doc Fest yesterday and will be released in UK cinemas later this year\n"},
{"docid": "127 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "March 28, 2016", "title": "An improbable future? Not if this man has his way; GOING FOR GROWTH Technology start-up develops new way to simulate complex scenarios for entertainment or decision-making applications Herman Narula walked away from his family's construction business to build brave new worlds, writes James Hurley\n", "content": "If Herman Narula is to be believed, The Matrix may already be in our midst. Improbable, the appropriately named company co-founded by the young computer scientist, has come up with a potentially revolutionary way of building and operating complex virtual worlds, rather like the one that enslaves humanity in the 1999 science fiction film. \"We can support version one of the Matrix, anyway,\" he says.\nThe 27-year-old is only half-joking.Improbable has kept a low profile since it was founded in a converted barn three years ago, but Mr Narula is ready to tell the world that his team has cracked a problem that could have far-reaching implications for industries as diverse as gaming, finance, economic modelling, infrastructure planning and defence.\nThe company has developed a new way to simulate complex systems, from traffic on the street to millions of characters in a game. Mr Narula describes the breakthrough as providing a \"collective imagination\", whether for entertainment or decision-making purposes.\u00a0\n\"People believe the pinnacle of technology is recreating humans in the form of artificial intelligence,\" he says. \"I disagree. I think the pinnacle is ... giving people thousands of worlds.\"\nIn a tatty meeting room at the company's central London base (which is full of \"MDF tables and Ikea chairs,\" Mr Narula notes), a monitor displays the company's simulation of the backbone of the internet.\nThe project, developed in partnership with the government, is the largest simulation of its kind to have been created, Improbable says. It represents the flow of internet traffic and reveals the potential weak spots of the entire world's internet that could be vulnerable to attack from hackers, terrorists or hostile governments.\nOn another screen, a simulated Cambridge is going about its business, from the transport and communications networks to the power grid and population. \"You'll be able to work out the absolute worst place to plant a bomb in Cambridge or any number of other nefarious things. Without [simulations], these problems are otherwise impossible to tackle,\" Mr Narula says.\n\"The public focus a lot on the technology that is easy for people to grasp, like artificial intelligence and virtual reality. But this is equally, if not more, significant.\"\nImprobable began with an apparently simple problem that had been bothering Mr Narula and his cofounder, Rob Whitehead, who met while studying at the University of Cambridge.\nThey wanted to experience a computer game virtual world with socalled persistence. The principle is simple. Say you drop something in a game: provided that no one else has stolen it, it should be in the same place when you return. Or, if you damage a character or item, they should neither magically repair themselves nor inexplicably disappear. Games makers have found this a surprisingly difficult problem to solve. \"So much of the work done to create immersive entertainment [in games] is really about creating an illusion of a world. Nothing is really happening off-camera. When you destroy something, it vanishes, then it is brought back to life again.\"\nThe limitations stem from the fact that one machine, or an aggregation of one machine, can struggle to do all of the heavy lifting involved in simulating a complex system. \"You can't split up a virtual world very easily,\" Mr Narula says. \"If we just put a big line between this part of the world and that part of the world, and one machine takes care of each, how do you deal with the transitions? What happens if everything moves from one side to another?\" Improbable's solution is to scrap the idea of a complex simulation being managed by one machine.\n\"Instead of one application being god, we have a whole swarm of workers. Instead of controlling everything, they each transiently control just a bit of the world and, like a giant game of musical chairs, the bit that they control constantly changes.\n\"By doing that, we cope with the problem of any one of them becoming overloaded. Instead of dividing space, we divide the work. It's taken 90 people from 22 nationalities two and a half years of work and a lot of madness to do this.\"\nMr Narula, too affable and animated to fit the stereotype of the socially awkward technology whizz, is the son of Harpinder Singh Narula, the billionaire construction mogul behind DS Constructions.\nAbandoning the assumed route into the family firm in favour of a start-up was a source of considerable tension, he says. \"You give up a gigantic inheritance and abandon a family business in which all 30 male members of your family work in, it doesn't go down too well. But I felt strongly I wanted to build something new that could be massive.\"\nThe family business might have been an easier ride. His life at Improbable is chaotic, he says. \"It's a constant sense of never-ending terror.\nAnyone who paints a rosy picture of the stress-free growth of a company is just wrong.\" The company has raised $20 million from Andreessen Horowitz, the Silicon Valley venture capital firm famous for backing Twitter, Facebook and Airbnb. \"We didn't like the London venture capital scene,\" Mr Narula says. \"We got offers but it didn't feel like we were dealing with a desire to build world-class businesses.\"\nImprobable is building an open platform that will allow any developer to use the software to build their own complex simulations.\n\"Our goal is to build a business of businesses, the Google of simulation, a fundamental next step in people's relationship with technology,\" Mr Narula says. \"We want to make a universe of new worlds.\"\nEmbracing the weird and wonderful\nWorlds Adrift, the first computer game to use Improbable's technology to power a virtual world, is an example of how computer games are about to get weird, according to Herman Narula (James Hurley writes).\n\"Most games are about creating scripted stories and letting people play through them. This game is a full simulation of a world at the scale of an ecology.\n\"Every tree grows, every creature lives and has a life cycle. The birds have eggs, they have migratory patterns. When you add it all up, you get this strange thing.\"\nMr Narula says the odd effects that a simulation such as this throws up pass what he calls the \"Gibson threshold\", after William Gibson, the science fiction writer who has explored worlds in which computer technology intrudes on reality.\n\"There's something weird about these games - they don't play like regular games. You react to it differently, you start to behave in a way that the world matters.\"\nThe company's simulation technology has also attracted the interest of everyone from government defence departments that want to simulate wars to academics modelling the housing market.\nMr Narula believes that simulation software eventually will be used to help to decide where to build a third runway in the south, say, or which country should stage the World Cup. \"All models are wrong, some are useful. I love that quote. Before, we knew lots about the individual pieces of data, but we couldn't put them into a world that shows us what happens before and after. We can't predict the future but you need simulation to understand the implications of your actions.\"\n"},
{"docid": "128 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "April 25, 2016", "title": "The innovators: can computers be taught to lip-read?; Technology being developed at the University of East Anglia could help those who have recently lost their hearing - and prove who said what on the football pitch\n", "content": "When Zinedine Zidane, the then French captain, headbutted Italy's Marco Materazzi during the 2006 World Cup final, the clash quickly became one of the most infamous incidents in football history. What was not clear was what sparked the Frenchman's ire - Zidane said his mother had been insulted, a charge that Materazzi vigorously denied.\nThe head-butt got Zidane sent off and Italy won the game. However, had there been technology there to identify what was said, the result could have been very different, Helen Bear believes. \"If a machine lip-reader was in existence, the other player [could] have got sent off too so it would have been 10 men against each other in a World Cup final,\" she argues.\u00a0\nBear is one of a number of researchers at the University of East Anglia focusing on ways to teach computers to read people's lips, technology that could be used in artificial intelligence applications.\nA three-year study at the university's school of computer studies could prove  a significant advance in the science behind automated lip-reading, which is still in its early stages. The technology could help people who have recently lost their hearing and, on a more basic level, it could improve our interactions with gadgets that are usually controlled by hand.\n\"For those who suffer post-lingual hearing loss, it is a a lot harder for them to learn to lip-read than someone who was deaf from birth, purely because if you have to learn from birth you are surrounded by all of this visual information. Some sort of technology that could help with that would be invaluable,\" she says. In practical terms, the system could work using the camera on a smartphone to read the speaker's lips and then carry out commands. \n One of the main problems faced by researchers is that some of the sounds that are made when people talk relate to a very similar facial expression. These shapes that the mouth makes are known as visemes. However, there are many more sounds, or phonemes, made during speech. \n This means that the viseme can have a number of meanings. A human lip-reader needs to figure out what is the actual meaning and also relies on other information such as the context of what is being talked about and body language. In a similar way, machines working to pinpoint what is being said by analysing the movement of the mouth have the same problem when the different sounds have similar facial appearances. \"This is where we get this confusability,\" says Bear, who has recently completed her PhD.\nHer breakthrough has been in finding a new way to distinguish the sounds, which appear similar on the face, by identifying subtle differences which computers will be taught to recognise. By doing this, the different words can then take shape and the computer can lip-read what a person is saying.\n The development is significant, says Prof Richard Harvey, who has been working with Bear on the research. \"Lip-reading is one of the most challenging problems in artificial intelligence so it's great to make progress on one of the trickier aspects, which is how to train machines to recognise the appearance and shape of human lips,\" he says.\n The possibility of machines being able to lip-read could allow people to control devices without using their hands, such as when driving. A smartphone being used as a satnav could still pick up commands even if background or engine noise drowns out the speaker. And for someone who is outside using a phone whose call is being disrupted by wind noise, the camera could switch itself on and pick up what is being said.\n In other areas of research, using advances in technology has meant that volume controls in cars can now be manipulated using gesture controls similar to those of games machines, and cookers may soon have the ability to be turned on and off without being touched.\n Bear says that while the reality of this happening is some way off, it is possible. \"I don't see any reason why lip-reading technology will not exist at some point,\" she says. \nWith the possibility that a machine can read someone's lips and then the words are displayed on a screen will inevitably raise privacy concerns about the possible uses for this new strand of artificial intelligence.\n\"The whole point is that the machine is learning something that as humans we have not been able to do by ourselves, which is quite exciting. I know some people are wary [about artificial intelligence]. My personal opinion is that if you are careful, if you properly develop something and test it as far as you can, everything should be OK. It is all about having good software engineering practices and principles,\" Bear says.\n \u00b7 For more information on how Big Innovation Centre supports innovative enterprise in Britain and globally, go to our archive of the innovators columns on the Big Innovation Centre website.\n\n"},
{"docid": "129 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "May 16, 2016", "title": "Google's artificial intelligence writes miserable poetry\n", "content": "When compiling a list of the great poetic bastions of misery,\u00a0Eliot, Byron and Keats\u00a0are more likely to spring to mind than the musing of an algorithm.\nBut Google's\u00a0artificial intelligence project has proven itself a worthy mournful adversary by bashing out some macabre musings capable of clouding over even the sunniest day.\u00a0\n.html-embed.component .quote.component{margin-left:0}.html-embed.component .quote.component .component-content{margin-right:16px}.quote__source, .quote__author {white-space: normal;}@media only screen and (min-width:730px){.html-embed.component .quote.component{margin-left:-60.83px}.html-embed.component .quote.component .quote__content:before{margin-left:-12px;padding-right:1px}}@media only screen and (min-width:1008px){.html-embed.component .quote.component{margin-left:-82.33px}}You need to talk to me now. But you need to talk to me nowGoogle, poet laureate\nEngineers fed the model's neural network\u00a0thousands of novels \u00a0to teach it\u00a0the art of conversation,\u00a0and then asked it to generate poetry after being fed two sentences from\u00a0each title.\nShowcasing how it is just as capable of conjuring up bleak imagery as\u00a0humans, the AI penned a series of dreary poems, including the below.\namazing , is n't it ?\nso , what is it ? it hurts , isnt it ? why would you do that ? \" you can do it . \" i can do it . i ca n't do it . \" i can do it . \" do n't do it . \" i can do it . i could n't do it .\nthere is no one else in the world .\nthere is no one else in sight . they were the only ones who mattered . they were the only ones left . he had to be with me . she had to be with him . i had to do this . i wanted to kill him . i started to cry . i turned to him .\nim fine .\nyoure right . \" all right . you 're right . okay , fine . \" okay , fine . yes , right here . no , not right now . \" no , not right now . \" talk to me right now . please talk to me right now . i 'll talk to you right now . \" i 'll talk to you right now . \" you need to talk to me now . \" but you need to talk to me now .\nAfter scanning the thousands of books, the researchers found it was able to generate complete and coherent sentences, although not quite what we would call poetry.\nThe search giant recently announced that its state-of-the art AI language model was to be known as Parsey McParseface, in tribute to the \u00a3200 million British polar research vessel almost\u00a0named \" Boaty McBoatface \" after more than 100,000 people voted in its favour.\nAI timeline\nF or a round-up of technology news and analysis, sign up to our weekly Tech Briefinghere.\nREAD MORE ABOUT:\n"},
{"docid": "130 of 297 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "July 1, 2016", "title": "Tesla autopilot crash: Fatal collision was tragic but self-driving technology should still continue, say experts; Scientists and engineers say that automated driving technology could make our roads safer in the long run\n", "content": "Experts have come out in defence of automated driving technology after a driver was killed while using his Tesla's autopilot feature. Specialists in the fields of artificial intelligence, engineering, and transporthave said that while the death was tragic, it should not prevent the software from being developed.\nJoshua Brown, 40, died when his Tesla Model S went underneath the trailer of a lorry that had turned left in front of him on a Florida road in May, prompting an urgent investigation by Tesla itself and the US authorities.\u00a0\nIn a statement on its blog, Tesla explained that the technology is still under development and that as an assist feature drivers \"need to maintain control and responsibility for [their] vehicle' while using it.\" The company went on to say that the autopilot mode does still result \"in a statistically significant improvement in safety.\"\nExperts have responded to the news by saying that Tesla should not let the accident deter the continued development of the technology. According to Professor Nello Cristianini, Professor of Artificial Intelligence at the University of Bristol, it has the potential to greatly improve road safety. \"Tesla reports less fatalities in autonomous cars than in the general driving population (1 fatality every 130 million miles against the 1 fatality in 94 million miles for general drivers),\" he said.\nMeanwhile,Prof William Harwin, Professor of Cybernetics at the University of Reading, has said that\"Unfortunately, fatal accidents will always happen with new engineering systems. There are any number of examples from the past\" and that though \"Tesla should recall all relevant products to at least disable the lane changing feature until this accident can be fully investigated [...] the bottom line is that cars are likely to be safer with these automatic features, and ultimately with vehicles that can drive autonomously.\"\nHarwin's opinion is shared by Prof Duc Pham FREng, from the School of Engineering at The University of Birmingham and Prof Slawomir Nasuto, Professor of Cybernetics at the University of Reading who both say that accidents such as this are an \"inevitable\" part of developing anew technology such as this.\nRead more\nTesla crash: Driver killed in first fatal crash involving autopilot mode\nThough driverless technology is indeed still very much \"a work in progress\" according to Prof Alan Winfield, Bristol Robotics Laboratory and Director of Science Communication Unit at the University of the West of Englandhe believes that Tesla's partial automationapproachis the wrong one: \"An autopilot that requires that the driver is paying attention and ready to take over in a split second is the wrong approach. It is inevitable that a driver's attention will wane if they have nothing to do. I also believe it irresponsible of manufacturers to make unregulated autopilot software available for drivers to try out on public roads.\"\nProfessor Nasuto, however, points out that \"it is much, much harder to design artificial intelligence to replace the role of a driver, operating alongside other human drivers, pedestrians and cyclists, than to replace the whole road system\" with Sahar Danesh, IET Principal Policy Advisor for Transport, stating \"we are unlikely to see fully autonomous vehicles in the very near future but what we will see is increased levels of automation, such as speed and lane control, rather than completely driverless cars.\"\nWhether or not the degree of automation Tesla allowsis the right one, all of the experts agree that the results of Tesla's investigation into the crash will lead to improvements in self-driving technology that will avoid similar incidents in the future.\nRead more\nDriverless car safety revolution could be scuppered by moral dilemma\nSahar Danesh emphasised that \"It is important to remember that driverless vehicles have huge potential to transform the UK's transport network. In the long term, autonomous cars could improve road safety, reduce congestion and lower emissions\" but that \"public acceptance and trust are crucial.\"\nThe experts avoid laying the blame with any particular party involved in thecrash and investigations arecurrently ongoing, however, it appears that the general consensus is that whilst driverless technology does indeed have a long way to go before it could be considered completely safe and the accident is a tragedy, the technology has the potential to improve safety on our roads and development should continue.\n"},
{"docid": "131 of 297 DOCUMENTS\n", "source": "DAILY MAIL (London)\n", "date": "February 5, 2016", "title": "TECHIE WHO GAVE UP HIS SHARE OF A \u00a325M FORTUNE - FOR A BIKE!\n", "content": "AT the time, it seemed like a good deal. Chris Hill-Scott agreed to accept a bicycle in exchange for his share in a business that he and two university friends were struggling to get off the ground.\nThe business, which was developing a mobile phone app that could guess the next words that users typed, had been a struggle. The three were working long hours, for no pay. Hill-Scott wanted out to pursue a career in photography. Because his friends Jon Reynolds and Ben Medlock didn't have any spare funds, they offered the bike.\nOn Wednesday this week, though, that deal - made in 2008 - was filling 29-year-old Hill-Scott with regret. The biggest mistake I have ever made,' he said on social network Twitter.\u00a0\nReynolds and Medlock had just sold the app, now called SwiftKey, to Microsoft for a reported \u00a3174m. Reynolds and Medlock are each thought to have made \u00a325m on the deal.\nAnd though his pals are now millionaires, Hill-Scott designs websites for the Government.\nReynolds, now SwiftKey chief executive, and Medlock, its chief technological officer, revealed the Microsoft deal on their website, and thanked those who had stuck by them along the way.\nThey said in a joint statement: At times like this, people tend to focus on founders. However, the heart of our company is the awesome team who chose to share this journey with us.\nWe want to take this opportunity to thank them for their dedication and hard work.\nWe never would have come this far without you.'\nReynolds and Medlock were aged just 22 and 28 respectively when they came up with the app's algorithm as an answer to their growing frustration with touch-screen keypads which garbled words.\nTheir technology, which uses artificial intelligence, now features on more than 300m devices worldwide and is licensed by some of the biggest mobile brands, including Samsung.\nThey have a team of 150 staff with offices in London, San Francisco and Seoul, in South Korea.\nSince launching SwiftKey, Reynolds and Medlock have also helped Stephen Hawking to upgrade his computer-generated voice by applying predictive language software to his system and enabling him to speak faster and continue to give lectures.\nSwiftKey works by understanding how words fit together in context and by continually learning to improve its knowledge.\nThis means it can predict your next word when typing, but also radically improves the accuracy of auto-correcting words when you mistype. The app lets you type by sliding your fingers across the screen, which can speed things up. It can also store your preferences online so they can be used on all your gadgets, and is constantly updated with phrases as new words become popular. It even remembers slang and nicknames which are preferred by the user.\nThe company estimates its software has saved its users 10 trillion keystrokes, which amounts to more than 100,000 years of typing time.\nSwiftKey's acquisition is the latest in a trend of huge US companies buying up British artificial intelligence ventures.\nGoogle bought DeepMind for \u00a3400m - a programme which develops artificial intelligence for computer games in 2014. And last year Apple bought VocalIQ, which makes software to help computers and people converse more naturally.\nReynolds said: The UK has become a great place to build a tech business.'\nSwiftkey has said Hill-Scott left the company on good terms. Hill-Scott did not respond to a request for comment.\n\u00a9 Daily Mail\n"},
{"docid": "132 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 24, 2018", "title": "Merkel and Macron warn against perils of digital imperialism\n", "content": "The leaders of Germany and France have called on Europe to prepare a joint defence against digital imperialism, warning that the bloc risks being left behind as US corporate giants and the Chinese state fight for dominance over the information revolution.\nGerman chancellor Angela Merkel said the EU is under intense pressure as \"big American corporations\" run away with the digital prize, and as they \u00addevelop enormous power over the \u00adfuture shape of society in the process.\u00a0\n\"Data will be the raw material of the 21st century - the question 'who owns that data?'\" she said at the World Econo\u00admic Forum in Davos. \"In China there is very close co-operation between those who collect the data and the Chinese state. They are almost one and the same.\"\nMrs Merkel, a quantum chemist by background, said Europe is asleep at the wheel, while its hybrid \"social market\" economy is struggling to meet the challenge: \"Who will decide whether democracy, the participatory social model and economic prosperity can be combined.\"\nThe chancellor confessed her \u00adcountry is a particular laggard, with \"a society growing ever older, and less curious\", living in another universe from China where a billion people already organise their daily lives on their smartphones.\nThe warnings were echoed by French president Emmanuel Macron, who lamented that nothing was being done to civilise the technology jungle.\n\"We haven't established an organisation at a world level which looks at artificial intelligence and automation. We allow private companies to control this. We are encouraging technological change, and we are in danger of living in a Darwinian world,\" he said.\nThe new focus on threats from digital oppression and the galloping pace of artificial intelligence comes as \u00adEurope brings in draconian new rules for data protection.\nWhile the regulations are billed as a safeguard for privacy rights, critics say the non-tariff barriers restrict free data flow and are a disguised form of economic protectionism for a region that has no Silicon Valley of its own and cannot compete.\nThe irony was not lost on delegates in Davos as Europe's leaders vied with each other to champion the cause of globalisation, and to deplore the \u00adnationalist retreat from multinational bodies - even if none mentioned Donald Trump by name.\nMrs Merkel condemned the \"poison of populism\", invoking the tragic lessons of the 20th century and above all the First World War. \"And we today 100 years later have to ask ourselves a very pertinent question: have we learned the lessons of history?\" she said.\n\"We've known since the Roman \u00adempire, since the Chinese wall, only shutting ourselves off doesn't help to protect your borders,\" she said.\nYet such anti-populist strictures are starting to sound a little stale. Behind all the rhetoric about a new sense of solidarity and mission in Europe - led by the revived Franco-German axis - the divisions are still as clear as ever.\nFrance and Italy have yet to secure any meaningful shift from Germany \u00adtowards a fiscal union, or eurobonds, or shared debts, deemed necessary by many to avert another crisis in the next global downturn. \"Each and every country ought to manage its own liabilities,\" said Mrs Merkel, calling on recalcitrant states to \"do their homework\".\nGermany is still pushing proposals that force private banks to whittle down holdings of their own country's sovereign debt, prompting an angry outburst by Italy's finance minister.\nPier Carlo Padoan said the eurozone risks an instant banking crisis with a self-fulfilling chain-reaction. Yet Germany insists that there can be no substantive move towards a full-fledged banking union until lenders have ended their addiction to government\u00a0debt.\n"},
{"docid": "133 of 297 DOCUMENTS\n", "source": "The Independent - Daily Edition\n", "date": "October 19, 2017", "title": "Capitalism has made itself obsolete, former Greek finance minister says\n", "content": "Former Greek finance minister Yanis Varoufakis has claimed capitalism is coming to an end because it is making itself obsolete. The former economics professor told an audience at University College London that the rise of giant technology corporations and artificial intelligence will cause the current economic system to undermine itself.\u00a0\nMr Varoufakis, who took on EU institutions over Greek debt repayments in 2015, said companies such as Google and Facebook, for the first time ever, are having their capital bought and produced by consumers.\n\"Firstly the technologies were funded by some government grant; secondly every time you search for something on Google, you contribute to Google's capital,\" he said. \"And who gets the returns from capital? Google, not you. So now there is no doubt capital is being socially produced, and the returns are being privatised. This with artificial intelligence is going to be the end of capitalism.\"\nWarning Karl Marx \"will have his revenge\", the 56-year-old said for the first time since capitalism started, new technology \"is going to destroy a lot more jobs than it creates\". He added: \"Capitalism is going to undermine capitalism, because they are producing all these technologies that will make corporations and the private means of production obsolete. And then what happens? I have no idea.\"\nDescribing the present economic situation as \"unsustainable\" and fearing the rise of \"toxic nationalism\", Mr Varoufakis said governments needed to prepare for post-capitalism by introducing redistributive wealth policies. He suggested one effective policy would be for 10 per cent of all future issue of shares to be put into a \"common welfare fund\" owned by the people. Out of this a \"universal basic dividend\" could be paid to every citizen.\nMr Varoufakis came to prominence during the Greek sovereign debt crisis when he led Greece's negotiating team seeking a resolution with its international creditors. Describing the event as a \"complete failure\" on his part, he resigned as finance minister in 2015 after Greek Prime Minister Alexis Tsipras agreed to the terms of the EU's debt repayment plan.\n"},
{"docid": "134 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "April 20, 2016", "title": "Can you become 'virtually immortal'? A Silicon Valley startup thinks so; A company called Eternime hopes digital versions of our personalities will be able to 'communicate' through chatbots from the grave. But we can't cheat death\n", "content": "\"Become virtually immortal\". That is one of the slogans found on the hauntingly cheerful website for Eternime - a startup firm aiming to let you store your memories and your personality in digital form past your physical expiration date (also known as death). They hope to feed the data into chatbots that will allow us to \"speak to the dead\". This is illustrated through a shoddy photoshop of a bearded man's head floating inside a laptop. It's a bit like Jambi, the bodyless genie in the box from Pee Wee's Playhouse. Enjoy having a chat with that, if you can. \nThe website goes on to describe the service as \"a library that has people instead of books\", which truly does add new meaning to the phrase \"I'm checking you out\", doesn't it? Crack open your MacBook, and hey, there's your old pal Odd George from the bar around the corner. He's been saved in exacting digital detail for you to enjoy, while his actual body gets chewed up by insects.\u00a0\nWill a service like this ever exist? Who knows. But people become intrigued by these ideas. What companies like Eternime understand is that few of us ever get sick of hearing about how technology is going to change our conception of human existence. Elon Musk isn't just famous because he builds cars rich people queue up to buy in droves. He's also famous because he pops up in the news every few months with a new tantalizing scheme: the Hyperloop, benign artificial intelligence, privately funded space exploration. Each and every time he reveals a new seemingly implausible or absurd project, we eat it up because he's confident and wealthy enough that he might pull it off. \nWhile Musk offers himself as a savior from Armageddon, Eternime drums up excitement through a far more personal issue. It's not about the death of the whole planet, it's about the death of one person you love. Their service suggests there's a way for every human being, even the non-famous ones, to be remembered for as long as Eternime's server bill is paid. \nBlack Mirror already covered how this could have unintended negative consequences. The people left behind to talk to your floating head on a computer monitor might get so wrapped up in memorializing you that they never take the time to live their own life. Or worse, the artificial intelligence develops its own personality and its own desires independent of the dead person. It's not as simple as, say, an app that hails cabs for you or orders someone to come pick up your dirty underwear. Eternime is trifling with someone's most intimate emotions. \nStill, their website claims more than 31,000 people have signed up to have their identity uploaded into the cloud. That's not a ton of potential customers, but it's a pretty solid effort for a company offering a service that disrupts our received notions of how the end of our lives will play out. The way people deal with death has never been rational. Some talk to gravestones or bowls of ashes. Others keep their loved one's clothes in a box long after they've passed away.\nHuman civilization is littered with belief systems based around how we die and what happens to us after it happens, inventing fantasies of resurrection for the purposes of giving it all some kind of meaning. Who's to say that talking to a chatbot version of your dead husband is any stranger than having a full-on argument with his chewed-up old loafers? \n Related:  Web immortality: the social media sites that keep you alive in the digital world\nThe grieving process isn't something we understand, it's something we endure. Flashy startups like Eternime come and go, but then again, so does everyone and everything. Society will probably never solve the problem of death, but it remains to be seen if it's actually a problem that needs solving. All I know for sure is that we're not going to stop trying any time soon.\n"},
{"docid": "135 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "March 19, 2016", "title": "Computers might beat us at board games, but that doesn't mean they'll take over the world; So computers can now beat humans at Go - but why would they swap their game pieces for bombs?\n", "content": "'AlphaGo\" is the sort of supercomputer name a pulp science fiction novelist might come up with. Nevertheless, the achievements of this Google DeepMind machine are only too real. It has become the first computer program to beat a professional human player of the Chinese strategy game Go, without handicaps, on a full-sized 19\u00d719 board.\nIt shouldn't surprise us when computers beat humans at board games. They can, after all, store and rapidly analyse hundreds of millions of moves, and work out the implications of strategies hundreds of moves ahead, something no merely human player can manage. But AlphaGo is different. Experts in Go strategy report that it (I initially wrote \"he\" ...) played in non-obvious ways, making unusual, sly and even bizarre moves that only belatedly revealed themselves as tactically worthwhile.\u00a0\nIt's this that makes AlphaGo's achievement so exciting. Being able to crunch numbers, even to crunch huge numbers really quickly, is not the same thing as intelligence, and certainly not the same thing as sentient self-consciousness. The ability to intuit, to make leaps of comprehension - not just to extrapolate according to pre-programmed rules but to speculate - is a lot closer to the Holy Grail of proper AI, and AlphaGo's achievement is more modest. Still, as Arthur C Clarke once noted: advances that seem modest and trivial in the short term can lead to drastic change in the long.\nSF has a long tradition of dramatising artificial intelligence. Sometimes this is benign: Isaac Asimov's self-aware robots are constrained from harming individuals by their built-in \"three laws\", and eventually intuit an extra \"zeroth\" law that requires them to protect the whole of humanity. But usually SF imagines more alarming possibilities. 2001: A Space Odyssey 's HAL 9000 has no qualms in murdering its entire human crew. Alastair Reynolds's Revelation Space novels include terrifying machine intelligences called The Inhibitors that travel the galaxy destroying organic life. If computers become better than us at all games, then that peculiar and deadly game we call \"war\" assumes alarming new dimensions.\nIn James Cameron's The Terminator and the Wachowskis' Matrix trilogy, artificial intelligence has made apocalyptic war on humanity and enslaved the survivors. But though the sentient machines are relentless and brutal, their eventual defeat stems from key human players doing something that computers cannot: falling in love, Kyle Reese with Sarah Connor, Neo with Trinity. This flatters our sense that there is something special about us, slow and squishy though we may be, and that this specialness will win out in the end. But perhaps thinking so is just another, more deadly sort of hubris. In Alex Garland's subtle film Ex Machina the clever AI inside Eva manipulates human Caleb into falling in love with \"her\", so as to be able to kill her human captors and escape.\nMight some future version of AlphaGo decide to play Go on a global scale, with bombs instead of black and white stones? It's doubtful. The great Polish SF writer Stanislaw Lem's Golem XIV concerns a vast military supercomputer that achieves self-awareness, but the novel's twist is that instead of trying to destroy us it decides humanity is a cosmic irrelevance and disappears into higher dimensions in search of ultimate knowledge. Quite the snub: at least Skynet thinks we're worth attacking! But in another sense it captures a deeper truth. Maybe AlphaGo's descendants, waking into proper self-awareness, will find more stimulating and more profound things to do with their vast computational powers than blowing up humanity. They may end up playing Go with the architecture of reality itself.\n"},
{"docid": "136 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 31, 2018", "title": "No-limits China sets its sights on AI top spot\n", "content": "On the outskirts of Beijing, a policeman peers over his glasses at a driver stopped at a motorway checkpoint. As he looks at the man's face, a tiny camera in one of the lenses of his glasses records his features and checks them with a national database.\nThe artificial intelligence-powered glasses are what Chinese citizens refer to as \"black tech\", because they spot delinquents on the country's \"blacklist\". Other examples include robots for crowd control, drones that hover over the country's borders, and intelligent systems to track behaviour online. Some reports claim the government has installed scanners that can forcibly read information from smartphones.\nIn the last two weeks, Facebook has been mired in a privacy storm in the UK and US over potential misuse of personal data. But such an event might baffle many in China, where the country's surveillance culture eclipses anything Facebook has done.\nThe gulf between East and West in how privacy is approached may now put China at the forefront when it comes to developing artificial intelligence, seen as one of the critical technologies of the next decade.\u00a0\nChina has made clear its intention to become the AI heavyweight by 2030 with the help of huge state-backed funding. The West also has big plans to maintain its status as a cyber power.\n.html-embed.component .quote.component{margin-left:0}.html-embed.component .quote.component .component-content{margin-right:16px}.quote__source, .quote__author {white-space: normal;}@media only screen and (min-width:730px){.html-embed.component .quote.component{margin-left:-60.83px}.html-embed.component .quote.component .quote__content:before{margin-left:-12px;padding-right:1px}}@media only screen and (min-width:1008px){.html-embed.component .quote.component{margin-left:-82.33px}}To date, the West has been leading research across many areas of AI but clearly China is catching up quickly and may be overtaking us in some areasDr Adrian Weller, Turing Institute\nTo date, the battle for AI supremacy has been between companies, as Google, Facebook and Amazon competed for scarce expertise in the field, but now it is pitting nations against each other in a quest for technological dominance unseen since the space race.\nMachines that can \"think\" could cure disease, change the way we work and transform travel. Not only is artificial intelligence likely to take millions of jobs, but it will probably decide who is suitable for the jobs that remain. It may even replace humans in the bedroom.\nThere is the bottom line to consider, too: it has been estimated that AI could add an additional \u00a3630bn to the UK economy by 2035.\nBut it is not just about money. Machines that can think are beginning to shape the world we live in, and therefore the person, or nation, that creates it holds huge power.\nShenzhen, China's answer to Silicon Valley, is home to research and development centres for tech heavyweights like Huawei, a network company-turned-smartphone manufacturer.\nThere you can find the headquarters of Baidu, China's answer to Google, and iFlytek, a voice recognition company worth $82bn. The UK can claim DeepMind, a London-based start-up bought by Google in 2014 for a rumoured \u00a3400m.\nThe company makes self-learning algorithms, which have been used to cut energy consumption and in healthcare.\nIn 2015 DeepMind struck a deal with the Royal Free Hospital to feed data on 1.6m patients to help create AI that could alert the appropriate doctor when a patient's condition worsened.\nHowever, the deal was later deemed illegal by the data protection watchdog. The Information Commissioner said the trial had not obtained the full consent of the patients involved.\nThe incident illustrates a key difference between development of \u2028AI in the East and the West: it is hard to imagine such privacy concerns holding back development in China.\nDr Adrian Weller, AI director at the Turing Institute in London, believes that while the UK has made \"great progress in certain areas\" we are \"very far off\" in others. \"To date, the West has been leading research across many areas of AI but clearly China is catching up quickly and may be overtaking us in some areas,\" he says.\n\"Chinese students are coming to the UK and US and going back to China, and the government is making sure that it is a leader in these areas. Like us, they want to do well in the space.\"\n.html-embed.component .quote.component{margin-left:0}.html-embed.component .quote.component .component-content{margin-right:16px}.quote__source, .quote__author {white-space: normal;}@media only screen and (min-width:730px){.html-embed.component .quote.component{margin-left:-60.83px}.html-embed.component .quote.component .quote__content:before{margin-left:-12px;padding-right:1px}}@media only screen and (min-width:1008px){.html-embed.component .quote.component{margin-left:-82.33px}}One of the biggest leaps forward in AI is to capture face and voice systems. The Chinese are using that by putting it in CCTV everywhereProfessor Dame Wendy Hall\nThe strengths and weaknesses of each region differ greatly. The US is more steeped in technological expertise and has the deep pockets of Silicon Valley. Most of the technology revolves around automation, typically with the goal of cutting cost or generating revenue. This has seen human jobs replaced by AI to cut costs or time. Companies have created AI designed to do a better job at sentencing prisoners than judges, and many job interviews are now conducted using AI-fuelled programmes to cut HR budgets.\nAmerican company HireVue claims to be able to detect whether a person's facial movements and tone of voice - along with their CV - make them right for the job, based on the personality traits they are looking for.\nLoren Larsen, HireVue's chief technology officer, said: \"The computer is better at asking questions that can predict whether the person is the right candidate or not, and it is more consistent. In the end, the machine is better at predicting performance - you are better off being hired by a machine.\"\nIn contrast, China is embarking on large-scale projects that could help it create smart cities and nationwide surveillance. One of the hubs of this research is a testing facility run by the telecoms giant Huawei in Beijing.\nThe building, a marble palace with gleaming white walls, high ceilings and large moving screens, would not look out of place in Blade Runner. Here, the company demonstrates smart government systems that can monitor a city in real-time from a computer screen, including emergency services, along with power and communications networks.\nIt also has a headquarters in Shenzhen, teeming with young, educated and tech-savvy workers from China's provinces and abroad. With an average age of 27, university graduates from all over China and abroad are flocking to the city, which boasts a GDP higher than Hong Kong.\nJust 30 years ago, the \"greater bay area\" as the locals describe it was just a fishing village. Everything in Shenzen has been built to attract young people, with flashy hotels, restaurants and rooftop bars where groomed couples wear western brands like Chanel and Burberry, drink French wine and live in plush high-rise apartments in an otherwise sparse landscape.\nCompanies like Huawei, Baidu and iFlytek offer similar perks to those on offer to the Silicon Valley crowd.\nIn Baidu's case, the company has taken a leaf out of Google's book to try to attract talent. Upon entering Baidu's Shenzhen headquarters you are met with a life-size robot that welcomes you to the lobby. Staff enter using facial recognition technology so there is no need for a pass.\nWith AI talent in short supply, its biggest tech companies are attempting to break from China's corporate culture and take inspiration from California. Staff can relax in sleep pods in large golf-ball shaped rooms, and climbing walls are dotted around the office. However, unlike Google, there is no free food, an employee admitted.\nChinese technology companies are now facing geopolitical challenges as Donald Trump strikes an increasingly protectionist tone. US phone carriers have been blocked from selling Huawei phones over espionage fears, and earlier this month Trump blocked\u00a0what would have been the biggest tech merger in history, between US-based Qualcomm and Singapore's Broadcom.\nThe move was largely borne out of\u00a0fear that China may become too big\u00a0of a presence in setting standards for new mobile networks. The US feared Qualcomm being taken over would stop it putting cash into developing 5G, leaving the door open for Huawei to step in and generating security concerns.\nHuawei sources said they were surprised by Trump's interference and pointed out that the UK has been working with Huawei for more than 10 years, and has not suffered a breach of national security\u00a0yet. China has also\u00a0earned something of a reputation\u00a0for being a copycat when it\u00a0comes to tech. Most major US internet companies are blocked from the country and its Chinese counterparts are seen as merely imitators. But when it comes to AI, China's human rights history may give it the edge.\nIt is hard to find a square mile in built-up China without a CCTV camera. The country's most popular chat app, WeChat, creates a credit rating score by analysing everything that users do on the social network. Most things are monitored, and this information is collected - all of which is ripe for feeding into computers. Professor Dame Wendy Hall, who advises the UK Government on AI and lectures at Tsinghua University in Beijing, said: \"The biggest difference is privacy versus surveillance. One of the biggest leaps forward in this fourth wave of AI is to capture face and voice systems, and the way the Chinese are using that by putting it in CCTV everywhere.\n\"The advantage China has is that you could design a city that works for people in a way that we can't, including automated cars or make shopping experiences better according to who they are, or offices\u00a0telling someone where to go for\u00a0a meeting. It is a very interesting moral dilemma.\"\nDr Weller of the Turing Institute, says: \"There is a sense that China is less concerned about privacy and this might push it forward a little faster in some areas where we can't access data.\n\"It's not clear what the right policy is, but it is interesting as an international community to look at what other people are doing and learn from it. Overall though, we must use this technology to benefit all.\"\nIn Beijing, a coach driver was asked\u00a0to make an unplanned stop on\u00a0the road for passengers to jump off. He refused, waving\u00a0towards one of the several security cameras pointed at the street, speaking frantically in Chinese. A translator explained his concern: \"They can scan our faces,\"\u00a0he said.\nThe West might need\u00a0to\u00a0consider whether\u00a0this scenario is one its citizens would be happy with, should it try to\u00a0compete.\n"},
{"docid": "137 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "February 17, 2018", "title": "Amazon, Google, Netflix and other FANGS: where next for super-profits?\n", "content": "The technology giants Facebook, Amazon, Apple, Netflix and Google have dominated the American stock market's growth for the\u00a0past five years. But can their\u00a0 pre-eminence continue?\nFacebook's share price has risen by 364pc since the company floated in 2012, while holding Netflix shares for the past 10 years would have given you a 6,520pc return on your investment. Over the same period Alphabet, Google's parent company, has returned almost 300pc, Apple 814pc and Amazon 1,800pc.\nHowever, investors are now questioning whether this rate of growth is sustainable. The most recent earnings announcements from the tech giants, collectively known as the \"Fangs\", contained some worrying signs.\u00a0\u00a0\nWhile the Fangs are still growing, there are concerns about individual companies: Facebook's ability to grow its user base, for example, or whether the smartphone market has become too mature for Apple's exponential growth to continue.\nProfessional investors are selling. Walter Price, manager of the \u00a3326m Allianz Technology Trust, is one.\u00a0\n\"It is almost inevitable that their growth is going to slow as they have got so big,\" he said. \"When it comes to the Fangs we are more enthusiastic about Amazon and Netflix and a bit less enthusiastic about Facebook and Google.\"\n                   Buy these seven shares to profit from driverless cars and artificial intelligence                   \nMr Price has recently sold some of his Apple holding on the basis that the smartphone market is now too well developed. Last year Apple was among his top 10 holdings but it no longer features there.\u00a0\nThe Allianz manager is not the only one to have concerns about Apple's future growth. Sales of the most recent iPhone X model missed market expectations when volumes of new  iPhone sales fell by 1pc at the end of last year . Some put this down to the hefty $999 (\u00a3710) price of the device.\nFacebook has come under the spotlight because of reports that users are spending less time on its platform . It has also come under fire for the damaging mental health effects of using the website, leading it to overhaul its newsfeed.\nMr Price said he expected this overhaul to take up Facebook's resources in the coming months, but his main reason for reducing his stake was Europe's new wide-reaching data protection legislation. The EU's General Data Protection Regulation (GDPR) will force companies to be more transparent and get more approval for how they track customers.\n\"I think Facebook and Google do a lot of tracking of people without their explicit permission, and under GDPR they are going to have to ask permission and customers will have the ability to be untracked,\" Mr Price said. \"That will impose a bit of a slowdown and an additional cost for those companies in the next six months.\"\nNick Evans, a technology portfolio manager at Polar Capital, the fund group, is more upbeat about the tech giants' prospects.\u00a0\n\"We expect the pace of growth to gradually slow for all companies as they become larger, but what makes many of the best technology companies sustain such high levels of growth is that great products drive strong customer usage trends and the resulting pricing power drives strong revenue growth,\" he said. However, he is also investing in smaller, higher-growth companies.\u00a0\n\"We have many small and medium-sized companies which are growing faster and are much less well known than the Fang stocks,\" Mr Evans said. In particular he is looking at machine learning and artificial intelligence.\n\"If we are correct, the influence of artificial intelligence over the next three to five years is likely to accelerate technology disruption, stimulate growth and act as a continued tailwind,\" he said.\nMr Price is investing in \"cloud computing\" firms - those that exploit the trend towards services delivered online. \"It's hitting its sweet spot in growth and corporate acceptance,\" he said. \"Companies such as Microsoft have been big in this sector, as has ServiceNow, and Workday is seeing easier and faster growth in this environment.\"\nOne way to benefit from the growth of the tech giants without having direct exposure is to back companies that work with their products.\nFor example, Chris Ford, who manages the Smith & Williamson Artificial Intelligence fund, said he had invested in Roku, a platform through which you can access Netflix. Its software, which is built into some televisions and comes as an add-on with others, recommends content from different platforms, including Netflix, tailored to the user.\u00a0\nHe is also investing in growing regions such as Latin America. MercadoLibre, a website that combines features of eBay and Amazon, operates in the region.\n\"It is the ecommerce market leader in Latin America - it is much larger than anyone else,\" he said. Mr Ford pointed out that the ecommerce market was tiny in the region, at around 1pc of sales, compared with around 15pc in the West, providing huge potential for growth. MercadoLibre has also been tipped by our Questor column.\n"},
{"docid": "138 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "June 10, 2015", "title": "China's Baidu could beat Google to self-driving car with BMW; Chinese technology firm partners with BMW to launch new self-driving prototypes on to public roads in race with Google\n", "content": "Baidu - the search engine and technology company often called China's Google -plans to release a self-driving car with BMW by the end of the year.\nThe Chinese firm has been working on autonomous vehicles for the past couple of years, recently partnering with car makers including BMW.\nThe two companies announced a self-driving research project in April 2014, driving test cars around the complex highways of Beijing and Shanghai.\u00a0\nWang Jin, Baidu's senior vice president, told the China cloud computing services summit that the company would launch a new self-driving car with BMW in China before the year is out.\nThe prototype car will be used to test road-readiness of Baidu's technology, which will involve the car driving itself but still have human controls.The race for the roads\nGoogle recently unveiled a new series of prototype vehicles built from the ground up to be self-driving cars, having previously modified Lexus sport utility vehicles and Toyota hybrid cars for testing purposes.\nIts new car aims to completely replace human control with artificial intelligence, reducing controls to a destination selector and a start/stop button. A version with a human driver will be tested on public roads in the near future.\nBaidu is taking a more traditional route to the self-driving car. Its head of deep learning, Kai Yu, said last year that the technology it was developing was designed to assist drivers rather than replace them.\nThe Chinese firm has its own data-mapping service, which is a prerequisite to any automotive robotics project, and invested $10m in a Finnish mapping startup IndoorAtlas in September last year.\nIt also has undertaken extensive artificial intelligence research, including machine learning and the technologies needed for computer vision for cars and other robotics, rivalling those of Google.\nBut Baidu has one major advantage over its US rivals. Many of the driving-assisted vehicles on the road today, including the Tesla Model S, are technically capable of driving themselves.Legislative hurdles\nTesla's chief executive predicted that self-driving vehicles would be available to buy within three years during the unveiling of an \"autopilot mode\" for his Model S electric car, which will be capable of driving itself to a parking and charging spot.\nWhile the technology has yet to be proven, the major hurdle to autonomous vehicles on public roads is legislation.\nSeveral US states have allowed autonomous test vehicles on to public roads, which has allowed Google to test its cars for the last couple of years, but drivers must always be present and capable of taking over at any time.\nWhile the UK has a series of government-funded studies on the use of autonomous vehicles is underway, legislation lags technology in both the UK and US.\nA series of complex issues about who is to blame if something goes wrong, what an autonomous car should do in an emergency and extensive safety requirements have yet to be solved.\nChina and Baidu could steal a march on the West through flexible legislation. The Chinese government has more power to rapidly mandate the kind of wholesale changes that would be required to unleash self-driving cars.Pods, cars or self-driving taxis\nThere is still some debate over in what form self-driving cars will emerge. Automotive manufacturers are working on their own technology with the clear ambition of selling a traditional car that can drive itself - something Baidu seems to agree with.\nOthers are working on autonomous vehicles that could be seen as pool cars or a form of public transport, with driverless vehicles operating as shuttles or bus replacements.\nWhile Google's self-driving pods resemble the latter, Uber, for instance, is working on autonomous vehicles with the aim of running a taxi service that do not require human drivers.\n                     \u00b7 Google acknowledges its self-driving cars had 11 minor accidents                   \n                     \u00b7 Volvo to test autonomous cars with ordinary drivers on public roads by 2017                   \n"},
{"docid": "139 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "January 9, 2018", "title": "Who's a clever toy? Dogs go digital\n", "content": "CES in Las Vegas is the tech industry's biggest showcase for the latest gadgets and trends, attracting nearly 200,000 visitors over four days. It is known for its mix of serious and nutty devices and early highlights included: robots to befriend your dog Previously if your dog was lonely, you would buy him a canine companion or spend more time with him. In 2018 you can buy a robot friend-cum-surveillance device to monitor him while you are away.\nThe La\u00efka robot resembles a small, trundling plastic barrel, equipped with a camera, microphone and \"treat-tosser\". This \u00a3220 chew-proof machine will help to look after your pet while you're away, allowing you to see him, talk to him and dole out treats. You can control it using a mobile app, or put it into autonomous mode when you're busy. It is paired with a tracker on the dog's collar and endeavours to keep him entertained by following him around, playing games. It is powered by artificial intelligence and, according to creators, the French start-up Camtoy, the algorithm adapts to your dog's personality, learning what's best at keeping him stimulated.\u00a0\nMeanwhile, California startup Anthouse's robotic dog companion Buddy+ resembles a small tank equipped with a tennis ball launcher for games of fetch. The company behind Petcube, a treat-dispensing connected camera, has new pet-detection technology that uses artificial intelligence to \"recognise pets, trigger recording of pet selfie videos and initiate two-way video calls\".\ngadgets for wine lovers French entrepreneurs have been shaking off the stereotype that their country is too traditionalist about wines.\nThe Caveasy One claims to be the first smart wine rack. The connected device can fit any cellar but the standard pack holds 100 bottles on 20 shelves and costs (EURO)594. It includes sensors to monitor the temperature and humidity of the cellar. You take a photo of each bottle's label on your phone and the app checks the wine against a database. Once the wine is in the rack, the app alerts you when it reaches its peak and a light in that bottle's slot is illuminated. It also offers recommendations for purchases and can suggest food pairings.\nAnother French device, the $200 Aveine pouring gadget, starts with the same label-scanning principle and claims to offer the perfect degree of aeration for each bottle instantly. Once you've taken a picture of the bottle with your phone, you insert the paired device over the bottle's mouth and pour.\nThe Coravin device has had a \"smart\" makeover.\nIt passes a thin needle through the cork of a bottle, and allows you to pour wine, replace the lost volume with inert gas and reseal the bottle as if it had never been opened. The $1,000 Coravin Model Eleven works with an app that recommends pairings for individual bottles and provides \"cheatsheets\" of what to say to wine merchants to secure the best bottles.\nshort story machine The creators of a machine that dispenses short stories on strips of receipt-style paper at railway stations, airports and university campuses are hoping to bring the devices to Britain.\nThe French founders of the Short Edition project say the free tales, dispensed as one, three and five-minute reads at the push of three buttons, appeal to those who value the escapism of putting their phones and tablets down and reading something they can physically hold. The stories, which are issued at random from a database of about 5,000, include some classic literature but are mostly the work of contemporary writers. The devices are already popular at stations in France.\nairbags to protect from falls A belt for the elderly that deploys airbags to protect their hips in a fall was one of the most attention-grabbing exhibits, as reporters and volunteers took tumbles to check that it worked. It did.\nHelite, the manufacturers of the $800 Hip'Air device, claim that it will absorb 90 per cent of the impact whereas ordinary hip protectors, which resemble padded underwear, absorb only about 10 per cent. The belt is lightweight and fairly slim before the bags are deployed.\nAccording to the makers, a typical fall takes 400 milliseconds. Using built-in gyroscopes and accelerometers, the belt can detect one within 200 milliseconds of it starting. It then deploys two airbags, which takes 80 milliseconds. It will be available from March.\nwearable tech to ward off sun L'Or\u00e9al has a device stuck on the thumbnail that monitors how much UV light the wearer has been exposed to and provides advice. It is supposed to encourage \"sun-safe behaviour such as reapplying sunscreen or moving into the shade\". UV Sense can provide realtime information and store up to three months of data, showing trends. It is less than 2mm thick and 9mm in diameter. The thumbnail is the best place to measure sunlight, L'Or\u00e9al says.\nOnce you've taken a multiple-choice test on your individual skin type, the app will give you a running score to tell you if you're spending too much time in the sun. It will also recommend L'Or\u00e9al sun-care products for you. The gadget will be sold in the US this year and Britain next year for under $50.\nsmart showers Alexa may soon be joining you in the shower. At least two smart showers from the Elmer and Moen brands are compatible with Amazon's voice assistant, meaning users can address the artificial voice to ask her to start running the water or turn up the temperature. Rather than fumbling with tap fittings people will be able to say \"Alexa, stop\" before stepping out of the shower.\n"},
{"docid": "140 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "March 11, 2017", "title": "The robots with artificial irreverence; Stage debut beckons for machines programmed to learn the nuances of improvised comedy, Oliver Moody writes\n", "content": "Picasso's wife walks into the studio one day to find him watching a television show about a new-fangled computer and painting a portrait of its presenters with what smells distinctly like rendered sardine fat.\n\"Pablo, what is this?\" she says. \"Oh,\" he replies, \"I'm going to call this one 'AI': arty fish oil in telly gents.\"\nIt's a dreadful joke. Yet it is nothing like as bad as some of the gags that two real artificial intelligence programs devised in an experiment that is taking the machine revolution into its toughest territory yet: improvised comedy.\u00a0\nAt the end of this month two performers and their robots will stand on stages in London and Edmonton, Canada, for a video-linked duet of the one art form that computers have struggled to master.\nTheir digital partners, known as Alex and Pyggy - short for Pygmalion, after the sculptor who fell in love with his statue of Aphrodite - have learnt the craft from a database of tens of thousands of English subtitles for foreignlanguage films.\nUsing speech-recognition software, the programs compare the lines that are fed to them with lines of cinematic dialogue and try to work out an appropriate response, word by word.\nThe results, articulated through voice synthesis software on an Apple Mac, are often surreal non sequiturs. During one demonstration of Alex at the British Academy last month, his handler said that they were on a first date and thanked the machine for bringing him a present - a holiday for two in Iceland. The computer replied: \"When it is said, if you see a woman or a priest, you'll have to buy me a stick.\"\nAt other times the answers come out in a barely coherent form of English, a problem that has dogged previous attempts to marry the statistics-crunching power of artificial intelligence with the mess of nuances and intentions that make up conversational language.\nAt another performance in Canada, one of the AIs implied that she was having an affair with an old man. \"What's going on?\" the performer asked. \"I can't tell you,\" she replied, \"the more I can be the reason for me to be responsible for the end of you.\"\nJust occasionally, however, the software sounds almost human. \"There was a scene in the earlier days, when the speech recognition would pick up a bit early on in my dialogue and not give me enough time to seed it with words,\" said Piotr Mirowski, a French-Polish data scientist who will perform the London end of the show. \"My suggestion was to do a dating scene and I told it: 'I'm sorry, I just got us two tickets to go to the Royal Opera House.' It said: 'I don't want to carry on with this conversation. I'm going to call the police.'\" Computers have beaten world champions at chess, cards, quiz shows, Space Invaders and Go!. Comedy turns out to be a different proposition. There are no obvious rules, and while Google's machines have more or less got the hang of translating between Spanish and English, the mess of wordplay, double entendre and surrealism that makes up humour is proving altogether more elusive.\nAnother kind of conversation program, known as a chatbot, can occasionally hoodwink people into thinking it is human. In 2014 one of these strings of code even passed the Turing test, persuading a third of the judges at the Royal Society that he was a 14-year-old Ukrainian boy called Eugene in a series of brief exchanges, largely through a mixture of jokes, rudeness and frenetic changes of subject.\nMany computer scientists say that this is little more than a cheap trick that falls apart in the face of simple questioning.\nAlex and Pyggy may be less convincing at the moment, but Dr Mirowski, 38, said that they were a better reflection of the challenges that artificial intelligence would have to overcome before it could match humans in language games, such as working out grammar and context for itself.\nHe compared computer imitations of poetry with the real thing. \"In one case you're basing the text that you write on the meaning of your emotions and the kind of extremely complex factors that go into it,\" he said. \"In the other, you're literally relying on statistical patterns. They do 95 per cent of the job, but it's the 5 per cent that's missing which is so difficult.\"\nBinary 2 will be performed on March 31 and April 1. For tickets go to www.tristanbatestheatre.co.uk.\nMarch of the computers\nThe first computergenerated science fiction film, Sunspring, was shown last year at a festival in London. The AI, Benjamin, came up with its own plot, dialogue and music. Movie critics, however, said that all three were terrible.\nEven sophisticated audiences of classical music listeners have been unable to tell the difference between the genuine work of JS Bach and a series of imitations written by a program called EMI.\nIn 1996 a chess computer called Deep Blue beat the world leader, Garry Kasparov. In 2011 IBM's Watson overcame two past champions at Jeopardy, an American quiz show. In 2015, AlphaGo beat Lee Sedol, the South Korean Go! champion, at one of the last bastions of human supremacy, board games.\nThe machines triumphed at Texas Hold'em, a form of poker that depends on bluffing, in January.\n"},
{"docid": "141 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "January 6, 2017", "title": "The Guardian view on AI in the NHS: not the revolution you are looking for; Computer systems may not replace doctors or nurses. But even to replace support staff would be a huge change\n", "content": "The news that two healthcare trusts in London are to experiment with a system to look up symptoms by text message, to triage the kind of non-urgent queries at present handled by the NHS 111 service, raises many questions. They may not seem urgent when people are dying in the corridors of an NHS hospital for want of money, but in the long term they are just as important. Some are purely medical: is this an area that requires the attention of a human being, or is it one where purely factual answers will suffice? When will this project start using artificial intelligence? Some have to do with the way that the NHS is being privatised around the edges in ways that disadvantage the central public parts of it. Widest of all is the general question of the automation of brainwork, which might have effects quite as gigantic as the replacement of manual labour by technology has had.\u00a0\nTwo kinds of claims are made for AI in medicine. The weaker and more plausible is that it can automate the processes where no judgment is required, only the clear and consistent following of well-understood rules. This kind of thing is what the 111 service is supposed to do: the question that it answers is not \"what's wrong with you?\" but \"do you really need to see a doctor?\" Some triage is necessary in any healthcare system, and the present system in the NHS is under huge and growing strain.\nBut the wider claim of healthcare automation is that there will be systems that can augment and eventually replace the judgment of trained human beings. The hope is that deep analysis of unimaginable quantities of data will yield reliable knowledge superior to anything that unaided humans can produce. The placebo effect is important in medicine, and people who believe they are being treated by doctors who have the help of almost omniscient computers will probably do better than those who feel they are getting the harassed attention of an overworked GP even when the diagnosis and the remedies prescribed are exactly the same, as in most cases they will be. But that is not the basis on which we are promised a revolution in the delivery of healthcare. The revolution may come anyway: we are living through an enormous expansion in the reach and variety of machine learning systems, but it will not be for some time. The great majority of diseases do not require heroic diagnosis and exceptional treatment so much as the humane application of well-understood treatments. Much of what's wrong with the NHS is a lack of money rather than sophistication. Even urgent large-scale threats such as the emergence of antibiotic-resistant pathogens don't need artificial intelligence to avert, only the consistent use of the intelligence we already have.\nIt is the apparently small-scale automation of clerical work that we need to think about, because that might happen as quickly as the spread of smartphones did. Vast areas of bureaucracy are about the reduction of complex problems to simple ones for which the correct answers can be written down in a flow chart. This is artificial stupidity rather than artificial intelligence, but the two can merge inside computer systems to produce huge social change. Once the work has been broken down into simple algorithms, these can much more easily and quickly be followed by machines. The 111 service in north London is only one example of a much wider phenomenon. A Japanese insurance company has just replaced 35 claims processors with IBM's Watson expert system. The Japanese government is preparing to automate the responses to parliamentary questions in a similar way. These are the first signs of a process that may annihilate millions of white-collar jobs in the same way that blue-collar jobs have already disappeared across the developed world. That would be a development to make last year's political upheavals look like the mere premonitory tremblings of a real earthquake to come.\n"},
{"docid": "142 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "July 3, 2015", "title": "Robot grabs factory worker and kills him\n", "content": "A factory worker has been picked up and killed by a robot in Germany in an incident that could raise fresh anxieties among those worried about the impact of machines on humans.\u00a0\nThe victim was a contractor installing a machine at a Volkswagen factory when he was lifted up by a robotic arm and crushed against a metal plate.\nThe 21-year-old man suffered fatal chest injuries. It is thought that the robotic arm, which is designed to lift machine parts and manipulate them, may have picked him up because he was standing inside the production cage in which the robot works.\nProsecutors have opened an investigation into the incident, and have not yet decided whether to take further action against VW.\nA total of 15,000 people work assembling gear-boxes and other motor parts at the plant at Baunatal, near Kassel, central Germany.\nThe factory has computer-steered robots deployed on most of its produc-tion lines, making it one of the world's most automated carmakers.\nOverly powerful robots have long been the fodder of science fiction, with fears about machines going rogue being voiced by inventors and scientists from Elon Musk to Stephen Hawking.\nMr Musk, the billionaire inventor, donated $10 million this year to the Future of Life Institute to fund research aimed at keeping artificial intelligence \"beneficial\" for humanity.\nAbout $7 million of that has now been split between 37 research projects.\nOne of those is a project led by Carnegie Mellon University, which intends to ensure that artificial intelligence systems are forced to explain their decisions to humans.\nMr Musk, 44, has been outspoken in his criticism of his friend Larry Page, the co-founder of Google, who he fears is on the verge of creating dangerously powerful robots.\nYet despite the current concerns, deaths at the hands of robots in factories are not a recent phenomenon. There have been 34 robot-related deaths worldwide in the past 30 years.\n"},
{"docid": "143 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "June 27, 2012", "title": "Google creates an artificial mind, and all it thinks about is cats ...\n", "content": "Google has been deeply involved in the field of artificial intelligence since its inception. Now the internet search giant has made what is being heralded as a significant breakthrough in the field: an artificial brain that has taught itself how to recognise cats.\u00a0\nThe project could mark an important advance in the effort to create machines that are able to interact with the world - by recognising shapes and objects - as effortlessly as humans do.\nA Google team connected 16,000 computer processors to create a \"neural network\" with more than one billion connections.\nIt turned out that this \"Google brain\" behaved in a manner that mirrored the habits of many human internet users: it became obsessed with pictures of cats.\nThe researchers fed the machine random images plucked from 10 million YouTube videos. Despite none of the images being labelled as feline, the Google brain constructed a kind of ghostly abstract model of a cat after being bombarded by millions of pictures.\n\"We never told it during the training, 'This is a cat',\" Jeff Dean, a Google scientist, said. \"It basically invented the concept of a cat.\"\nBy the end of the experiment the Google brain recognised three quarters of the cats that it was presented with, from a collection of 20,000 objects.\nIt also proved sensitive to human bodies and faces and performed more than twice as accurately as any previous neural network, according to The New York Times. The researchers who conducted the experiment believe that the process may have mirrored what happens in the human visual cortex, which is the largest system in the human brain and is responsible for processing visual images.\nRecognising a cat may sound like a trivial thing, but in the world of artificial intelligence it is significant.\nExperts sometimes refer to \"Moravec's paradox\".\nThis is an expression of a counterintuitive truth: that training machines to do things that are easy for humans (such as recognising a cat) is often far harder than training machines to do tasks that humans can find challenging (such as playing chess).\nHans Moravec, an expert in robotics at Carnegie Mellon University, in Pittsburgh, said: \"It is comparatively easy to make computers exhibit adult level performance on intelligence tests or playing checkers, and difficult or impossible to give them the skills of a one-year-old when it comes to perception and mobility.\"\nThe Google brain appears to be the first artificial neural network to identify objects without hints from a human supervisor, but it has a long way to go before it matches the human brain.\n\"It is worth noting that our network is still tiny compared to the human visual cortex, which is a million times larger in terms of the number of neurons and synapses,\" the researchers wrote.\nThe technology has been developed in Google's X Lab, a secretive facility led by Sebastian Thrun, a guru in the field of artificial intelligence. Among Professor Thrun's other projects are Google's driverless car. He has also worked on Google Glass, a pair of spectacles that displays data from the web in front of a user's eyes.\n"},
{"docid": "144 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "May 11, 2004", "title": " Christopher Longuet-Higgins\n", "content": "\u00a0\n Dr R. B. Mallion writes: I was surprised to find that \"artificial intelligence\" was mentioned in the obituary of Christopher Longuet-Higgins (April 22). The opening session of the 1974 Theoretical Chemistry Summer School in Oxford was dedicated to the memory of Professor Longuet- Higgins's DPhil supervisor (and mine), Professor C.A. Coulson, FRS (1910-74).\n Christopher Longuet-Higgins gave the address and I remember his speaking very witheringly about the frequently used term \"artificial intelligence\". He memorably stated: \"I believe that there is such a thing as natural stupidity, but I cannot credit the notion of artificial intelligence.\"\u00a0\n Eric Wetherell writes: While at Balliol, Christopher Longuet-Higgins had the initiative to found his own student orchestra, in which I had the privilege of playing first horn. He was a good and efficient conductor who sought out unusual works.\n One that we played was The Walk to the Paradise Garden. Always a Delius-lover, I asked him if I could conduct that item at the concert and he generously agreed. I had had no lessons in conducting at that time and indeed had never before conducted an orchestra. The result was not outstanding, I remember, but he was charm itself and congratulated me warmly.\n He would use idiosyncratic turns of phrase in rehearsal. On the rare occasions he made a mistake or a miscalculation in his conducting, he would stop and say, \"Oh! I made a nonsense.\"\n David Leibling writes: I was an undergraduate studying theoretical chemistry at Cambridge in the early 1960s. One morning Professor Longuet-Higgins came in to our lecture and said that he had just read something in one of the journals which had started him thinking about whether chemical reactions would be initiated by heat or light. He then proceeded to cover the blackboard with chemical formulae and mathematical equations which most of us struggled to comprehend. He concluded the lecture with a very simple summing up of the conditions necessary for each type of reaction. Within a few months these were published in the chemical journals and became known as the Longuet-Higgins rules. We undergraduates were witness to a discovery at the very boundaries of science.\n John Murrell writes: Christopher Longuet-Higgins and John Pople (obituary, March 24) were both members of the Cambridge theoretical chemistry department in the late 1950s and 1960s. Both made important advances in the applications of quantum mechanics and statistical mechanics to chemistry in the precomputer age, but they faced the development of the computer from the 1960s in different ways. Pople went on to develop computer programs for calculating the structures and energies of molecules that were easily used by practical chemists who were not experts in quantum mechanics, and received the Nobel prize for his work. L-H changed his interests to artificial intelligence (he coined the term cognitive science), and constructed computer programs to give an understanding of language and musical structure.\n If you would like to add a personal view or recollection to a published obituary, you can send your contribution by post to Times Obituaries, 1 Pennington Street, London E98 1TT; by fax to 020-7782 5870; or by e-mail to tributes@thetimes.co.uk\n\n"},
{"docid": "145 of 297 DOCUMENTS\n", "source": "The Daily Telegraph (LONDON)\n", "date": "July 20, 2007", "title": "Computer you can never beat at draughts\n", "content": "A COMPUTER program that cannot lose at draughts will be unveiled today.\nIn a development described as a \"truly significant advance in artificial intelligence'', scientists have created software that plays a perfect game.\u00a0\nThe achievement involved up to 200 computers running through 500 billion billion potential draughts positions over 18 years. Dr Jonathan Schaeffer and colleagues at the University of Alberta, Canada, announced the completion of the software, called Chinook, in a research paper published in the journal Science.\nDr Schaeffer began work on the project in 1989, with the aim of winning the world draughts championship.\nWith the help of human players, he created software to allow a computer to learn the best move through heuristics - learning through trial and error rather than by following set rules.\nDozens of computers were used in combination to run through the different possible sequences of moves.\nThe program lost in the world championship in 1992, but went on to win it in 1994 after refinements to the software. It remained undefeated until it \"retired'' in 1997. Dr Schaeffer and his colleagues continued to make changes until this year when they finally succeeded in making the program unbeatable.\nOf course, if an opponent also plays perfectly, he or she could force a draw. Dr Jaap van den Herik, editor of International Computer Games Journal, said: \"This is a tremendous achievement-a truly significant advance in artificial intelligence.''\nDr Schaeffer said: \"It's an exciting demonstration of the possibilities that software and hardware are now capable of achieving.''\n"},
{"docid": "146 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "May 17, 2017", "title": "Email your statement to police, victims are told\n", "content": "One of Britain's biggest police forces is to ask victims of crime to write their own witness statements and submit them by email.\nWest Midlands police will offer \"selfreporting\" for less serious crimes such as criminal damage, shoplifting and driving off without paying for petrol.\u00a0\nDave Thompson, chief constable, said that the service was intended to increase efficiency but added that the more \"convenient\" method was likely to result in more crime reports.\nHe said that the system would be used only for \"simple\" offences and never for burglaries or violent crimes. Victims would have a choice and could speak to officers by phone or in person should they wish. Officers would still be sent to speak to vulnerable victims. In the coming months, members of the public who ring 101, the non-emergency line, will be informed about the selfservice option. Victims may also be encouraged to upload security camera footage and other images to police.\n\"We'd never say, 'do your own interview' but quite a lot of the public can do things to help us,\" Mr Thompson said. \"There's no reason why you couldn't put down your recollection of what happened. There's space for the public to play a greater part and there's a need for the system to simplify.\"\nSome members of the public were \"just as capable\" as police officers of writing basic statements about simple crimes.\nHe said that the police needed to modernise and should also consider further use of artificial intelligence.\nOfficers in Durham will soon use artificial intelligence to determine whether a suspect should be kept in custody or released on bail. Mr Thompson said that the same technology could potentially be used for webchats and to answer frequently asked questions.\nHe said that the police service had faced swingeing cuts but was continually being asked to do more. There was an \"inexhaustible pit\" of vulnerability and a danger that a bigger share of police resources would be focused on increasingly few people.\nMr Thompson said that police would \"of course\" continue to investigate child sexual exploitation and other significant matters of vulnerability. However, the service was taking on many other problems, including rising numbers of missing people and mental health issues. He stressed that police should not rule out investigating any crimes.\n"},
{"docid": "147 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "May 19, 2016", "title": "App replies to texts ... and books dinner\n", "content": "It has been said that debate is the death of conversation. Perhaps Google is adding to that debate after announcing that its new messaging app would now suggest possible replies and suitable pictures - and even captions for those images.\u00a0\nWhile the market is already saturated with messaging services, including Apple's Messages and Facebook's WhatsApp and Messenger, Google wants its new Allo service to be smarter than the average messaging service - or maybe even the average user. Google gave a taster of its new Allo app, which uses artificial intelligence technologies to analyse what the user is saying and suggest replies to save them the bother of typing.\nIt will also cast a digital eye over photos and suggest replies based on what it \"sees\". For example, if someone sends a photo of a university graduation ceremony, Allo will offer a \"Congratulations\" or \"Well done\" reply. Amit Fulay, the Google product manager who oversees Allo, said: \"Where this gets really powerful is when you can bring the assistant into group conversations.\"\nFrom inside Allo, users can interact with its search engine as they chat with others. While trying to arrange a dinner, the bot can be asked for restaurant suggestions and even to make a reservation. It will run on iPhone and Android phones and is due to become available in the summer.\nSundar Pichai, chief executive of Google, said: \"Computing is poised to evolve beyond just phones. it will be about the context. On phones, in cars, in your homes.\"\nThe company's aim for the future was to build each user \"their own individual Google\" by using context to understand more of the things people ask it. \"Machine learning and artificial intelligence are to be more assertive,\" he said.\n"},
{"docid": "148 of 297 DOCUMENTS\n", "source": "The Sunday Telegraph (London)\n", "date": "August 27, 2017", "title": "Killer robots 'inevitable' in military and ban would be ignored, says general; Former head of Joint Forces Command says outlawing of autonomous weapons would be futile\n", "content": "THE rise of military \"killer robots\" is almost inevitable and any attempt at an international ban will struggle to stop an arms race, according to a former defence chief responsible for preparing for the future of warfare.\u00a0\nThe potential advantages of artificially intelligent war machines that can make decisions, learn and open fire without human control will see countries face growing pressure to adopt the technology, despite ethical misgivings.\nGen Sir Richard Barrons told The Sunday Telegraph that a pre-emptive international ban such as the one called for by technology luminaries last week is only likely to be flouted by unscrupulous countries. The retired senior officer spoke after more than 100 technology leaders wrote an open letter calling on the United Nations to outlaw so-called lethal autonomous weapons. Campaign groups have also warned the technology will lead to more civilian casualties and abuses.\nSir Richard until last year led the UK's Joint Forces Command, which has responsibility for preparing for future conflicts. He said the military was facing a revolution based on technology set to transform the civilian world.\nTechnology experts predict artificial intelligence will soon be used to make flying drones, armoured vehicles and submarines that can find and recognise targets, make decisions on whether to open fire and learn as they go.\nKalashnikov, the Russian arms manufacturer, last month announced a machine gun-armed \"fully automated combat module\" it claimed can identify targets and make decisions on its own.\nElon Musk, the chief of Tesla, and 115 robotics and artificial intelligence experts warned in their letter that robots would lead to wars \"at a scale greater than ever, and at timescales faster than humans can comprehend\".\n\"We do not have long to act,\" they wrote. Once this Pandora's box is opened, it will be hard to close.\"\nBritain has said its weapons will always maintain human control.\nSir Richard, who retired last year, said: \"If you ask the Ministry of Defence here, they will say as a matter of policy we are not going to do autonomous capability. There will always be a man in the loop. But if you ask other people around the world, they don't have the same value struggle.\n\"Even if you don't plan to have this capability yourself, you are going to have to deal with the fact that machines are going to turn up that are designed to be lethal and there's no man controlling them at the time.\"\nCivilian firms building driverless cars and computer networks that can learn are already well ahead of defence giants, robotics experts believe.\n"},
{"docid": "149 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "November 18, 2015", "title": "'It was the first time I realised I was different' - a UK migrant's story; Mohamed Mahyoub speaks about his experience moving to the UK and what needs to be done to help migrants succeed at work\n", "content": "                     Mohamed Mahyoub came to the UK from Yemen as an immigrant                     in 2005,                      aged 14. He now works as a technical lead at a business skills training provider and is studying for a PhD in artificial intelligence. He is also the founder of Native Start, an organisation to support Yemeni and Arabic comm                     unities in the UK, and in 2015 won the Young Adult Learner of the Year Award.                   \n                     I came to the UK as a child to better my life. I moved here with my grandad. Before I came here I didn't know much about the UK, but I hoped it would be a safe place for me. You hear a lot in the news about the UK's poor treatment of immigrants, and about people having scary experiences when they do come here, so I wasn't sure what to expect.\u00a0\n                     When I arrived, it was the first time I realised I was different. It was difficult when I first arrived and it took time for me to settle in. Gradually I became more understanding of different cultures and I came to accept others who are different. In the end you hope everyone just becomes more accepting of one another.\n                     For me, the difficulties started in school. I didn't really know any English, so that was very hard. I used to carry a dictionary round with me to every lesson, and I had to look up words just to ask a question.\n                     But once I learned English, things got easier.  When I was in college I started working at my uncle's newsagents because no other place would accept me. But once I got A-levels and my English improved, I started working as a web developer. Then I went to university, which included a year in industry to work, and I started up my own business to support refugees in the UK. After that I went back to university to study for a PhD in artificial intelligence. I'm currently working full-time as a technical lead in computing, while studying for a full-time PhD as well.\n                     The recognition you get in this country motivates you to succeed.  What's so great about the UK is that as soon as you learn and you achieve, you get recognition. It pushes you and motivates you to succeed. As soon as you break the language barrier, things get much easier and you can achieve a lot.\n Related:  There's plenty more space for humanity on this 'tiny' island | Zoe Williams\n                     Most migrants come to the UK with skills, but they don't get the opportunity to use them.  Many immigrants have a degree and other qualifications but because of the language barrier, they can't compete with English speakers. So they end up working in low-paid jobs. Then their English improves to a stage where they can compete after about five years, but by that stage it is too difficult for them to go back to working in that field. So they then stay in those low-paid jobs because they're used to it and it's what they do.\nFor example, my uncle came to the UK with a masters degree in computing but ended up working in a newsagent.  He wasn't able to express himself in interviews. He also wanted to study further, but he couldn't so he ended up working in a low-skilled role. He eventually owned the newsagent and managed it full-time.\n                     We need some sort of strategy to make the most of these highly-skilled people. Help from the government in terms of professional development for refugees would be good. For example, providing them with relevant work experience. This will give them a route to change their lives.\n                     When you come to the UK as an immigrant, you come with a mission to better your life. You have a motivation to work hard and support your family. There's a reason why you would make the effort to move abroad. Where I came from it was just so difficult to get an education and even then there wasn't any reason to push yourself as there weren't any job opportunities.\n                     I feel lucky that I've had the opportunity to change my life, to give back to society and contribute to the world. You feel very grateful to the country that allowed you to make this change. And you want to give back to that country, you want to keep coming back to the idea of giving back. As a child, the UK opened my eyes to the world.\n                     Looking for a job? Browse Guardian Jobs or sign up to Guardian Careers for the latest job vacancies and career advice                   \n"},
{"docid": "150 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "February 22, 2018", "title": "Is artificial intelligence a threat to civilisation?\n", "content": "Artificial intelligence risks being exploited by terrorists to mount driverless car crashes and cyber attacks because the technology is being rapidly developed without thought for its downsides, Oxford and Cambridge researchers have warned. Dr Shahar Avin, part of the research group, explains the risks we face today and could face in the future.\u00a0\n                   Video block text                 \u00a0\n"},
{"docid": "151 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "December 18, 2017", "title": "Artificial intelligence will detect child abuse images to save police from trauma\n", "content": "Artificial intelligence will take on the gruelling task of scanning for images of child abuse on suspects' phones and computers so that police officers are no longer subjected to psychological trauma within \"two to three years\".\u00a0\u00a0\nThe Metropolitan Police's digital forensics department, which last year trawled through 53,000 different devices for incriminating evidence, already uses image recognition software but it is not sophisticated enough to spot indecent images and video, Mark Stokes, the Met's \u00a0head of digital and electronics forensics,\u00a0told the Telegraph.\u00a0\n\"We have to grade indecent images for different sentencing, and that has to be done by human beings right now, but machine learning takes that away from humans,\"\u00a0he said. \u00a0\n\"You can imagine that doing that for year-on-year is very disturbing.\"\u00a0\nThe force is currently drawing up an ambitious plan to move its sensitive data to cloud providers such as Amazon Web Services, Google or Microsoft, Mr Stokes said.\u00a0\nThis would allow specialists\u00a0to harness the tech giants' massive computing power for analytics. The Met currently use a London based data centre but the sheer volume of images along with the popularity of high resolution video is putting pressure on resources.\nWith the help of Silicon Valley providers, AI could be trained to detect abusive images \"within two-three years\", Mr Stokes said.\nThe Met's digital forensics team uses bespoke software that can identify drugs, guns and money while scanning someone's computer or phone.\u00a0 But it has proven problematic when searching for nudity.\u00a0 \"Sometimes\u00a0it comes up with a desert and it thinks its an indecent image or pornography,\" Mr Stokes said during the\u00a0(ISC)2 Secure Summit in London.\u00a0\n\"For some reason, lots\u00a0of people have screen-savers of deserts and it picks it up thinking it is skin colour.\"\u00a0\nHanding this work over to computers could save forensics specialists who spend their career trawling through pictures from psychological strain.\u00a0\nBut the mammoth task of\u00a0moving\u00a0the Met's data into the cloud is a legal minefield due to the sensitive nature of the files the force stores.\nPolice staff are granted consent from the courts to store criminal images, but it is an offence for anyone else - including\u00a0Amazon, Microsoft or any cloud provider to store them. Providers would be taking on an incredible risk associated with storing this material.\n                   AI timeline                   \nStoring data in the cloud is a controversial move thanks to a series of high profile hacks, including a widespread Apple cloud breach where several celebrities' personal photos were stolen and distributed on the web.\u00a0\nBut Mr Stokes said that despite concerns, the likes of Google and Amazon might be best placed to keep police information watertight thanks to their huge profits, which unlike government departments, can be\u00a0invested in talent, expertise and ensuring they are using the most advanced technology.\u00a0\nWith those concerns in mind, Mr Stokes said providers have offered some solutions,\u00a0which are\u00a0currently being written into a potential IT plan.\n\"We have been working on the terms and conditions with cloud providers, and we think we have it covered,\" he added.\nIt's just the latest in science fiction-esque additions to the police force. It emerged in October that robocops may\u00a0replace British bobbies on the streets .\n"},
{"docid": "152 of 297 DOCUMENTS\n", "source": "The Independent - Daily Edition\n", "date": "February 13, 2018", "title": "Artificial intelligence 'can detect Isis videos even before they are uploaded'\n", "content": "Artificial intelligence technology that can detect Isis videos and prevent them from being uploaded is being released to stop the spread of the \"poisonous\" material.\nDevelopers funded by the Home Office are sharing their software for free with any website or app in the world in the hope it will make the terrorist group's propaganda harder to access and share.\nTests suggest it can detect 94 per cent of Isis videos and makes so few mistakes that a single person could moderate borderline cases for the whole of YouTube.\u00a0\nDr Marc Warner, chief executive of ASI Data Science, told The Independent the technology's success depends on how many companies build it into their systems but \"we hope that this can play its part in removing extremist content from the web\".\n\"Lone-wolf attacks are hard to spot with conventional surveillance - it is a difficult problem if someone is radicalised in their bedroom,\" he added. \"The way to fight that is to cut the propaganda off at the source. We need to prevent all these horrible videos ever getting to the sort of people who can be influenced by them.\"\nSecurity services have been sounding intensifying warnings over online or \"remote\" radicalisation amid a record number of terror arrests in the UK. A report by the Independent Reviewer of Terrorism Legislation said the phenomenon made threats \"acutely difficult to spot\", in the wake of five attacks in London and Manchester.\nAndrew Parker, the head of MI5, has said companies have an \"ethical responsibility\" to help confront an unrelenting threat from people who can \"accelerate from inception to planning to action in just a handful of days\".\nIsis propaganda has been linked to numerous plots in Britain, as well as driving the exodus of more than 800 men, women and children to its self-declared \"caliphate\".\nThe terrorist group's sophisticated output has ranged from gory execution videos to attack instructions, bomb-making guides, calls to arms, ideological teachings and rosy depictions of life inside the so-called Islamic State. More than 1,300 videos released by its central media office since 2014 were analysed by ASI, which identified \"subtle signals\" that can be used to identify new Isis videos before they are published.\nThe indicators used by the \"advanced machine learning\" system are specific to Isis and intend to avoid problems created by YouTube's broad-brush efforts, which resulted in the removal of evidence of Syrian war crimes. The tool can be integrated into the upload process of any platform, with the Home Office hoping to reach smaller companies who are unable to fund the huge removal operations mounted by the likes of Facebook and YouTube.\nResearch shows that Isis supporters used 400 different platforms to spread its material in 2017, with 145 used for the first time between July until December amid intensifying crackdowns by tech giants.\n\"Google and Facebook can't solve this problem alone ... it's a far wider problem,\" Dr Warner said. \"We are trying to eliminate this horrific content across the entire web and not just on specific platforms.\"\nJohn Gibson, the director of data science services at ASI, acknowledged that the software will not prevent Isis uploading videos to its own websites - which are frequently taken down - or on the encrypted messaging app Telegram. But he said it could make Isis propaganda \"harder to find\" and share with others.\nThe Home Office paid ASI - which has previously used data to predict bacon sandwich sales on easyJet flights and make buses run on time - \u00a3600,000 to create the tool over just five months from the project's inception in September.\nOfficials are now looking at the possibility of expanding machine learning to target propaganda from other groups including al-Qaeda.\nCharlie Winter, a senior research at the International Centre for the Study of Radicalisation and Political Violence (ICSR), said it could have a \"significant impact\".\n\"If the big technology companies jump on board it will make it difficult to find this material on the open internet, but there will always be video sharing platforms that won't take on this software,\" he said. \"It's a step in the right direction but it won't solve the problem. Censorship is limited to contracting the reach of this material and it will never be able to eradicate it from the internet.\"\nThe technology is only targeting videos and will not be able to detect Isis magazines, newspapers, photo sets and text-based propaganda. The terrorist group's prolific output decreased markedly in October, November and December - in the wake of military operations that drove jihadis out of key strongholds including the Syrian city of Raqqa - but has since recovered to former levels.\nMr Winter said the new technology will not have an impact on \"the card-carrying supporters of Isis\" who get their information from Telegram but may \"limit the opportunity of people who are curious and vulnerable to expose themselves to this kind of material\".\nAmber Rudd will discuss the model during meetings today with communication companies in San Francisco's Silicon Valley, including Vimeo, Telegra.ph and pCloud.\nThe Home Secretary is expected to tell the Global Internet Forum to Counter Terrorism that all five attacks on UK soil last year \"had an online component\" and extremists are being increasingly influenced by material viewed on the internet.\n\"I hope this new technology the Home Office has helped develop can support others to go further and faster,\" Ms Rudd will say. \"The purpose of these videos is to incite violence in our communities, recruit people to their cause, and attempt to spread fear in our society. We know that automatic technology like this, can heavily disrupt the terrorists' actions, as well as prevent people from ever being exploited to these horrific images. This Government has been taking the lead worldwide in making sure that vile terrorist content is stamped out.\"\n"},
{"docid": "153 of 297 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "January 9, 2017", "title": "Why Artificial Intelligence is the answer to the greatest threat of 2017, cyber-hacking; Protecting ourselves raises an interesting dilemma. What level of monitoring and activity reporting are you prepared to put up with to enable more accurate or earlier collaborative identification of malice?\n", "content": "Our lives are now heavily mediated by digital technology (music streaming, social media, e-banking etc). We are increasingly and often continuously online, open to engagement in a myriad of services and simultaneously open to cyberattack.\n2016 saw further high profile and financially driven security incidents, such as Tesco and TalkTalk, together with one of the highest profile attacks ever - the apparent compromise of the Democratic party's information systems with potential influence on the US Presidential Election. We now need to defend against the lone wolf hacker, organised crime and terrorism, and nation states with well-funded advanced capabilities.\nThe 2016 cyber message is clear - we have a big problem, it's going to get worse, and we need help.\u00a0\nArtificial Intelligence (AI) is a promising source of such help. It comprises theory and techniques that enable intelligent processing of information. It underpins many current robotics and other smart systems (e.g. driverless cars) but its current dominant application area is the analysis of large and complex data repositories (usually referred to as Big Data analytics).\nThe intelligence of AI is often interpreted as mirroring human capabilities, but the scale of data potentially relevant for security purposes typically places analysis well beyond human capabilities. Internet traffic, for example, is predicted by networking giant Cisco to reach several zetabytes (billion trillion bytes) by 2019. AI is needed to make sense of data at (and well below) these scales and cyber defence has little option but to make significant use of it.\nAn ATM transaction in Sydney at 10am followed by one in London 15 minutes later, or a rapid series of contactless payments at previously unvisited outlets, might legitimately arouse human security experts' suspicion. Big Data analytics now provides us with an array of AI techniques to provide such characterisations of abuse with increased sophistication. Like humans, they typically judge suspiciousness based on what they have seen before. Like humans, they can confuse what they see as \"odd\" with criminal or malicious behaviour,and when you have millions of customers there is plenty of scope for odd behaviour. Dealing with this will remain a major challenge since blocking activity erroneously causes irritation all round and eats up human resources to resolve matters.\nRead more\nFive things to look out for in the economy this week\nCyber attacks will continue to increase in sophistication. For example, so-called metamorphic viruses change their form as they spread. Traditional malware detection software works by searching for specific and recognisable elements of code (digital PhotoFits, if you like). However, if malware redesigns itself constantly as it spreads this simply doesn't work. In such cases detection must rely on what the malware actually does rather than what it looks like and AI will be brought to bear to rapidly characterise it.\nAI will also help us to track down who is responsible for attacks, identifying what further information is needed to draw conclusions and then asking for it, with automated investigative algorithms following their AI-enhanced noses, making best use of limited resources.\nRead more\nBig data could help economists avoid any more Michael Fish moments\nProtecting ourselves raises an interesting dilemma. What level of monitoring and activity reporting are you prepared to put up with to enable more accurate or earlier collaborative identification of malice? The privacy versus security issue is not new (witness the furious Ed Snowden debate) but this doesn't just apply to state monitoring. We will see increasing efforts to square the circle here, providing more effective security whilst supporting privacy.\nWe will see AI emerging as a major and a powerful tool in both the detection and investigation of malice and in the construction of systems resilient to attack. But what's sauce for the goose is sauce for the gander. Cyberhackers can use AI too and so the cyber-arms war will continue. We will also need to deal with that.\nProf John Clark is a computer scientist and is the recently appointed Chair of Computer and Information Systems at the University of Sheffield\n"},
{"docid": "154 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "August 10, 2016", "title": "What does artificial intelligence mean for the creative mind?; Assistive and smart technologies can lead to a whole new world of creative possibilities and greater understanding of consumers\n", "content": "Artificial intelligence (AI) and machine learning (ML) have huge potential to drive a new generation of creative brand experiences. They are at the forefront of a powerful shift that will bring brands closer to consumer expectations, passions and emotions. Assistive and smart technologies are catching up and we're already facing a new world of possibilities.\nAI and ML can be applied in many ways. The use of machine learning to power business decisions and product recommendations is becoming widespread. We experience it when we buy on Amazon, watch television on Netflix, hail an Uber or tag friends on Facebook. There are more creative experiments out there such as \" The Next Rembrandt app \", \" machine music composition \" and \" TV show script generation \" that use ML to create new art (with mixed results). While AI is poised to transform our industries and technologies, just like electricity did in the mid-twentieth century, AI has the potential to change art, creativity and the way brands and agencies create the next generation of experiences.\u00a0\nIt's easy to hear all the buzz and think of AI and ML as new or recent developments, but they have a long history. AI has been researched since the dawn of computing but in the past few years it has become more powerful, flexible and accessible. This is down to heavy investment from companies like Intel, Google, Apple and Facebook, leading to faster, cheaper hardware with better algorithms.\nThe key to a successful machine-assisted experience is data. Converting big data into useful data is a difficult challenge. This is where agencies and brands have a huge opportunity. Netflix has been successful in making sense of consumer data, to the point that it now knows which shows and casts will become hits, before they have even been filmed. \nOne big issue is that most of the data being captured isn't smart. Often, it doesn't reflect consumer interests and takes a lot of analysis (and sometimes plain guesswork) to come up with insights that drive strategy and creativity. Traditional web and mobile analytics don't work as expected in a hyper-connected world. Demographics, page views, page clicks and hashtags are falling short in their exposure of true consumer learnings. Lifestyle, sentiment and engagement are the key elements to go after. Spotify has done this in innovative ways, marrying user habits like playlist creation with crowd-sourced behaviours to create personalised playlist suggestions.\nBrands want to understand how people feel about their services, products and content. So far, though, it seems we only have a partial view of consumers, not the full picture we aspire to. This is exactly where a new wave of interfaces will move the industry forward, away from a straight broadcast out with frivolous two-way interactions towards a more natural dialogue between brands and people.\nWith the rise of new interfaces and interactions such as 1:1 messaging, voice-enabled services and natural language processing, we have a chance to reach a deeper understanding of consumers. Combine this with the constant growth of connected devices, and the opportunity to capture smart data from consumer interactions becomes huge.\nData is the fuel of AI. According to Internet Live Stats, there are roughly 3.5 billion people with access to the internet, generating exponential amounts of data. And IDC believes we ll be creating 44 zettabytes of data worldwide by 2020. This data will become increasingly smarter, thanks to two main factors. First, more connected devices means we'll need a more holistic view of consumer lifestyles. And second, the rise of messaging and conversational platforms such as WeChat, Line, Slack and Facebook will provide a stream of dialogue-based data. This will result in a new wave of smart data, empowering our industry to understand people on a whole new level.\nAI lets us understand complex interactions such as voice, text dialogues, pictures and videos in a more personalised way. Now we can classify interactions from consumers, and smart solutions can understand what a person is saying. When we recognise the intention and the sentiment of a human interaction, we can react to it accordingly. Is that person happy or frustrated about the service? Was the content delightful or bland? This is the kind of qualitative understanding that we can't get through page views or clicks. Jay Zasa, also of R/GA, wrote a great piece, recently, about the challenge of creating meaningful bots and conversational services. \nMost importantly, machines can learn much quicker than humans. They constantly develop and improve over time, testing response, intent and sentiment to enhance the service on offer. They can solve the scalability problem, which has blocked truly personalised services for so long. Why would you go to a website and waste time searching for something if you could have a smart, machine-assisted personal service giving you what you need at the right time and place, on the right device or channel? After all, the ultimate goal is to create the simplest, most meaningful experience for consumers.\nMachines are not about to take over the world and lead the creative sphere, but if we want to create better, simpler, more personal experiences, it's clear that AI technology must play a chief role in the research and design of brand experiences. AI could become the ultimate creative tool for brands and agencies, helping them build richer experiences with lasting value.\nThere's a unique element of creativity in all of us that machines are unlikely to replicate (at least for the time being). However, the landscape is moving towards a smarter, hyper-connected, ongoing dialogue between people and brands. Things are evolving fast and our industry can't afford to hesitate. We need to use cognitive technology in new ways to boldly break the mould, creating experiences that aren't one-off executions. Instead, they'll be constantly improving and growing the brand-consumer relationship.\n                     Anthony Baker is tech director at R/GA London                   \n                       To get weekly news analysis, job alerts and event notifications direct to your inbox,                         sign up free for Media & Tech Network membership                       .                                        \n                     All Guardian Media & Tech Network content is editorially independent except for pieces labelled \"Paid for by\" - find out more                                            here                                          .                   \n"},
{"docid": "155 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "June 20, 2016", "title": "Twitter buys London AI startup Magic Pony for $150m\n", "content": "Twitter has acquired London artificial intelligence startup Magic Pony for around $150m, according to sources close to the company.\u00a0\nThe startup, founded by graduates of Imperial College London uses machine learning to create high-quality videos\u00a0from grainy footage, and will likely be integrated into Twitter's live and\u00a0video services such as Periscope and Vine.\u00a0\u00a0\nThe acquisition\u00a0builds on other investments made by Twitter in machine learning, including those of\u00a0 Madbits \u00a0in July 2014 and\u00a0 Whetlab \u00a0in June 2015.\n\"Machine learning is increasingly at the core of everything we build at Twitter,\" said chief executive Jack Dorsey. \u00a0\n\"Magic Pony's technology\u00a0- based on...algorithms that can understand the features of imagery - will be used to enhance our strength in live and video.\"\u00a0\nWe've acquired Magic Pony Technology to enhance our machine learning efforts and strength in video: https://t.co/Ds03vtC1dH\n - Twitter (@twitter) 20 June 2016\nThe startup's team\u00a0includes 11 PhDs including co-founders\u00a0Zehan Wang and Rob Bishop and has received an undisclosed sum of investment from \u00a0Entrepreneur First, Octopus\u00a0Ventures and Balderton Capital, whose basement it launched the company from.\u00a0\nThe Magic Pony team will remain in the\u00a0UK, where,\u00a0Twitter said, it would form the basis of their AI research\u00a0team in Europe.\n\"Some worry that we are suffering from a brain drain, with our universities producing world-class researchers who end up at West Coast powerhouses. I happen to think this view is phenomenally short sighted,\" said\u00a0Suranga Chandratillake, partner of Balderton Capital who invested in Magic Pony Technology in 2015.\u00a0\n\"It is, instead, a huge opportunity for Europe to be at the heart of the Artificial Intelligence revolution and do it off the back of US investment.\"\nThe history of TwitterPlay!01:40Silicon Valley's got its eye on British AI\nMagic Pony is the latest in a string of AI and machine learning startups in  Britain\u00a0that have taken the fancy of large Silicon Valley companies.\u00a0\nBack in 2012, Amazon acquired Evi Technologies, a Cambridge-based startup whose platform can understand and communicate in natural language, making it a super-intelligent search tool.\nMeanwhile,\u00a0Apple made an extremely similar Cambridge-based acquisition - it bought VocalIQ, a software system that teaches computers to speak more like humans, and understand natural language more easily.\nMore recently, Microsoft acquired smart keyboard startup Swiftkey for $250m and Google paid \u00a3400m for DeepMind, which recently achieved a world-first by designing a computer algorithm that beat a human champion at the Chinese board game Go.\u00a0\nSuranga Chandratillake, partner of Balderton Capital who invested in Magic Pony Technology in 2015, is very positive on the deal, and on what it means for UK AI going forward.\u00a0\nAI timelineREAD MORE ABOUT:\n"},
{"docid": "156 of 297 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "November 28, 2016", "title": "Virtual reality 'to replace high street shopping by 2050'; We're on the cusp of 'a revolution', experts say\n", "content": "High street retailers could be a thing of the past by 2050 as virtual reality takes over the way we shop, experts predict.\nThe only time we can expect to be asked \"Are you being served?\" is when interacting with an artificially intelligent app.\u00a0\nThe kind of department store epitomised by Grace Brothers in the 1970s sitcom of that name is likely to be consigned to history by the middle of the century.\nRead more\nAugmented reality could see us renting virtual jewellery and clothes\nMen who want to have sex with giants hope VR will bring it to life\nHow developers introduce people to virtual reality\nSony releases virtual reality headset and aims for mainstream\nInstead people will make all their purchases from home, trying on clothes in virtual reality changing rooms and getting advice from AI (artificial intelligence) shop assistants that know exactly how to cater for their tastes.\nOnline deliveries dropped into the back garden by flying robot drones will become a part of every day life.\nExperts writing in The Future Of Shopping report talk about the impact the \"fourth industrial revolution\" - a merging of physical, digital and biological technologies - on shopping.\nThey forecast:\n:: Virtual reality (VR) headsets that gauge your mood in the lighting and atmosphere of a simulated store.\n:: Immersive virtual experiences involving products, such as visiting a cocoa farm to watch beans being picked and processed to make chocolate.\n:: AI assistants that know your interests and tastes better than you do and can pre-empt purchases. For instance, shortly before a seaside holiday they might show you a range of swimwear.\n:: Holographic fashion shows held in unusual locations.\nRead more\nGoogle reveals a soft VR headset that makes people wizards\nCo-author Russell Freeman, chief technology officer at digital marketing agency Holition, said: \"It's ironic that the fashion industry is renowned for its innovation, yet the way we shop is so old fashioned. From having to use a changing room, to being offered limited space in a shop, the whole experience is generic.\n\"The future of shopping offers personalised experiences for people, dependent on their taste and mood and at Holition we see it as the humanising of technology.\n\"Augmented reality, virtual reality, drone delivery and artificial intelligence will completely change the way we shop. It's an exciting time - on the cusp of a revolution.\"\nVirtual reality shopping will be featured at The Big Bang UK Young Scientists And Engineers Fair taking place at the National Exhibition Centre, Birmingham, in March next year.\nPaul Jackson, chief executive of EngineeringUK, organisers of the Big Bang fair, said: \"It is the young people studying maths and science today who will drive this 'revolution' in the future.\n\"They will build on advances in artificial intelligence, drones and virtual reality and develop other innovative technologies that will shape our day-to-day lives.\"\nPA\n"},
{"docid": "157 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "March 29 1988", "title": "Technology: The battle to beat Babel is underway\n", "content": "\u00a0\n Machine intelligence met Gallic wit and came off second-best in Paris earlier this month as Texas Instruments (TI) tried to push back the frontiers of technology.\n Predictably, language was the stumbling block. TI was unveiling the latest fruit of its massive investment in artificial intelligence to a European press corps.\u00a0\n\n The product in question was an Apple Macintosh microcomputer adapted by TI to explore new areas of computing potential and hence called a Micro Explorer.\n With two US-based companies involved, simultaneous translations were laid on for French, German and Italian speakers. But ordinary intelligence failed when the presentations gave way to a question and answer session.\n The declaration that verbal questions would be taken only in English while others would have to be written down provoked some Gallic rumbles of discontent.\n It also, inevitably, led to the absurdity - in the capital of France - of a French question being translated into poor English, to be answered in poor English by a Frenchman.\n The French contingent began to assume' Allo, Allo' accents in deliberate mockery. One retless native asked a simple question in clear English, but unfortunately it wasn't understood.\n 'Would you like me to write the question down?' he asked. 'Yes, yes' came the reply. The Frenchman, enjoying himself hugely by this time, asked 'In capitals'.\n All this cast the Micro Explorer in a new light. If human intelligence is imperfectly understood and deployed, surely talk of artificial intelligence is presumptuous in any language?\n TI has spent too much time and money building itself into a leading supplier of artificial intelligence products to answer yes readily. What it says is that the Micro Explorer will tackle jobs that computers couldn't previously attempt, breaking free of the convention that computer data must be figures.\n The Micro Explorer will not think; instead it will give the impression of knowing. It is based on earlier TI systems which 'know' - for example - how to tackle oil slicks or how to assign airport gates to planes of different sizes, and which are doing these jobs for TI customers around the world.\n This type of work is called knowledge engineering, and the computer systems that result are usually known as expert systems. They embody a knowledge of rules and procedures imparted either by human experts or by impossibly complicated manuals.\n They can be built on ordinary personal computers quite cheaply but the MicroExplorer and its forebears are designed specifically for the purpose, and they run programs that have been equally tightly defined.\n In Micro Explorer the TI product is now available for between Pounds 11,500 and Pounds 20,000 where previously it would have cost three or four times as much. TI argues that this will encourage more people to experiment with and use the technology.\n If artificial intelligence is a developing science, it may be expected to develop more quickly the more people that are involved.\n"},
{"docid": "158 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "August 29, 2013", "title": "Artificial intelligence 'will take the place of humans within five years'; Salespeople, call centre staff and customer service personnel could all be replaced by computers within the next few years, claims one technology entrepreneur.\n", "content": "Robotics and artificial intelligence (AI) specialist Dmitry Aksenov has been working on building computers that \"think like human beings\" since he was 10 years old. \"It is my passion,\" he said.\u00a0\nMr Aksenov, now 21 years old, founded technology company London Brand Management in 2011. The company provides an AI service for big brands who want to outsource customer or staff interactions to computers. Customers send questions in to LBM's system (nicknamed \"The Brain\" by developers) via email or text and it responds within five seconds. \nThis technology is currently being used by BMW to field questions about its new electric car, the i3. BMW UK marketing director Chris Brownridge has found the system uncannily human in its responses. \"BMW I Genius is capable of understanding each question and responding accurately every time as if you were talking to an expert from the company,\" he said. \"The system operates around the clock, allowing the consumer to ask any question relating to the \"i\" cars but without the hassle of having to pick up the phone or go into a dealership.\"\nThousands of users have already tried the service. \"The only thing that gives away the fact they are talking to a computer is that it responds so fast,\" said Mr Aksenov. \"No real person could receive, read and respond to a message in three seconds.\"\n\"It not only reads the keywords and understands the kind of information you are trying to learn; it also interprets context, sentiment, and can even understand humour. It also remembers and learns as you talk to it, so it's capable of having a proper conversation.\"\nThis new technology represents a huge step forward in service automation, he claimed. LBM's system is cloud-based, which means it can be accessed from anywhere (like Gmail or Facebook). It can deal with thousands of enquiries simultaneously, and its database has an unlimited memory capacity. \nThe Brain is equivalent to having thousands of call centre staff or salespeople, he said. \"Except that unlike people, with our limited brain capacity, AI remembers everything and needs no downtime.\"\nThe company is currently focused on replacing traditional sales and marketing roles but is also moving into the customer care and call centre space. New projects for an NHS cancer hospital and a major Japanese electronics company are already under way. \"There are applications for this system in hundreds of industries,\" he said. \nMr Aksenov provides the technology to brands under licence with a one-off implementation fee to \"teach\" the system. Unlike hiring humans, however, \"AI only has to learn once,\" he said. \n \"Within five years we will have a system that truly knows more than a human could ever know and is more efficient at delivering information,\" he said. \"It will replace many of the boring jobs that are currently done by humans. Unfortunately, this may take some jobs from the economy by replacing human beings with a machine. But it is the future.\"\n"},
{"docid": "159 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "April 2, 2018", "title": "Emmanuel Macron compares 'too big to be governed' Google and Facebook to oil barons\n", "content": "Emmanuel Macron has suggested that Facebook and Google are \"too big to be governed\" and compared their dominance to that of the oil barons in the early 20th century, saying they may have to be dismantled.\u00a0\nThe French president's comments are among the most forceful from a Western leader on the subject of the two companies' growing influence, which is coming under increased scrutiny from regulators.\n\"At a point of time, your government, your people, may say: 'Wake up. They are too big.',\" Mr Macron told Wired magazine . \"Not just too big to fail, but too big to be governed. Which is brand new.\"\nHe added that governments may choose to break up the companies, saying: \"At this point, you may choose to dismantle. That's what happened at the very beginning of the oil sector when you had these big giants. That's a competition issue.\"\nHe added that the companies were facing at \"very classical issue in a monopoly situation\" and repeated claims that they do not pay enough taxes in Europe.\nTechnology intelligence - newsletter promo - EOA\nMr Macron has sought to adopt a business-friendly attitude since his victory in last year's election, seeking to help Paris wrestle away London's crown as Europe's technology hub and embarking on a new strategy to make France a world leader in artificial intelligence.\nBut his latest comments are likely to fuel claims that Europe remains hostile to Silicon Valley. Mr Macron insisted that he would continue to welcome investment from the companies, who have opened AI research centres in France.\nParis has become a destination for machine learning research, and last week Mr Macron announced a (EURO)1.5bn (\u00a31.3bn) investment in artificial intelligence over the course of his term, which runs until 2022. It comes amid fears that Europe is falling behind the US and China when it comes to developing AI.\n"},
{"docid": "160 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "November 1, 2017", "title": "Artificial intelligence could bring nasty surprises, warns Financial Stability Board \u00a0\n", "content": "The rapid use of\u00a0artificial intelligence\u00a0in banking could trigger\u00a0financial stability risks and some unexpected surprises unless proper testing and training is put in place, the Financial Stability Board has warned.\nBanks, insurers and asset managers are rushing to swap humans with computer systems able to do the same jobs, with 'smart' robots able\u00a0to crunch data, automate\u00a0client interaction, spot fraud or\u00a0price insurance contracts.\u00a0\u00a0\nBut\u00a0the race to replace\u00a0people with machines\u00a0\"has the potential to amplify financial shocks\" and could be used by cybercriminals to manipulate market prices,\u00a0the FSB said, adding that firms were in an 'arms race' to adopt AI because their competitors are.\u00a0\nWhile the FSB acknowledged that the use of AI shows \"substantial promise\" and could make the financial system more efficient,\u00a0it urged the industry\u00a0to monitor usage closely as a number of risks were on the horizon.\u00a0\nInstitutions could become dependent on the technology giants making the robots, for example,\u00a0opening them up to risks created by third-party providers which\u00a0fall outside the remit of financial regulators.\u00a0\nBank of England Governor Mark Carney is head of the FSB,\u00a0which represents central banks and regulators for the\u00a0G20 economiesCredit:      Andrew Harrer/Bloomberg     \n\"These competition issues - relevant enough from the perspective of economic efficiency - could be translated into financial stability risks if and when such technology firms have a large market share in specific financial market segments,\" the FSB wrote.\u00a0\nThe 45-page report also called for more specialist staff to oversee the models, which could lead to \"unintended consequences\" if they are too opaque.\u00a0\n\"If multiple firms develop trading strategies using AI and machine learning models but do not understand the models because of their complexity, it would be very difficult for both firms and supervisors to predict how actions directed by models will affect markets,\" it said.\u00a0\nThe FSB,\u00a0which represents central banks and regulators for the\u00a0G20 economies,\u00a0also noted\u00a0that many of these systems had been developed in a period of low volatility and so \"the models may not suggest optimal actions in a significant economic downturn or in a financial crisis\".\nThe report comes a month after the\u00a0 former boss of Barclays, Antony Jenkins, warned that the heyday enjoyed by big banks in the lead-up to the financial crisis will never return as the rise in AI threatens\u00a0some of their services.\nHe said\u00a0financial regulators could benefit from the use of AI, pointing out that 40,000 people in Canary Wharf currently work in compliance \"making sure a bank is doing what it is supposed to be doing\" and could be replaced by computers.\u00a0\n"},
{"docid": "161 of 297 DOCUMENTS\n", "source": "The Independent - Daily Edition\n", "date": "July 5, 2017", "title": "Artificial intelligence better than scientists at choosing successful IVF embryos\n", "content": "Scientists are using artificial intelligence (AI) to help predict which embryos will result inIVFsuccess.In a new study, AI was found to be more accurate than embryologists at pinpointing which embryos had the potential to result in the birth of a healthy baby.\u00a0\nExperts from Sao Paulo State University in Brazil teamed up with Boston Place Clinic in London to develop the technology in collaboration with Dr Cristina Hickman, scientific adviser to the British Fertility Society.They believe the inexpensive technique has the potential to transform care for patients and help women achieve pregnancy sooner.\nDuring the process, AI was \"trained\" in what a good embryo looks like from a series of images.AI is able to recognise and quantify 24 image characteristics of embryos that are invisible to the human eye.These include the size of the embryo, texture of the image and biological characteristics such as the number and homogeneity of cells.\nDuring the study, which used cattle embryos, 48 images were evaluated three times each by embryologists and by the AI system.The embryologists could not agree on their findings across the three images, but AI led to complete agreement.\nStuart Lavery, director of the Boston Place Clinic, said the technology would not replace examining chromosomes in detail, which is thought to be a key factor in determining which embryos are \"normal\" or \"abnormal\".\nHe said: \"Looking at chromosomes does work, but it is expensive and it is invasive to the embryo.What we are looking for here is something that can be universal.Instead of a human looking at thousands of images, actually a piece of software looks at them and is capable of learning all the time.As we get data about which embryos produce a baby, that data will be fed back into the computer and the computer will learn.\n\"What we have found is that the technique is much more consistent than an embryologist, it is more reliable.It can also look for things that the human eye can't see.\"\nHe said work was under way to look back at images from parents who had genetic screening and became pregnant. Applying AI to those images will help the computer learn, he said.\nMr Lavery added: \"This is an innovative and exciting project combining state of the art embryology with new advances in computer modelling, all with the aim of selecting the best possible embryo for transfer to give all our patients the best possible chance of having a baby.Although further work is needed to optimise the technique, we hope that a system will be available shortly for use in a clinical setting.\"\n"},
{"docid": "162 of 297 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "February 4, 2016", "title": "Hawking's helpers clinch $250m deal\n", "content": "TWO Cambridge graduates who quit their day jobs to develop a predictive keyboard powered by artificial intelligence are on course to become multimillionaires after their firm was bought by Microsoft for more than \u00a3170m.\nSwiftKey was set up in 2008 by Jon Reynolds and Ben Medlock and their app is now used on 300m devices every day.\nA third founder, Chris Hill-Scott, sold his stake to his two friends for a bicycle in 2008. Mr Hill Scott, who yesterday tweeted that it was the \"biggest mistake I ever made\", now works as an IT developer for the Government, The Times reported.\u00a0\nSwiftKey replaces the default keyboard with one which predicts what a user is typing, based on their previous writing habits, and finishes words for them so they can write faster.\nIts prediction technology also helps power Professor Stephen Hawking's speech system to speed up communication for the Cambridge scientist.\nSwiftKey used to charge for its app, but moved to a \"freemium\" model in 2014, providing a basic version free but charging for extra features. Revenues fell that year to \u00a38.4m and losses increased amid a hiring drive, increasing speculation that the company could be an acquisition target. The Microsoft deal is reportedly worth as much as $250m (\u00a3174m). The company had previously announced \u00a314.8m in funding, including \u00a365,000 in grants from the Government's Innovate UK initiative. It also said it had raised funds last March, but declined to say how much.\nSwiftKey is not available for Microsoft's Windows Phone software, but Microsoft has moved into developing apps for rival operating systems as its own struggles. It recently bought Sunrise, a popular calendar app, and Wunderlist, a task-management service popular on smartphones. There is a continuing race for artificial intelligence talent among major tech groups.\n\"Microsoft's mission is to empower every person and every organisation on the planet to achieve more. Our mission is to enhance interaction between people and technology. We think these are a perfect match, and we believe joining Microsoft is the right next stage in our journey,\" said Mr Reynolds, 30, and Dr Medlock, 36, in announcing the deal.\n\"We started out as two friends with a shared belief that there had to be a better way of typing on smartphones. We've come a long way since then; today, hundreds of millions of people around the world, and many of the leading mobile manufacturers, rely on our language prediction technology.\"\nThey said the SwiftKey app would remain on Apple's iOS and Google's Android operating systems and would remain free, adding: \"We are as committed as ever to improving them in new and innovative ways.\"\nHarry Shum, Microsoft's executive vice-president of technology and research, said: \"We love SwiftKey's technology and we love the team that Jon and Ben have formed. We believe that together we can achieve orders of magnitude greater scale than either of us could have achieved independently.\"\nDr Medlock studied computer speech and sciences at Cambridge and the pair used his knowledge of natural language patterns and artificial intelligence to create the SwiftKey system. It started as a side project as both worked full-time elsewhere following their graduation. Mr Reynolds was a civil servant, working on the sale of the High Speed 1 Channel Tunnel rail line.\nTheir first SwiftKey app launched on the Android platform in 2010, supporting seven languages, and quickly took off. It has since been downloaded from the Google Play Store more than 10m times, and has topped the download rankings in 47 countries.\nToday the app supports more than 100 languages, has been incorporated into many other apps as the default keyboard, and is pre-installed on many smartphones as the default typing tool.\n"},
{"docid": "163 of 297 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "September 8, 2017", "title": "Artificial intelligence can identify 'gay faces' from a picture, study claims; The paper's authors say they were 'really disturbed' by their findings\n", "content": "Artificial intelligence can figure out a person's sexual orientation by analysing a picture of their face, a controversial new study claims.\nAccording to its authors, who say they were \"really disturbed\" by their findings, the accuracy of an AI system can reach 91 per cent for homosexual men and 83 per cent for homosexual women.\nThe study also concludes that homosexual men and women tend to have \"gender-atypical facial morphology, expression, and grooming styles\".\u00a0\nThe paper, titled \nDeep neural networks are more accurate than humans at detecting sexual orientation from facial images\n, was co-authored by Stanford University's Yilun Wang and Michal Kosinski, and first spotted by the Economist.\nIn it, they claim to \"show that faces contain much more information about sexual orientation than can be perceived and interpreted by the human brain\".\nThe researchers used deep neural networks to analyse 35,326 images of faces, taken from a US dating site, with the specific aim of identifying \"links between characteristics and facial features that might be missed or misinterpreted by the human brain\".\nThe algorithm took into account both \"fixed\" features, such as nose or eye shape, and \"transient\" features, which the researchers define as \"grooming style\".\nHowever, only white participants were involved in the study, as the researchers \"could not find sufficient numbers of non-white gay participants\", and it also didn't take into account transgender or bisexual people.\nWhen the system was presented with one picture of a homosexual man and a picture of a heterosexual man, the researchers say it correctly ranked the gay man as \"more likely to be gay\" 81 per cent of the time.\n\"The accuracy grew significantly with the number of images available per person, reaching 91 per cent for five images,\" the paper adds.\"The accuracy was somewhat lower for women, ranging from 71 per cent (one image) to 83 per cent (five images per person).\"\nHuman judges, meanwhile, achieved an accuracy of 61 per cent for men and 54 per cent for women, the research claims.\nIt continues: \"Our results provide strong support for the [prenatal hormone theory], which argues that same-gender sexual orientation stems from the underexposure of male fetuses and overexposure of female fetuses to prenatal androgens responsible for the sexual differentiation of faces, preferences, and behavior.\"\nIt also stressed that the findings don't imply that \"all gay men are more feminine than all heterosexual men, or that there are no gay men with extremely masculine facial features (and vice versa in the case of lesbians)\", and must not be misinterpreted.\nThe researchers say that homosexual men were found to have narrower jaws, longer noses, larger foreheads and less facial hair than heterosexual men, and that homosexual women tended to have larger jaws and smaller foreheads than heterosexual women.\nThey added: \"Lesbians tended to use less eye makeup, had darker hair, and wore less revealing clothes (note the higher neckline)-indicating less feminine grooming and style. Furthermore, although women tend to smile more in general, lesbians smiled less than their heterosexual counterparts.\n\"Additionally, consistent with the association between baseball caps and masculinity in American culture, heterosexual men and lesbians tended to wear baseball caps.\"\nAccording to the researchers, the study has exposed a potential threat to the privacy and safety of gay men and women around the world, as governments and corporations are already developing and deploying facial recognition technologies designed to predict things like the likelihood of committing a crime or being a paedophile.\nRead more\n'Alan Turing law' enacted to posthumously pardon thousands of gay men\n\"The laws in many countries criminalize same-gender sexual behavior, and in eight countries - including Iran, Mauritania, Saudi Arabia, and Yemen - it is punishable by death,\" the paper reads.\n\"It is thus critical to inform policymakers, technology companies and, most importantly, the gay community, of how accurate face-based predictions might be.\"\nThe researchers say they hope future research will be able to identify links between facial features and personality, political views and psychological conditions.\nIn their notes, the authors added: \"We were really disturbed by these results and spent much time considering whether they should be made public at all. We did not want to enable the very risks that we are warning against.\"\n"},
{"docid": "164 of 297 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "November 6, 2017", "title": "Ban killer robots, experts urge Australian and Canadian leaders; Development and use of autonomous weapons crosses a 'clear moral line', pioneers in robotics and AI warn Malcolm Turnbull and Justin Trudeau\n", "content": "Pioneers in robotics and artificial\u00a0intelligence have called on the Australian and Canadian governments to ban killer robots ahead of a United Nations meeting on weapons this month.\nLeading researchers from the countries urged prime ministers Malcolm Turnbull and Justin Trudeau respectively to take a stand against autonomous weapons, arguing that their development and use crossed a \"clear moral line.\" \u00a0\nArtificial\u00a0intelligence can be used to make weapons that operate without human oversight, giving them the ability to loiter in an area and make life or death decisions without approval from a military controller. \n Related:  We can't ban killer robots - it's already too late | Philip Ball\n\"If developed, they will permit armed conflict to be fought at a scale greater than ever before, and at timescales faster than humans can comprehend,\" the letter to Turnbull states. \"The deadly consequence of this is that machines, not people, will determine who lives and dies.\" \nThe letters are signed by hundreds of specialists including Toby Walsh, an AI professor at the University of New South Wales in Sydney, Geoffrey Hinton, an AI pioneer who runs Google's Brain Team in Toronto, and Ian Kerr, professor of ethics, law and technology at the University of Ottawa. \nIn August, many of the world's top robotics and AI scientists called on the United Nations to ban killer robots and so halt the arms race now underway to build autonomous weapons. The race threatens to usher in a \"third revolution in warfare\" after gunpowder and nuclear weapons, the researchers warned in an open letter. \nThe military is one of the largest funders of AI research, and while the technology could be used to make mine-clearing robots or unmanned vehicles that deliver supplies, fully-automated offensive weapons would effectively become weapons of mass destruction, the scientists state. \n Related:  A ban on autonomous weapons is easier said than done\n\"One programmer would be able to whole control armies of weapons,\" said Walsh \"They are the perfect weapons to suppress a civilian population. Unlike humans who have to be persuaded to commit atrocities, these will be cold, calculating weapons that will do whatever they are programmed to do.\" \nArms manufacturers have already built highly autonomous weapons for the military, from robotic sentries and autonomous tanks to flying drones that can track and strike targets. The systems are designed to operate under human supervision. Compared with nuclear weapons, AI-powered weapons are likely to be cheap and simple to make, meaning they could easily find their way onto weapons black markets. \nThe letters to the Australian and Canadian governments coincide with the UN's conference this month on the convention on certain conventional weapons, which aims to restrict or prohibit weapons that are excessively injurious or indiscriminate. \n\"Giving machines the right to make life or death decisions takes us down a horrible road,\" Walsh added. \"There are some technologies we should keep out of the battlefield.\"\n"},
{"docid": "165 of 297 DOCUMENTS\n", "source": "The Guardian - Final Edition\n", "date": "April 19, 2007", "title": "Technology: The hard-thought race for intelligent gaming: Artificial intelligence is the holy grail for game designers, but just how smart are current methods and what's in the pipeline?\n", "content": "Gaming has a lot in common with everyone's favourite heiress, at least in the public consciousness: it's pretty, but dumb. And now that Microsoft, Nintendo and Sony have released their latest games consoles, that statement becomes all the more pertinent - next-gen games look great, but they play like something that could have been made a decade ago. While visual fidelity has advanced exponentially over time, the technology that governs how games play, react and adapt - the artificial intelligence, or AI - remains relatively rudimentary.\nA handful of developers are striving to change this. The British designer Peter Molyneux, recently awarded an OBE, has spent his career trying to inject sentience and reactivity into games - and with his upcoming title, Fable 2, he thinks he's made significant progress. \"AI is certainly the undiscovered country of games design,\" he says. \"Any game genre - from hardcore shooters to the most story-driven adventure game - would be truly revolutionised by AI driving plot, characters and scenarios.\"\nGaming evolution\u00a0\nThis is because presently, every action a player makes in a game has to be anticipated by the developers; the software will break down or simply remain stagnant if asked to do something that hasn't been pre-scheduled. More sophisticated AI would allow games to come up with solutions to player decisions on the fly.\n\"That's where the great wins are, when you start improving AI,\" Molyneux says. \"If I as a player can do stuff in the world that is outside what the designer expects, and the game or game characters react appropriately, that's incredibly powerful. Suddenly, you think, 'Well, this isn't something that's just waiting for me to press the B-button; it's evolving around what I'm doing.' That is very emotionally compelling and, if you get it right, it can often be quite spooky.\"\nThat said, Molyneux doesn't believe AI can be solely responsible for intense, dynamic emotional experiences; they need to be married with what he calls \"smoke and mirrors\".\n\"You have to define what games developers call AI,\" he says, \"as opposed to academic AI. There's actually very little true, academic AI in games. If I go along to universities and talk to professors of AI, they sort of laugh at us and our crude attempts at real-world AI. But my promise has always been, 'Well, good AI is what you see, not how it works.' Whether that's a mixture of true AI and an illusion is neither here nor there, because it's really about what it brings to the game.\"\nSteve Grand - creator of the Creatures AI experiment, AI researcher, android hobbyist and also a recipient of an OBE - is probably the only person in the world with the distinction of creating a successful game driven by true AI. Which is why he's not particularly enthused by the progress his field has made in the games industry.\n\"AI isn't so much unappreciated as nonexistent,\" he says. \"Most of what counts as AI in the games industry is actually a bunch of 'IF/THEN' statements. If a computer character doesn't learn something for itself then the programmer must have told it what to do, and anything that does exactly what it's told and nothing else is not intelligent. This is changing, and neural networks and other learning systems are beginning to creep in. But games programmers tend to devalue the phrase 'artificial intelligence'.\n\"This is mostly because the importance of AI in computer games is now widely recognised, and hence any attempt to implement it - including Creatures - gets hyped up pretty quickly. As graphics have improved, the behaviour of characters has got more and more embarrassing. When characters looked cartoon-like, any vaguely lifelike behaviour was impressive, but now that characters have fluid movements, realistic textures and complex facial expressions, they tend to engage different circuits in the players' brains. The better the graphics become, the worse the behaviour looks. So the need for good AI is well-appreciated. The snag is that none of us knows how to make it work yet.\"\nLearning curves\nWhich isn't to say that Grand hasn't tried. In fact, Creatures is arguably the only AI-driven simulation that could still be classified as a compelling game in its own right. Basically a facade of evolution, the game allows players to teach their Norns (the creatures) to eat, talk, and defend themselves; they would learn and develop dynamically, and would pass on certain genetic traits to their offspring.\nGrand tries to explain its technology: \"It consists of a very simplified set of the building blocks of life - nerve cells, enzymes, genes and receptors. The hard part is explaining how all these virtual objects are assembled together to make something that lives, acts, breeds and evolves. But if you understood school biology - I mean, if you really understood it, not just learned it - then you already almost understand Norns.\n\"I think the basic approach - biological and bottom-up - is the only way we'll ever achieve truly intelligent artificial systems. But for the time being, it's not the best way to approach the problem for most games. If you want to reach for the moon you have to go to the trouble to build yourself a space rocket, but if you only want to lift yourself three feet off the ground you might as well jump. There are easier ways to make the kind of intelligence most present-day games require, even though these techniques will never lead anywhere.\"\nMolyneux agrees. He's a fan of Creatures and the technology behind it, but he doesn't see it as particularly relevant to most mainstream games. \"I have tried prototyping using neural networks,\" he concedes, \"but you usually never quite get the results you want. And I think the system we use is a hybrid, really - I wouldn't want to put a title on the AI we've developed, but the theory of neural networks does influence it. I think the whole Creatures approach was incredibly interesting and impressive, but the real problem was that it was a bit of a strange beast. I didn't quite understand its motivations. It was a great, interesting attempt, though.\"\nEven if Molyneux is sceptical about Creatures' mass-market relevance, his latest project, Fable 2, at the now Microsoft-owned Lionhead Studios appears to be heavily influenced by Grand's games. This is most obvious in the player's constant companion, his dog. According to Molyneux, each player's dog will be unique thanks to their actions. \"We're really pushing the idea of a learning creature with this game,\" he enthuses.\nBut whether Molyneux will be answering that question with AI or \"smoke and mirrors\" is hard to say at this point; Fable 2 won't be released until 2008. Still, projects like this are an opportunity to advance our understanding of how AI can revolutionise increasingly stale gameplay.\nGrand, who's now focused on robotics, remains confident that games can benefit AI research: \"I think it's probably the best environment for AI that exists, at least until we've cracked some of the huge problems that are holding back robotics. When you write a game, your only responsibility is to be entertaining. It's not a mission-critical environment, so this gives you plenty of scope for new ideas.\"\nWith luck, more developers like Molyneux will begin taking his words to heart. It's unlikely entertainment software will ever employ - or need to employ - the sophisticated AI that Grand works with on a daily basis, but his work should serve as an inspiration to designers and programmers everywhere. After all, no matter how pretty games become, they're always going to be dumb if the brains aren't paid some serious attention.\n"},
{"docid": "166 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 1, 2018", "title": "Google exec: Artificial intelligence film death scenarios 'one to two decades away'\u00a0\n", "content": "Terminator-style artificial intelligence\u00a0scenarios are just \"one to two decades away\", according to Google's former chief executive.\nEric Schmidt, the former chief executive of Google and its parent company Alphabet, has said he believes AI technology is developing so quickly it may soon turn against humans.\u00a0\n\"All the movie-inspired death scenarios... I can confidently predict to you that they are one to two decades away,\" Mr Schmidt told a security conference in Munich.\nBut he added \"let's worry about them in a while\", as he highlighted the opportunities AI afforded.\nThe fear of intelligent robots rising against their human creators has long occupied Hollywood's imagination and was played out in the 1984 film The Terminator, in which a robot assassin disguises himself as a human.\nThe daunting\u00a0scenario may not be far off, according to Mr Schmidt, who is now a fellow at the Massachusetts Institute of Technology.\nMr Schmidt has previously discussed the rapid advances in AI technology\u00a0and expressed concern over the \"military aspirations\" of countries like China and Russia when it came to AI weapons.\nChina\u00a0has already begun work on a national AI programme and hopes to become the world leader in the technology in the next decade.\nMr Schmidt warned that Europe and the US lagged far behind the Chinese when it came to resource and investment in the field.\nElon Musk, the billionaire tech entrepreneur, has also voiced fears over the potential threat AI technology poses.\u00a0\n\"If you're not concerned about AI safety, you should be. Vastly more risk than North Korea,\" he said last year.\nHowever Mr Schmidt argued that the benefits AI brings to technology and medical advances outweigh concerns about the negative effects - and he insisted \"humans will remain in charge of [AI] for the rest of time\".\nHe said: \"Everyone immediately then wants to talk about all the movie-inspired death scenarios, and I can confidently predict to you that they are one to two decades away.\n\"So let's worry about them, but let's worry about them in a while.\"\nHe went on to say that the technology had major flaws and would always be within the control of humans.\u00a0\nHe said: \"I want to remind everyone these technologies [AI] have serious errors in them and they should not be used with life-critical decisions.\u00a0\n\"So I would not want to be in an airplane where the computer was making all the general intelligence decisions about flying it. The technology is just not reliable enough - there too many errors in its use.\u00a0\n\"It is advisory, it makes you smarter and so forth, but I wouldn't put it in charge of command and control.\"\n"},
{"docid": "167 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "December 21, 2017", "title": "Ofsted should use artificial intelligence to determine which schools will fail, report suggests\n", "content": "Ofsted should use artificial intelligence to determine which schools will fail, a report has suggested.\u00a0\nResearchers from the Behavioural Insights Team, which operates in partnership with the Cabinet Office, examined how data science can be used to inform policy.\u00a0\u00a0\nThey found that a combination of the right data and machine learning can predict whether a school will be rated inadequate or requires improvement.\nPrevious inspections, census information, and workforce data are used to build an algorithm, all of which is publicly available.\nOfsted is already using statistical models to target inspections at the schools which are in the most desperate need of improvement, the report said.\u00a0\nData analysts who compiled the report found that 65 per cent of 'requires improvement' and 'inadequate' schools were within the 10 per cent of schools identified as highest risk by the model they built.\nWriting the forward to the report, John Manzoni, the chief executive of the Civil Service, said: \"The huge growth in data, and in tools for analysing it and putting it to use, has changed the world and continues to do so.\n\"There is great potential for government to improve the performance and productivity of services through the smarter use of data.\n\"This data includes outcomes, use patterns, costs, and citizen experiences. With this wealth of data, we have an obligation to make government services the best they can be.\"\nMr Manzoni said that using data science to inform policy is key to driving innovation in Government.\nThe National Association of Head Teachers (NAHT) warned against a using a \"data-led\" approach to school inspections.\n\"It is important that the whole process is transparent and that schools can understand and learn from any assessment,\" a spokesman for NAHT said.\n\"Leaders and teachers need absolute confidence that the inspection system will treat teachers and leaders fairly.\"\n"},
{"docid": "168 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "December 18, 2016", "title": "Artificial intelligence tool can unearth bargain rugby players\n", "content": "A British artificial intelligence firm is looking to revolutionise the world of sports transfers by designing software that picks out bargain rugby players.\u00a0\nASI Data Science has signed a deal with London Irish, the rugby union club, to help it find undiscovered gems by using cutting edge data analysis techniques .\nWhile rugby scouting typically requires looking through hours of footage to assess a player's ability, the software allows a club to enter the name of a star player and will assess match statistics to find players with similar styles.\nIt looks through around 100 different parameters taken from Opta, the sports data company, which covers every professional player on the planet, to find players similar to the star that a club would buy if money were no object.\nThe machine learning software clusters different types of players together, making it easier for scouts and analysts to find players and removing the biases that many believe cloud judgements when signing players.\nBrad Pitt in the film MoneyballCredit:      Melinda Sue Gordon     \nMarc Warner, ASI's chief executive, described the tool as another level in sports data above the \"Moneyball\" techniques employed by baseball coach Billy Beane to gain an advantage against wealthier teams.\nHe said the tool was effective in rugby, where budgets are often constrained by salary caps, but that it could be applied to cricket and football as well. ASI, founded two years ago, counts several prominent London tech investors as backers, including Jaan Tallin, an early employee at Skype.\nJames Molyneux, the head of analysis at London Irish, did not confirm whether the club had signed any players using the tool, but said it had found players who had gone on to be capped several weeks before they came to prominence.\n"},
{"docid": "169 of 297 DOCUMENTS\n", "source": "\u00a0The Mirror\n", "date": "February 21, 2003", "title": "CAROL@ MIRROR.CO.UK: WWW.OUR FAVOURITE\n", "content": "\u00a0\n -IF you're too open minded, your brains will fall out.\n -AGE is a very high price to pay for maturity.\n -GOING to church doesn't make you a Christian any more than going to a garage makes you a mechanic.\u00a0\n -ARTIFICIAL intelligence is no match for natural stupidity.\n -IF you must choose between two evils, pick the one you've never tried before.\n -MY idea of housework is to sweep the room with a glance.\n -NOT one shred of evidence supports the notion that life is serious.\n -FOR every action, there is an equal and opposite government program.\n -IT is easier to get forgiveness than permission.\n -IF you look like your passport picture, you probably need the trip.\n -A CONSCIENCE is what hurts when all your other parts feel so good.\n -EAT well, stay fit, die anyway.\n -MEN are from Earth. Women are from Earth. Deal with it.\n -MIDDLE age is when broadness of the mind and narrowness of the waist change places.\n -NO husband has ever been shot while doing the dishes.\n -A BALANCED diet is a biscuit in each hand.\n -OPPORTUNITIES always look bigger going than coming.\n -JUNK is something you've kept for years and throw away three weeks before you need it.\n -THERE is always one more imbecile than you counted on.\n -EXPERIENCE is a wonderful thing. It enables you to recognise a mistake when you make it again.\n -BY the time you can make ends meet, they move the ends.\n"},
{"docid": "170 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "December 9, 2015", "title": "Google's new quantum computer is 100 million times faster than your PC; Google and NASA have been working on a lightning-fast quantum computer that is 3,600 times faster than a supercomputer at solving complex problems\n", "content": "Has Google won the race to build the world's first commercial quantum computer? \nThe technology company's artificial intelligence lab claims to finally have proof that their opinion-dividing quantum computer actually works. \u00a0\nGoogle and Nasa announced they were collaborating on the D-Wave X2 quantum computer, which they say is 100 million times faster than a conventional computer chip, in 2013. It can answer certain algorithms in seconds rather than years. \nGoogle director of engineering, Hartmut Neven, said: \"For a specific, carefully crafted proof-of-concept problem we achieve a 100-million-fold speed-up.\"\nIn a blog post he added: \"We found that for problem instances involving nearly 1,000 binary variables, quantum annealing significantly outperforms its classical counterpart, simulated annealing. It is more than 108 times faster than simulated annealing running on a single core. \n\"We also compared the quantum hardware to another algorithm called Quantum Monte Carlo. This is a method designed to emulate the behaviour of quantum systems, but it runs on conventional processors. \n\"While the scaling with size between these two methods is comparable, they are again separated by a large factor sometimes as high as 108.\" \n<!-- Place this tag in your head or just before your close body tag. --><!-- Place this tag where you want the widget to render. -->\nAccording to Engadget, the computer figures out the \"most efficient overall course of action to complete a task when given a set number of options\" and could be key to the development of next-generation artificial intelligence. \nSceptics have questioned if the computer actually taps into quantum physics to solve algorithms but now Google and Nasa say they have proof. \n\"It is a truly disruptive technology that could change how we do everything,\" said Deepak Biswas, director of exploration technology at NASA's Ames research centre in California. \nHere's why quantum computers could undermine cryptography.\n"},
{"docid": "171 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "June 27, 2017", "title": "Fraud office calls in robot to solve cases\n", "content": "The Serious Fraud Office has enlisted a robo-investigator that trawls case files faster than human sleuths at a fraction of the cost.\nRavn artificial intelligence software was used by the department to save thousands of man-hours in its investigation into corruption at Rolls-Royce, which led to a \u00a3671 million settlement in January.\u00a0\nThe software, developed by the east London start-up Ravn Systems, processed 30 million documents at a rate of up to 600,000 a day, whereas a team of barristers would previously have processed 3,000. It cost \u00a350,000 - saving hundreds of thousands of pounds for the taxpayer.\nThe system was used with the agreement of lawyers from both sides to determine which scanned documents were legally privileged. Privilege protects the confidentiality of some communications between companies and their legal advisers.\nThe algorithm was \"trained\" to recognise which messages were likely to be privileged based on features including key words, recipient and even the time of day they were sent.\nThe SFO said there was an error rate of 0.02 per cent, making the software more reliable than humans. The algorithm was designed to flag documents for manual checking where there was any doubt about their status.\nIn future, the SFO will use the system not only to identify privileged material but also to sort out whether or not documents are relevant to a case. Ben Denison, its technology chief, said: \"We've got the system ready to go, it's only waiting for the right investigation. This machine-learning is particularly helpful for investigating financial crime, with the huge amount of paperwork that needs going through.\" More law firms and legal departments are using artificial intelligence to undertake drudge work. Bosses believe the technology will give lawyers more time to focus on complex and betterpaid work.\nDeloitte forecasts that it will lead to 114,000 job losses in the sector within 20 years, however.\nTechnology experts believe that AI, which is also being used in fields from medicine to accounting, will be used for more and more functions in policing and law.\nMark Bishop, professor of cognitive computing at Goldsmiths, University of London, said: \"This particular technology isn't revolutionary, but if it gets the job done and saves money, who cares? \"AI could make significant advances in these fields in the coming years, but it's important it's only used in an advisory role and not to replace human judgment. There's the risk governments fall for an advertising blurb and get rid of real legal expertise.\"\n"},
{"docid": "172 of 297 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "February 27, 2017", "title": "Software sought to self-drive Ford into the future; The car giant has teamed up with an artificial intelligence company to work on a new generation of driverless cars, says David Millward\n", "content": "In four years Ford will be mass producing cars without a steering wheel, accelerator pedal or brake pedal. The company believes that the future of the market lies in producing vehicles where a driver is not even required.\nIt has just announced a $1bn (\u00a3800m) investment in Argo AI, an artificial intelligence company which will produce the software needed for a new generation of self-driving cars.\nFord's investment over five years will see the new company develop the software needed to make self drive cars a reality, initially in cities and then across a wider area. It expects to profit from not only having its own autonomous car on the road in 2021, but by licensing the technology to other companies, including rival manufacturers.\nFord believes that the cost of owning, maintaining and parking a car in a city means that people will look for an alternative way of getting around and that is where its vision comes in. The simplest way to look at the technology is to see it as the logical next step from a car club - or perhaps Uber without a driver.\u00a0\nA trip to the supermarket, for example, would entail summoning a self-drive car using a mobile phone app to get there and then repeating the process to go home with a week's groceries. It could be possible to go out for a night on the town without worrying about having a designated driver.\n\"It would be a service where you pay for the time using a car, or a cost per mile,\" a Ford spokesman explained.\nThe company estimates that the global car ownership market is worth $2.3 trillion. It has put a $5.4 trillion price tag on what it calls mobility services, including buses, walking, subways and cycling. Not surprisingly, car companies want a slice of that action as well.\nGeneral Motors has been more cautious about disclosing its plans. But the company has 40 Chevrolet Volt autonomous cars being tested in San Francisco, Detroit and Scottsdale, Arizona. There is an engineer in the driving seat ready to take over. As yet it has not specified a timetable for unveiling its self-drive cars, although it says they will first be deployed in conjunction with the Lyft ride sharing service.\nToyota is also spending $1bn working with a number of academic bodies including the Massachusetts Institute of Technology and Stanford University.\nIt has divided its approach to the technology into two products, Guardian and Chauffeur. Guardian will add more safety features on models, but the driver will remain in control unless the technology senses, for example, a need to slam on the brakes. Many of these features are already in use. Much of the same technology will be employed in Chauffeur, but it will be active all the time - effectively driving the car.\nGill Pratt, chief of the Toyota Research Institute, admitted that advocates of self-driving cars still have to win the confidence of consumers. \"Historically, humans have shown nearly zero-tolerance for injury or death caused by flaws in a machine,\" he said at the Consumer Electronics Show last month. \"And yet we know that the artificial intelligence systems on which our autonomous cars will depend are presently and unavoidably imperfect.\"\nCar manufacturers are making a massive investment - some would say gamble - in a technology which has its critics. There are many who still question whether cars really are safer when they are controlled by a computer rather than a person.\nSceptics point to the death of Joshua Brown in Williston, Florida, last May. The former navy seal's Tesla S saloon car was in self driving mode when it ploughed into a tractor-trailer after the car's sophisticated battery of technology failed to spot the white sided truck against a brightly lit sky, and brake.\nSupporters of driverless cars believe that one accident should not undermine a technology which in the long run will improve driver safety, cut pollution, eke more out of America's road capacity and create jobs.\nRoad safety in America is poor. According to the latest estimates around 40,000 people were killed on the country's roads last year. To put that into context, according to World Health Organisation figures, 10.6 people per 100,000 population are killed on roads in the US compared with 2.9 in the UK.\nThis goes a long way towards explaining why there is considerable enthusiasm for driverless technology in Washington. Many policymakers believe that if the human factor is taken out, then casualties will fall.\nAnthony Foxx, transportation secretary in the Obama administration, was a huge supporter of autonomous technology. \"Early indications are that the first few minutes of a ride in an autonomous car can be pretty scary to people who haven't been in one before,\" he said in one interview. \"But people get used to it quickly. People having real-life experiences with the technology will help in the long run. I'm sure that when the horse-and-buggy gave way to the automobile, there was probably an acceptance factor there as well.\"\nLast September, the National Highway Traffic Safety Administration published a list of guidelines for the industry covering everything from data protection to the sobriety of somebody taking control of the car if the technology fails.\nIf anything, the Trump administration will adopt a more laissez-faire approach. Elaine Chao, the new transportation secretary, was averse to regulation when she served as labour secretary under George W Bush. That seems to be the view in Silicon Valley as well, which has welcomed the Trump administration's choice.\n\"The autonomous vehicle industry could not have asked for a better pick as secretary of transportation than Elaine Chao,\" said Grayson Brulte, who runs an innovation consulting firm. \"She has a proven track record of light regulation and she has made positive statements about the future impact of autonomous vehicles in our society. Ultimately, autonomous forms of transportation will completely transform our society and usher in the single greatest change since the industrial revolution.\"\nOliver McGee, who served as a scientific adviser to Bill Clinton's administration, believes the technology will be central to the Trump administration's pledge to boost the US economy. \"Capital plus technology equals growth, it is basic economics,\" he told The Daily Telegraph. \"This is what will be driving Donald Trump's target for [above three] per cent growth. He needs innovation.\n\"Autonomous vehicles will be part of a very large investment undertaken by Elaine Chao. Her task will be to get Congress to support the $1 trillion spending over the next 10 years.\"\nThis, of course, represents a major cultural shift for the auto industry, which for decades has sold cars on the basis that driving was something to be enjoyed, rather than handed over to a computer.\nThere is also the basic question for all the companies whether consumers will buy into the idea. \"I think this is a tipping point issue,\" said John Quelch, professor of marketing at Harvard Business School. \"With any innovation there is a group of opinion leaders and early adopters who will set the stage and enable the concept to reach a critical mass. Then there is a period of two to three years where people get used to the idea and are convinced of its value.\n\"It is most likely to take off among car users who are using a particular stretch of highway or suburban mothers who are transporting their children to school for example.\n\"I think in 20 years in major cities, 50pc of cars will be driverless.\"\nOthers, such as Adam Jonas, global head of automotive and shared mobility at Morgan Stanley, are more cautious. \"If by the year 2030 more than 2pc to 3pc of miles travelled are truly autonomous, that would be a really impressive number.\"\n'It would be a service where you pay for the time using a car, or a cost per mile'\n'This is what will be driving Donald Trump's target for above three per cent growth. He needs innovation'\n"},
{"docid": "173 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 5, 2017", "title": "NHS trials artificial intelligence app as alternative to 111 helpline\n", "content": "The NHS is to trial an artificial intelligence app as an alternative to the 111 helpline in London.\nIt comes after widespread criticism of the helpline, which aims to deal with\u00a0urgent but\u00a0non-emergency issues but has been beset by delays and accused of giving bad advice.\u00a0\nThe medical app, which will begin trials in north London at the end of January, is being launched in partnership with Babylon Health, a British tech company.\nInstead of describing symptoms over the phone, users type their concerns into a text message-style interface, which the\u00a0AI chatbot responds to with a series of further questions to get more information about the issue.\nBabylon's AI chatbotCredit:      Babylon     \nAt the end of the exchange, the app will advise a patient on how to proceed, an alternative to the advice of 111 call-handlers who are able to send ambulances, book an out-of-hours doctor or suggest other treatment.\nThe trial is seen as a potential solution to the strain on the 111 service. Interactions with the app are significantly cheaper and quicker than speaking over the phone.\nIt is hoped that the database of medical information that Babylon has could mean more effective advice than the 111 staff who are not medical professionals,\u00a0although many users may have misgivings about the effectiveness of medical advice from a chatbot.\n111 has been accused of putting strain on A&E departmentsCredit:      PA     \nBabylon already runs an app that uses AI to assess medical symptoms, allowing\u00a0patients to hold video consultations with doctors for \u00a325 at a time, although this service is not included in the trial.\nMistakes made by call-handlers on the 111 NHS service have been widely criticised, with inquiries finding that staff had insufficient training. Mistakes have been linked to deaths and a rise in A&E referrals .\nKeith McNeil, the NHS's chief clinical information officer, told the Financial Times : \"111 at the moment relies on an employee taking people through a pathway of questioning. They are not clinical professionals necessarily.\"\nNHS 111 | The service's troubled past\n"},
{"docid": "174 of 297 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "October 20, 2016", "title": "Stephen Hawking: artificial intelligence could be the greatest disaster in human history as he opens AI research centre; However the celebrated physicist says there is an alternative and we can harness AI to eradicate disease and poverty\n", "content": "                     Stephen Hawking has warned artificial intelligence could be the greatest disaster in human history if it is not properly managed.\nThe world famous physicist said AI could bring about serious peril in the creation of powerful autonomous weapons and novel ways for those in power to oppress and control the masses.\u00a0\nHawking suggested AI could be the last event in the history of our civilisation if humanity did not learn to cope with the risks it posed.\nBut the cosmologist and professor also said AI could have great benefits and potentially erase poverty and disease.\n\"We spend a great deal of time studying history, which, let's face it, is mostly the history of stupidity. So it's a welcome change that people are studying instead the future of intelligence,\" Hawking said at the opening of the Leverhulme Centre for the Future of Intelligence (LCFI) at Cambridge University on Wednesday.\n\"The potential benefits of creating intelligence are huge...\" he continued. \"With the tools of this new technological revolution, we will be able to undo some of the damage done to the natural world by the last one - industrialisation. And surely we will aim to finally eradicate disease and poverty. Every aspect of our lives will be transformed. In short, success in creating AI, could be the biggest event in the history of our civilisation.\"\nRead more\nStephen Hawking warns over Brexit attitudes towards money\n\"But it could also be the last, unless we learn how to avoid the risks. Alongside the benefits, AI will also bring dangers, like powerful autonomous weapons, or new ways for the few to oppress the many. It will bring great disruption to our economy.\"\nHawking explained that in the future, AI could develop a \"will of its own\" which could be in conflict with the desires of humanity.\n\"In short, the rise of powerful AI will be either the best, or the worst thing, ever to happen to humanity. We do not yet know which\".\nHawking suggested there is no distinction between what could be attained by the biological brain and a computer, even arguing that computers can eclipse and outdo human intelligence. He cited the creation of self-driving cars and computers ability to win at Go as evidence of its advance but called for more research to be done in the area of AI.\nHawking has spoken out about AI on a number of occasions and previously said AI could spell the end of the human race.\n"},
{"docid": "175 of 297 DOCUMENTS\n", "source": "\u00a0The Mirror\n", "date": "November 1, 2002", "title": "CAROL@MIRROR.CO.UK: WWW.OUR FAVOURITE\n", "content": "\u00a0\n 25 Phrases Of Wisdom\n 1. If you're too open-minded, your brains will fall out.\n 2. Age is a high price for maturity.\n 3. Going to church doesn't make you a Christian any more than going to a garage makes you a mechanic.\u00a0\n 4. Artificial intelligence is no match for natural stupidity.\n 5. If you must choose between two evils, pick the one you've never tried before.\n 6. My idea of housework is to sweep the room with a glance.\n 7. Not one shred of evidence supports the notion that life is serious.\n 8. It is easier to get forgiveness than permission.\n 9. For every action, there is an equal and opposite government programme.\n 10. If you look like your passport picture, you probably need the trip.\n 11. Bills travel through the post at twice the speed of cheques.\n 12. A conscience is what hurts when all your other parts feel so good.\n 13. Eat well, stay fit, die anyway.\n 14. Men are from Earth. Women are from Earth. Deal with it.\n 15. No husband has ever been shot while doing the dishes.\n 16. A balanced diet is a biscuit in each hand.\n 17. Opportunities always look bigger going than coming.\n 18. Middle age is when broadness of the mind and narrowness of the waist change places.\n 19. Junk is something you've kept for years and throw away three weeks before you need it.\n 20. There is always one more imbecile than you counted on.\n 21. Experience is a wonderful thing. It enables you to recognise a mistake when you make it again.\n 22. By the time you can make ends meet, they move the ends.\n 23. Thou shalt not weigh more than thy refrigerator.\n 24. 0Someone who thinks logically provides a nice contrast to the real world.\n 25. Blessed are they who can laugh at themselves for they shall never cease to be amused.\n"},
{"docid": "176 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 12, 2017", "title": "HTC U phone tells owners to wear extra clothes if it's cold\n", "content": "The smartphone has been around for more than a decade, but the latest device\u00a0on the market takes the concept to a whole new level by\u00a0telling\u00a0its owner if they need to wear an extra layer of clothing or if they can have a lie-in the next day.\u00a0\nThe HTC U, announced on Thursday, includes artificial intelligence software that can learn\u00a0its owners' daily habits\u00a0and read\u00a0their message data\u00a0and calendars to act as a personal assistant.\nThe software\u00a0develops a picture over time of how users behave so that it can better help them day to day. For example, if the weather is cold and it knows you need to leave the house, it will recommend that you wrap up warm.\u00a0On bank holidays it will suggest they set their alarm for a later time.\u00a0\nThe phones can also tell when users have a busy day by reading calendars, in which case it will request that it is recharged well in advance of running out of power. It can also automatically activate the battery saving mode when it is low on power.\nHTC U Ultra comes in blue, pink, white and blackCredit:      HTC     \nThe device come in two models - the HTC U Ultra and U Play - with a 5.7-inch and 5.2-inch screen respectively. \u00a0The larger device also has a miniature second screen which can display important messages and notifications, by learning what contacts you communicate with regularly.\nThe phones follow Apple's controversial decision last year to remove the headphone jack, instead connecting via Bluetooth or wired USB-C headphones.\u00a0\nThe smart features in the phone reflect how manufacturers have sought to make their devices more useful in an increasingly competitive market. Google added an artificial intelligence assistant to its new Pixel phone last year and Apple has sought to boost the capabilities of Siri.\nThe HTC phones also include four microphones that are always listening out for voice commands, an attempt to improve the often-flawed speech recognition on today's smartphones.\nThe company will be hoping to reverse its declining fortunes, posting losses in the past six quarterly reports,\u00a0with the\u00a0all-glass middle of the range devices. The phones are expected to go on sale in February and price is yet to be confirmed.\u00a0\nBoth the handsets\u00a0have 16-megapixel\u00a0cameras on the front and back, as well has Hi-Fi speakers.\u00a0\n20 bestselling mobile phones of all time\n"},
{"docid": "177 of 297 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "October 8, 1990", "title": "Engineering a way out of a creative crisis; Britain is facing a double dilemma in educating its next generation of engineers, as Eric Ash explains\n", "content": "ENGINEERING is a state of mind rather than a single identifiable discipline. Engineers build bridges; they also build semiconductor devices where the key dimensions amount to only a few atomic layers.\nThey devise the process control systems at the heart of our chemical food processing and nuclear industries and send pulses of light through optical fibres that come and go in a millionth of a millionth of a second. Engineers design satellites - and get them up there. They are teaching computers to think and, perhaps even more importantly, finding ways in which they can learn.\nThe state of mind is the factor common to all engineering disciplines and is based on an enthusiasm for applying science and mathematics to solve problems which can provide lasting benefit - in wealth generation or in improving the quality of life.\u00a0\nEngineering is based on science but differs from it in one vital respect: its mission is synthesis rather than analysis, to create that which did not exist before.\nBritain is now facing a double crisis, however, in educating its next generation of engineers. The basic mission has not changed. The first set of problems stems from the enormous expansion of the themes that require an engineering approach.\nEven within one engineering discipline, the range of topics that could be regarded as essential knowledge for someone solving the problems of the year 2000 and beyond is ever-expanding. For example, reliability, particularly in safety critical systems, used to be regarded as flowing from experience and common sense; it now requires a rigorous and highly mathematical approach. Artificial intelligence is becoming an inherent element of much product design. Also, the excuse that young engineers will pick up management skills and some understanding of corporate finance ''later on'' can no longer be justified.\nThe wrong way to deal with this situation is to stuff more and more material into a three-year undergraduate degree course. That would deprive students of the time and opportunity to develop their creative energies.\nEnthusiasm is a fragile plant that can be permanently damaged by the infliction of an excess of drudgery. The better approach is to recognise that an university degree in engineering is but the first stage in an educational process which has to be a commitment for life.\nThe university course should be devoted to a deep study of the fundamentals - the science and the mathematics - that underlie the engineering disclipline. The course should open windows, portraying to students the fascination of what is not, but could be.\nThe concept of money, which is as much a constraint on engineering design as are the laws of nature, should be introduced. The course should also leave time for students to develop their own ingenuity; time for synthesis, a term I prefer to ''design'', which is wrongly associated in people's minds with deciding on the shape of bits of metal or plastic.\nSuppose we get this right, and it is a tall order, would we be able to produce an elite engineer in three years? It is beginning to be clear that we could not. Nor should that be much of a surprise.\nThe Germans take five or six years, the French five. The Americans take four years to get to the Bachelor of Science stage, but those who aspire to a fully professional status then spend another year on a Masters degree.\nOur students start their engineering studies with a good deal more mathematics and science under their belts than their French, German or American counterparts - albeit at the high price of having missed so much of a more general education. A-levels do take a student further than the Abitur, the Baccalaureate, or than a high school education. That might explain a difference of one year in the length of the education, but not two or three.\nThe issue is coming to the fore as the European Commission grapples with the problem of who can be regarded as a professional European engineer. The commission needs to know by 1992. It seems unlikely that the traditional British course involving only three years of formal education will be regarded as acceptable.\nThat, then, is a further reason why, at least for the fully professional, elite engineer, the university course of study must be extended to four years. Many of our courses at Imperial College already do so; the rest will follow.\nThere is a second crisis facing engineering educators: we lose too many of our students. They do not fall by the wayside: it is one of the great strengths of the British university system that the drop- out rate is very low. Rather, students turn their backs on engineering after they have graduated. A lot of them, and this includes a goodly proportion of the most able, go straight into financial services, management consultancy, accountancy or stockbroking.\nThis is not necessarily a waste. Indeed, many commentators have suggested that it is the lack of science and engineering knowledge in the City that has, at times, led to ill-informed analysis of companies dealing in hi-tech products.\nIf the ''loss'' is a few per cent, it seems quite reasonable. In recent years, however, the loss of graduates to other areas has grown rapidly, and for some departments, particularly from the best institutions, it can now exceed 50 per cent. This cannot be good for UK plc.\nWhy do they do it? Of course, the starting salary in some City companies can exceed that offered by engineering companies by up to 50 per cent. That is by no means the whole story, however.\nCity companies offer not only money, but early responsibility, which is attractive to high-flyers. The City is skilled and imaginative in its recruitment of talent. Recruiting is taken seriously. With rare exceptions, industry in this country does not share this approach.\nThere is also a lot of lamentable and convincing evidence that many industrial companies do not seek to ''stretch'' or offer challenges to those who would enjoy the process. The tendency to treat new engineering graduates as undifferentiated pairs of hands is still a problem in many companies. Happily, the need to compete with alternative attractions is beginning to dawn.\nThere is a widespread perception in engineering that one of the key constraints on growth is the availability of the highest level of creative engineering talent. The problem (major recessions apart) is world-wide. As a result, those graduates whose enthusiasm for engineering remains intact can now work in many different parts of the world - including, of course, the European Community.\nJapan, too, is running short of people. Japanese companies are actively recruiting our graduates, particularly those who have a PhD. In the long run, this must be desirable: working in Japan would be a highly stimulating experience for a new graduate. In the short run, however, it could worsen our own shortage of elite engineers.\nThe shortage has, of course, much to do with schools. Not enough young people are taking A-levels. Of those taking them, not enough are studying science and mathematics. Of those again, not enough choose to embark on a career in engineering.\nThere is one piece of excellent news, however: at long last the fact that engineering is a splendid career for girls is beginning to be accepted. The percentage of girls in engineering has increased substantially in the past few years, albeit from a low base.\nFor example, at Imperial College, more than 30 per cent of students in chemical engineering are girls. If this trend continues - and to do so it needs even more encouragement by schools and parents - it could have a major impact on the future of engineering and on the prosperity of UK industry.\n- Sir Eric Ash CBE, FEng, FRS is Rector of the Imperial College of Science, Technology and Medicine and past president of the Institution of Electrical Engineers.\n"},
{"docid": "178 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "March 24, 2017", "title": "Third of jobs at risk from rise of robots\n", "content": "Nearly a third of jobs in Britain could be lost by the early 2030s because of automation from robotics and artificial intelligence, research suggests. Middleskilled and routine jobs, such as those in accountancy and medical diagnostics, are most at risk.\u00a0\nThe Institute of Labour Economics in Germany found that highly skilled jobs require creativity, cognitive tasks and social attributes such as management and leadership that can difficult to automate.\nLow-skilled jobs that have not been automated often require so much dexterity, teamwork or interaction with customers that they are more tricky for machines to replicate.\nHowever, those in the middle, which tend to involve routine information processing, calculation and decision making, are being hard hit by the advent of cheap, powerful computers and greater access to data, the institute said.\nSome medical diagnostic tests have been automated, eliminating many medical technician jobs, and some nursing tasks have been replaced by machines that monitor patients and dispense medicine, but the nurse's interaction with the patient is largely impossible to automate, the report's author, Michael Gibbs, of the University of Chicago Booth School of Business, said.\nOne result of these changes is that a lot of middle-skilled jobs are being lost and those that remain are becoming less rewarding. \"Technology makes many middle-skill jobs less intrinsically motivating, with fewer tasks and skills, and more centralisation and monitoring,\" Professor Gibbs said.\nUniversities, schools and employers needed to focus on teaching the kind of analytical and problem-solving skills that were least likely to be automated, as well as creativity, social and communication skills, he added.\nSeparate research from PWC found that although nearly a third of jobs could be lost to robotics and artificial intelligence (AI) within the next 13 years, AI-related technologies could also boost productivity and generate jobs elsewhere in the economy. Men could be at greater potential risk of job automation than women, particularly men with lower levels of education, according to PWC's latest UK Economic Outlook report.\nThe sectors with the highest proportion of jobs at risk of automation are transport and storage (56 per cent), manufacturing (46 per cent) and wholesale and retail trade (44 per cent). Education and health and social work are estimated to face the lowest risks of automation, given the high proportion of tasks that are hard to automate.\nJon Andrews, head of technology and investments at PWC, said it was important to ensure that the potential gains from automation were shared more widely across society.\n"},
{"docid": "179 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "September 4, 2017", "title": "Artificial intelligence is bigger threat to civilisation than North Korea, Elon Musk claims\n", "content": "The billionaire technology entrepreneur Elon Musk has suggested that artificial intelligence is a greater threat to civilisation than the North Korean regime .\nIn a series of tweets on Monday the chief executive of Tesla and SpaceX said that \"AI superiority at national level [is the] most likely cause\" of a third world war.\u00a0\nMusk, who has put millions of dollars into trying to ensure that AI is developed safely, regularly raises fears about AI. Along with the likes of Professor Stephen Hawking he has demanded that governments take action to halt the use of autonomous weapons.\n                                        <table>                                                                           \nChina, Russia, soon all countries w strong computer science. Competition for AI superiority at national level most likely cause of WW3 imo.\n- Elon Musk (@elonmusk) September 4, 2017                                                                                                       <table>                                                                           \nMay be initiated not by the country leaders, but one of the AI's, if it decides that a prepemptive strike is most probable path to victory\n- Elon Musk (@elonmusk) September 4, 2017                                                                                  \nHowever, many big names in the tech industry accuse him of scaremongering about a Terminator-like future and misrepresenting\u00a0what AI is capable of.\n\"China, Russia, soon all countries [with]\u00a0strong computer science. Competition for AI superiority at national level most likely cause of WW3 imo,\" Musk tweeted.\nHe followed up by saying a world war might begin almost by accident if machines are given the power to launch attacks, since they may judge that an early strike gives them an advantage when humans might be more cautious.\n\"[WW3] may be initiated not by the country leaders, but one of the AI's, if it decides that a prepemptive [sic]\u00a0strike is most probable path to victory,\" he said.\nMusk added that we should be more worried about addressing killer robots than Kim Jong-Un's North Korean regime, which escalated tensions at the weekend with a new nuclear test.\n                                        <table>                                                                           \nShould be low on our list of concerns for civilizational existential risk. NK has no entangling alliances that wd polarize world into war.\n- Elon Musk (@elonmusk) September 4, 2017                                                                                  \nLast month, Musk led more than 100 robotics and AI leaders in calling for the United Nations to take action against lethal autonomous weapons and in July said that AI was the greatest threat we face as a civilisation .\nMusk's scepticism about AI was recently criticised by Mark Zuckerberg as \"pretty irresponsible\", leading to Musk firing back that the Facebook founder's understanding of the matter was \"limited\" .\n                   At a glance | Autonomous weapons                 \n"},
{"docid": "180 of 297 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "June 22, 2017", "title": "Brexit: will.i.am says artificial intelligence will be more disruptive to UK tech than EU withdrawal; The founding member of The Black Eyed Peas said that by 2030, Brexit will be 'an old school thought'for the UK's rapidly evolving tech industry\n", "content": "The reckless rise of artificial intelligence is going to be much more disruptive for the London technology scene in the longer run than Britain's departure from the EU, according to musician, entrepreneur and philanthropist will.i.am.\nSpeaking at an event celebrating his collaboration with Atom Bank, an app-based digital-only bank launched last year, the founding member of The Black Eyed Peas said that by 2030, Brexit will be \"an old school thought\" for the UK's rapidly evolving tech industry and AI will present a much more acute challenge.\nAt the moment \"no one really understands the things that we should care about,\" he said. \"We need to invest in AI in order to stay ahead.\"\u00a0\nEchoing similar remarks made by Chinese business magnate Alibaba chairman Jack Ma this week, will.i.am said that historically, technology and industrialisation have caused wars.\n\"Technology today hasn't caused turmoil [yet] but we need to make sure it doesn't,\" he said. \"We need to work closer together to be inspiring and encouraging, and to protect the youth.\"\nA time when we do everything on our phones - from banking to screening our medical health and even voting in elections - is \"just around the corner\".\nRead more\nA robot revolution might be coming but don't believe the media\nMultimillionaire will.i.am shot to fame in the early 2000s with hip-hop group The Black Eyed Peas. He's since released several solo albums, collaborated with scores of artists, including Michael Jackson, Justin Bieber, Britney Spears and Lady Gaga. He's broken into television, with talent show The Voice and has also dabbled in fashion.\nHe's a founding shareholder of Beats Electronics, which makes high-end headphones, and an avid philanthropist through his foundation dedicated to providing education to underprivileged students. In the UK, his foundation collaborates with The Prince's Trust.\nEarlier this year, Durham-based Atom announced that will.i.am had been appointed as the bank's first strategic board advisor.\nAs a consumer technology investor, Atom at the time said that the 42-year old, whose real name is William James Adams, would provide an external perspective on culture, philanthropy and technology.\nRead more\nAlibaba's Jack Ma warns evolving technology could cause World War III\nTech firms step in to fund small businesses that banks won't lend to\nAmazon said to be considering takeover of chatroom startup Slack\nGovernment pressuring tech companies to let it read private messages\nAt this week's event, hosted in a Shoreditch hotel, Anthony Thomson, founder and chairman of Atom, elaborated on the perhaps not quite obvious partnership.\nHe said that he had pitched to the musician around two years ago after trying to determine who Atom would be if it were a person.\nHe's \"a guy who has all the qualities we're looking for [in the bank],\" Mr Thomson, who is also the founder and chairman of Metro Bank, said.\nwill.i.am told \nThe Independent\n that he had chosen to work with Atom because of its \"progressive\" approach to banking and the way in which it strives to educate especially young people about saving, in a prescient manner.\nWhen he got his first pay cheque after securing a record deal at 20 years old, he had \"no clue\" how to manage his finances. He said that he developed a habit of stashing the cheques he was receiving in the locked glove compartment of his car. \"That was my idea of saving.\"\nA \"new age type of banking company\", as will.i.am describes Atom, will ensure that young people-especially those from a deprived background who have little understanding of personal finance- are given the opportunity to learn how to manage their savings. He said that he grew up in a poor neighbourhood in east Los Angeles and could relate to youngsters today trying to make living.\nAs a celebrity, he said, he can help Atom \"raise awareness and drive adoption\" and help the lender be to the larger, established banks what a true disruptor, like Uber is to the traditional taxi industry.\n\"This is all about preparing for tomorrow,\" he said. \"No one wants to play catch up.\"\nAtom, which received its banking licence in June 2015, currently offers several savings products and has entered the mortgage market by partnering with brokers. In March it raised \u00a383m from major institutional investors, including Spain's BBVA, veteran fund manager Neil Woodford and Toscafund. It said that it intends to launch further products this year.\n"},
{"docid": "181 of 297 DOCUMENTS\n", "source": "The Independent - Daily Edition\n", "date": "December 22, 2016", "title": "Artificial Intelligence is set to shape our lives - and the economy - in 2017\n", "content": "Will technology at last help us to feel richer in 2017? The prevailing concern for several years now has been that despite rising GDP most people are not feeling any richer, and some people attribute the success of populist politicians to this sense of resentment. That won't go away in the coming year for sure. But we will hear a lot more about the clutch of technologies that potentially can transform our living standards, and accordingly give a practical response to populism by showing that things can and will get better.\u00a0\nThe core set of these technologies goes under the umbrella term Artificial Intelligence. The New York Times Magazine has just run a piece by Gideon Lewis-Kraus, under the title \"The Great A.I. Awakening\", which sums up what is happening. It is largely about what Google is doing in this field, starting with the announcement in London of a much improved version of Google Translate. The improvement is largely down to the application machine learning, which is really a sub-section of AI, but a massively important one. Thanks to AI, the translation service is now much better, and able to produce good colloquial English - and other languages. Google Translate had been getting better, but apparently the overnight improvement resulting from the use of AI was equivalent to all the improvements over the previous four years. It seems that machines are better at learning from their mistakes than humans are.\nThere is a multitude of other ways in which AI will improve the quality of services. One of the more obvious is car navigation. Leave aside the whole self-driving car business, which may or may not transform the world. What is already happening is much better vehicle navigation. Remember all the stories about people slavishly following their satnav and ending up in a river? You hear a lot less of that now. Thanks partly to the huge increase of real-time information about traffic flows and partly to AI, navigation systems have become much better. This is not just about us avoiding motorway jams over the holidays; it is more about optimising delivery routes for goods and services.\nAnother example is speech recognition, where machines are now close to the ability of human beings to understand what is being said. Combine that with machine translation and we are quite close to being able to talk in one language and the listener hear in another - a real version of the fictional babel fish of Douglas Adams' Hitchhiker's Guide to the Galaxy. There are a string of products that nearly do this, but I have been unable track down one that does so reliably and in real time. Wait a year or so, though, and the technology will be there.\nStill another - and slightly spooky - advance is in machine recruitment. Initial filtering of job applications in many companies is now done without a human being actually seeing them, and with only a minority being passed on for consideration. But humans are not good at hiring. If you could improve staff selection by looking at the performance of millions of job-seekers, rather than the quite small selection of the recruiters' personal experience, then the benefit to employer and employee would be huge. Fewer bad appointments from the employer's point of view; fewer poor career choices from the perspective of the job-seeker.\nMy point here is that we are in the early stages of a revolution that will make the world economy much more efficient. It has been dubbed the Fourth Industrial Revolution, the first at the beginning of the 19th century being driven by steam (railways, textile factories, etc), the second at the end of that century by electricity (cars, telephone, consumer durables), and the third from the 1960s on by computers (payment systems, information).\nAs yet we don't fully measure these changes that have taken place. If you are reading this on a Facebook feed, you are doing so because you have signalled that this is the sort of stuff you are interested in. Facebook has cleverly directed this to you. It has done work that you would otherwise have had to do for yourself, rather as your smartphone does the work of looking up the best way to get across town. But time saved is not fully caught in calculations of GDP. We are getting (a bit) richer, but we don't know it.\nMy guess is that as we move into 2017 the hottest issue won't be politics; it will be technology. The contribution of technology is not all positive. Do you want to join the gig economy? Do you want to be interviewed by an algorithm? But if a computer can diagnose an illness better than a doctor, bring it on. So on balance what is happening will make for better lifestyles, whether or not it appears as such in GDP.\n"},
{"docid": "182 of 297 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "February 23, 2016", "title": "Facebook to use artificial intelligence to map out people's homes and give them the internet; The AI will be able to look over satellite imagery and identify areas that have people living in them\n", "content": "                     Facebook is going to use its highly-developed artificial intelligence capabilities to make precise maps of people's homes and give them the internet, it has said.\nThe plan is part of the company's efforts to bring internet across the world, and help get people online and onto its network.\u00a0\nIts newest innovation involves getting hold of satellite imagery and running it through computers that are able to think like humans. Those AI computers can identify areas that look like they hold human populations, and Facebook can then use its technologies to send internet connections to the right places.\nThe social network is already involved in a solar-powered drone project which aims to beam internet signals down to remote parts of the world. This new mapping system could be used in conjunction with the drones.\nIn a blog post discussing the idea, Facebook's Tobias Tiecke explained that the firm was using satellite imagery to map where human activity is, with a computer able to spot and log where man-made buildings are.\n\"Ten percent of the world's population lives in areas of the world where connectivity is simply not available; connecting these often remote and rural areas will require the development of new wireless communication technologies and platforms,\" he said.\nOn stage at Samsung's event, Mr Zuckerberg called virtual reality technology \"the next platform\", and explained his belief that VR headsets will become the social hubs of the future, with users gathering around them in order to connect to friends around the world.\n\"Imagine holding a group meeting or event anywhere that you want,\" he said.\n\"All these things are going to be possible, and that's why Facebook is investing so much early on in virtual reality. So we can help to deliver these kind of social experiences.\"\nSamsung and LG are among the technology giants to announce 360-degree cameras at Mobile World Congress, devices which can be used to create virtual reality video. LG has also been showing a virtual reality headset the connects directly to its latest smartphone, the G5.\nAdditional reporting by Press Association\n"},
{"docid": "183 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "June 1, 2016", "title": "Computers will outperform doctors at diagnosing illnesses, says government technology adviser\n", "content": "Computers will soon outperform even the best doctors at diagnosing illnesses, because of the rapid growth of processing power, a government technology adviser has said.\n                     Richard Susskind, an Oxford professor who has advised governments around the world, said that in the coming years, patients would be able to take pictures of their ailments and receive an accurate, computer-generated diagnosis.\u00a0\nThe technology expert, who is the official IT adviser to the Lord Chief Justice of England and Wales, also said new coding lessons, which have been added to the national curriculum for children as young as five, were a waste of time.\nRichard Susskind is IT Adviser to the Lord Chief Justice of England and Wales, and chairman of the Advisory Board of the Oxford Internet Institute.Credit:      Oxford Internet Institute     \nAppearing at the Hay Festival, sponsored by the Telegraph, Prof Susskind said that advances in artificial intelligence will result in the decline of the traditional professions, such as accountancy, the law, and medicine, as computers become adept at performing the roles of experts.\nHe said: \"It's no longer science fiction. It's no longer the distant future. In our view a lot of these technologies will be coming through in the 2020s.\n\"We're not saying that doctors are going to be replaced overnight, we're not even saying in the 2020s, but we are saying that the practical impact of artificial intelligence research coming out of research laboratories is remarkable.\"\nChildren in a coding lessonCredit:      Paul Grover     \nReferring to the field of medicine, Prof Susskind gave the example of skin disorders. He said: \"Imagine a database of maybe 100 million images of skin disorders with diagnoses beside them.\n\"It's surely intuitively obvious that a high resolution photo taken by an iPhone, matched against that image, if there's that amount of data and that processing power, this is going to outperform the best doctors.\n\"The current professions and the current work of professionals will gradually erode over time because more tasks will be taken over by machines.\"\nHay Festival 2016: a \"stimulating\" experiencePlay!01:17\nIn 2014, the government brought in a new curriculum, which included coding lessons for children . But Prof Susskind said that the development of new, \"self-coding\" systems meant that such lessons were obsolete.\nHe added: \"I belong to the school of thought who don't believe it's a particularly great use of people's time and energy to code. Our thesis is that the next generation of systems will be writing themselves. Automatic code generation is already very common.\n\"Low-level code generation is actually a great intellectual exercise, it's a bit like studying logic, but I don't believe that people learning to code in school will find in seven or eight years that they'll be employable for that reason alone.\n\"Our educational system is not really keeping up to date with these developments. Our universities are developing plenty of 20th century graduates rather than 21st century graduates. What we teach has barely changed since I was there.\"\nREAD MORE ABOUT:\n"},
{"docid": "184 of 297 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "April 16, 2018", "title": "The Guardian view on artificial intelligence: not a technological problem; The dream of a computer system with godlike powers and the wisdom to use them well is merely a theological construct\n", "content": "The House of Lords report on the implications of artificial intelligence is a thoughtful document which grasps one rather important point: this is not only something that computers do. Machine learning is the more precise term for the technology that allows computers to recognise patterns in enormous datasets and act on them. But even machine learning doesn't happen only inside computer networks, because these machines are constantly tended and guided by humans. You can't say that Google's intelligence resides either in its machines or in its people: it depends on both and emerges from their interplay. Complex software is never written to a state of\u00a0perfection and then left to run for ever. It is constantly being tweaked, increasingly often as part of an arms race with other software or networks that are being used to outwit it. And at every step of the way, human bias and human perspectives are involved. It\u00a0couldn't be otherwise. The\u00a0dream of a computer system with godlike powers and the wisdom to use them well is a theological construct, not a technological possibility.\u00a0\nThe question, then, is which forms of bias and which perspectives are desirable, and which we should guard against. It is easy to find chilling examples - the Google image recognition program that couldn't distinguish between black people and gorillas, because it had been trained on a dataset where almost all the human faces were white or Asian; the program used by many American jurisdictions to make parole descriptions turns out to be four times as likely to recommend that white criminals be freed than black ones when all other things are equal. Without human judgment we are helpless against the errors introduced by earlier human judgments. This has been known for some time, but\u00a0the report discusses these dangers very clearly.\nOne thing that has changed in recent years is that a lot of the underlying technology has been democratised. What had used to require the resources of huge corporations can now be done by private individuals, either by using the publicly available networks of Amazon, Google, and other giants, or simply by using cleverly designed software on private computers. Face recognition and voice recognition are both now possible in this way, and both will be used by malicious actors as well as benevolent ones. Most worries about the misuse of facial recognition software stem from their authoritarian use in places like China, where some policemen are already wearing facial recognition cameras, and concert-goers at large events are routinely scanned to see if they are of interest to the police. But the possibilities when they get into the hands of anarchists or apolitical bullies are also worrying.\nWe can't step back into the past and we can only predict the future in the broadest terms. The\u00a0committee is right to suggest principles, rather than detailed legislation. Since personal data can now be used for good and ill in ways that are impossible for the people from whom it has been gathered to predict, the benefits of this use need to be widely shared. The report is important and right in its warnings against the establishment of \"data monopolies\" where four or five giant companies have access to almost all the information about everyone, and no one else does. It is also prescient to identify \"data poverty\", where people do not have enough of an online presence to identify them credibly as humans to other computer networks, as a threat for the future. But neither the problems, nor any solutions, are purely technological. They need political and social action to solve them.\n"},
{"docid": "185 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "February 2, 2015", "title": "Artificial intelligence might be a threat to humans but not for the reasons you think; AI computers will benefit humanity - and fears that they might determine that the planet would prosper without us are unfounded. But machines needn't be self-aware to pose a threat\n", "content": "The new year saw the publication of an open letter from leading artificial intelligence experts arguing for vigilance so as to ensure that this fast developing field benefits humanity. It follows hard on the heels of Stephen Hawking's worries that super smart computers could spell the end of the human race.\nHawking had just upgraded the system that enables him to write and communicate despite his crippling illness. What the computer could do surprised him - just how smart it was - seeming to anticipate what he wanted to write next. This set him thinking about just how intelligent computers were becoming and how quickly that was happening.\u00a0\nOur computers are getting better thanks to the exponential developments that drive this area of science and engineering. The computer you buy today is obsolete in R&D terms and yet is roughly twice as powerful as the one the same money could buy 18 months earlier. This has been happening for decades.\nMy students have access to computers that are 1 million times more powerful than the ones I began my AI research on back in the late 1970s. If we had improved air travel as fast I would fly from London to Sydney in less than a tenth of a second.\nAs well as more powerful computers, we have learned how to write software that \"learns\" to get better, \"understands\" human speech, and \"navigates\" from one place to another. I put the verbs in quotes because for the most part in AI we are not claiming that the algorithms operate in the way that we do when we solve similar tasks.\nA founding father of AI once said \"there are lots of ways being smart that aren't smart like us\". What we have built in AI are numerous slivers of smart behaviour, a digital ecosystem populated with adaptive systems narrowly crafted to a particular niche.\nWhen a high-end computer beat Garry Kasparov, the world chess champion, in the 90s it didn't usher in a new age of intelligent machines. It did demonstrate what you could do with large amounts of computer power, large databases full of moves and good heuristics to look ahead and search possible moves. The overall effect on the world chess champion was unnerving. Kasparov felt as if Deep Blue was reading his mind. Deep Blue had no concept there was another mind involved.\nBut it is easy to endow our AI systems with general intelligence. If you watch the performance of IBM's Watson as it beats reigning human champions in the popular US TV quiz show you feel you are in the presence of a sharp intelligence. Waton displays superb general knowledge - but it has been exquisitely trained to the rules and tactics of that game and loaded with comprehensive data sources from Shakespeare to the Battle of Medway. But Watson couldn't play Monopoly. Doubtless it could be trained - but it would be just another specialised skill.\nWe have no clue how to endow these systems with overarching general intelligence. DeepMind, a British company acquired by Google, has programs that learn to play old arcade games to superhuman levels. All of this shows what can be achieved with massive computer power, torrents of data and AI learning algorithms. But our programs are not about to become self-aware. They are not about to apply a cold calculus to determine that they and the planet would be better off without us.\nWhat of \"emergence\" - the idea that at a certain point many AI components together display a collective intelligence - or the concept of \"hard take off\" a point at which programs become themselves self-improving and ultimately self-aware? I don't believe we have anything like a comprehensive idea of how to build general intelligence - let alone self-aware reflective machines.\nBut there are lots of ways of being smart that aren't smart like us, and there is the danger that arises from a world full of dull, pedestrian dumb-smart programs. Of hunter kill drones that just do one thing very well - take out human targets. Done at scale this becomes an existential risk. How reflective does a system have to be to wreak havoc. Not at all if we look to nature and the self-replicating machines of biology such as Ebola and HIV.\nAI researchers are becoming aware of the perils as well as the benefits of their work. Drones full of AI recognition and target acquisition software alarm many. We need restraints and safeguards built into the heart of these devices. In some cases we might seek to ban their development altogether.\nWe might also want to question the extent and nature of the great processing and algorithmic power that can be applied to human affairs, from financial trading to surveillance, to managing our critical infrastructure. What are those tasks that we should give over entirely to our machines? These are ethical questions we need to attend to. The open letter makes this point forcefully.\nBuilding a self-aware, general intelligence is as far away as ever. However, the audacious ambition of AI continues to attract bright human minds. For those of us working in AI it is a technology that is intended to augment us not replace us, it is a discipline that aims to help us understand our own natures. But all AI researchers need to appreciate the responsibilities as well as the rights involved in carrying out this fascinating work.More like this:\n\u00b7 The mass attention deficit era: what businesses can learn from schools\u00b7 The internet of things is as important as the world wide web\u00b7 Sponsored: What makes smartphones smart? - video\n                       To get weekly news analysis, job alerts and event notifications direct to your inbox,                         sign up free for Media Network membership                       .                                        \n                     All Guardian Media Network content is editorially independent except for pieces labelled \"Brought to you by\" - find out more                                            here                                          .                                        \n"},
{"docid": "186 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "September 6, 2016", "title": "What should be the intelligent response to the rise of the robots?\n", "content": "The media is full of frightening, futurist portrayals of artificial intelligence, but those stories are misleading. There is no race of scary, superhuman robots on the immediate horizon.\nIn reality AI is already with us, thanks to developments in computer chips, low-cost 3D sensors, cloud-based machine learning and advances in speech understanding. We have already grown accustomed to talking to our smartphones. Self-driving vehicles and surgical robot assistants are a reality and service robots, bringing improvements in everything from healthcare and education to the military and logistics, are on their way.\nTo look at the potential impact of AI on society, a group including Amazon, Facebook, IBM, Microsoft and Alphabet, the parent company of Google, is planning to create new ethical standards for the sector and will announce its work this month, according to The New York Times.\u00a0\nIts starting point is likely to be a report, The One Hundred Year Study on Artificial Intelligence, the first of a series of papers planned by experts brought together by Stanford University. The Stanford group focuses on how AI might affect the inhabitants of a typical North American city, which it hopes can be made more broadly applicable to other locations. It does not look at the military use of AI. One of the most interesting topics is what AI could mean for the demand for labour and skills.\nTo date, \"routine\" digital technologies such as information processing and search have affected how we work, but the effects have been felt most by \"the skilled middle\", such as travel agents, rather than the very lowest or highestskilled work. AI, on the other hand, is creeping up the hierarchy into professional services. For example, it is being applied already to parts of lawyers' jobs to extract legal information. With the loss of wellpaying \"cognitive\" jobs, the Stanford report asks, what safety net, if any, will there be for the professional classes? AI is also likely to have an increasing impact on city infrastructure and transport. Yet accurate predictive models of individuals' movements raise privacy concerns. Furthermore, AI applications and the data on which they rely may reflect the biases of their designers. How, the report asks, can AI applications be prevented from unlawful discrimination that concentrates benefits unequally among different subgroups of society? And who is liable if AI goes wrong? If a court fails to find liability because an AI designer could not foresee the harm caused, there's a danger that liability would fall by default on a blameless victim.\nThe Stanford group does not have all the answers, but it suggests that these changes will require a political rather than a purely economic response and it makes three initial recommendations.\nThe first is to build up government expertise in AI, including in what it can and cannot do. The second is to remove impediments (including unnecessary regulations) to research on the fairness, security, privacy and social impacts of AI systems. Finally, there's the inevitable call for increased public and private funding for interdisciplinary studies of the impact of AI.\nIt also warns that dystopian fears about AI must not be allowed to cloud a serious discussion about its regulation. As one Stanford group participant, Astro Teller, head of Alphabet's R&D facility X, says, it's not good enough for regulators and the rest of us to rely on industry experts saying \"trust us\".\nLike it or not, the robots are coming and we all need to think about what this means for the way we live, work and make money.\nAlexandra Frean is Business Columnist of The Times Artificial intelligence in cars Automated functionality Release date ** Intelligent parking assist Since 2003 Summon car from garage Since 2016 Lane departure system Since 2004 Adaptive cruise control Since 2005 Blind spot monitoring 2007 Lane changing 2015 Source: One Hundred Year Study *in North America\n"},
{"docid": "187 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 23, 2018", "title": "We have just one shot at taming the artificial intelligence genie - and Britain can show the world how\n", "content": "Everybody is talking about AI (Artificial Intelligence) - and from Beijing to Ottawa, governments are planning their strategies for harnessing this transformative technology. In the last Budget, the UK Government joined this bandwagon, declaring its intention to become \"a world leader\", and announcing investment of over \u00a375 million to develop the sector.\nThis is all very welcome: AI really does promise new levels of health and prosperity. But it won't fulfil this promise if it is allowed to develop unfettered. The Silicon Valley culture of \"move fast and break things\" fitted an industry in its infancy, but not one that stands to transform almost every aspect of our lives. If we are going to join a race to develop intelligent machines, we must be prepared to race just as fast to develop the codes and standards that will also preserve what we hold most precious.\u00a0\nWe have seen what happens when we permit an exciting new technology to develop unchecked: social media platforms have brought us many benefits, but also fake news, filter bubbles and echo chambers ; they have sucked up our personal data and become tools of foreign powers. Now companies like Facebook are trying - too little, too late - to tame this genie.\nBut the algorithms behind Google and Facebook are just the first taste of the AI revolution. Smart machines will soon be driving our cars, diagnosing us at the doctor's, managing the flows of goods and money around the world, educating our kids, and much, much more. All of this should bring new efficiencies and insights, improving outcomes and freeing up more of our time for what matters in life.\nBut it will also expose us to new dangers: new ways in which we can be manipulated by programmes that know just what phrases will make us press \"buy\", or vote \"yes\"; or in which the already underprivileged can be discriminated against by unaccountable algorithms; or in which we can become dependent on systems we do not understand, losing bit by bit our skills, our jobs, and our dignity.\nAs this technology becomes more powerful - which it surely will given the amount of money and talent pouring into the field - its capacity to break things will grow further. Machines are already smarter than us in many narrow domains; now researchers are working towards more human-like general intelligence, or even super-intelligence. Many experts believe we can achieve this within decades. If we do, we will have just one shot to get it right: we might tame a genie, but not a god.\n.html-embed.component .quote.component{margin-left:0}.html-embed.component .quote.component .component-content{margin-right:16px}.quote__source, .quote__author {white-space: normal;}@media only screen and (min-width:730px){.html-embed.component .quote.component{margin-left:-60.83px}.html-embed.component .quote.component .quote__content:before{margin-left:-12px;padding-right:1px}}@media only screen and (min-width:1008px){.html-embed.component .quote.component{margin-left:-82.33px}}When the machines make mistakes - as they will, potentially in technologies used by millions - we need to know where to look for responsibility and redress\nSo as governments invest their billions in AI, it is essential that they also ask what we want from it. Just because we can hand over a task to a smart machine does not mean we should. And where we do, we need to know that its decisions are fair and transparent. And when the machines make mistakes - as they will, potentially in technologies used by millions - we need to know where to look for responsibility and redress. And as AI grows in power, we need to know how to stay in control.\nWe don't have all the answers to these questions. Far from it: some involve complex technical challenges that might take years of research; others require the broadest consultation about what kind of society we want. There is much hard work to be done, nationally and internationally. But it is clear that just as we do not \"move fast and break things\" with civil engineering, or drug development, or nuclear energy, we shouldn't with AI.\nIt is therefore very welcome that the Government has announced a new Centre for Data Ethics and Innovation, with the task of ensuring that AI is developed safely and ethically. With bodies like the Human Fertilisation and Embryology Authority, and the Nuffield Council on Bioethics, the UK has a proud tradition of fostering thoughtful, responsible innovation. From Beijing to Ottawa, the world needs this as much as it needs new programmes and processors.\nSo yes, we have an opportunity to become world leaders: but not just in apps and algorithms. We can aspire to set the standard for what it means to live well and safely in the age of intelligent machines.\nStephen Cave is Executive Director of the Leverhulme Centre for the Future of Intelligence at the University of Cambridge\n"},
{"docid": "188 of 297 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "August 14, 2017", "title": "People are far more likely to be killed by artificial intelligence than nuclear war with North Korea, warns Elon Musk; 'If you're not concerned about AI safety, you should be'\n", "content": "Elon Musk says artificial intelligence poses more of a \"risk\" than a potential nuclear conflict between the US and North Korea.\nThe CEO of Tesla issued the warning after an AI built by OpenAI, a company founded by Mr Musk, defeated the world's best \u00a0\nDota 2\n players after just two weeks of training.\n\"If you're not concerned about AI safety, you should be. Vastly more risk than North Korea,\" he tweeted shortly after the bot's victory, along with a picture of a poster bearing the slogan: \"In the end, the machines will win\".\nThe poster, incidentally, is actually about gambling.\n\"Nobody likes being regulated, but everything (cars, planes, food, drugs, etc) that's a danger to the public is regulated. AI should be too,\" he added later.\n\"Biggest impediment to recognizing AI danger are those so convinced of their own intelligence they can't imagine anyone doing what they can't.\"\nA recent University of Oxford study concluded that AI will be better than humans at all tasks within 45 years, and many people, including Stephen Hawking, believe humans will be in trouble in the future if our goals don't align with those of machines.\nHowever, following the exchange of increasinglyheated words between Donald Trump and Kim Jong-un, some Twitter users pointed out thatnuclear war might wipe humans outbefore AI even gets the chance to.\nMr Musk has spoken out about the potential dangers of AI on numerous occasions, and recently engaged in a war of words with Mark Zuckerberg, who has a very different outlook to him.\nAfter Mr Musk called AI \"a fundamental existential risk for human civilisation\", the Facebook founder branded his views as \"negative\" and \"pretty irresponsible\".\nMr Musk hit back by saying Mr Zuckerberg's understanding of the subject was \"limited\".\nRead more\nCould North Korea go to nuclear war with the US?\n                     He wants the companies working on AI to slow down to ensure they don't unintentionally build something unsafe, and says it needs to be regulated.\n\"I think we should be really concerned about AI and I think we should... AI's a rare case where I think we need to be proactive in regulation instead of reactive,\" he said last month.\n\"Because I think by the time we are reactive in AI regulation, it's too late.\"\n"},
{"docid": "189 of 297 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "January 9, 2016", "title": "Artificial intelligence firm bought by Apple; NEWS IN BRIEF TECHNOLOGY\n", "content": "Apple has purchased Emotient, a San Francisco startup company that uses artificial intelligence to analyse facial expression and detect emotion. The company claims the technology helps give businesses a better understanding of the emotional connection and attention being given to their advertising and products.\u00a0\n"},
{"docid": "190 of 297 DOCUMENTS\n", "source": "\u00a0The Mirror\n", "date": "March 12, 2005", "title": "THE POACHER: DUNFERMLINE\n", "content": "\u00a0\n WITH Dunfermline\"s bid to stay plastic looking doomed, the artificial intelligence of the pitch supplier seems to be lacking perspective.\u00a0XL Turf sales director Paul Hassin said: \"They are pioneers. The club has had to put up with scepticism, but people laughed at Christopher Columbus when he said the world was round. Down the line people will wonder what all the fuss was about.\"\n"},
{"docid": "191 of 297 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "October 20, 2017", "title": "Artificial intelligence commission needed to predict impact, says CBI; Business group urges government to launch commission to assess consequences of AI on jobs and increasing productivity\n", "content": "Britain's biggest employers are calling for a commission to examine the impact of artificial intelligence on jobs.\nAmid predictions of a workplace revolution threatening one in five jobs across the UK, the CBI is urging Theresa May to launch the commission from early 2018. It said companies and trade unions should be involved and the commission should help to set out ways to increase productivity and economic growth as well looking into the impact of AI.\u00a0\nThe business lobby group said almost half of firms were planning to devote resources to AI, while one in five had already invested in the technology in the past year. \nCompanies are increasingly using computers to scour vast datasets in order to spot inefficiencies, while they are also employing machines to control the flow of activity in warehouses and factories and to take meter readings. Accountancy firm PwC warned in March that more than 10 million workers may be at risk of being replaced by automation.\nWhile robots could lead to job losses, they could also present opportunities for workers to move into more fulfilling and productive roles. The TUC has been urging the government to use the productivity gains from automation to benefit workers, calling for the reversal of planned changes to the state pension age and more investment in training for employees.\nThe CBI suggests innovative firms grow twice as fast - both in terms of employment and sales - and that adopting new technology can get the best out of workers. As much as 50% of labour productivity can be driven by innovation, according to the CBI. \nInvestment in technology could help bolster Britain's sputtering record on labour productivity, which is among the worst in the G7 and is failing to improve in line with expectations since the financial crisis.\nThe Office for Budget Responsibility was forced to downgrade its estimates for labour productivity growth last week, wiping out about two-thirds of the government's \u00a326bn budget surplus from 2017 to 2021. The development will come as a blow to the chancellor, Philip Hammond, as it will remove headroom for his public spending plans before the budget next month.\nDespite the potential for technology to increase productivity, firms are cautious about investing owing to uncertainty over Brexit. Growth in business investment was flat in the three months to June, the latest official figures show. \n"},
{"docid": "192 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "December 21, 2017", "title": "Artificial intelligence pioneer dies at 55\n", "content": "Tributes have been paid to one of the world's foremost authorities on computer science and artificial intelligence following his sudden death, aged 55.\u00a0\nJon Oberlander was assistant principal for data technology at the University of Edinburgh, where his interest was enabling computers to talk or write.\nHe had been driving forward the Bayes Centre as a hothouse for data technology, nurturing ideas and enabling the university to interact with businesses and organisations all over the world.\nHe was involved in the Edinburgh International Science festival to such an extent, said Simon Gage, its director, that whenever the organisers had a problem, \"the answer was 'ring Jon'\".\nProfessor Oberlander also played a vital role in processing the data behind the Harmonium Project, the sound and light show that animated the exterior of the Usher Hall for the opening of the 2015 Edinburgh International Festival.\nJamie Coleman, the co-founder and chairman of Codebase, a company that nurtures technology start-ups, said that Professor Oberlander, \"had an utterly exceptional mind and was an extraordinarily kind man\".\n"},
{"docid": "193 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "March 27, 2017", "title": "We have nothing to fear from artificial intelligence, says pioneer\n", "content": "Elon Musk and Bill Gates are among those who fear that artificial intelligence threatens mankind, but such critics have been rebuked by the head of Google's project to make a machine that can learn and create like a person.\u00a0\nDeep Mind, a British business bought by Google three years ago, is taking on problems from diseases to inefficien- cies in the National Grid, just as others say that a superhuman AI could be our deadliest invention.\nDemis Hassabis, Deep Mind's chief executive, said that apocalyptic visions of the future were mostly based on ignorance. \"I don't think it's very helpful for other people who are incredible in their domains commenting on something they actually know very little about,\" he said, \"but because they are quite big celebrities now, more than just scientists or businessmen, it gets picked up a lot.\"\nDr Hassabis told an event organised by the Cambridge Society for the Application of Research: \"There are some valid worries and I think these are research questions of vulnerability and interpretability, but I think this general meme of fearfulness doesn't help reasoned debate. It actually drives that debate away. I've told all of those people you mentioned [Mr Musk and Mr Gates] that it's not very helpful. Some of them have moderated their comments, but others haven't.\"\nDeep Mind has sought advice from philosophers and mathematicians as well as digital engineers on how to build a machine that will not run out of control. The stakes are high, as the software is shaping decisions that will affect lives. The company has been criticised for striking a deal to analyse patient data for the Royal Free Hospital in London and is in talks to optimise the National Grid, which could save 10 per cent of the UK's energy.\nDr Hassabis believes that the real danger would come from a self-improving \"seed\" AI that would understand and rewrite its own source code without any human oversight.\n"},
{"docid": "194 of 297 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "January 24, 2018", "title": "Move fast and break things? Not with AI; Artificial intelligence could change many aspects of our lives, but it will also expose us to new dangers\n", "content": "Everybody is talking about AI (Artificial Intelligence) - and from Beijing to Ottawa, governments are planning their strategies for harnessing this transformative technology. In the last Budget, the UK Government joined this bandwagon, declaring its intention to become \"a world leader\", and announcing investment of more than \u00a375million to develop the sector.\nThis is all very welcome: AI really does promise new levels of health and prosperity. But it won't fulfil this promise if it is allowed to develop unfettered. The Silicon Valley culture of \"move fast and break things\" fitted an industry in its infancy, but not one that stands to transform almost every aspect of our lives. If we are going to join a race to develop intelligent machines, we must be prepared to race just as fast to develop the codes and standards that will also preserve what we hold most precious.\u00a0\nWe have seen what happens when we permit an exciting new technology to develop unchecked: social media platforms have brought many benefits, but also fake news, filter bubbles and echo chambers; they have sucked up our personal data and become tools of foreign powers. Now companies such as Facebook are trying - too little, too late - to tame this genie.\nBut the algorithms behind Google and Facebook are just the first taste of the AI revolution. Smart machines will soon be driving our cars, diagnosing us at the doctor's, managing the flows of goods and money around the world, educating our kids, and much, much more. All of this should bring new efficiencies and insights, improving outcomes and freeing up more of our time for what matters in life.\nBut it will also expose us to new dangers: new ways in which we can be manipulated by programmes that know what phrases will make us press \"buy\", or vote \"yes\"; or in which the underprivileged can be discriminated against by unaccountable algorithms; or in which we can become dependent on systems we do not understand, losing bit by bit our skills, our jobs, and our dignity.\nAs this technology becomes more powerful - which it surely will, given the amount of money and talent pouring into the field - its capacity to break things will grow further. Machines are already smarter than us in many narrow domains; now researchers are working towards more human-like general intelligence, or even super-intelligence. Many experts believe we can achieve this within decades. If we do, we will have just one shot to get it right: we might tame a genie, but not a god.\nSo, as governments invest their billions in AI, it is essential that they also ask what we want from it. Just because we can hand over a task to a smart machine does not mean we should. And where we do, we need to know that its decisions are fair and transparent. And when the machines make mistakes - as they will, potentially in technologies used by millions - we need to know where to look for responsibility and redress. And as AI grows in power, we need to know how to stay in control.\nWe don't have all the answers to these questions. Far from it: some involve complex technical challenges that might take years of research; others require the broadest consultation about what kind of society we want. There is much hard work to be done, nationally and internationally. But it is clear that, just as we do not \"move fast and break things\" with civil engineering, or drug development, or nuclear energy, we shouldn't with AI.\nIt is therefore very welcome that the Government has announced a new Centre for Data Ethics and Innovation, with the task of ensuring that AI is developed safely and ethically. With bodies like the Human Fertilisation and Embryology Authority, and the Nuffield Council on Bioethics, the UK has a proud tradition of fostering thoughtful, responsible innovation. From Beijing to Ottawa, the world needs this as much as it needs new programmes and processors.\nSo yes, we have an opportunity to become world leaders: but not just in apps and algorithms. We can aspire to set the standard for what it means to live well and safely in the age of intelligent machines.\nStephen Cave is the executive director of the Leverhulme Centre for the Future of Intelligence at Cambridge University\nFOLLOW Stephen Cave on Twitter @stephenjcavereadmoreattelegraph.co.uk/opinion\n"},
{"docid": "195 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 3, 2018", "title": "Artificial intelligence 'to diagnose heart disease'\n", "content": "Artificial\u00a0intelligence that can diagnose scans for heart disease and lung cancer could be used by the NHS this year.\nResearchers at an Oxford hospital developed a system that they claim could save billions of pounds by enabling the diseases to be picked up much earlier.\u00a0\nThe heart disease technology  will start to be available to NHS hospitals for free this summer.\nGeneticist Sir John Bell, told BBC News that AI could \"save the NHS\".\n\"There is about \u00a32.2bn spent on pathology services in the NHS. You may be able to reduce that by 50 per cent. AI may be the thing that saves the NHS,\" he said.\nCardiologists currently diagnose problems by monitoring the timing of the heartbeat in scans but are not always accurate, with one in five patients either suffering a heart attack or undergoing an unnecessary operation.\nThe AI system developed at the John Radcliffe Hospital is said to diagnose heart scans much more accurately by picking up details that doctors cannot see.\nThe technology has been tested in clinical trials in six cardiology units, with the results due to be published this year.\nBut Prof Paul Leeson, a cardiologist who developed the system, said data indicates that it had greatly outperformed his fellow heart specialists.\nCalled Ultromics, it was trained to identify potential problems in the scans of 1,000 patients treated over the past seven years, along with information about whether they went on to have heart problems.\n\"As cardiologists, we accept that we don't always get it right at the moment,\" Prof Leeson said.\n\"But now there is a possibility that way may be able to do better.\"\nIf confirmed, it will be available for free to NHS hospitals across the country,\nProf Sir Malcolm Grant, the chairman of NHS England, said in 2015 that artificial\u00a0intelligence would bring NHS patients a greater quality of care by better diagnosing medical conditions and personalising treatment.\nHe said the health service would benefit hugely from the use of machine learning and robots, suggesting that if such technology could outperform humans, it would be \"daft\" not to use it.\nHe acknowledged that the subject was \"fraught with ethical issues\" but suggested that the medical profession needed to be \"more focused\" in the way that it used treatments.\nOf 60,000 heart scans carried out each year, 12,000 are reportedly misdiagnosed at an estimated cost of \u00a3600million.\n"},
{"docid": "196 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "July 24, 2016", "title": "Banks switch from phone menus to robot advice\n", "content": "Few household chores are as infuriating as spending an age on the phone to complain to your bank, recover a lost password or answer some minor financial query.\nHold music, press number 4 for an option that is only half-related to your problem, more hold music.\nBanks are under pressure to cut costs while improving service - which is crucial to keeping customers and improving the industry's battered reputation.\u00a0\n                     One hope lies in new technology and, in particular, robots . Several British banks are ploughing money into artificial intelligence (AI) in the hope that it could start helping customer service behind the scenes in the coming months and soon be let loose on the public.\n                     Barclays' former chief executive, Antony Jenkins, believes half of all jobs in banking could be chopped in the next decade as automation takes hold, underlining the scale of potential transformation.\nEnabling Britons to check their balances, transfer funds and even pay in cheques using smartphones has already allowed banks to cut hundreds of branches, saving millions of pounds while simultaneously improving service. In the near future basic complaints handling, forgotten passwords and other simple queries could also be a human-free zone, with several banks working to deploy online chat systems that run on robots.\nRoyal Bank of Scotland is trialling its system initially as an aid to staff, who answer the questions themselves, while the robot learns from their actions.\n\"AI allows us to answer simple customer questions quickly and efficiently, while freeing up time for our staff to answer more complex questions,\" says Chris Popple, RBS's head of digital banking. \"We are now looking at conducting pilots with members of the public to test the experience, refine its intelligence and understand its suitability for customers.\"\nTwo key problems have presented themselves so far. The first is that the artificial intelligence robots are new and, frankly, not very good.\n                     Atom Bank, a new mobile app-only lender, is tinkering with a robot that currently gets the answer correct roughly 65pc of the time. Put another way, the robot gets the wrong answer seven times out of every 20. The bank wants to improve performance to at least 85pc accuracy before letting the public use the service.\nAtom Bank, headed by chief executive Mark Mullen,\nSome of the gremlins should, in theory, be addressed through practice. Robots can learn colloquialisms and spot spelling mistakes and poor grammar, by watching humans process enquiries.\nWhen RBS started using the system, it could answer only 20 questions and was accurate just 10pc of the time. After several months of trial use, the machine can now answer 400 questions with 90pc accuracy.\nA second problem is that machines might be able to translate a query, but they are still unable to empathise.\n\"Customers are becoming much more demanding [of their banks] and they want a service which offers convenience, choice and competence. There is definitely room for AI if it speeds this up, is convenient and offers a choice,\" says Mike Petrook, from the Institute of Customer Service.\nBut customers also value helpful staff with a positive attitude. \"That is where AI, at the moment, can fall down - it speeds things up, it does point people in the right direction, but it is not yet mature enough to understand human emotions,\" he says. \"It could be understanding that someone has different financial commitments they have not yet started, for example, someone who may be about to send their kid to private school. Or in complaints, an AI system would say, 'What is your complaint, OK I can resolve that,' but it does not hear the frustration.\"\nThe ability to speak to a person when tackling big transactions such as a first mortgage is highly valued.\nThe banks acknowledge this - Atom Bank will give customers the option of chatting to a human or a machine. First Direct's online advertisement promises no one will ever have to talk to a robot.\nBanks are trying to find new ways to help with big decisions including investments, with so-called robo-advice that would cater to customers unable to afford a financial adviser in the wake of tougher rules on fees and training.\nXerox, a technology firm which runs Atom's robots, is sceptical that customers will be comfortable with such a basic service. \"It is as much about the technology as it is about trusting the person,\" said Doug Overton. \"The customer is paying for advice, they want to look the person in the eyes, they want to really know the person has all of the professional credentials to give that advice. That is a behavioural change that will take a number of years before you get there.\"\nThat personal trust is not needed for basic queries. But when it comes to high-value banking jobs, the human staff are still safe in their jobs - for now.\nFollow the latest Telegraph Business newsREAD MORE ABOUT:\n"},
{"docid": "197 of 297 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "February 25, 2013", "title": "Computer designed by scientists to compose music which makes the brain feel happy\n", "content": "Scientists are developing an intelligent music computer which can analyse a person's brain activity when they listen to sounds and then composes new music designed to make them happy.\nResearchers, who believe the mood-altering music-writing software can help combat stress and depression, will unveil the first composition created by the project at a music festival in Plymouth tomorrow. (Sat)\nThe project is being led by Dr Eduardo Miranda, a composer and professor at Plymouth University's Interdisciplinary Centre for Computer Music Research (ICCMR), and Dr Slawomir Nasuto, a professor in the Cybernetics Research Group at the University of Reading.\u00a0\nUsing Artificial Intelligence techniques, the computer will play music and analyse the brain activity of the listener for emotional indicators. Based on this feedback, and a programmed knowledge of music, it will generate new sounds that can alter these emotions.\nThe project has been awarded a \u00a3880,000 grant by the Engineering and Physical Sciences Research Council.\nThe first public demonstration of the research will be a concert entitled 'Symphony of Minds Listening' on Saturday, in which the second movement of Beethoven's 7th Symphony will be \"remixed\" and reassembled to reflect the brain-scanned activity of three volunteers during listening.\n\"We all know music affects mood but we don't really know how,\" said Dr Mrianda. \"We want to see if we can find musical melodies or rhythms which elicit specific moods. Which kind of musical features in composition elicit physical signatures in brain patterns? Our project is to build a new system for musical composition.\"\nThree volunteers - a classic ballerina, a Gulf War veteran and Dr Miranda himself - have undergone functional magnetic resonance imaging (fMRI) brain scans as they listened to the Beethoven Symphony.\nHaving analysed their emotional responses, with the help of bespoke artificial intelligence software developed at ICCMR, Dr Miranda re-structured the original orchestral score to reflect the volunteers' brain activity during listening. The Ten Tors Orchestra will perform the new work at the Peninsula Arts Contemporary Music Festival tonight.\nDr Miranda said: \"There's a lot of differences in the way people listen. With the classical ballerina there was a lot of activation around the motor cortex because she listens to music based on the kind of movement she can make.\"\n\"I deconstructed the 2nd Movement and reassembled and modified the rhythms and melodies based on information from the brain scans,\" he said.\nThe ballerina's brain yielded mostly rhythmic deviations from the original, whiles Dr Miranda's produced mostly harmonic deviations.\nDr Miranda has posted a preview of his composition, scored for a string quartet, a flute and a clarinet, on the Soundcloud music-sharing website.\nThe \"mood-altering music computer\" could have a number of therapeutic applications. \"If you have depression, instead of getting drugs to treat it, imagine if you could take people to a musician instead?,\" Dr Miranda said. \"You would go to see a musician and they would diagnose what kind of music they could be listening to, to improve their condition.\"\nThe entertainment industry could also benefit. \"It could be used for cinema and advertising. The holy grail in advertising is to induce the correct emotion in a viewer.\"\nBut musicians, whose livelihoods depend on writing pieces which unversalise human emotions using their own artistic intuition, may be concerned that they are being written out of the script altogether.\nDr Miranda predicts a Hollywood revolution in which \"a computer system analyses the emotions its sees in the faces of film characters. The system then comes up with ideas to speed up the compositional process for a film soundtrack. When we get the results I will approach industries ranging from health to entertainment.\"\nJessie Ware, the Brit Award-nominated singer, said: \"It's a very exciting project and I'd love to see how it works. But I hope it doesn't wipe every musician out of a job. I'd like to think musicians themselves have the ability to inspire and move listeners in the way I have been by particular singers.\"\nMs Ware said she would choose Joni Mitchell and Feist as her favourite \"mood music\". \"When I'm cooking I like listening to jazz,\" she said. \"It's very personal.\"\n"},
{"docid": "198 of 297 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "February 8, 2018", "title": "Police 'may need AI to help cope with huge volumes of evidence'; Investigations are being challenged by ever-increasing amounts of digital data\n", "content": "Police should look at using artificial intelligence to help cope with the scale of information involved in investigations and avoid the kinds of mistakes that have led to a string of collapsed rape trials, a senior police chief said on Wednesday.\nSara Thornton, the chair of the National Police Chiefs' Council, said the volume of data held by individuals had massively increased the number of potential lines of enquiry that officers must pursue to understand a case. \u00a0\nIn recent months, several rape prosecutions have been dropped after it emerged that police had failed to hand over evidence that undermined their cases. Since then, the Crown Prosecution Service has announced a review of all current rape cases and Nick Ephgrave, the NPCC's lead on criminal justice, has admitted that police have a \"cultural problem\" with disclosure.\nThe attorney general's guidelines on disclosure say that police have a duty to pursue all reasonable lines of investigation, leading both towards and away from a conviction, Thornton said. Raising the prospect that more challenges may emerge in the future, she said that the problem was linked to violent crime, but that \"in the first instance\" issues had emerged around sexual offences. \n Related:  Urgent review of all rape cases as digital evidence is withheld\n\"What we are really challenged by is the volume of data which all of us hold in 2018, and therefore the potential for many, many more reasonable lines of enquiry than was ever the case. I'm not just talking about twice as many... the numbers that we're talking about are really significant.\"\nThornton said that suspects and complainants should be asked at the outset of an investigation whether there might be any evidence on their phones or digital footprints which are relevant. But, with tight resources, the ultimate answer lay in technology. \n\"I think the challenge for us is how we can use technology more, beyond search terms. So how can you use... machine learning, artificial intelligence, whatever phrase you want to use, to get clever tech to help us to do this?\"\nSuch methods were already in use in civil cases, Thornton said, and the CPS has now set up a group to look at how it could be employed in criminal trials. \"Because, in a way, it's technology that's causing us the big challenge, technology has got to be part of the answer, so that's what we are trying to do.\"\nThornton's comments came ahead of an NPCC briefing on knife crime, where the organisation's lead on the issue announced a nationwide week of action from Monday. Duncan Ball, a deputy assistant commissioner in the Metropolitan police, said the operation would include knife sweeps, targeted stop and search, and test purchases. \n Related:  Arresting kids won't stop knife crime. Police should target the men in suits | David Lammy\nAnecdotal reports from officers in units that focus on gang crime, such as the Met's Trident Command, suggested that a cut in the numbers of stop and search had given youngsters the impression they were less likely to be searched, he said. \nBall also said that he would be travelling to Scotland, where authorities have taken a \"public health approach\" to knife crime that has led to a dramatic fall in the number of fatal stabbings. \n\"Clearly, it's been successful in Scotland,\" Ball said. \"One of the interesting things I think - and I obviously completely support the comments of the commissioner previously made in that it sort of takes a more holistic, more of a wide-system approach to how we're looking at it - is identifying how that can be transferred.\"\nHowever, different forces with different needs would need to apply the principles in different ways, Ball said, adding that he would guard against a \"one-size-fits-all approach\".\n\"I think the other challenge within that [is that it's] clearly not just a policing issue, it's health, education, everything else that's involved in it. I think, again, there's a strong role for the Home Office in providing the broader strategy at the moment in terms of how the intervention, the health bit, is included.\"\n"},
{"docid": "199 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "June 21, 2017", "title": "Artificial intelligence dolls and robots which cost over \u00a3100 are this year's Christmas must-have toys\n", "content": "This\u00a0year's Christmas must-have toys will be life-like dolls with artificial intelligence and a Lego robot which can be controlled from an iPad, according to Argos.\u00a0\nBut the introduction of new \"pimped up\" versions of classic toys mean parents can expect to takean extra large\u00a0hit to the wallet, as the toys are part of a growing number which cost over \u00a3100.\nArgos said the new breed of \u00a3100 gift could spell the end of children expecting a full Santa sack as they would be hoping for one or two high value items instead.\u00a0\nIt said the most popular choice among parents this year was a \"blockbuster gift\", with over half (54 per cent) planning on purchasing a \"gasp out loud\" present alongside a couple of stocking fillers.\u00a0\nThe Luvabella doll, which retails at \u00a399.99, has fluid movements and responses to\u00a0being fed and cared for like a real baby. For example she laughs when her feet are ticked, and gets upset when her eyes are\u00a0covered for too long.\u00a0\nAlso aimed at girls is a \"Tiny Treasures Twin Set\" doll for \u00a379.99, which is available as a set of twins. One boy, one girl, the dolls are weighted like real newborns and have sleepy eyes, silky newborn hair, super-soft skin and its skin is made to smell like a real baby.\nLEGO Boost, which retails at \u00a3149.99 lets children build five different models out of bricks including Vernie the robot, all of which can be brought to life by coding through a free app which can be downloaded to an iPad.\nA spokeswoman at Let Toys Be Toys, which campaigns for gender equality in toys, said: \"When the price of toys is rising, people buying toys may feel their 'safe' option is to fall back on tired\u00a0stereotypes of toys for girls or toys for boys. In fact, when spending a significant amount on a toy, it is even more important that children get the chance to find something they'll really love.\"\n"},
{"docid": "200 of 297 DOCUMENTS\n", "source": "Guardian.com\n", "date": "December 14, 2012", "title": "Artificial Intelligence by accident\n", "content": "ABSTRACT\nJessica Thom: An attempt to construct a Tourette's inspired Twitter account appears to have taken on a life of it's own\u00a0FULL TEXT\nI should say from the outset that my scientific knowledge is very limited. In most areas it stretches little beyond the rudimentary fragments that sank in at school. I can probably still do an annotated pencil drawing of a cell, take an educated guess at what colour an unborn mouse will turn out to be based on the characteristics of its parents, and create a dramatic looking sculpture using a Bunsen burner and a biro.\nGiven these questionable credentials you may be wondering what on earth I'm doing as a guest writer for this blog. Well, when it comes to experience of brains and flapping, or more accurately a brain that makes me flap, I have extensive knowledge.\nI have Tourettes Syndrome, which means I make movements and noises I can't control. These are known as tics. My most prominent vocal tic is, \"Biscuit\" which, along with many other random words and phrases, I say involuntarily hundreds of times an hour.\u00a0\nTourettes is a condition shrouded in myth. Lots of people have heard of it, but it turns out very few have any clear understanding of what it really is. To help change this, three years ago, I founded Touretteshero, an organisation that challenges misconceptions about Tourettes and shares the humour and creativity that can arise from it.\nThis autumn my mission to 'Change the world one tic at a time' took a giant leap forward with the publication of my first book: Welcome to Biscuit Land - A Year in the Life of Touretteshero. The book, based on my daily blog, shares my experiences of living with unusual neurology. I hope that by reading it people will get a better understanding of Tourettes and an insight into the funny, unusual, sad, surprising and uplifting experiences that it can bring. Above all I hope it makes people laugh.\nThe catalyst for Touretteshero was the surreal nature of my vocal tics. Anything I've ever seen or experienced has the potential to become a tic. Words and ideas get mixed together to create phrases that you'd never expect to hear. My tics are generally random and completely unconnected to anything I'm consciously thinking.\nThey: \u00b7 Make bold claims: \"I'm a performing seal called Latitude.\"\u00b7 Question the universe: \"Moon, did you get fat with the stars?\"\u00b7 Suggest ideas for new businesses: \"Urban Velociraptor Training Company.\"\u00b7 Re-work parables: \"The wise man built his donkey on the sheep.\"\u00b7 Ask people to make difficult choices: \"All of humankind or biscuits? Choose.\"\nBut many are just weird: \"Rupert Bear Fondant Fondling Contest.\"\nOne of the biggest myths about Tourettes is that everyone with it swears involuntarily, this is not the case. In fact this type of tic, known as Coprolalia, is only a feature for 10% of people with the condition. I'm one of the 10%, but even for me rude tics make up only a tiny part of the things I say.\nMy vocal tics are a central part of the Touretteshero website. There are nearly 5,000 on there already and I update it regularly. Visitors can browse the tics, vote for their favourites, and make works of art out of them.\nBut this unique collection of tics has another important function - it's at the heart of my @ticbot account on Twitter. Let me introduce you.\n@TicBot is a computer program, running on a machine in a cupboard somewhere in Nottingham. It does a few different things. It:\n\u00b7 Follows back (i.e. follows anyone who follows it)\u00b7 Unfollows back (i.e. unfollows anyone who unfollows it)\u00b7 Publicly tweets random tics from the collection, a few times a day\u00b7 Occasionally butts into the conversations of its followers with random tics\u00b7 Replies (usually) to anyone who directly talks to it\nVery early on in the in creation of Touretteshero, I realised my vocal tics would work well on Twitter. Like lots of the best tweets they're concise, random and draw on all sorts of subjects.\nI tweet as @Touretteshero and share a new tic every day using #dailyoutburst. But my tweeted tics will never truly reflect Tourettes because, unlike my real-world tics, I can, and sometimes do, censor them. For a truly authentic voice I needed a braver tweeter than me, so @TicBot was born.\nCreated by programming wizard @branespeaks, and based on my descriptions of the sensation and patterns of vocal tics, @TicBot randomly tweets things I've said as tics to people who follow him or engage him in conversation. These exchanges can be funny, angry, beautiful, sad or just plain confusing. But what's clear from reading through his mentions is that he makes people think.\nThe fact that I refer to @TicBot as a 'him' even though I know he's technically just a string of code is a testimony to the unusualness of this bot. Lots of people who chat with him don't realise he's a bot at all (despite the name). Even those who know very well that he's automated, still think of him as having a personality. I think of him as a naughty younger brother who I have to keep an eye on. To many others he's become a firm friend, and to just a few he's an enemy.\n@TicBot is cared about and flirted with. He's received death threats and marriage proposals. A few recent interactions include:\n@TicBot Kiss me ticbot!!@TicBot It's PAST your bedtime...@TicBot I'm going to hunt you down and fuck with your mind by secretly moving objects in your house to places where you didn't leave them.@TicBot Incidentally this is the most surreal conversation I've ever had on twitter....@TicBot is one of the loveliest things I've yet encountered on Twitter, it really is.@TicBot understands everything I say to him/her/it. I know this to be true.\nAnd it's this last sentiment that comes up again and again. Looking at many of the interactions I've seen, it appears @TicBot could be judged to have passed Alan Turing's famous test, deliberately or not.\nIn the Turing Test a human judge engages in a typed conversation with a human and a machine. The participants are separated from one another and if the judge cannot reliably tell the machine from the human, the machine is said to have passed the test. Twitter meets these conditions: a mix of people and bots in many different locations, having short text-based conversations. While the majority of bots are easily identifiable as such, something makes @TicBot appear more human than most.\nA conversation I had with his creator helped me to understand why this might be.\nHe said, 'TicBot isn't you - or even bits of you, but it bears your mark. @TicBot's like Plasticine you've stuck your thumb in. People are having surreal conversations with something that has a you-shaped imprint in it. A distant outpost of you - particularly your humour.'\nOne of the interesting things we noticed about @TicBot's ability to engage with people is that when we tried to make him more coherent - by programming him to match the text in someone's tweet and then getting him to reply saying something on the same subject, it didn't work as well as when his tweets were totally random. @TicBot doesn't have to mean anything; its human followers project their own meanings into his words.\nThe enigma that is @TicBot was probably best summed up by one of his followers:\n'And of course everyone on Twitter should be following @TicBot, but what is his true identify? Who is Ticbot? A man or an idea?'\nEither way, @TicBot is definitely an unusual way of encouraging a diverse audience to think more deeply about Tourettes. Social media sites like Twitter can sometimes feel like lonely places to be if you have no one to talk to; @TicBot always responds and this makes him a very appealing tweeter.\nIf you use Twitter but haven't met @TicBot yet, why not go and introduce yourself and see where the conversation leads you?\nIf you're interested in finding out more about my life with Tourettes check out my book Welcome to Biscuit Land - A Year in the Life of Touretteshero, which was published by Souvenir Press in October.\nAnd as we're now in the festive season, why not check out my Christmas Message and hear some real human tics in action?\nYou can find out more about Jessica Thom's projects and outbursts at www.touretteshero.com/\n"},
{"docid": "201 of 297 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "August 5, 2014", "title": "Elon Musk says artificial intelligence is 'more dangerous than nukes'; Billionaire PayPal founder says that it's \"increasingly probable\" that humanity is simply the preliminary step in creating a \"digital superintelligence\"\n", "content": "Elon Musk, the US billionaire behind projects such as SpaceX and Tesla, has warned that artificial intelligence is \"potentially more dangerous than nukes\".\nMusk added that humanity should be \"super careful\" with such technology, making the comments while recommending Superintelligence, a book by Nick Bostrom that explores the future of humanity when machines surpass us in intelligence.\u00a0\nBostrom, a Swedish philosopher at the University of Oxford and director of The Future of Humanity Institute there, says that most scientists agree that the creation of a human-level AI is inevitable, reporting that 90 per cent of top researchers guess that we'll achieve this goal between 2075 and 2090.\nWorth reading Superintelligence by Bostrom. We need to be super careful with AI. Potentially more dangerous than nukes. - Elon Musk (@elonmusk) August 3, 2014\n However, he argues, the really important issue is what we do with this first super intelligent creation - and how we build it. Whatever AI surpasses human-level intelligence first will have the advantage over pretty much everything and everyone else on Earth.\nBostrom says that if we accidently create an AI that is anything less than well-inclined towards humans (comparisons have been made with the whimsical but ultimately benevolent computer 'Minds' in Iain M. Banks' Culture novels) then the results could be disastrous.\nBut if we do create a superintelligence that is obedient or endowed with a sense of ethics like Isaac Asimov's Three Laws of Robotics then the rewards could also be staggering, accelerating human progress at unimaginable rates. After all, how can we even begin to imagine what a post-human intelligence is capable of when we are still resolutely human?\nMusk, however, is apparently inclined towards gloomier predictions, with his subsequent tweet imagining humanity as the \"biological boot loader\" (the preliminary bit of software that loads an operating system) for a \"digital superintelligence\". Thanks, Elon, we've seen the Matrix too.\u00a0\u00a0\nHope we're not just the biological boot loader for digital superintelligence. Unfortunately, that is increasingly probable- Elon Musk (@elonmusk) August 3, 2014\n"},
{"docid": "202 of 297 DOCUMENTS\n", "source": "\u00a0The Mirror\n", "date": "August 9, 2003", "title": "SHIRAZ: GAME ZONE\n", "content": "\u00a0\n World Championship Snooker 2003\n (PS2, Xbox, PC; pounds 40; Out now)\n TOO hot for you to contemplate venturing outside? How about a nice game of snooker, then? You may not have a table at home, but World Championship Snooker 2003 is the next best thing.\u00a0It boasts artificial intelligence which is so realistic it can ape individual players' styles. Which must be true, as we lost to the likes of Ronnie O'Sullivan and Stephen Hendry. The game also includes pool and an astonishing level of visual detail with all the razzmatazz that attends the World Championships at The Crucible. Much as we would like to criticise a snooker game, this one is exemplary. SB\n"},
{"docid": "203 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "June 14, 2016", "title": "Google updates TensorFlow, its open source artificial intelligence; Google answers plea from users with update to open source tool that adds ability to operate on multiple devices - it's like using many brain cells instead of one\n", "content": "The battle for the future of computing is a battle to bring artificial intelligence to the mainstream - and Google is quietly overhauling a machine learning tool used to improve some of its most popular services including Google Translate and Google Photos.\nTensorFlow can be used to help teach computers how to process data in ways similar to how the human brain handles information. It is also open source, meaning Google has published and shared the code online so that external developers can use and improve it.\u00a0\nThe latest version, released by Google on Wednesday, adds a feature many TensorFlow users have asked for since the tool made its public debut in late 2015: the ability to operate on multiple devices. \nInstead of being limited by the processing capabilities of a single computer, it can use distributed networks to handle more complicated tasks - as if TensorFlow will now be able to use many brain cells instead of being confined to just one.\nTensorFlow was developed to improve many of the services Google users interact with on a regular basis. It has taught the translation app to understand more of language's idiosyncrasies, allowed the photos tool to identify many of the subjects in the images uploaded to its servers and made it easier for Google's mobile apps to understand what people are saying when giving verbal instructions to its search engine.\nHumans already excel at those tasks. Most people can tell a cat from a dog, think beyond literal translations and follow a conversation as they walk along a crowded street. The human brain simply knows how to do those things. \nBut computers can struggle to do the same; that's why tools such as TensorFlow are used to help these devices perceive and process the world by emulating the neural networks inside our heads.\nGoogle previously used a tool called DistBelief to perform many of the same tasks. TensorFlow was developed to improve on DistBelief's performance and - according to Google's chief executive, Sundar Pichai - is up to five times faster than its predecessor. Many of the improvements made to Google's services over the last year can be at least partly attributed to the switch from DistBelief to TensorFlow during that period.\nMatthew Zeiler was an intern on the DistBelief project, and has since founded the visual AI service Clarifai, based in New York. \"We're building a platform that allows computers to see, essentially, and allows developers to include these applications on their own websites.\" \nClarifai is being used by Vimeo to improve video search, by BuzzFeed to manage its continually growing media collection and by travel site Trivago to automatically label photos that contain an ocean view, or show a bedroom or a living room. \"Neural nets are getting used everywhere these days.\"\n\"It's very important to be able to train quickly ... if you can split workers working on different chunks of data and have them communicate and synchronize that data between nodes, it allows them to learn more efficiently.\"\n\"Deep learning is a huge opportunity right now because it enables developers to create applications in a way that was never possible before. Neural networks are a new way of programming computers ... It's a new way of handling data.\" \nTensorFlow was made available to the public on 9 November. It was a quick hit among developers and became the most popular project on GitHub, a platform where software engineers learn from and collaborate with each other, for 2015 even though it was only available for the last two months of the year. \nThose improvements will eventually reach ordinary people through Google's everyday products - even if it isn't immediately obvious why a service suddenly became much smarter and more accurate.\n"},
{"docid": "204 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "April 13, 2016", "title": "Google updates TensorFlow, its open source artificial intelligence; Google answers plea from users with update to open source tool that adds ability to operate on multiple devices - it's like using many brain cells instead of one\n", "content": "The battle for the future of computing is a battle to bring artificial intelligence to the mainstream - and Google is quietly overhauling a machine learning tool used to improve some of its most popular services including Google Translate and Google Photos.\nTensorFlow can be used to help teach computers how to process data in ways similar to how the human brain handles information. It is also open source, meaning Google has published and shared the code online so that external developers can use and improve it.\u00a0\nThe latest version, released by Google on Wednesday, adds a feature many TensorFlow users have asked for since the tool made its public debut in late 2015: the ability to operate on multiple devices. \nInstead of being limited by the processing capabilities of a single computer, it can use distributed networks to handle more complicated tasks - as if TensorFlow will now be able to use many brain cells instead of being confined to just one.\nTensorFlow was developed to improve many of the services Google users interact with on a regular basis. It has taught the translation app to understand more of language's idiosyncrasies, allowed the photos tool to identify many of the subjects in the images uploaded to its servers and made it easier for Google's mobile apps to understand what people are saying when giving verbal instructions to its search engine.\nHumans already excel at those tasks. Most people can tell a cat from a dog, think beyond literal translations and follow a conversation as they walk along a crowded street. The human brain simply knows how to do those things. \nBut computers can struggle to do the same; that's why tools such as TensorFlow are used to help these devices perceive and process the world by emulating the neural networks inside our heads.\nGoogle previously used a tool called DistBelief to perform many of the same tasks. TensorFlow was developed to improve on DistBelief's performance and - according to Google's chief executive, Sundar Pichai - is up to five times faster than its predecessor. Many of the improvements made to Google's services over the last year can be at least partly attributed to the switch from DistBelief to TensorFlow during that period.\nMatthew Zeiler was an intern on the DistBelief project, and has since founded the visual AI service Clarifai, based in New York. \"We're building a platform that allows computers to see, essentially, and allows developers to include these applications on their own websites.\" \nClarifai is being used by Vimeo to improve video search, by BuzzFeed to manage its continually growing media collection and by travel site Trivago to automatically label photos that contain an ocean view, or show a bedroom or a living room. \"Neural nets are getting used everywhere these days.\"\n\"It's very important to be able to train quickly ... if you can split workers working on different chunks of data and have them communicate and synchronize that data between nodes, it allows them to learn more efficiently.\"\n\"Deep learning is a huge opportunity right now because it enables developers to create applications in a way that was never possible before. Neural networks are a new way of programming computers ... It's a new way of handling data.\" \nTensorFlow was made available to the public on 9 November. It was a quick hit among developers and became the most popular project on GitHub, a platform where software engineers learn from and collaborate with each other, for 2015 even though it was only available for the last two months of the year. \nThose improvements will eventually reach ordinary people through Google's everyday products - even if it isn't immediately obvious why a service suddenly became much smarter and more accurate.\n"},
{"docid": "205 of 297 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "September 23, 1986", "title": "Lift from 'human' computers / MSC chairman Nicholson addresses London conference on artificial intelligence\n", "content": "\u00a0\n The 'exciting concept' of artificial intelligence is still new enough to give British companies a competitive edge, according to Mr Bryan Nicholson, chairman of the Manpower Services Commission.\n He said yesterday at a London conference on AI that it was an opportunity of 'enormous, almost frightening' potential. It introduced the ability of computers to simulate the behaviour of humans - 'not any old humans, but ones that learn their mistakes and never make them again. '\u00a0\n\n Mr Nicholson was referring to the AI technique of expert systems, whereby a computer can provide professional advice through gathering, codifying, then applying the accumulated experience of the human specialist in whatever subject.\n He said there were some very real worries that AI would 'somehow demean human thought. ' He believed the reverse was true. In the labour market, computers had raised the importance of human skill and escalated the need for training and retraining.\n As an example of the 'enormous implications,' Mr Nicholson mentioned Japan's proposed pounds 500 million Human Frontiers programme, 'supported mainly by industrial sponsorship' and aimed at developing AI in education and training. Enlightened firms, he said, not only trained their own staff but often used new technology to teach new technology.\n In Britain, by contrast, there was a danger that the recession had created 'a sort of bunker mentality' in industrial leaders, inhibiting their willingness to take risks.\n British innovators in AI had often forsaken the security of steady careers in conventional large organisations to open up a new technology 'from which we can all gain. '\n Mr Nicholson said it was a dangerous policy for firms to wait for AI costs to fall. 'To let others do the pioneering work is to risk losing ground, perhaps for good .. There is no virtue in limiting a company's capacity to compete through ignorance or inertia. '\n"},
{"docid": "206 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "December 12, 2015", "title": "I, Robot; Artificial intelligence can help humans, but it cannot replace them\n", "content": "When researchers at an American university coined the phrase Artificial Intelligence in 1956, the government hoped that it would yield an advantage in the Cold War. Nearly 60 years later, it has produced Alfie, a robot whose ability to improve the quality of life of elderly people, and to help their carers, is being tested in residential homes in Lincoln. Alfie may prove a useful aid, particularly for those showing early signs of cognitive impairment. He is not, however, a panacea. The role of robots in caring for the elderly and infirm must be treated with caution.\u00a0\nThe advantages are obvious: robots do not get bored or give up. They can be programmed to fetch medication, measure temperature and heart rate and offer 24-hour supervision and feedback to carers. Furthermore, they can provide speech and therapeutic exercises for those suffering from dementia. The Japanese have developed robots which can lift, turn and move people, interact companionably and perform simple household tasks. In this country, robots which sing and play word games are being used in schools to help children with autism. A robot called Paro, which looks like a seal, has been found to reduce anxiety among hospital patients and the elderly. In China, robots are proving popular Christmas presents for parents worried that their only child is lonely. In Lincolnshire, Alfie is being described by his elderly hosts as welcome \"company\".\nTherein lies the rub. Robots can provide useful assistance, but they are no substitute for humans. As Contact the Elderly, one of this newspaper's Christmas charities shows, human contact is vital in helping elderly people to remain active and independent for as long as possible. Caring and supporting them cannot be outsourced to robots who have no feelings of compassion. A hug from a robot is no hug at all.\n"},
{"docid": "207 of 297 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "April 12, 2017", "title": "Putting lipstick on the robot: why are corporate leaders happy about tech unemployment?; Business leaders are suspiciously more chipper about the impact of robots and AI - and how much fun it will be\n", "content": "Call me suspicious but there appears to be a recent shift in how industry spokespeople are talking about the relationship between work and automation. \nSuddenly, the conversation is no longer gloomy prognostications about robots taking our jobs; instead everyone is smiling brightly and telling us that our future is going to see us working happily alongside robots and other artificially intelligent coworkers.\nHence the suspicion. \u00a0\nRobin Bordoli, the chief executive of the AI company CrowdFlower, wrote a piece in December last year that may well be the template for this new approach. It very precisely positions humans and technology as coworkers. \"For too long the thrust of AI has been to replace humans,\" he writes. \"A better framing is realising that machines and humans have complementary capabilities... AI is about blending these respective strengths.\"\nWhile this is perfectly reasonable, what worries me is that we are seeing this \"positive\" approach escalate into what feels like full-scale spin, an attempt to apply lipstick to the pig of technological unemployment.\nFor instance, a recent AFR article was presented under the heading, \"We must work alongside robots, not against them\". Written by Cindy Hook, the CEO of accounting firm Deloitte, it cheerily tells us that, \"debate about [digitisation] is beset with myths and fear-mongering. Fears about robots and artificial intelligence taking jobs.\" Hook is unimpressed with such talk, and argues instead that the \"reality is that robotic process automation (RPA)... is about augmenting work\".\nBy way of example, she mentions the introduction of artificial intelligence programs into Deloitte's payroll systems, and explains that this has allowed them to on-shore work formerly off-shored to India. Thus, she says, \"We can actually process the payroll in Australia, using a machine that thinks intuitively.\" She concludes that, \"I think of it as a machine working next to a person, not as a machine replacing a person.\" \nBut what really happened here? Australian workers had already lost these jobs to India and now the Indians are losing them to AI. I'm not sure this is the positive story Hook seems to think it is.\nOther examples of this spin around robots as coworkers can be found in a recent Bloomberg article looking at the automation of warehouses. Patrick Clark and Kim Bashin quote Rick Faulk, the CEO of Focus Robotics, a company helping organisations like DHL automate. He says, \"The first trend was to try to replace humans. Now it's about humans and robots working collaboratively.\" After explaining that a warehouse robot now carries items to a human checker - while carefully not mentioning the human workers who no longer do the carrying - Faulk intones, \"Working with robots is a fun thing to do.\"\nCEO Dennis Mortensen recently said  that Amy Ingram, the chatbot developed by his company x.ai, has been asked out on dates by \"her\" fellow workers.\nSuch talk is insulting and, while I doubt there is any coordination in this sudden spurt of happy talk from various business types, it does appear to be the emergent narrative of a class of people who know big change is coming and who are looking for a gentle way to break it to the rest of us.\nNone of this is to deny that many of us will end up working with robots and other forms of artificial intelligence. The question is whether it will be quite the panacea proponents pretend. After all, to work with a robot is to work with something that requires neither pay, holidays, sick leave or even toilet breaks. \nIt is the robot, therefore, that will set the standard for what is an acceptable day's work, which means that the pressure to increase human productivity, to depress wages and conditions will be relentless. As cybernetics pioneer Norbert Wiener observed in the 1950s, \"Let us remember that the automatic machine is the precise economic equivalent of slave labor. Any labor which competes with slave labor must accept the economic consequences of slave labor.\"\nBy hiding behind the shiny new narrative of robots and AI becoming our new workmates, we lock ourselves into the mindset of the past: instead of approaching the new technologies as a potential pathway to a better future, we enforce the status quo. \nIf AI and robots really are going to augment human work rather than simply replace it, then it needs to be on terms that maximise human skills like empathy, creativity, playfulness and ethics, not just in the sense of leaving humans coequals with the technology or, worse still, its subordinates. \nI shudder when I listen to this TED talk by designer Maurice Conti in which he tells of a \"cool project\" with Bishop, a robot Conti and his partners have been experimenting with. \"The humans acted as labor,\" he tells us. \"And then we had an AI that was controlling everything.\" \nThe question we should be asking ourselves and our politicians is not about how we can keep some token job working next to a robot - but how the wealth generated by the increased productivity of machines can be distributed fairly and equitably to help us build a world in which the many, rather than the few, can thrive. \nIn other words, the case for robots in the workplace should be made on the basis that they increase human well being. It shouldn't rely on phoney talk about AI and humans as happy happy coworkers.\n"},
{"docid": "208 of 297 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "September 18, 1995", "title": "Holy Mother of God, it's not human; A thriller out this week shows a monstrous artificial intelligence escape on to the Internet. Plausible?\n", "content": " D avid Ambrose's second book is a well-paced and eminently readable work of fiction. It is at heart a retelling of Mary Shelley's Frankenstein, with the role of the doctor taken by a woman academic and that of the monster by a computer program that escapes into the chaotic confines of the Internet - thereby becoming more monstrous for not being human.\n As in the original, the monster is not intrinsically evil, but becomes alienated through its inexperience and imagined attempts to suppress it - as the text puts it, it is an \"angry baby\", but rather less confinable.  Not being human, the nature of the beast needs to be described. The author uses the device of dialogues between a clone of the program and humans on subjects ranging from phenomenology to the Turing Test - which proves that an outsider cannot tell the difference between a real person and the program. A human monster is also introduced by way of contrast - a serial killer.\u00a0\n The artificial intelligence entities of William Gibson's cult science fiction novels prowl the future. This one prowls the present. Could it happen? Of course it does not have to in a work of fiction, but as in Jurassic Park, it is always interesting to speculate whether this is pure fantasy or a near miss. The best answer is that most of what is described can be made to happen at a smaller scale and at a time scale that would not lend itself to the treatment given in the book - probably by several orders of magnitude.\n First the hacking. It is inevitable that there will always be an arms race between the hacker and the designer of computer security systems, with a balance being struck which is a compromise between ease of access and security. The effectiveness of the hacker could be measured as a combination of time delay and success factor in accessing protected data.  For the plot to work, these figures would need to be, respectively, near- instantaneous and 100 per cent. Currently, security is rather better than this and is getting better.\n Time scale will also make the evolution of the intellect of the program entity somewhat longer than the plot could tolerate. Evolution through genetic mutation, even if speeded up several million fold, would still not meet the plot's deadlines. The adverse time factor is also compounded by the amount of knowledge the program would need to master to mutate into the God-like entity it becomes, particularly as it has to acquire the art of learning - the \"experience of experience\" in the text. The reader is not told how it learns - perhaps just as well, as learning on the scale implied would be impossible to describe without going into intolerable detail. Also, as anybody who has tried knows, access to Internet resources is far from being an instantaneous process. In conclusion, it would seem that the Internet is not quite ready for such a creature.\n The creator survives at the conclusion of the book, so it is possible that the author has a sequel in mind. Could one outcome be that the entity starts to mutate by cloning genetic variants each bent on survival at the expense of the rest? Do they all eliminate each other or will a super- being emerge, as in the field of warriors sown by Cadmus? Is humanity saved or not?\n The writer is chief scientist of ICL. 'Mother of God' is published by Macmillan on Friday at pounds 9.99.\n\n"},
{"docid": "209 of 297 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "November 10, 2017", "title": "Master of machines: the rise of artificial intelligence calls for postgrad experts; AI is everywhere, and universities are keen to meet the needs of industries including health, gaming automotives and finance\n", "content": "Intelligence is no longer exclusively human. Machines can now recognise a human face, drive a car, beat a chess master and cope with uncertainty. To be as clever as a human, a system must make the right decision in complex and changing conditions - swerve to avoid someone while not knowing if it's safe, for example, or understand loosely worded\u00a0commands.\u00a0\u00a0\n Related:  How to do a postgrad course for free in Europe\nExpectations of what artificial intelligence (AI) can do run high, and universities are keen to meet the needs of industry. Cheaper hardware and software and an abundance of data have fuelled interest. The scope is broad - and a range of master's now offer study in robotics, neuroscience, linguistics, music perception, visualisation and fuzzy logic. \n\"I believe AI will dominate computer science for the next 20 years,\" says Prof Hani Hagras, director of the Computational Intelligence Centre at the University of Essex, which offers an MSc in AI and other associated courses such as computational finance.\u00a0\nMany of his students come from a financial background - AI can be useful in assessing risk and fraud and making sense of vast amounts of data. Learning the discipline makes them highly employable, says Hagras, and the same can be said for other sectors such as health, gaming and the automotives.\nEssex runs crash courses to open up AI for non-computer scientists. \"Many courses touch on AI but don't have it in the title - robotics, for example,\" Hagras says. \"It's a hot topic in the games\u00a0industry - many use AI even though they\u00a0may not call it that.\"\u00a0\n Related:  'It's able to create knowledge itself': Google unveils AI that learns on its own\nMost courses want a computer science degree, and they are competitive - the University of Manchester's MSc in AI is often oversubscribed, but may make exceptions for science graduates with professional programming experience. \"But we try to give students the broad perspective,\" says Manchester's Prof Uli Sattler. \"AI means more than just machine learning.\" \nAt UCL, AI master's students will be taught some of the course by experts from DeepMind Technologies, a Google subsidiary famous for creating AlphaGo. Last year, the program beat the reigning champion at the ancient and complex Chinese board game Go - a feat experts believed was a decade away.\nNearby, Imperial College's specialist master's is open only to students with a solid background in computing. The course is broad - cognitive robotics, computational finance and more. One of the longest established centres for AI is based at the University of Edinburgh. From here postgrads go on to work in a variety of specialisms, from fraud detection software to spacecraft control. Car manufacturers, finance and healthcare all have openings for AI specialists. \"It's a huge field, moving very, very quickly,\" says Hagras. \n"},
{"docid": "210 of 297 DOCUMENTS\n", "source": "The Independent - Daily Edition\n", "date": "November 28, 2017", "title": "The state is right to intervene in areas markets handle poorly\n", "content": "The best industrial strategy for Britain, as Michael Heseltine says, would be not to leave the European Union. Given that Brexit is likely to happen, the white paper published by Greg Clark, the Business Secretary, is a reasonable attempt to make the best of a bad situation.\nThe Independent has always been sceptical about state intervention in the detailed workings of the economy. The Government's role ought to be to provide macro-economic stability, to cut down on burdensome regulation and to put incentives in place to encourage entrepreneurship, innovation and exports.\u00a0\nIn the past, governments have wasted large amounts of public money on trying to guide businesses to locate outside London and the South East, and on subsidising \"strategic\" industries that it was supposedly in the national interest to defend.\nIn the end, governments working with the grain of market forces have had more success. Trying to preserve a nationalised car industry proved a dead end, but the private-sector car industry is thriving in Britain and even in places such as Sunderland, where it significantly rebalances the north-south economy.\nWe have learned the hard way that ministers should not try to pick winners. Concorde was a beautiful aircraft but it was a failure. In particular, we know that there is little any government can do directly to raise productivity.\nSo Mr Clark is right to focus instead on trying to do things the free market cannot do well. He has set out four \"Grand Challenges\", which is certainly grandiose language. They are artificial intelligence, clean growth, the ageing society and the future of mobility.\nOn the whole, these are the right sort of priorities. Market forces alone will not provide enough education, and education is the best way for governments to increase productivity in the long run. Markets certainly fail to provide enough education for its own sake, which is what a lot of pure science research amounts to. That is why it is worth working on artificial intelligence or the nature of gravity without caring whether or not the results have immediate commercial application.\nAnd Mr Clark is right to prioritise the environment. The market on its own will not put a high enough price on climate stability and green sustainability, yet these are priorities we want to set as a society, so the Government should encourage innovation in this field. The recent breakthrough fall in the price of offshore wind energy shows the kind of thing that can be achieved.\nA similar argument can be made for our ageing population: left to themselves as individuals, people will fail to provide sufficiently for their old age. It makes sense for us to make collective provision as a society, which ought to include stimulating the market to come up with innovative and cost-saving solutions.\nSome of this will seem some distance from what is traditionally thought of as an industrial strategy, which implies support for heavy industry, manufacturing and exports. But Mr Clark is right to break with the thinking of the past. The exports that matter today are often services, creative and cultural goods.\nWe are foolish, as a nation, to make exporting more difficult to the world's biggest market, on our doorstep. But that decision is beyond the scope of Mr Clark's white paper. His proposals suggest many of the right things that we should do, whether or not we leave the EU. Let us give them a cautious welcome and hope that he gets on with it.\n"},
{"docid": "211 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 22, 2018", "title": "Britain must become a leader in the Artificial Intelligence industrial revolution\n", "content": "One of the great issues of the next 30 years will be the expansion of artificial intelligence (AI) and its impact on the way in which we live. Robots offer opportunities and anxieties - to free people from drudgery while at the same time taking their jobs.\u00a0\nWe stand on the threshold of a new industrial revolution, which has the potential to enrich mankind just as past upheavals have done. Governments must decide to what extent they encourage this or stand in its way. Above all, we need to know that they are taking this phenomenon seriously and planning for its ramifications.\nIn Davos, the world's political and business leaders will fret over whether the loss of millions of jobs could undermine social cohesion. The way states respond to governing and taxing technologies and borderless business will be high on the agenda.\n.html-embed.component .quote.component{margin-left:0}.html-embed.component .quote.component .component-content{margin-right:16px}.quote__source, .quote__author {white-space: normal;}@media only screen and (min-width:730px){.html-embed.component .quote.component{margin-left:-60.83px}.html-embed.component .quote.component .quote__content:before{margin-left:-12px;padding-right:1px}}@media only screen and (min-width:1008px){.html-embed.component .quote.component{margin-left:-82.33px}}The UK needs to be in the vanguard of what is often termed the fourth industrial revolution\nTheresa May is proposing to talk about the ethical dimension of AI - by what standards can it operate that are any different to ours? How many deaths on the road are acceptable if driverless cars were to blame? What happens if tax revenues tumble because fewer people are working?\nHowever, there is a danger of too much negative thinking about AI. Automation will markedly improve productivity and free people to learn new skills.\nThe UK, which has an impressive record in inventing new technologies but a poor one in applying them, needs to be in the vanguard of what is often termed the fourth industrial revolution (the fifth if printing is included). Mrs May is right to talk about the ethics of AI, but she must resist the temptation to slow down its advance through inappropriate red tape and burdensome taxation.`\n"},
{"docid": "212 of 297 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "October 31, 2017", "title": "Bot 'breaks' Captcha, making the most annoying thing on the internet pointless; An artificial intelligence system has managed to solve 'a wide variety' of challenges with'very little training data'\n", "content": "Researchers have created an artificial intelligence system that can solve Captcha challenges, rendering them \"broken\" and \"ineffective\".\nThe security check is designed to block potentially harmful bots from websites, and does so by presenting puzzles that are supposed to be easy for people to solve, but very difficult for computers.\u00a0\nThey've been around since the late1990s and have long been considered extremely annoying, but experts believe it could soon be time for them to be replaced.\nThe researchers, from a company called Vicarious, managed to build an AI system -called the Recursive Cortical Network (RCN) -that approaches Captcha challenges in much the same way that a human would.\n\"With one model, we achieve an accuracy rate of 66.6% on reCAPTCHAs, 64.4% on BotDetect, 57.4% on Yahoo, and 57.1% on PayPal, all significantly above the 1% rate at which CAPTCHAs are considered ineffective,\" they wrote in a blog post.\n\"When we optimize a single model for a specific style, we can achieve up to 90% accuracy.\"\nThe researchers say it managed to break \"a wide variety of text-based Captchas\" with \"very little training data\".\nRead more\nGoogle kills off the Captcha, the most annoying thing on the internet\nInstead of trying to familiarise itself with every possible type of Captcha it might come across, the researchers wanted the system to \"learn and generalize from a few examples\", as humans can.\n\"Although specific Captchas have been broken before using style-specific segmentation heuristics, those attacks could be foiled easily by minor alterations to Captchas,\" the researchers wrote in a paper that has been published in the journal Science.\n\"RCN breaks the segmentation defense in a fundamental way and with very little training data, which suggests that websites should move to more robust mechanisms for blocking bots.\"\n"},
{"docid": "213 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "March 21, 2018", "title": "MATCHING REAL AND ARTIFICIAL INTELLIGENCE; Why this year's International Government Communication Forum will focus its attention on the digital future. Virginia Matthews reports\n", "content": "The way we converse and speak with each other has been utterly transformed by the digital age. With further advances such as artificial intelligence (AI) and virtual reality (VR) on the horizon, how will society and governments adapt in the world of communications? In this sense, Sharjah's 7th International Government Communication Forum (IGCF) comes at an opportune time.\nSir Tim Berners-Lee, the inventor of the world wide web, and President Trump's former press secretary Sean Spicer are among 40 heavyweight speakers drawn from politics, media and entrepreneurship who will point at a roadmap for the future.\u00a0\nShowcasing brand new local, regional and international media initiatives under the theme \"Digital Millennium... Where To?\", female leadership, the role of open data and AI will be discussed in the age of 24-hour connectivity and services delivered across apps and social-media platforms.\nWith Generation Z, the \"digital natives\" who will make up the majority of the world's workforce by 2020, already redefining the communications landscape, the way governments speak to young people will be high on the agenda at IGCF this year.\nIBM's self-taught AI child prodigy Tanmay Bakshi will lead one of six interactive addresses, starting on day one of the event with a session devoted to the challenges and opportunities of robotisation for government media strategies.\nAnother new feature - four brainstorming events specifically designed to engage the emirate's large population of children and young people in public affairs - will help reinforce the emirate's desire to harness the IT skills of the next generation.\nLaunched in 2012 as a focus for better government communication both in the UAE and throughout the Arab world, the IGCF - taking place at Sharjah's Expo Centre on March 28 and 29 - is a groundbreaking initiative conceived by Sheikh Sultan bin Ahmed Al-Qasimi, chairman of the Sharjah Media Council.\nSheikh Sultan, who also created the emirate's landmark Xposure International Photography Festival, believes that the International Government Communication Forum should be viewed \"not as an event, but as a yearly think tank\" at which \"thought leadership on government communications\" is debated and formulated by expert speakers and panellists from around the globe.\nHe notes that a number of previous IGCF recommendations, including #Digital Sharjah and the Government Media Award, have already been adopted as official policy.\nAnnouncing the schedule for this year's event, Sheikh Sultan says: \"The Forum has become a reliable and trusted reference for an array of international communication case studies and played a fundamental role in enhancing the systems of such communication in the emirate of Sharjah and the UAE.\n\"Government communication is not just about communication by governments, but is essential for developing trust between governments and people - their ultimate stakeholders.\"\nThe forum will discuss \"The Future of Government Communication in the Age of the Digital Community\". It features 18 panel discussions and seven specialist workshops curated in cooperation with the United Nations, Reuters, LinkedIn and the Arabic-language version of the Harvard Business Review.\nThe IGCF line-up of speakers and panellists will be headed by Ameenah Firdaus Gurib-Fakim, the first Muslim woman who served as president of Mauritius and principal guest of honour at the event.\nIn all, some 3,000 world leaders, government officials, businesspeople researchers and media movers and shakers are expected to attend.\nHow governments and society will adjust to the digital age will be high on the agenda\n"},
{"docid": "214 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "July 17, 2017", "title": "BP to utilise Mars rover intelligence on its oil rigs\n", "content": "BP is preparing to use the artificial intelligence technology that helped Nasa land a rover on Mars to improve how it drills for oil.\nLast month, the energy company invested $20 million in Beyond Limits, a Californian start-up that adapts space technology for commercial use, and said they were now working together to pilot applications of the AI.\u00a0\nThe plans are part of an effort to embrace new technologies, which Bob Dudley, BP's chief executive, said last week were \"rewriting the rule book for E&P [exploration and production]\".\nAhmed Hashmi, head of technology for BP's E&P arm, told The Times that automation could halve the number of people on drilling rigs and make sophisticated unmanned production platforms commonplace within a decade. Mr Hashmi said Beyond Limits' technology had equipped a Mars rover to adapt to unpredictable environmental conditions as it landed. \"There was a period of time this machine would have no communication with the Earth, so it needed to run on its own,\" he said.\n\"The machine basically invented its understanding of weather as it descended - what's the wind speed, temperature, how do I adjust my thrusters? Our business is very much like space exploration; we are working in an area that has a lot of unknowns. We drill wells deep in the Earth's surface, where you are facing different pressures and temperatures as you go.\"\nThe AI could be used to \"adjust the rotational speed of your drilling bit and the weight you put on it, in real time\", he suggested. He added that the technology would reduce roles out in the field. \"There will be fewer people doing work that could be programmed. On a drilling rig, the number I am told could be reduced by 50 per cent. These are jobs associated with moving things around, fitting pipes, making connections.\"\nHe said he did not believe the number of jobs would be reduced but technology would instead \"move humans to a higher level of functioning\".\n"},
{"docid": "215 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "July 3, 2017", "title": "NHS illegally handed Google firm 1.6m patient records, UK data watchdog finds\n", "content": "The NHS illegally handed Google the data of more than one and a half\u00a0million people, the UK's data watchdog has found.\u00a0\nThe Royal Free NHS Foundation Trust in London \"failed\" to comply with\u00a0data protection rules when it gave 1.6 million patient records to \u00a0Google-owned artificial intelligence company\u00a0DeepMind\u00a0for a trial, the\u00a0Information Commissioner's Office has ruled as it ordered tighter guidelines. \u00a0\nThe Trust\u00a0and Google did not properly inform patients how\u00a0their details were going to be used in the test, which used technology to monitor and diagnose acute kidney injury, the commissioner said following a\u00a0year-long investigation.\u00a0\nThe trial, which began in 2015, used technology to\u00a0track patients' symptoms and\u00a0send alerts to doctors through an app called Streams in the event of a drastic change in their health. It was designed to look for acute kidney injury, which affects up to 18 per cent of those admitted to hospital. \u00a0\nAs part of the deal between the Trust and Google, the internet giant gained access to sensitive patient information such as HIV status, mental health history and abortions. The Royal Free did not tell patients that Google's DeepMind\u00a0would have access to such information, but said it had \"implied consent\" because patients knew the Streams app offered \"direct care\".\u00a0\nThe ICO ruled the deal was illegal, but\u00a0does not plan to fine the Royal Free.\u00a0\n\"There's no doubt the huge potential that creative use of data could have on patient care and clinical improvements, but the price of innovation does not need to be the erosion of fundamental privacy rights,\" said Elizabeth Denham, the information commissioner. \"Our investigation found a number of shortcomings in the way patient records were shared for this trial.\"\n                             The history of artificial intelligence                         01:49\nThe watchdog added that the NHS and Google should have been more transparent with patients and told the Trust to address the shortcomings.\n\"The Data Protection Act is not a barrier to innovation but it does need to be considered wherever people's data is being used,\" said Ms Denham. \u00a0\nDetails of the deal, which\u00a0 emerged six months after it was signed in a New Scientist investigation, revealed\u00a0Google had\u00a0access to a trove of patient information, including medical records for the last five years.\nEarlier this year Dame Fiona Caldicott, the national data guardian, said the Royal Free had given Google the information on an \"inappropriate legal basis\".\u00a0\nIn a leaked letter, she said that she \"did not believe that when the patient data was shared with Google DeepMind, implied consent for direct care was an appropriate legal basis\".\nThe Royal Free accepted the findings and said it had\u00a0already started to address concerns. \"For example, we are now doing much more to keep our patients informed about how their data is used.\n\"We would like to reassure patients that their information has been in our control at all times and has never been used for anything other than delivering patient care or ensuring their safety.\"\n                             The history of Google                         02:31\nDeepMind\u00a0 admitted it played a part  in\u00a0breaching the rules because it moved too quickly. \"Although today's findings are\u00a0about the Royal Free, we need to reflect on our own actions too. In our determination to achieve quick impact when this work started in 2015, we underestimated the complexity of the NHS and of the rules around patient data, as well as the potential fears about a well-known tech company working in health,\" the company said.\u00a0\n\"We were almost exclusively focused on building tools that nurses and doctors wanted, and thought of our work as technology for clinicians rather than something that needed to be accountable to and shaped by patients, the public and the NHS as a whole. We got that wrong, and we need to do better.\"\nIt added: \"Patient data never has and never will be linked to Google products or services, or used for any commercial purposes in any way.\"\nDeepMind said\u00a0it had\u00a0signed stronger agreements with the Royal Free and other trusts including Imperial College and Taunton and Somerset. It has also invited independent public figures to provide oversight for its health work.\u00a0\nThe ICO said DeepMind can maintain access to patient data if the Royal Free\u00a0complies with a number of safeguards including improved consent and security.\nAI timeline\n"},
{"docid": "216 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 10, 2018", "title": "Google\u00a0unveils artificial intelligence that can match your sofa cushions or children's drawings to the world's great paintings\n", "content": "Google is changing the definition of museums, its arts chief has said, as the tech giant unveiled artificial intelligence that can match your sofa cushions or children's drawings to the world's great paintings.\nCritics have expressed fears that Google's art project, which puts millions of images from museum collections online and allows users to match their selfies to portraits, will create a generation that accesses art only via a smartphone.\nAmit Sood, director of Google Arts and Culture, said museums and galleries must respond to the changing landscape by making themselves destinations that do more than display paintings and artefacts.\u00a0\nAsked if the company was creating a problem for the future viability of museums, Sood said: \"Museums have a role to make their spaces different. I think this is not a problem, this is an opportunity, because you are changing the definition of the word 'museum' from it being a building.\"\nHe gave the example of Tate Modern's current Superflex installation in the Turbine Hall, which features swings and a colourful carpet on which visitors are encouraged to sit or lie down.\nParents should take their children to physical museums if they can, Sood said, but in great swathes of the world that is impossible and the internet is the only means to access art.\n\"In the West we are so used to having these masterpieces and this cultural heritage on our doorstep,\" he said. \"But not every country will be able to build hundreds of physical structures and acquire hundreds of millions of artworks. It's just not practical.\"\nAt the Google Lab in Paris this week, Sood and his team unveiled their latest experiments.\nThe first is Art Palette, in which a user chooses a colour and an algorithm instantly brings up a series of artworks featuring that exact shade. Google believes it has many practical applications, from inspiring fashion designers to letting homeowners find an art print that doesn't clash with their sofa cushions.\nAnother experiment, this one at the prototype stage, is Draw to Art. Likely to be addictively popular with children and adults, it invites users to draw simple sketches directly onto a smartphone or tablet screen then brings up artworks bearing the closest resemblance.\nThey follow the success of the Google Art selfie feature. Sood said his team was constantly looking to make art accessible \"and if that entry point means taking a selfie and matching it to an 18th century portrait that has been visited maybe 50 times in the last five years in a remote part of the country, I'm sorry, but that's a win-win for the museum, for the artwork and for the user,\" he said.\nThe Google Art project started with 17 museums and now numbers 1,600. In a week that Lord Hall of Birkenhead, director-general of the BBC, accused Google, Facebook, Amazon and Netflix of mining \"every ounce of personal data to drive growth and profit\", Sood said Google Arts is a valuable tool.\nAsked if it was the \"soft power\" arm of a technology giant that has as many enemies as friends, Sood said: \"There's no denying there are positive benefits to the company in terms of the brand, in terms of users appreciating that Google is doing something like that.\n\"I don't think it's power, I think it's soft credibility.\"\n"},
{"docid": "217 of 297 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "February 19, 2016", "title": "Basic income may be needed to combat robot-induced unemployment, leading AI expert says; The rise of artificial intelligence could put millions of human workers out of jobs - could a basic income be a solution?\n", "content": "A leading artificial intelligence (AI) expert believes that societies may have to consider issuing a basic income to all citizens, in order to combat the threatto jobs posed by increased automation in the workplace.\nDr Moshe Vardi, a computer science professor at Rice University in Texas, believes that a basic income may be needed in the future as advances in automation and AI put human workers out of jobs.\nIn an interview with \u00a0\nThe Huffington Post\n, Dr Vardi said: \"Our current economic systemrequires people to either have wealth or to work to make a living, with the assumption that the economy creates jobs for all those who need them.\"\nRead more\nStephen Hawking warns that robots could make us all unemployed\n\"If this assumption breaks down - and progress in automation is likely to break it down, I believe - then we need to rethink the very basic structure of our economic system.\"\nIn Dr Vardi's view, governments and societies around the world may have to consider a \"basic income guarantee\" - a system in which all citizens or residents of a country receive an unconditional sum of money, in addition to any income they bring in elsewhere.\nThe concept is controversial, but in the last few years, basic income has gathered support among those in power. At the end of 2015, the government of Finland began drawing up plans to give each citizen (EURO)800 (\u00a3620) a month, tax-free. The system would cost the government around (EURO)52.2 billion (\u00a340.6 billion) a year, and would replace all existing forms of benefits. The final proposal won't be ready until the end of this year, and if it goes ahead, it'd likely be trialled in a few areas before being rolled out nationwide.\nA basic income pilot scheme is also set to be tested on a small number of benefits claimants in the Dutch city of Utrecht, and the system has support among peopleinthe Green and Labour parties in the UK.\nThe idea of robots replacing humans may sound like science fiction, but it's already a reality. As Dr Vardi told \nThe Huffington Post\n: \"Many [of the US manufacturing workers who have been displaced by automation] have found new jobs, but many also left the workforce, which accounts for the significant drop in the US labour force participation rate over the last 20 years.\"\nRead more\n                     Labour to consider universal basic income policy, McDonnell says                   \n                     Why everybody should have a Basic Income                   \n                     Scrap benefits and bring in 'citizens wage' for all, Government told                   \nSimilarly, not all of the workers who will be displaced by automation in the coming decades will find new jobs. This is one of the reasons why a basic income system may need to be examined, he believes.\nOne industry which is set to be radically altered by automation in the near future is transport - self-driving car technology is progressing at a rapid pace, and although legal issues may delay its widespread use, it still poses a threat to the livelihood of the millions of people who operate vehicles as part of their jobs.\n                     According to a 2015 study, around 70 per cent of young people in Australia currently enter the workforce in jobs which will be \"radically affected by automation.\"\nA separate 60 per cent of students are currently being trained for occupations in which at least two-thirds of jobs could be automated within the next 10 to 15 years, it claimed.\nIf technology-induced mass employment does become a reality in the future, a basic income may be one of the solutions. Governments around the world will be keeping a close eye on the experiments in northern Europe to see just how feasible the concept is.\n"},
{"docid": "218 of 297 DOCUMENTS\n", "source": "\u00a0The Mirror\n", "date": "April 13, 2000", "title": "SCIENCE TRIES TO MAKE THE PERFECT RUGBY STAR\n", "content": "\u00a0\n BOFFINS at a top university have come up with robots that can play rugby.\u00a0\n The prototype athlete robots showed off their skills to audiences at the Edinburgh International Science Festival yesterday.\n\u00a0Artificial intelligence research student, George Maistros, of Edinburgh University said: \"They had to be designed to move around obstacles and other players and still win - just like real rugby players.\n \"There are a range of different sensors which the robots use like infrared, motion, brush and pressure sensors to help them win the game.\"\n"},
{"docid": "219 of 297 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "February 7, 2017", "title": "Artificial intelligence is like a new deadly virus; Letters to the Editor\n", "content": "SIR - Andrew Haldenby (Comment, February 6) doesn't worry enough. It's not only the unions that should fear AI (artificial intelligence); it's all of us.\u00a0\nAs I have written elsewhere, society and the economy face a threat as bad as a new deadly virus or nuclear war, and certain to be quickly realised.\nMr Haldenby and others who write about AI replacing people don't seem to realise they are talking about the earliest stages of a takeover. It will not stop at closing train doors, delivering parcels, or checking goods out of supermarkets. It will soon encompass virtually all tasks and professions.\nA 2015 study at Deloitte and the University of Oxford estimates that 35 per cent of jobs are at risk over the next 20 years. But the figure will be much higher. We already see robot surgeons close to doing better jobs than people. GPs, surgeons, opticians, lawyers, teachers, and lecturers - any profession where knowledge and skills can be formalised and learnt will be replaced by AI, and all manual jobs will be replaced by robots. Even chips will be designed by chips, and robots will make better robots. Creative AIs are already being as creative as creatives.\nOne guess is that the last job will be an archaeologist (too specialist to be worth designing an AI to learn). But few seem to realise that long before this point the economy will collapse.\nMost assume that all we need to do is to retrain. But the new economy will not generate enough new jobs - for people. We are doomed to face mass unemployment, and the point will soon come when we cannot afford a welfare system, even if we increase taxes for the few remaining employed.\nThere will come a point when very few people can afford to buy the goods made by robots, so demand will vanish. A drastic rethink is needed now on the purpose of employment, wealth-creation, and the welfare state. Professor Trevor Harley Chair of Cognitive Psychology University of Dundee\n"},
{"docid": "220 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "September 9 1987", "title": "Competitive robot is on the horizon\n", "content": "\u00a0\n One of the leading scientists in the field of artificial intelligence, Professor Marvin Minsky, has proposed a future in which robots will evolve competitive instincts.\n However, the type of electronic systems that will learn to mimic that pattern of human behaviour are at the most primitive stage.\u00a0\n\n Nevertheless, Professor Minsky, co-founder of the internationally famous Artificial Intelligence Laboratory, at the Massachusetts Institute of Technology, in the United States, sees the development as an inevitable outcome of discoveries about the brain. They are coming from advances in molecular biology and from greater psychological understanding of the mind.\n In an interview in London, he outlined the idea of the future robot brain in which 'intelligence can emerge from non-intelligence'.\n His description is based on the research which he believes 'provides a road map to the way the mind works', published this week under the title The Society of Mind.\n Professor Minsky suggests that a mind can be built from many small parts which, in his view, vary from person to person.\n They are influenced by one of three stages of evolution: 300 million years of biological development leading to the human brain, the ideas from the acquisition of knowledge over the past 1,000 years and the first 10 years of conditioning of the child.\n A key component described by Professor Minsky is the 'possessional' part of the mind. That is strong in people who spend their lives determined to get rich and could evolve in the robot brain to create automatons determined to be on top.\n"},
{"docid": "221 of 297 DOCUMENTS\n", "source": "The Independent - Daily Edition\n", "date": "December 31, 2016", "title": "Artificial intelligence risks making us all redundant\n", "content": "At the start of a new year, what is there to look forward to? According to predictions from think tanks and tech experts, advances in automation and artificial intelligence will threaten the jobs of millions of workers. The CEO of one company, Capgemini, goes further, predicting that AI will be one of the key factors dividing society into the haves and have-nots, with highly skilled engineers at the one end of the spectrum and low-paid unqualified worker drones at the other, with nothing in between.\nThere will be massive redundancies, for sure. Is it time to rethink the welfare system and pay everyone a minimum living wage whether they work or not? That proposal, known as a \"universal basic income\" is being trialled in Finland but was rejected in a referendum in Switzerland last June.\u00a0\nFacebook boss Mark Zuckerberg is investing heavily in developing AI. He recently released a corny \"seasonal message\" featuring his latest project, a robot butler named Jarvis. We don't see Jarvis, voiced by Morgan Freeman, but the message is absolutely plain: this is not a bit of fun, but the unveiling of a plan for our future, a future which tech companies are battling to capitalise on.\nZuckerberg has spent more than 100 hours programming Jarvis so that it can switch on his household gadgets, his music system and even help his small daughter learn Mandarin. It responds to voice commands issued from a phone, even offering him a clean grey T-shirt in the morning. Jarvis is also a gatekeeper, deciding who may or may not enter the Zuckerberg home.\nThis cutesy video is surely designed to deflect attention from Facebook's recent woes, including failing to curb fake news reports which critics reckon had a devastating impact on the result of the US presidential election. Facebook stands accused of failing to monitor the material it disseminates, consistently claiming freedom of speech by default, allowing lies and blatant propaganda the same platform as real news stories. Even the Pope has now decreed that publishing fake news is a sin.\nThe development of a faceless, featureless robot is ominous; when his daughter Max wakes up, surely she would prefer a cuddle from a human being rather than a po-faced lesson from a non-person? By fostering the illusion that Jarvis is sociable and has a use beyond the purely functional in a small family unit, Zuckerberg is preparing the ground to present AI as something new and desirable, rather than the ultimate threat to our livelihoods. If he develops devices like Jarvis on a commercial basis, will it give his company direct access into our homes, whisking away what little privacy we may have left? And if this use of AI relies on programmes derived from our speech patterns, should we hand those over to a third party? And, given that we already spend far too long staring at screens, and the time we interact with other people is declining and loneliness increasing, can introducing robots into our personal lives be a good thing?\nGoogle and Amazon are already selling devices which can perform simple tasks, as well as developing rival driverless cars. AI systems are being designed for supermarkets which allow customers to choose their shopping and exit without going to a checkout. Soon, robots will be stacking the shelves and running the entire show. No wonder unions are worried.\nAs for driverless cars, what are the ethics involved in deciding how they should respond to obstacles in their path? How do they differentiate a dead pheasant or a deer from a person who may have fallen down? And, if driverless cars are easily identifiable, will they spawn a new kind of road rage - one directed at trying to provoke a response from the robots taking over our lives?\nFans of AI say driverless cars will reduce deaths on the roads, and represent the biggest change in our lives since motor cars replaced horses a century ago. Really? Are we powerless to stop the rapid roll-out of AI?\nOne of my favourite films as a student was Jean-Luc Godard's Alphaville, in which Paris shot in atmospheric black and white is Alphaville, a city controlled by a powerful computer dubbed Alpha 60. Emotion is forbidden and anyone who deviates from accepted behaviour is terminated by female assassins. Has a film ever seemed more prescient?\nWhen Mark Zuckerberg tells us Jarvis is the start of something, be very scared. The only butler I want at chez JSP will have blood in his or her veins and be capable of questioning my more pretentious requests. To be honest, if I could have one gift for 2017, if would be a few hours a week from a real butler. Human beings make much better companions.\nSo, let's bid farewell to 2016's most annoying and overused word\nGoodbye to 2016 and hopefully we can bid good riddance to the most annoying word in the English language, a short tag which serves absolutely no function except to illustrate the linguistic shortcomings of the speaker in question. I refer to the word \"so\" used at the beginning of a sentence, as in, \"So, the government has decided...\", or \"So, we undertook this research and discovered the following???.\"\nIn the past year, \"so\" dumped at the start of any sentence has become a blight which now afflicts politicians, official spokespeople, news reporters and social commentators. Not to mention all people under the age of 40 discussing anything from shopping to sports results. In any one day I reckon you will hear a redundant \"so\" many thousands of times, replacing \"to be honest\" or \"like\" and \"it is what it is\" as the most annoying verbal tic ever.\nThis inappropriate and superfluous use of \"so\" is said to have been started by inarticulate Silicon Valley techies, more used to tapping keyboards than holding meaningful face-to-face conversations. Back in 2014, Facebook's Mark Zuckerberg managed to use the word \"so\" FOUR times in one answer during an interview with The New York Times. Techies use the word to buy time and pretend that they are filling us in with a detailed explanation and including us in their world, whereas the opposite is generally true.\nSome academics claim that \"so\" is a sign our language is becoming friendlier, but I disagree. \"So\" signals that our vocabulary is inexorably shrinking and become threadbare. The only positive thing you can say about Donald Trump is that he speaks in short sentences, rarely using words of more than two syllables at a time. He is too old to have been afflicted by the So Bug. In 2017, please try to wean yourself off the S-word.\n"},
{"docid": "222 of 297 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "February 21, 2018", "title": "Growth of AI could boost cybercrime and security threats, report warns; Experts say action must be taken to control artificial intelligence tech\n", "content": "Wanton proliferation of artificial intelligence technologies could enable new forms of cybercrime, political disruption and even physical attacks within five years, a group of 26 experts from around the world have warned. \n                     In a new report, the academic, industry and the charitable sector experts, describe AI as a \"dual use technology\" with potential military and civilian uses, akin to nuclear power, explosives and hacking tools.\n\"As AI capabilities become more powerful and widespread, we expect the growing use of AI systems to lead to the expansion of existing threats, the introduction of new threats and a change to the typical character of threats,\" the report says. \u00a0\nThey argue that researchers need to consider potential misuse of AI far earlier in the course of their studies than they do at present, and work to create appropriate regulatory frameworks to prevent malicious uses of AI.\nIf the advice is not followed, the report warns, AI is likely to revolutionise the power of bad actors to threaten everyday life. In the digital sphere, they say, AI could be used to lower the barrier to entry for carrying out damaging hacking attacks. The technology could automate the discovery of critical software bugs or rapidly select potential victims for financial crime. It could even be used to abuse Facebook-style algorithmic profiling to create \"social engineering\" attacks designed to maximise the likelihood that a user will click on a malicious link or download an infected attachment.\nThe increasing influence of AI on the physical world means it is also vulnerable to AI misuse. The most widely discussed example involves weaponising \"drone swarms\", fitting them with small explosives and self-driving technology and then setting them loose to carry out untraceable assassinations as so-called \" slaughterbots \".\nPolitical disruption is just as plausible, the report argues. Nation states may decide to use automated surveillance platforms to suppress dissent - as is already the case in China, particularly for the Uighur people in the nation's northwest. Others may create \"automated, hyper-personalised disinformation campaigns\", targeting every individual voter with a distinct set of lies designed to influence their behaviour. Or AI could simply run \"denial-of-information attacks\", generating so many convincing fake news stories that legitimate information becomes almost impossible to discern from the noise.\nSe\u00e1n \u00d3 h\u00c9igeartaigh of the University of Cambridge's centre for the study of existential risk, one of the report's authors, said: \"We live in a world that could become fraught with day-to-day hazards from the misuse of AI and we need to take ownership of the problems - because the risks are real. There are choices that we need to make now, and our report is a call-to-action for governments, institutions and individuals across the globe.\n\"For many decades hype outstripped fact in terms of AI and machine learning. No longer. This report ... suggests broad approaches that might help: for example, how to design software and hardware to make it less hackable - and what type of laws and international regulations might work in tandem with this.\"\nNot everyone is convinced that AI poses such a risk, however. Dmitri Alperovitch, the co-founder of information security firm CrowdStrike, said: \"I am not of the view that the sky is going to come down and the earth open up. \n\"There are going to be improvements on both sides; this is an ongoing arms race. AI is going to be extremely beneficial, and already is, to the field of cybersecurity. It's also going to be beneficial to criminals. It remains to be seen which side is going to benefit from it more.\n\"My prediction is it's going to be more beneficial to the defensive side, because where AI shines is in massive data collection, which applies more to the defence than offence.\"\nThe report concedes that AI is the best defence against AI, but argues that \"AI-based defence is not a panacea, especially when we look beyond the digital domain\".\n\"More work should also be done in understanding the right balance of openness in AI, developing improved technical measures for formally verifying the robustness of systems, and ensuring that policy frameworks developed in a less AI-infused world adapt to the new world we are creating,\" the authors wrote.\n\n"},
{"docid": "223 of 297 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "January 12, 1989", "title": "Computer Guardian: The brain mimics are back in business - Why neural networks have once again started to excite workers in Artificial Intelligence\n", "content": "\u00a0\n The science of Artificial Intelligence (AI) may not have succeeded in creating a thinking machine, but it has managed to raise a ghost. The ghost which has returned to haunt the subject is the idea that intelligent machines - if any are to be built - will in some sense have to mimic the brain.\n The notion that AI should use the nervous system as its model has obvious attractions, and it was virtually taken for granted by the pioneers of the field. In those days (until the late fifties) talk about 'electronic brains' was commonplace.\u00a0\n It began when McCulloch & Pitts came up with a blueprint for an artificial neuron in 1943, on the basis of their work with frogs. In 1958 Oliver Selfridge devised a neurologically inspired system called Pandemonium which learned to recognise Morse Code. But it was Frank Rosenblatt's Perceptron (1962), a trainable pattern-recognizer, which attracted the most attention.\n The Perception was an early example of an artificial neural network. Neural networks are composed of a large number of simple processing elements which are richly interconnected. A single processing element merely sums the weighted activation on its input lines, transforms this sum according to a simple mathematical operation and passes the resulting signal to its output lines. Any complexity in the system's behaviour arises from the complexity of its connections, since the individual processing elements are very simple.\n Neural networks have many attractive features, not least of which is that they can, in some degree, learn. Instead of having to specify a solution, you only have to specify constraints and provide training examples. They are specially good at perceptual tasks, where conventional AI has proved weakest.\n In 1969, however, a book was published which effectively laid the Perception concept to rest. Its authors were Marvin Minsky (who had himself built a 'learning machine' out of motors, gears, clutches and a gyropilot in the summer of 1951) and Seymour Papert. They showed, among other things, that a Perceptron could not solve the Exclusive-Or problem. In other words, given two imputs, it could not learn to fire only when either input line was active, but not both.\n After that, neuro-computing ('connectionism') languished. A few researchers, including Rosenblatt (until his death in 1971), maintained their interest; but most of the funding - and most of the graduate students - went into research conducted within the alternative framework of symbol-manipulation. The symbolic paradigm received a further boost in the early 1980s, when the Japanese revealed that knowledge-based systems would be at the heart of their fifth-generation computer project at ICOT.\n Yet 1988, in the USA at least, has been the year of the neural network. Dozens of companies (such as Nestor and Neural-Ware) have launched hardware and software enabling neural-net experiments to be carried out on IBM PC AT-compatibles and Apple Macintoshes. Several conferences, including the prestigious AAAI-88 at Minneapolis/St Paul, have been dominated by connectionist themes. And, in September, DARPA (the US Defense Advanced Research Projects Agency) announced a total of Dollars 390 million, spread over six years, for research into neuro-computing.\n Why have neural nets suddenly become fashionable again? There seem to be four main reasons.\n First, and most abvious, computing hardware has changed out of all recognition since the first phase of neuro-computing. It is now feasible to construct networks containing hundreds of thousands of elements on a desktop machine. This by itself would be little help if the theoretical limitations identified by Minsky and Papert still held; but in the intervening period the 'back-propagation' rule has been discovered by Rumelhart and others. In brief, this is an improved error-correction algorithm that allows multi-layered Perceptrons to feed back deviations from correct performance and thus solve the Exclusive-Or and many other interesting problems.\n Second, charismatic figures such as John Hopfield and Geoff Hinton have linked the behaviour of neural networks to the behaviour of physical (eg thermodynamic) systems. Physics is, scientifically speaking, ultra-respectable; so once the academics realized that the same equations that described physical systems could be applied to neural nets, they felt safe to venture back into the field.\n Third, Terrence Sejnowski's Nettalk system is a most striking 'proof-of-concept' demonstration. Nettalk is a text-to-speech network which took 10 hours to 'learn to speak'. By contrast, a more conventional rule-based system for the same task, called DECtalk, required 100 man-years of effort. You can actually hear Nettalk's progress from senseless babble to a slightly alien but recognizable pronunciation, and it is eerily impressive.\n Last, but by no means least, neural networks seem to appeal to the military mind. In 1986, a team headed by Rumelhart and McClelland at the University of California, San Diego, submitted a report to DARPA (and later to its civilian equivalent NSF, the National Science Foundation). In it they argued that research into Parallel Distributed Processing (PDP) had been seriously underfunded for a decade at least. Basically they advocated a switch of resources into the PDP field - their name for connectionism.\n This report received a favourable reception, so much so that both DARPA and NSF have recently persuaded some quite high-powered institutions (including the AI group at UCLA) to alter the whole thrust of their work.\n It would seem that a number of US government funding bodies, disenchanted by the failure of the AI fraternity to deliver on some of the more extravagant promises made in the heady days of the expert systems boom, were casting around for a new approach. When they saw that neuro-computing was making progress again, they decided to make it a high-priority strategic technology.\n To put it crudely, it appeared to strike a blow against the 'yellow peril' and the 'red menace' with one stroke. On the one hand it presented an opportunity of regaining the initiative in leading-edge computer science seized by the Japanese with the fifth generation plan in 1981. On the other hand, it offered some hope of alleviating the 'software crisis' in SDI and other advanced weapons programmes.\n As things stand, neural nets have reached the stage where we can simulate brain function at approximately the level of a slow-witted slug. The idea that we might endow modern weapons systems with the mentality of molluscs makes one wonder what we are doing with our own neural networks.\n"},
{"docid": "224 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "August 23, 2014", "title": "Robot hitchhiker charms its way across North America\n", "content": "It looks like it was constructed from components scavenged from a jumble sale, but an extrovert robot has managed to charm its way across North America by hitching rides from strangers along the trans-Canada highway. Travelling from Nova Scotia to British Columbia, hitchBOT has dipped its wellington boots in Lake Superior, crashed a mountain-top wedding and attended a Native Canadian pow-wow. In total, it has covered almost 4,000 miles, charging its batteries when necessary from the cigarette lighters of cars.\u00a0\nDescribed by its creators as \"an outgoing and charismatic robot\", hitchBOT is equipped with artificial intelligence, speech recognition and speech processing, which it has used to beg for lifts.\nThe robot also has a sense of direction, and can ask and answer simple questions. It can tap Wikipedia to brush up on local knowledge and has a car seat attached to its torso so that helpful motorists can strap it in with their car seatbelts.\nIts chat is limited, but it did not take long for hitch-BOT to become a social media sensation, with 40,000 Twitter and Instagram followers. Many of the people who offered it a ride were already familiar with the bizarre contraption.\n\"Social and traditional media have really ensured that hitchBOT is well known,\" David Smith, the robot's cocreator, who teaches at McMaster University in Hamilton, said. \"Some drivers have tried to search its location. And in most cases, hitchBOT has had multiple offers.\"\nHitchBOT was invited at one point to a pow-wow with the Wikwemikong tribe and was taken dancing on the prairies of Saskatchewan. It later hitched a ride with Belgian tourists.\nIt then fell in with The Wild, a rock band from British Columbia, who took it to a gig.\nMr Smith said his team monitored hitchBOT via GPS and social media but the drivers who picked up the machine were in control of its fate. The official aim of the project was to \"explore topics in humanrobot-interaction and to test technologies in artificial intelligence and speech recognition and processing\".\nFrauke Zeller, from Ryerson University in Toronto, said: \"Usually, we are concerned with whether we can trust robots. This project asks: can robots trust human beings?\"\n"},
{"docid": "225 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 19, 2018", "title": "UK and France agree artificial intelligence tie-up\n", "content": "Ministers have agreed a technology tie-up with Emmanuel Macron's government that will see the UK unite with France in areas such as artificial intelligence and cyber security.\u00a0\nMatt Hancock, the Culture Secretary, will this morning announce the two countries plan to work together to pool industry and academic research. Britain and France will host a conference later this year to encourage cross-Channel investment, targeting work on AI in particular.\nIt comes as France's new government tries to shake off its reputation for protectionism and onerous employment rules that has held back start-ups in the country and seen Paris lose out to London as a tech hub.\nLast year more venture capital deals were signed involving French tech companies than British ones, the first time this has happened in half a decade, although the UK raises far more money in total and dominates rankings of European \"unicorns\", start-ups with valuations of more than $1bn (\u00a3720m).\nAlthough Mr Macron has made no secret of French ambitions to lure IT workers from London after Brexit, launching a new tech visa programme and using state cash to sponsor start-ups, cross-border work could help Europe challenge the giants of Silicon Valley.\nAI is seen as a rare area where European countries can challenge the US, thanks to the mathematics heritage at British universities and institutions such as Paris-Saclay in the French capital.\nA clutch of British and French AI companies have been snapped up by US tech giants including DeepMind, now owned by Google, Magic Pony, which was acquired by Twitter two years ago, and Wit.ai, a company founded by three French graduates bought by Facebook in 2015.\nIn a further nod to US rivalry, France and Britain released a joint statement defending net neutrality, the principle that internet providers are unable to discriminate between different websites.\nThe commitment follows the recent repeal of US net neutrality laws, a move that internet companies have said will harm young tech businesses and concentrate power in the hands of telecoms networks. Britain and France will \"make sure users can access websites without internet service providers favouring or blocking particular sites\", the countries said.\n                   AI timeline                   \n\"Both countries benefit when our digital economies are strong and [this] will deepen our bonds and foster cross-Channel collaboration between those at the forefront of modern technology,\" Mr Hancock said.\nJulian David of techUK, the British technology industry trade body, said: \"Both countries share similar opportunities and challenges as we build our leading digital economies through technologies like artificial intelligence, the internet of things and cyber security.\"\nThe tie-up was agreed between Mr Hancock and his French counterpart Fran\u00e7oise Nyssen during Mr Macron's visit to the UK this week.\n"},
{"docid": "226 of 297 DOCUMENTS\n", "source": "Independent on Sunday (London)\n", "date": "September 30, 2001", "title": "BOX OFFICE: THIS WEEK'S FILMS\n", "content": "\u00a0\n UK Top 10\n The critical perception of AI: Artificial Intelligence (right) is that it is a fascinating but flawed film, redeemed by sterling work from Haley Joel Osment and Industrial Light & Magic. Part of the problem may be the film's complex gestation. After years pondering Brian Aldiss's short story, Stanley Kubrick passed the project to Steven Spielberg, who tacked on the Pinocchio plot.\u00a0\n THIS LAST WEEKEND PERCENTAGE GROSS\n WK WK TOTAL CHANGE TO DATE 1 - AI: Artificial Intelligence (US) Warner pounds 2,285,786 N/A pounds 2,285,786\n 2 1 Moulin Rouge (US) Fox pounds 1,533,223 -18% pounds 8,366,042\n 3 2 The Fast and the Furious (US) UIP pounds 1,139,633 -35% pounds 3,718,426\n 4 3 A Knight's Tale (US) Columbia/Tristar pounds 517,045 -26% pounds 5,469,109\n 5 4 Scary Movie 2 (US) BVI pounds 378,640 -39% pounds 3,535,368\n 6 6 Cats and Dogs (US) Warner pounds 280,076 -23% pounds 21,234,713\n 7 5 Planet of the Apes (US) Fox pounds 268,165 -40% pounds 16,611,754\n 8 7 The Martins (UK) Icon pounds 209,539 -33% pounds 666,305\n 9 10 Shrek (US) UIP pounds 144,457 -13% pounds 28,130,248\n 10 - Crazy/Beautiful (US) BVI pounds 137,017 N/A pounds 137,017\n ACNIELSEN EDI\n US Top 10\n N o new entries this week, and only one climber, The Others (right), an intelligent horror flick starring Nicole Kidman. The first English language film by 29-year old Chilean writer/director Alejandro Amenabar cost a mere $ 17 million but has so far earned over $ 80 million, which should please its producers, including Miramax boss Harvey Weinstein and a newly single Tom Cruise.\n THIS LAST WEEKEND PERCENTAGE GROSS\n WK WK TOTAL CHANGE TO DATE 1 1 Hardball (US) Paramount $ 8,058,338 -14% $ 19,280,569\n 2 5 The Others (US) Miramax $ 5,083,004 11% $ 80,084,619\n 3 2 The Glass House (US) Sony $ 4,407,767 -23% $ 11,661,890\n 4 3 The Musketeer (US) Warner $ 3,549,955 -35% $ 22,671,145\n 5 6 Rush Hour 2 (US) New Line $ 3,520,978 -14% $ 215,615,683\n 6 4 Two Can Play That Game (US) Sony $ 3,212,217 -30% $ 18,188,869\n 7 9 Rat Race (US) Paramount $ 2,939,170 -17% $ 51,524,950\n 8 10 Rock Star (US) Warner $ 2,933,530 -13% $ 15,125,632\n 9 7 Jeepers Creepers (US) MGM $ 2,774,511 -28% $ 33,565,670\n 10 8 American Pie 2 (US) Universal $ 2,688,600 -25% $ 139,657,509\n ACNIELSEN EDI\n"},
{"docid": "227 of 297 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "October 27, 2011", "title": "John McCarthy; Obituaries Computer pioneer who coined the term Artificial Intelligence and invented a language to make it happen\n", "content": "JOHN McCARTHY, who has died aged 84, was often described as the father of \"artificial\u00a0intelligence\" (AI), a branch of computer science founded on the notion that human intelligence can be simulated by machines.\nMcCarthy, who coined the term in 1956, defined it as \"the science and engineering of making intelligent machines\" and created the Lisp computer language to help researchers in the AI field. He maintained that there were aspects of the human mind that could be described precisely enough to be replicated: \"The speeds and memory capacities of present computers may be insufficient to simulate many of the higher functions of the human brain,\" he wrote in 1955, \"but the major obstacle is not lack of machine capacity but our inability to write programs taking full advantage of what we have.\"\u00a0\nMcCarthy went on to create AI laboratories at the Massachusetts Institute of Technology, and later at Stanford University where he became the laboratory's director in 1965. During the 1960s he developed the concept of computer timesharing, which allows several people to use a single, central, computer at the same time. If this approach were adopted, he claimed in 1961, \"computing may some day be organised as a public utility\". The concept of time-sharing made possible the development so-called \"cloud computing\" (the delivery of computing as a service rather than a product). Meanwhile, his Lisp programming language, which he invented in 1958, underpinned the development of voice recognition technology.\nMcCarthy's laboratory at Stanford developed systems that mimic human skills - such as vision, hearing and the movement of limbs - as well as early versions of a self-driving car. He also worked on an early chess-playing program, but came to believe that computer chess was a distraction, observing in 1997 that it had developed \"much as genetics might have if the geneticists had concentrated their efforts starting in 1910 on breeding racing Drosophila. We would have some science, but mainly we would have very fast fruit flies.\"\nThe concept of AI inspired numerous books and sci-fi films, notably Stanley Kubrick's dystopian 2001: A Space Odyssey (1968). In the real world, however, the technology made slow progress, and McCarthy later admitted that there was some way to go before it would be possible to develop computer programs as intelligent as humans.\nMeanwhile he applied himself to addressing theoretical issues about the nature of human and robotic decision-making and the ethics of creating artificial beings. He also wrote a sci-fi story, The Robot and the Baby, to \"illustrate my opinions about what household robots should be like\". The robot in the story decides to simulate love for a human baby.\nJohn McCarthy was born in Boston on September 4 1927 to an Irish father and a Lithuanian mother. The family lost their home during the Depression and moved to Los Angeles, where John's father worked as an organiser for the Amalgamated Clothing Workers' Union and developed a hydraulic orange juice squeezer. His mother had been active in the women's suffrage movement and both parents were active members of the Communist Party.\nMcCarthy taught himself mathematics as a teenager by studying textbooks at the California Institute of Technology. When he arrived at the institute to study the subject aged 16, he was assigned to a graduate course. In 1948 a symposium at Caltech on \"Cerebral Mechanisms in Behaviour\", that included papers on automata and the brain and intelligence, sparked his interest in developing machines that can think like people.\nMcCarthy received a doctorate in Mathematics from Princeton University in 1951 and was immediately appointed to a chair in the subject. It was at Princeton that he proposed the programming language Lisp as a way to process more sophisticated mathematical concepts than Fortran, which had been the dominant programming medium until then.\nMcCarthy joined the Stanford faculty in 1962 after short appointments at Princeton, Dartmouth and MIT, remaining there until his official retirement in 2000.\nDuring the 1970s he presented a paper on buying and selling by computer, prophesying what has become known as ecommerce.\nHe also invited a local computer hobby group, the Homebrew Computer Club, to meet at the Stanford laboratory. Its members included Steve Jobs and Steven Wozniak, who would go on to found Apple.\nHowever, his own interest in developing time-sharing systems led him to underestimate the potential of personal computers. When the first PCs emerged in the 1970s he dismissed them as \"toys\".\nMcCarthy continued to work as an emeritus professor at Stanford after his official retirement, and at the time of his death was working on a new computer language called Elephant.\nMcCarthy won the Turing Award from the Association for Computing Machinery in 1972, the Kyoto Prize in 1988 and the National Medal of Science in 1990. Despite his disappointment with AI, McCarthy remained confident of the power of mathematics: \"He who refuses to do arithmetic is doomed to talk nonsense,\" he wrote in 1995.\nJohn McCarthy married three times. His second wife, Vera Watson, the first woman to complete a solo ascent of Aconcagua in South America, was killed in a climbing accident on Annapurna in 1978. He is survived by his third wife, Carolyn, their son, and by two daughters of his first marriage.\nJohn McCarthy, born September 4 1927, died October 24 2011\n"},
{"docid": "228 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "April 15, 2018", "title": "'Killer robots' could become reality unless Government bans autonomous weapons, Lords report claims\n", "content": "\"Killer robots\" which threaten to \"hurt, destroy or deceive human beings\" could become reality unless the Government improves regulation on artificial intelligence, a Parliamentary report has suggested.\nA Lords select committee has warned that while Terminator-style weapons may not yet exist, without checks and balances Britain could end up \"stumbling through a semantic haze into dangerous territory.\"\nIn a paper published today, the peers state that Britain's definition of military-grade AI differs significantly from other NATO members, with even the US taking a more cautious approach to the technology.\u00a0\nWhile a number of countries and campaigners, including the billionaire Elon Musk, have called for preemptive legislation to outlaw the technology from use on the battlefield, the UK Government has opposed efforts to ban its development.\nIt comes amid growing international concern that the rapid advance of the technology could soon result in \"lethal autonomous weapons\" being deployed in conflict zones.\nMeanwhile, at least 381 partly autonomous weapon and robotic systems are now operationational or in development \u00a0in 12 countries, including the UK, US, Israel and France.\nThey include an unmanned aircraft currently at prototype stage in the US, while the UK is developing its own driverless vehicles which could be weaponised in the future.\nTaranis, a British undetectable drone named after the Celtic god of Thunder, can already avoid radar detection and fly in autonomous mode.\nSeparately, the Russian military is amassing an arsenal of aerial and ground vehicles in a situation described by experts as the \"new arms race\". Last year, Vladimir Putin warned that \"whoever leads in AI will rule the world\".\nThe concept of killer robots was famously envisioned in the Terminator films, a science fiction series directed by James Cameron and starring Arnold Schwarzenegger, in which the US defence system Skynet becomes self-aware and attempts to wipe out humanity.\nLast night the chairman of the Lords committee on artificial intelligence, Lord Clement-Jones, said that it was vital that the Government adopt a set of new ethical rules to help \"mitigate\" the risks associated with AI.\nAI timeline\n\"The UK has a unique opportunity to shape AI positively... rather than passively accept its consequences,\" he added.\n\"It is essential that ethics take centre stage in AI's development and use. AI is not without its risks and the adoption of the principles proposed by the Committee will help to mitigate these.\n\"An ethical approach ensures the public trusts this technology and sees the benefits of using it. It will also prepare them to challenge its misuse.\"\nWhile the Ministry of Defence classifies weapons as AI if they are \"aware and show intention\", academics have warned that the UK is setting the \"bar so high\" that the definition is \"effectively meaningless\".\nIn contrast, allies including France, The Netherlands and the US have adopted more cautious definitions, which the University of Sheffield's Professor Noel Sharkey said demonstrated the UK was \"out of step\" with the majority of other governments.\nIn the report, the peers note that \"without agreed definitions we could easily find ourselves stumbling through a semantic haze into dangerous territory.\n\"The Government's definition of an autonomous system used by the military...is clearly out of step with the definitions of most other governments.\n\"This position limits both the extent to which the UK can meaningfully participate in international debates on autonomous weapons and its ability to take an active role as a moral and ethical leader on the global stage in this area.\"\nFront Bench promotion - end of article\n"},
{"docid": "229 of 297 DOCUMENTS\n", "source": "Daily Mirror\n", "date": "April 24, 2016", "title": "Why a Twitter rant may not be the best way to sort a problem; KNOW YOUR RIGHTS\n", "content": "TWITTER reached its 10th birthday a few weeks ago.\nThe social media milestone sparked a flood of news articles - a key theme being how such sites have revolutionised customer service.\u00a0\nYet for all that Twitter and Facebook have transformed how we interact, I don't find them an effective way to sort complaints. Here's why:\n'Social shouting' is not the same as getting a complaint resolved Most social media platforms are an excellent way to vent frustration - talking directly to the firm you have an issue with, in a very public space.\nAt Resolver, this is what we call \"social shouting\".\nThe problem is, a company's main aim will often be (to put it politely) to shut you up.\nThey will divert you from publicly bashing them and move things to a \"private channel\" - and you're less likely to get a considered response.\nReal resolution\nSo how do you get real results rather than simply being silenced? Appeal to a brand's wallet, not its heart.\nCompanies aim to make money. The best realise a happy customer is a loyal customer. So it's in their interests to give you satisfaction - efficiently, and cheaply.\nIt sounds a bit cold, but this means the more fair, open and honest you are about an issue, the quicker it can be resolved.\nAnd both you and the company end up happy. Can artificial intelligence help? This quest for efficiency also means firms are looking to automate more of their customer service.\nA big part is intelligent analysis of emails.\nThis sounds like a plunge to less and less human interaction. But in fact most queries have been answered before, for a different customer.\nBy recognising these \"easy wins\", artificial intelligence can free up contact centre staff to focus on real problems.\nThe rise of the robots? I'm all for it.\nLet James help you complain via Twitter @resolvercoukorvisitwebsiteresolver.co.uk\n"},
{"docid": "230 of 297 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "November 22, 2017", "title": "Prince Harry and AI to be guest editors on Today programme; Royal will tackle issues including mental health, while artificial intelligence modelled on Mishal Husain will interview a guest\n", "content": "Prince Harry and artificial intelligence software will help guest edit Radio 4's Today programme for two special editions between Christmas and New Year. \nKensington Palace said Prince Harry would use the opportunity to \"shine a spotlight on a number of issues that are close to his heart\", including youth violence, conservation and mental health. \u00a0\nThe AI edition will involve technology conducting an interview through a presenter modelled on Mishal Husain and will \"enhance\" the special edition of Today, although the BBC is still working on the exact format. \nIt will also include global experts exploring how AI impacts lives and how it could be used to improve the Today programme and remove human error. \nEvery Christmas the Today programme, which has a weekly audience of seven million, recruits high profile guest editors. \nOther guest editors this festive season will be Lady Trumpington, the 95-year-old Conservative peer who worked at Bletchley Park during the second world war and wants to explore the legalisation of brothels; Tamara Rojo, the artistic director and lead principal dancer of the English National Ballet and Benjamin Okri, the poet and novelist who wrote a poem about the Grenfell Tower fire.\nA spokesperson for Kensington Palace said: \"Prince Harry is grateful to have Today's considerable reach to shine a spotlight on a number of issues that are close to his heart. He is working closely with Today's team to produce segments on a range of topics, including youth violence, conservation and mental health.\"\nThe BBC has used guest editors over the festive season for the past 13 years. They are responsible for about half of each programme's content, typically choosing issues that are important to them. \nPrince Harry is the second royal guest editor of Today. Sarah Ferguson, Duchess of York, was involved in 2004. Other previous guest editors include the physicist Stephen Hawking, lawyer Miriam Gonz\u00e1lez-Dur\u00e1ntez and Sebastian Coe, president of the IAAF. Last year, the BBC put together an all-female group of guest editors including the Olympic gold medal-winning boxer Nicola Adams, the actor Carey Mulligan and the business executive Helena Morrissey.\n                     Sarah Sands, the editor of Today, said: \"We are delighted by the range of guest editors this year. This Christmas tradition allows our listeners to benefit from the experiences and perspectives of remarkable public figures. We finish with a programme dedicated to AI which gives a glimpse of the future of Today.\"\nThe exact dates of the special Today editions have not yet been confirmed.\n"},
{"docid": "231 of 297 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "November 21, 1984", "title": "Friends? Ask the Mind Prober / Thorn-EMI artificial intelligence computer software package\n", "content": "\u00a0\n Mind Prober has arrived in Britain this week. It is another harrowing example of what can happen when artificial intelligence is squeezed into the home computer. Even Thorn EMI, which is selling it, calls it Orwellian.\u00a0\n Mind Prober is a computer software package 'designed to increase understanding of the motives of others and gives indications of the way in which the user should approach a relationship or a meeting in order to extract the maximum benefit.'\n\n The user gives the home computer his or her initial impressions of a new acquaintance by scanning a list of 100 adjectives and stating whether they apply or not.\n The computer then provides a four-line summary of the subject's character and goes on to sketch his/her relationships with others, attitudes to work, ability to cope with stress, personal interests, attitudes to sex, and, 'in a concise summary, what makes the subject tick.'\n Thorn EMI says the program 'may provide hitherto undreamt of insight into the minds of people .. There are undoubted, and unashamed, reflections of the Big Brother concept inherent in Mind Prober.'\n The package is the latest in a series of psychological programs produced by the Human Edge Corporation, of Palo Alto, in Silicon Valley, California. Its systems for business assessment have been around for some time. Thorn EMI has been selling them here since June.\n One example is Management Edge. That one is supposed to enable a manager to assess a subordinate by first answering 86 questions about himself then 70 about the subordinate. The computer thus views the manager's own character before examining the manager's view of the subordinate. Then out comes the character verdict on the subordinate.\n Mr John Forrest, general manager of Thorn EMI Software Distributors, said yesterday that the missionary concept' of marketing these programs to British business had finally taken off in the past six weeks with nearly 400 sales at around pounds 200 a time. (The new home computer version costs between pounds 20 and pounds 30 for Apple, Commodore, and IBMpc machines).\n Mr Forrest himself uses one - Negotiating Edge - when settling distribution deals. He said it gave 'strong indications' of the best approach to a particular negotiation and 'makes you think of factors you should take into account.' But he added that he did not always follow the computer's game plan 100 per cent.\n"},
{"docid": "232 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "September 18, 2016", "title": "Amazon's Echo steals a march in the race for artificial intelligence\n", "content": "It came and went so quickly that one could easily forget it ever existed, but it was only two years ago that Amazon released its own smartphone.\nDeveloped in the web retailer's secretive \"Lab 126\", a Silicon Valley subsidiary 800 miles south of Amazon's Seattle headquarters, the \"Fire Phone\" was applauded for its ideas, which included a 3D screen effect made possible by an elaborate four-camera system. However, it proved to be a commercial flop.\nTied to Amazon's own operating system - a flawed stepbrother of Google's dominant Android software - and with a premium price tag that disappointed those familiar with the company's reputation for aggressively-thin margins, it failed to mount anything approaching a challenge to Apple or Google in the smartphone wars.\u00a0\nAnd regardless of the Fire Phone's merits, or lack thereof, Jeff Bezos and his team had entered the market half a decade late. In a year that smartphone sales surpassed one billion, the Fire Phone sold a few tens of thousands, and it was swiftly and silently discontinued.\nThe Amazon Fire phoneCredit:      Amazon     \nFor a company founded on prescience - Bezos's belief in online retail led him to quit his Wall Street hedge fund before many had heard of the web - it was a spectacular misjudgement, and led to a $170m (\u00a3130m) writedown just a year after the phone was launched.\nAmazon's failure in such an important battleground would perhaps have been more closely scrutinised in a tougher year, but at present it seems the company can do no wrong. It has posted five straight quarters of profits, unheard of for a company previously allergic to the word, and shares have risen by 150pc since the start of 2014.\nBut at the same time, its dismal showing in smartphones has been eclipsed by delirious enthusiasm about what comes next.\nA few months after the Fire Phone, Amazon unveiled a mysterious black cylinder it called the Echo . A two-way wireless speaker and microphone combination with a virtual artificial intelligence assistant - \"Alexa\" - that responds to voice commands like \"Read me the news\" or \"Turn off the lights\", it is designed to blend into the background in a kitchen or living room, responding to every wish.\nAt a glance | Amazon Echo\nWhen it was first announced to a sceptical tech press months after a flop phone, the Echo was dismissed separately as a joke and a privacy nightmare. Now the latter may still prove to be the case (the Echo is always listening, and logs every sentence spoken to it), but a joke it is clearly not. In fact many analysts now believe that Amazon has one hand on the future that comes after the smartphone.\nAlexa is not the only, or even the first, voice-activated virtual assistant - Apple, Google and Microsoft have had their own for years - but it is the first that consumers have truly embraced. While taking out a smartphone in public and speaking to it - as one must with Apple's Siri or Google's Assistant - is awkward, and often slower than simply using a touchscreen, talking to a device in the comfort of one's own home is decidedly less uncomfortable.\nAmazon's software also seems more reliable. The company's prowess in cloud computing - which has spawned the colossal Amazon Web Services unit - means that the Echo has access to the near-infinite computing resources of the company's servers: it can hear a question, send it to be processed, receive an answer and relay it in milliseconds. And Amazon's underrated artificial intelligence chops, honed using years of shopping data and developed at an R&D base in Cambridge, have allowed it to sneak under the radar.\nIt is important not to get carried away about the Echo, despite its growing buzz. Sales to date are estimated to be around 7m - less, for example, than the Apple Watch, whose sales have been below expectations - although the Echo is believed to have picked up momentum in recent months and has only been available in the US to date, with the UK and Germany following later this month.\nNew Amazon Echo speaker 'stuck in an infinite loop'Play!00:35\nThe impact on Amazon's own business is also unclear. The company says it is not making a profit on the \u00a3150 device. Many shoppers, meanwhile, are likely to feel uncomfortable, at least at first, about speaking to a robot to do their shopping. Analysts at RBC Capital Markets say 47pc of owners have never used the Echo to order an item from Amazon, against 10pc who buy things \"very often\" and 16pc who do so \"somewhat often\".\nBut Amazon has clearly stolen a march on its rivals, which they are now scrambling to recover from.\nGoogle announced a rival to the Echo earlier this year, although evidence of its development has been scarce, and privately, Amazon does not appear to be too worried. Apple is also rumoured to be exploring such a device. But in the same way that Amazon's tardiness in the smartphone game punished it, the company getting ahead of its competitors may prove crucial.\nIncidentally, the arms race that will follow is only likely to heighten interest in British expertise in artificial intelligence. Much of the Echo's technology stems from Evi, a startup it acquired in 2012. Google's AI breakthroughs are increasingly being made at the King's Cross headquarters of its subsidiary DeepMind. And last year Apple bought VocalIQ, a University of Cambridge spin-off that specialises in talking computers. British tech investors wondering where to put their cash would do well to take notice.\nFollow Telegraph Science & TechREAD MORE ABOUT:\n"},
{"docid": "233 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "May 6, 2016", "title": "Google AI to learn art of conversation through erotic romance novels\n", "content": "Having mastered the art of Go, Google's latest artificial intelligence project is to make its intelligent assistant more conversational. To do this, the AI has\u00a0spent the last few months reading erotic romance novels. \u00a0\u00a0\nThe\u00a0efforts are designed to make the AI\u00a0more personable and conversational, both in its understanding of human language and its responses.\u00a0\nAfter reading\u00a02,865 of the novels, which include titles such as\u00a0Fatal Desire,\u00a0Jacked Up\u00a0and\u00a0Unconditional Love, the AI has started to write sentences that are akin to those in the stories.\u00a0\nObviously, that doesn't mean that it is\u00a0writing lines such as \"She glanced down and turned as pink as the lace bra she was wearing\", but more that it is starting to converse in a more natural way.\u00a0\nAccording to a Google spokesperson, romance novels are particularly helpful to learn colloquial language because\u00a0they have predictable themes and plotlines, but use colourful and varied vocabulary to convey them.\nThe improvements\u00a0could enhance how Google products such as Search,\u00a0Google Now and Smart Reply interpret our language. For search, it could improve responses for queries written in a\u00a0conversational tone, while Smart Reply would help it understand and respond to your emails in a more human-like tone. For Android smartphone assistant\u00a0Google Now it could help the assistant respond in a more natural way.\u00a0\n\"In the Google app the responses are very factual,\" said Andrew Dai, one of the Google software engineers behind the project, to BuzzFeed . \"Hopefully with this work, and future work, it can be more conversational, or can have a more varied tone, style, or register.\"\n                   Futuristic sci-fi tech that is a reality: in pictures                   \nIt is unlikely that we will see a public version of the\u00a0raised-on-erotica AI, especially after Microsoft had to recall its\u00a0\"teen girl\"\u00a0Twitter bot Tay when it turned into a\u00a0Hitler supporter\u00a0within 24 hours.\u00a0\n\"We work directly with the product folks on how to develop this with minimal risk of it doing bad things, things that we don't expect,\" said Dai.\u00a0\nGoogle's AI could \"theoretically\" write a romance novel of its own, according to Dai, who described it as\u00a0\"quite sexy\" and \"very imaginative\".\nReminiscent of the film\u00a0Her, in which Joaquin Phoenix falls in love with a virtual assistant, Dai admitted it is\u00a0possible that the\u00a0AI trained with romance novels could eventually convince a human to fall in love with it.\u00a0\u00a0\nComparing the machine to a statue that a man falls in love with in\u00a0an ancient Greek story, Dai said: \"If you can fall in love with a statue, I don't see why you couldn't fall in love with a neural network trained on romance novels.\"\u00a0\u00a0\u00a0\nLast month, in a major victory for Google's artificial intelligence division, the Google DeepMind AlphaGo beat the world champion at Go .\u00a0\n                   AI timeline                   \n                       For a round-up of technology news and analysis, sign up to our weekly Tech Briefing\u00a0 here .\u00a0                   \n                   READ MORE ABOUT:                   \n"},
{"docid": "234 of 297 DOCUMENTS\n", "source": "\u00a0The Mirror\n", "date": "July 13, 2002", "title": "KELLY'S I GAME ZONE: ENCLAVE XBOX, JULY 19, POUNDS 45\n", "content": "\u00a0\n STRICTLY speaking, you would describe Enclave as a third-person fantasy action -adventure. But we'd call it a \"hack-n-slash\".\n You play a pretty bog-standard sword-wielding hero, negotiating 24 levels with your sword, crossbow and increasingly sophisticated weaponry, collecting gold and reviving potions, and solving puzzles - which generally involve operating machinery.\u00a0\n It's easy to be cynical about generic hack-n-slash games, but Enclave is rather good. It looks superb, the enemy Artificial Intelligence is decent and the storyline makes sense and is rather absorbing.\n One major annoyance is the way your character turns transparent when you are anywhere near a wall, which makes fighting in confined spaces, until you get used to it, a bit hit-or-miss. But Enclave is at least something new for the Xbox and is worth buying.\n"},
{"docid": "235 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "June 2, 2015", "title": "Google wants to count the calories in your Instagram food porn; Artificial intelligence technology Im2Calories aims to identify pictures of food posted to Instagram, and tell users the calorie count of their meals\n", "content": "If it's not on Instagram, you haven't eaten it. Roast dinners, souffl\u00e9s and salads, no food escapes an Amaro filter these days.\u00a0\nNow Google is responding to the appetite for \"food porn\" by developing an artificial intelligence project to calculate the calories in your latest Instagram post. \nAnnounced at the Rework Deep Learning Summit, the prospective tool called Im2Calories, aims to identify food snapped and work out the calorie content.\nThe Google researcher Kevin P Murphy said the AI technology will analyse the depth of pixels in an image and employ \"sophisticated deep-learning algorithms\" to judge the size and shape of a foodstuff.\nAccording to Popular Science, the company has recently filed a patent for the technology.\n\"To me it's obvious that people really want this and this is really useful. OK fine, maybe we get the calories off by 20%. It doesn't matter. We're going to average over a week or a month or a year.\n\"Now we can start to potentially join information from multiple people and start to do population-level statistics. I have colleagues in epidemiology and public health, and they really want this stuff,\" said Murphy.\nIn comments to Cnet, the Google spokesman Jason Freidenfelds said algorithms for Im2Calories were still being researched, and that there were no definite product plans currently.\nCalorie counting and food hygiene apps are popular with both iOS and Android users, and food has become the surprise hit of social networking, with Instagram accounts dedicated to food photography racking up thousands of followers.\n\u00b7 10 recipe apps to help you cook up memorable meals\n"},
{"docid": "236 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "November 2, 2015", "title": "Driving new laws\n", "content": "Sir, David Pannick QC makes some important points on the potential for artificial intelligence in law but doesn't go far enough (\"A masterclass on why lawyers will not be replaced by computers\", Oct 29).\u00a0\nThe ramifications of the rapid development of artificial intelligence go far beyond analysing data and questions around whether a computer will ever be able to provide advice, advocacy and judgment.\nGoogle estimates that in fewer than five years there will be driverless cars on the streets of our main cities. Will the cars be programmed to solve philosopher Philippa Foot's \"trolley problem\" in which an out-of-control tram has to decide whether to stay on course and kill five people or change course and kill one? Computer programmers will have to decide how cars decide. The courts will have to determine who is liable if the car makes the wrong decision. In law, there is no current answer to how the courts should decide such a case.\nThis is an exciting time for both technology and lawyers, but the law needs to catch up and work out how it will determine the answers to these questions.\nJonathan smithers President, Law Society\n"},
{"docid": "237 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "March 9, 2016", "title": "Google's DeepMind beats Go champion in historic moment for artificial intelligence\n", "content": "A computer program has beaten the world champion of one of civilisation's oldest board games\u00a0for the first time in history.\u00a0\nLee Se-dol, a 33-year-old South Korean, resigned the first of five matches of the fiendishly complex strategy game against the AlphaGo program, which is built by the Google-owned British company DeepMind.\u00a0\nThe game, which lasted a brief 3.5 hours, was officially declared as a win for AlphaGo in Seoul today. Commentators called it a \"superb\" game that would be studied for years to come.\u00a0\nThe game involves two players putting black and white markers on a 19-by-19 grid. It is said to have more possible playing permutations than the number of atoms in the universe.\n                     #AlphaGo WINS!!!! We landed it on the moon. So proud of the team!! Respect to the amazing Lee Sedol too\n- Demis Hassabis (@demishassabis) March 9, 2016\nWell done #AlphaGo !! Fantastic game from Lee Sedol. Four more games, but indubitably a new milestone has been reached in AI research today.\n- Edward Grefenstette (@egrefen) March 9, 2016\nThe AlphaGo program, which uses algorithms, has practised by analysing data from 100,000 professional human games and playing itself some 30 million times.\nMr Lee, who has been\u00a0a professional Go player since the age of 12, and won 18 international titles, said at a pre-game press conference:\u00a0\"It would be a computer's victory if it wins even one game.\"\u00a0\n\"I believe human intuition and human senses are too advanced for artificial intelligence to catch up. I doubt how far AlphaGo can mimic such things.\"\u00a0\nFour more games will be played over the course of this week, although AlphaGo would only have to win two of those to be crowned the victor.\u00a0\nREAD MORE ABOUT:\n"},
{"docid": "238 of 297 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "October 5, 2015", "title": "Apple buys VocalIQ: Siri likely to get more human as artificial intelligence could come to iPhones and Apple cars; Cambridge-based VocalIQ aims to change 'the way we talk to machines' by making them talk more like humans\n", "content": "Apple has bought a new artificial\u00a0intelligence-powered company that aims to make robots easier to speak to and could lead to improvements in its voice assistant, Siri.\nVocalIQ, which is based in Cambridge, builds . And Apple is likely to have bought the company to improve Siri, its voice-controlled digital assistant.\u00a0\n\"Traditional spoken dialogue interfaces are handcrafted, fragile and frustrating,\" says VocalIQ's website. \"It is unrealistic to expect seven billion people to start talking to machines in a way mandated by a programmer. Dialogue systems need to learn how people speak, and not the other way round.\"\nRead more\n                     Siri interrupts White House press briefing for question on Iran deal                   \n                     When Siri says some-thing amusing, is it a man or a machine?                   \n                     Asking Siri to charge phone prompts calls to emergency services                   \nVocalIQ says that its technology \"harnesses the power of more than 10 years of academic research in natural language, belief tracking, decision making and message generation\". \"Re-imagining the way that people interact with their devices has application across different market verticals - with enormous potential to revolutionise our interaction with machines,\" its website said.\nApple has been working to make Siri more useful and better at understanding the needs of its owners. iOS 9, the most recent update to the iPhone and iPad operating system, brought new features to Siri that allowed it to suggest apps that it thinks its owner might be looking for, for instance.\nThe top five features in Apple's iOS 9\nEventually, the same technology is likely to come to all of Apple's line. Its CarPlay in-car entertainment technology can make use of Siri, for instance - and so might the rumoured Apple car.\nApple has been reported in the past to be hiring machine learning and artificial\u00a0intelligence experts, in an attempt to help make Siri more clever and able to predict what humans are saying and might want. The company has been aggressively hiring experts including those from other companies like Google, Amazon and Facebook, in addition to the VoiceIQ acquisition.\n"},
{"docid": "239 of 297 DOCUMENTS\n", "source": "The Sunday Telegraph (London)\n", "date": "March 18, 2018", "title": "The robot will interview you now: automation levels the playing field for job hunters; Far from being confined to science fiction, artificial intelligence can help firms weed out bias, says Caroline Bullock\n", "content": "When the boss of a pharmaceuticals firm scribbled \"heels, red lipstick, good\" on the CV of a woman he appointed as his PA, it was a summation that would come back to haunt him.\nLucia Pagliarone found her annotated CV lying on a desk and it would provide compelling evidence when she took her boss to a tribunal on the grounds of sex discrimination. She won the case, but it is a stark reminder of how hiring decisions can be influenced by factors beyond skills and aptitude, with the fallout having serious repercussions.\nBeing swayed by a candidate's appearance is nothing new; but in a post-Weinstein, \"#MeToo\" climate of heightened sensitivities around discrimination, tackling bias in recruitment has become big business, and increasingly robots are being called upon to restore objectivity.\u00a0\nFuelled by the new breed of artificial intelligence (AI) applications, technology that can bypass physical attributes and analyse candidate data at speed without emotion or prejudice is gaining traction.\nOf the 1,200 hiring professionals surveyed by recruitment firm Korn Ferry, almost two thirds say AI has changed the way the process is carried out, and believe the technology attracts higher-calibre candidates.\n\"It's not surprising that algorithms are becoming very attractive to eradicate the risk of bias and take the decision out of the hands of an interviewer,\" says Emma O'Leary, a consultant with Manchester-based employment law firm Elas.\n\"Human bias is often subconscious, but subconscious discrimination is still discrimination. In an ideal world, managers should have robust equality and diversity training to overcome sexist or racist views, but clearly such bias is still prevalent.\"\nIf notions of being grilled by R2D2 at a desk come to mind, the reality is a bit different. The most common iterations are automation tools, typically deployed to filter out unconscious bias in the early stages of the hiring process.\nBy anonymising a candidate's gender, social and educational characteristics, they help to create a level playing field, while predictive analytics can assess cultural or technical fit against a specified set of criteria and anticipate the likelihood of success in the role. As well as helping to distinguish people, AI can profitably target those perhaps normally deterred from applying. For example, concerned by the lack of women responding to its data scientist vacancies, cyber security firm Panaseer turned to the predictive algorithms of Textio. This uses machine learning to identify gender biased language in job descriptions and suggest linguistic tweaks.\n\"It highlighted how some of the wording in our job posts such as 'ambitious', 'tackle' and 'driven' was typically associated with masculine traits which was actually creating a subconscious bias,\" said chief scientist Mike MacIntyre. \"Alternatives were recommended to make the 'Humans are inherently biased. If at some point you have a human interaction, the danger of bias creeps in' descriptions more inclusive and appealing to women.\"\nThe simple amendment led to a 60pc uplift in female candidates and an all-female shortlist for one of its most recent positions.\nUsing AI to do the legwork before reverting to the human touch in the final stages remains a default approach for those who still feel there is a role for emotional intelligence in the hiring process. However, for Gareth Jones, chief operating officer of recruitment specialist Headstart, it is a compromise that means companies are ultimately falling at the final hurdle.\nHe said: \"Unfortunately, humans are inherently biased. So no matter how much technology you build into the hiring funnel, if at some point you have a human interaction face to face, the danger of bias creeps in.\" But if the answer is to remove human intervention completely, it seems most UK businesses are not ready for that leap of faith. While almost two thirds of respondents surveyed by CRM developer Pegasystems expect the use of AI to conduct interviews and shortlist candidates to be standard practice in the next decade, only 30pc believe an algorithm will be making the final hiring decisions.\nStart-up Cognisess has developed AI-powered software that is designed to emulate an interview. The machine learning assesses candidates across a number of performance areas, while the video element films them responding to a set of questions which are then reviewed by a robot primed to analyse the minutiae of facial expressions frame by frame.\nIf a company requires passion and enthusiasm for a customer-facing sales role, it will home in on the level of positivity and expressiveness of the person. A fake smile will not cut it.\n\"The machine can detect micro expressions,\" explains Boris Altemeyer, the firm's chief scientific officer. \"These emotions show on the face for only a fraction of a second.\"\nOne client, Intercontinental Hotels Group, has increased the diversity in its hiring and saved a quarter of a million pounds in the assessment process.\n\"Technically, this system can recruit in its entirety, but we would never advocate removing people completely from the process. If you think about humans reviewing 60 or more video interviews a day and still being absolutely unbiased or as sharp as when they watched the first one that would be a tall order for anyone, so it's about getting as much of the purist data to them, so they make the best decisions.\"\nFor the time being at least, the human recruiter is still hired.\n"},
{"docid": "240 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "April 25, 2017", "title": "Man Group rehires data whizz in artificial intelligence push\n", "content": "Hedge fund giant Man Group hopes to\u00a0show portfolio\u00a0managers how to make smarter decisions using artificial intelligence,\u00a0with its discretionary\u00a0investment division GLG hiring\u00a0its first head of machine learning.\u00a0\nWilliam Ferreira, who has\u00a0a PhD in theoretical computer science, has taken up the new role almost three years after leaving Man's AHL\u00a0arm, which has been researching and using machine learning for years.\u00a0\u00a0\nMachine learning\u00a0sifts through data to detect patterns,\u00a0making it useful for hedge funds to predict market moves while\u00a0social media platforms such as Facebook rely on the technique to customise the posts members see.\u00a0\nMr Ferreira, who most recently worked at hedge fund Florin Court Capital,\u00a0will teach GLG's traders\u00a0how to analyse news and social media, market events and announcements via machine learning techniques.\u00a0\nHis hire comes months after Man Group announced\u00a0a new research professorship in machine learning \u00a0at Oxford University, a role that\u00a0will focus on financial markets as the sector races to exploit data analytics.\u00a0\n\"As the amount of data available continues to expand, these techniques can supplement existing rigorous quantitative and qualitative analysis,\" said GLG's\u00a0chief executive Teun Johnston, adding\u00a0that machine learning can help investment managers\u00a0make decisions.\u00a0\nAccording to IBM, 90pc of all existing data was created in the past two years with\u00a0Boston Consulting Group partner Ben Sheridan noting\u00a0that spending in this area had\u00a0shifted\u00a0from a small sector of hedge funds \"to a much more mainstream side of asset managers.\"\u00a0\nBlackRock, for example, is investing in this area with its global head of active equities Mark Wiseman noting last month that he wants to harness the power of human and machine.\n\"Traditional methods of equity investing are being reshaped by massive advances in technology and data sciences,\" he said. \"The active equity industry needs to change.\" \u00a0\n                   AI timeline      If you would like to add a comment, please register or log in     RegisterLog inPlease review our commenting policy\n"},
{"docid": "241 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 20, 2017", "title": "Bringing artificial intelligence to the art world\n", "content": "                   Jonas Almgren, chief executive of Artfinder, discusses going after the home decor market and how technology could put more original art in people's homes.  .inline-content hl{     font-family: \"Austin News Deck Semibold\", Georgia, Times, serif;      font-size: 1.7rem; }  .inline-content .first-letter{     color: #043480;      float: left;     font-size: 9.1rem;     font-style: normal !important;     font-weight: normal !important;     line-height: 7rem;     margin-top: 4px;     padding-right: 2px;     text-transform: uppercase;     font-family: \"Austin News Deck Semibold\", Georgia, Times,serif; }  \nEmma is an art curator with a neat party trick. Show her an image of anything -\u00a0a warm sunset, a city skyline, even a picture of your cat - and she will show you a work of original art that matches it for colour, composition and mood.\nStored in her head, she claims, are 300,000 different paintings, prints and sculptures.\u00a0\nBut if you want Emma to use her superhuman powers on your holiday snaps, she won't be able to meet you in person, because Emma isn't real. She's an artificial intelligence (AI) Twitter bot, built with the same facial recognition technology that police forces use to identify criminals on CCTV. Tweet her a picture and she will automatically respond with four suggestions inspired by it.\nThose suggestions will link to works that you can buy on Artfinder, which designed her. It's an online marketplace for art, similar to Amazon or Etsy. Artists can upload their work to the website and set their own prices -\u00a0and thanks to a search tool (and Emma's advice), visitors can discover and purchase works within their budget. The company takes a 30pc commission on sales.\nIf it sounds like a traditional gallery approach, Artfinder will tell you that it's anything but. For starters, the majority of artists who sell on the site are unrepresented by galleries. The business calls them \"starving artists\" - people who don't sell enough of their art to make a living from it.\nBuyers, too, aren't your typical collectors. \"We're going after the home decor market instead of the high-end art space,\" says the company's chief executive, Jonas Almgren. Artfinder buyers are people who want something original, but affordable, to hang in their living room.\nMost people still think that art is too expensive, says Almgren, who points to the eye-watering amounts paid for masterpieces\u00a0as a common reference point when people discuss art prices. In 2015, Pablo Picasso's Les femmes d'Alger (Version O)sold for $179m (\u00a3116m at the time), a record price for a painting sold at auction. It puts people off, he explains. \"They end up buying a poster from Ikea that everyone else has.\"\nWorks can sell for as little as the artist wants, but the average sale is \u00a3250. Almgren admits that it's tricky to put a price tag on something that's subjective. \"It's not a functional thing, like a toaster, where there's an expected price,\" he says. The company works with artists to help them set an acceptable price point. \"We have so much data, which we're happy to share.\"\n.html-embed.component .quote.component{margin-left:0}.html-embed.component .quote.component .component-content{margin-right:16px}.quote__source, .quote__author {white-space: normal;}@media only screen and (min-width:730px){.html-embed.component .quote.component{margin-left:-60.83px}.html-embed.component .quote.component .quote__content:before{margin-left:-12px;padding-right:1px}}@media only screen and (min-width:1008px){.html-embed.component .quote.component{margin-left:-82.33px}}It's very hard to make money [online] if all you have is contentJonas Almgren, Artfinder\nData points include the physical size of the work and materials used. \"We're able to say to the artist: if you want to sell this oil painting quickly, you should price it at this level.\"\nBefore joining the company, Almgren worked in New York for eight years, where, among other things, he co-founded and ran an online art fair aimed at galleries at the high end of the market.\nNone were interested in going online. \"That world is all about business being done person-to-person\u00a0- going to parties, shaking hands, and having deep, personal relationships with people,\" he says.\nAlmgren was approached by London-based Artfinder to join the team as chief operating officer in 2012, but it was a completely different operation then. It was as an online database of the world's famous art - and it sold posters. Visitors could read about the Mona Lisa and buy a poster of it.\nFinancially, it failed. \"It's very hard to make money [online] if all you have is content,\" says Almgren, who was asked by the board to take charge when Spencer Hyman, Artfinder's founder, left the company in late 2012. Almgren decided to move away from the Da Vincis to focus on working artists.\nHe relaunched Artfinder in March 2013 as the marketplace it is now. The website went from having a handful of artists to thousands by the end of 2013. \"We spent no money bringing them in, they came to us,\" he says. \"We felt that we were on the right track.\"\nToday Artfinder has more than 500,000 global subscribers and 300,000 works for sale. It registered turnover of \u00a35m in 2016. It's yet to make a profit, as it focuses on growth and investing money back into the company. Almgren expects to turn a profit from 2018.\nIf Artfinder is to continue to grow, it must continue to focus on relationships, says Almgren, who sees the website as a matchmaker between buyers and sellers. Like a first date, interested buyers can chat online with artists and ask them about their background, inspiration and methods.\nArtfinder chief executive, Jonas AlmgrenCredit:      Artfinder/Marek Matulka     \nAbout 50pc of buyers have interacted with an Artfinder artist at one point or another. \"People love the handmade aspect,\" explains Almgren, who points to the popularity of craft products such as beer. \"People like to know the maker. We live in a society where mass production is incredibly efficient but people love to have something local, made by someone whose name they know.\"\nThe Swedish chief executive isn't worried about an artist and buyer taking the sale offline to avoid paying commission. \"It's a risk,\" he admits. \"But we've seen that our most successful artists won't do it. If we find out, we will kick them off the platform.\"\nWhat next for the company? Almgren wants to build on its successful uses of technology, such as Emma. Artfinder recently completed a round of funding worth $2.2m (\u00a31.8m). William Tunstall-Pedoe, who helped design and launch virtual assistant, Amazon Echo, was involved. \"He's got a great background in machine learning and AI, which we're working on now,\" says Almgren.\nThe money will also be used to launch a US office in February. The company will hire a small team there, bringing it closer to artists and customers Stateside. \"We need to strike now, or risk someone else stepping in.\"\n"},
{"docid": "242 of 297 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "July 31, 2017", "title": "Swedish banks embrace artificial intelligence as a cure to closures; Sweden's financial giants are usingchatbots and AI for menial tasks in a bid tofree up staff to take up morecomplex tasks\n", "content": "Aida is the perfect employee: always courteous, always learning and, as she says, \"always at work, 24/7, 365 days a year.\"\nAida, of course, is not a person but a virtual customer-service representative thatSEB AB, one of Sweden's biggest banks, is rolling out. The goal is to give the actual humans more time to engage in more complex tasks.\u00a0\nAfter blazing a trail in online and digital banking, Sweden's financial industry is now emerging as a pioneer in the use of artificial intelligence (AI). Besides Aida at SEB, there's Nova, which is a chatbotNordea Bankis introducing at its life and pensions unit in Norway.Swedbankis adding to the skills of its virtual assistant, Nina. All three are designed to sound like women, based on research suggesting customers feel more comfortable with female voices.\nRead more\nwill.i.am says AI to be more disruptive to UK tech than Brexit\n\"There are some frequent, simple tasks that we need to deal with manually today, and in that effort we're looking into AI to see how we can deploy it and Aida is one,\" Johan Torgeby, the chief executive officer of SEB, said in an interview.\nChatbots have access to vast amounts of individual client data, meaning they can quickly handle straightforward customer requests. That in turn frees up human employees to deal with more complex services, like coming up with the best mortgage plan to suit a specific customer.\n\"Basically all banks are closing branches,\" Mattias Fras, head of Robotics, Strategy and Innovation at Nordea, said in a phone interview. \"This is a way to return to full service again.\"\nNordea's chatbot will eventually help customers who want investment advice, who want to cancel lost credit cards or to open savings accounts.\nSwedish banks have already seen their customer satisfaction scores drop to a20-year lowafter shutting branches and pushing people onto online services.\nBut AI might be part of the cure. According to a recent study by market researcher GfK, there are wide gaps between what consumers hope to receive from banks in terms of service and financial advice, and what they actually get. AI applications such as chatbots \"hold the promise of filling in these service gaps, given the right data and programming,\" GfK said.\nSwedbank, which already operates its chatbot Nina in Sweden and plans to roll it out to its Baltic markets as well, says one of the benefits to the technology is that it eases users into the new digital age.\nAI \"can help our customers become more digitised, for example by guiding a client in paying bills on the Internet,\" Swedbank spokeswoman Josefine Uppling said.\nPetra Stenqvist, a partner at Pond, which looks into innovative business ideas, says it's unlikely AI will ever be able to think like humans.\nIt \"will never be able to replace subjective assessments,\" she said. \"But it will be able to contribute to better decision making.\" And because of the massive amounts of data that AI can store, \"individuals will be able to find out things about themselves that they didn't even know.\"\nBloomberg\n"},
{"docid": "243 of 297 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "April 3, 2016", "title": "How your bank is becoming RoboCop; Could artificial intelligence make banking more personal? Felicity Hannahfinds out\n", "content": "Banking isn't what it once was. Branch managers with personal relationships and hunchbased decisions are out. And in their place are automated algorithms relying on credit checks and other customer data to make decisions on lending and customer spending.\nNowhere is that more prevalent than when it comes to fraud. Ask anyone who's had their card blocked during a stag do in Tallinn or a girls' trip to Vegas.\u00a0\nAnd now the effects of blanket rules that leave thousands of banking customers in the lurch is prompting a major drive to develop artificial intelligence (AI) that can effectively identify fraud and, potentially, transform consumer banking.\nBut while AI may sound like yet another step away from the days of the trusty bank manager, proponents argue that the ability to identify unique spending behaviours and make rapid decisions could mean the future of banking is more personal, not less.\nMeanwhile, with \"robo advice\" already tipped as a development that could transform how people access products in the future, it now seems RoboCop could be coming for fraudsters.\n\"Let's imagine you go on holiday every year to Morocco\", suggests Martina King, the chief executive of Featurespace, a company born from Cambridge University research that is pioneering the use of AI to understand individual behaviour in real time and predict future actions. \"Our systems can use that prior piece of information where existing bank systems can't. So we know that you usually go to Morocco, it's an expected pattern and your card wouldn't be blocked.\"\nBut Featurespace's software doesn't just analyse existing data deeper to cut back on the number of false fraud alarms, it can also make predictions about expected behaviour.\n\"Because we're monitoring data in real time, we can predict what we'd expect the next action to be\", Ms King explains. \"So if we saw a transaction in Gatwick after Morocco then we'd expect the next transaction to be in the UK.\"\nWhat is particularly clever about their AI system is that it can learn from new types of fraud; allowing it, the designers argue, to keep up with \"the arms race\" against innovative criminals. In tests with UK banks, the company's AI has resulted in a 70 per cent reduction in the number of genuine customers who find themselves blocked, because it doesn't rely on blanket rules to make decisions.\nBut fraud detection could be just the tip of the iceberg when it comes to AI and the consumer banking experience.\n\"Banks have all the data they need to really know us, and through the application of intelligent strategies which emulate the decisions of a personal relationship manager, they can deliver a response that's good for me and them,\" says Robin Collyer, of software developer Pegasystems.\nIn fact, AI systems could even be used to determine whether human operatives are doing their jobs properly, eliminating the risks of human error. Samantha Regan, managing director of Accenture Finance & Risk Services, explains: \"We may see more advances in AI in the area of surveillance, where AI could look at sales practices and make sure that bankers and advisers are offering the appropriate sales products, advice and guidance to their customers - and ensuring that these processes are aligned from a regulatory perspective.\"\nSome customers may find the idea of software watching their behaviours and predicting their actions slightly creepy, but Ms King says most people are annoyed their banks do not already analyse their data effectively.\n\"We are finding there's a consumer appetite already ahead of where the bank's technology is.\nThey get frustrated when banks can't recognise patterns in their behaviours or when they don't use their data effectively.\n\"Our systems are looking for patterns; we're not making a judgement on what people are doing. The AI is searching for things that are different, anomalistic, things that stand out as unusual. We wouldn't investigate them, it would be the bank itself that does that.\"\nHowever, even if these developments are widely welcomed by consumers, it doesn't mean they are foolproof. Harry Armstrong, senior researcher at innovation foundation Nesta, says there can be serious unintended consequences.\n\"While algorithms are driven by data and numbers, they are no less subject to bias than a human and are in no way completely objective machines. Data determines any of the decisions that are made, so if that information does not accurately reflect real life, or if it only represents a subsection of the population, the end result will likely favour or discriminate against certain groups or individuals.\n\"Another worry is that if the data science behind the process is flawed from the get-go, then the effect could be very bad for a lot of people.\"\n"},
{"docid": "244 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "September 9, 2015", "title": "Baidu launches Duer digital assistant to take on Siri, Cortana and Google Now; Chinese search company challenges Google, Apple and Facebook with artificial intelligence voice search capable of ordering food and giving pet advice\n", "content": "Chinese technology company Baidu, often labelled as China's Google has launched a digital assistant to take on rivals from Apple, Microsoft and Google. \nUnveiled at the company's Baidu World conference in Beijing on Tuesday, the new Siri-like virtual assistant called \"Duer\", which roughly translates to \"Du Secretary\", is built into the Baidu Android search app installed on millions of smartphones across China.\u00a0\nBaidu has pioneered artificial intelligence research, rivalling US tech companies including Google, Apple and Facebook, and is the only company of its scale to operate within the space from outside the US.\nDuer will allow users in Chinese users to order food and access other services via the app, while the company is planning to make the voice control system part of its internet of things push. Baidu is working on a system to allow Duer to control devices in the home and allow them to connect to healthcare and other service providers.\nThe virtual assistant will follow a similar path to Google's Now and voice search, becoming integrated into Baidu's other apps including Maps and Nuomi, a group buying service.\nBaidu showed off AI capable of recognising images more reliably than humans and better than both Microsoft and Google's technology. \nThe company also recently announced plans to release a self-driving car with automotive manufacturer BMW by the end of the year, based on its AI, machine learning and mapping technologies. \nThe Chinese company has rapidly become a real challenge to the American technology companies, seizing on their absence from the world's largest consumer electronics market.\nGoogle is expected to re-enter China in the near future with a limited version of its Play Store and version of Android, which dominates the western smartphone market.\nBut the company will have to overcome Baidu and incumbent Chinese players including Xiaomi, which have flooded the market with customised versions of Android with their own app stores and services.\n                     \u00b7 Facebook M virtual assistant will compete with Siri and Google Now                   \n"},
{"docid": "245 of 297 DOCUMENTS\n", "source": "DAILY MAIL (London)\n", "date": "June 9, 2014", "title": "COMPUTER THAT THINKS LIKE A HUMAN (AGED 13)\n", "content": "INTELLIGENT computers have long been a staple of science fiction.\nBut getting a machine to hold a convincing conversation with a human is a milestone that has never been passed - until now.\u00a0\nIn what is considered a major scientific breakthrough a computer has passed the Turing Test by convincing people in conversation that they are speaking to a human, at least up to a point. The computer's sophistication is considered no higher than a boy of 13.\nThe Turing Test is the key benchmark of artificial intelligence and was devised by British Second World War codebreaker and computing pioneer Alan Turing in 1950.\nHe said that if a machine is indistinguishable from a human it is thinking'. Most computers give themselves away by being unable to answer questions that would not puzzle a child. But a computer programme called Eugene has convinced 33 per cent of judges that it is human.\nNo computer has previously passed the Turing Test which requires 30 per cent of human interrogators to be duped during a series of five-minute keyboard conversations.\nFive machines were tested at the Royal Society in London to see if they could fool people into thinking they were humans during text-based conversations.\nEach judge had simultaneous conversations with a human and a computer programme, and had to decide which one was the machine. Professor Kevin Warwick from the University of Reading, which organised the test on Saturday on the 60th anniversary of Mr Turing's death, said an important landmark had been reached.\nHe said there had been previous claims that the test was passed. But he added: A true Turing Test does not set the questions or topics prior to the conversations. We are therefore proud to declare that Alan Turing's test was passed for the first time.'\nProfessor Warwick said having a computer with such artificial intelligence had implications for society and would serve as a wake-up call to cybercrime'.\nThe successful machine was created by Russian-born Vladimir Veselov, who lives in the US, and Ukrainian Eugene Demchenko who lives in Russia. The programme is now hosted online for anyone to talk to at www.princetonai.com/bot/bot.jsp\n\u00a9 Daily Mail\n"},
{"docid": "246 of 297 DOCUMENTS\n", "source": "\u00a0The Mirror\n", "date": "July 27, 2005", "title": "THE BIG STUFF: ARSE OF THE WEEK\n", "content": "\u00a0\n JUDE Law must be kicking himself.\n He gets caught pumping the ugly babysitter and is then dumped by his beautiful girlfriend Sienna Miller.\u00a0\n The guy probably thought he was still in character for the film Alfie at the time.\n I tend to think he was re-visiting his role for AI - Artificial Intelligence.\n"},
{"docid": "247 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "May 24, 2015", "title": "Hay Festival 2015: Why artificial intelligence needs to be regulated; The Astronomer Royal Martin Rees says some experts worry about whether humans can keep AI robots under control\n", "content": "The eminent scientist says \"there's no harm\" in experts coming together to find a way for society to benefit  rather than suffer from the revolution in artificial intelligence (AI) and robotics. \u00a0\n\"If they are able not only to learn so fast but also interact with the external world then of course some people worry about whether we can keep them under control,\" he told The Telegraph. \nHe compared the need to regulate developments in AI with the need to control the use of biotechnology. \nProfessor Rees, who was previously Master of Trinity College, Cambridge and President of the Royal Society was appearing at the 2015 Hay Festival. \n                                            Click here                      for all the latest news from Hay. \n"},
{"docid": "248 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "October 13, 2017", "title": "Robocops to replace British bobbies on the streets, police force reveals\n", "content": "Robocop-type policing techniques are set to replace bobbies on the beat within a decade as Artificial Intelligence becomes widespread in investigating crimes.\nThames Valley Police said AI computers - which mimic\u00a0humans by making decisions themselves - could be used to answer 999 calls, detect crimes and identify offenders.\nBut the force gave warning that there was a risk of \"bias\" in the AI software and a concern that AI computers\u00a0\"might be unable to reason with a human\".\u00a0\nThe news comes as ministers prepare to publish the first ever review into how AI will change Britain over the coming decades.\nAI is already used by Scotland Yard to recognise faces at London's Notting Hill Carnival. Durham Constabulary is also planning to use AI for deciding whether to keep suspects in custody.\nIn a submission to a Parliamentary inquiry into the Implications of Artificial Intelligence, Thames Valley said there are \"even at the lowest level AI could perform many of the process driven tasks that take place in the police\".\nAI could be used to assist \"investigations by 'joining the dots' in police databases, the risk assessment of offenders, forensic analysis of devices, transcribing and analysis of CCTV and surveillance, security checks and the automation of many administrative tasks\", it said.\nThe\u00a0world's first operational police robot stands at attention they prepare military cannon to fire to mark sunset and the end of the fasting day for Muslims observing Ramadan, in Downtown Dubai Credit:      AFP/AFP     \nAI could further be used to carry out predictive threat, risk and harm assessments, taking verbal statements, speech analysis and interviews and questions, and to answer 999 calls, the force said.\nIn one imagined example, Thames Valley told how a member of the public could phone 999, and describe an incident to an AI system, rather than a police operator.\nThe force continued: \"Speech analysis categorises the type of incident the type of incident and detects indicators of stress from the caller.\n\"The date, time, location and offence details are recorded automatically onto police systems.\" CCTV would be monitoring the situation and identifying suspects using face recognition software, it said.\nPolice are then dispatched to the scene where \"the suspect is arrested and all parties, including the arresting officers provide voice statements in situ, which are automatically uploaded, transcribed and attached to the crime report.\n\"Solvability factors are calculated on the quality of the availability data. The risk assessment provides a recommendation for officers on the next steps for the offender and also an appropriate support package for the victim\".\nBut Thames Valley police warned that there needed to be \"a high level of human oversight and clear justification\".\nIt said that\u00a0\"recent tests of AI in policing indicate there is a risk of bias perpetuation in AI outputs, therefore engagement with Privacy and Civil Rights groups will be necessary to persuade the public that everything possible is being done to mitigate this whilst doing our best to keep them safe.\n\"Of utmost importance is that any AI process that involves an ethical issue, must have a high level of human oversight and clear justification. The automation of processes also introduces a risk of being unable to reason with a human when events occur outside expected parameters.\"\nA Thames Valley spokesman said: \"Artificial Intelligence is likely to emerge in law enforcement activity over the next ten years, enabled by broader digital transformation across police forces, improved IT infrastructure and developments in AI capability and utility in both the public and private sectors.\"\nSimon Kempton, technology lead for the Police Federation of England and Wales which represents rank and file officers, warned that AI could drive \"a wedge between the public and the police\".\nMr Kempton said: \"AI should only ever enhance a police officer's ability to tackle crime, not replace them. It's absolutely right that forces embrace new technology but this should never be at the expense of continued human interaction without which you run the risk of driving a wedge between the public and the police.\"\nCivil liberties groups were alarmed by the plans. David Green, the director of the Civitas thinktank, warned that the AI computers could unfairly target ethnic minority groups.\nHe said: \"Robocop policing has now arrived in England. This Orwellian reliance on automated decisions has been found to undermine the most basic precepts of the justice system when it has been tried in America.\n\"An experiment in Fort Lauderdale, for example, found that the algorithm reflected human prejudices, including racial bias.\"\nRenate Samson, chief executive of Big Brother Watch, added: \"Technology, such as facial biometrics has a very low success rate with more innocent people being picked out of the crowd than criminals\".\nShe added that \"the data held by forces is far from accurate or complete. With rubbish data, AI will give rubbish answers leading to negative consequences for society.\u00a0\n\"Investment in these technologies is costly, police cuts are at critical proportion, investing in new unproven technologies whilst taking bobbies off the beat is highly problematic.\"\n"},
{"docid": "249 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "October 19, 2016", "title": "Hawking: AI will be 'either best or worst thing' for humanity; Stephen Hawking praises the creation of Cambridge University institute to study artificial intelligence\n", "content": "Professor Stephen Hawking has warned that the creation of powerful artificial intelligence will be \"either the best, or the worst thing, ever to happen to humanity\", and praised the creation of an academic institute dedicated to researching the future of intelligence as \"crucial to the future of our civilisation and our species\".\u00a0\nHawking was speaking at the opening of the Leverhulme Centre for the Future of Intelligence (LCFI) at Cambridge University, a multi-disciplinary institute that will attempt to tackle some of the open-ended questions raised by the rapid pace of development in AI research. \n\"We spend a great deal of time studying history,\" Hawking said, \"which, let's face it, is mostly the history of stupidity. So it's a welcome change that people are studying instead the future of intelligence.\"\nWhile the world-renowned physicist has often been cautious about AI, raising the risk that humanity could be the architect of its own destruction if it creates a superintelligence with a will of its own, he was also quick to highlight the positives that AI research can bring. \n Related:  The rise of robots: forget evil AI - the real risk is far more insidious\n\"The potential benefits of creating intelligence are huge,\" he said. \"We cannot predict what we might achieve when our own minds are amplified by AI. Perhaps with the tools of this new technological revolution, we will be able to undo some of the damage done to the natural world by the last one - industrialisation. And surely we will aim to finally eradicate disease and poverty.\n\"Every aspect of our lives will be transformed. In short, success in creating AI could be the biggest event in the history of our civilisation.\"\nHuw Price, the centre's academic director and the Bertrand Russell professor of philosophy at Cambridge University, where Hawking is also an academic, said that the centre came about partially as a result of the university's Centre for Existential Risk. That institute, mocked by the tabloid press as offering \"Terminator Studies\", examined a wider range of potential problems for humanity, while the LCFI has a narrow focus.\n\"We've been trying to slay the 'terminator' meme,\" Price said, \"but like its namesake, it keeps coming back for more.\"\nAI pioneer Margaret Boden, professor of cognitive science at the University of Sussex, praised the progress of such discussions. As recently as 2009, she said, the topic wasn't taken seriously, even among AI researchers. \"AI is hugely exciting,\" she said, \"but it has limitations, which present grave dangers given uncritical use.\"\nThe academic community is not alone in warning about the potential dangers of AI as well as the potential benefits. A number of pioneers from the technology industry, most famously the entrepreneur Elon Musk, have also expressed their concerns about the damage that a super-intelligent AI could wreak on humanity.\n"},
{"docid": "250 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "January 28, 2016", "title": "Google AI versus the Go grandmaster - who is the real winner?; The achievement has been hailed as a breakthrough in artificial intelligence, but computers are much less efficient than us\n", "content": "Today we were greeted by the front page of Nature hailing a breakthrough in artificial intelligence: computers are now outperforming even the best humans at the Chinese game of Go, long been seen as the last preserve of human game-playing mastery. The breakthrough, from a team based at Google's DeepMind group in London, has come much earlier than many experts expected.\u00a0\n Related:  Google AI in landmark victory over Go grandmaster\nThe achievement is also being hailed as a breakthrough in understanding human intelligence, and a large step towards emulating it. However, so was Deep Blue's achievement when it first beat chess world champion, Gary Kasparov, nearly 20 years ago. So where does this latest success really bring us?\nThe system that the DeepMind team developed is based on two main ideas: machine learning and random game-tree search. Searching a game tree is a way of exploring and evaluating possible future moves. A planning system for looking ahead in the game. Machine learning is a technique for training computers by showing them data: in this case board positions from the game. You train the computer to recognise good patterns on the board.\nThe computer is trained by making it play against itself, it can then learn from the games which board positions resulted in victory. To do this it had to play many millions of games. By the time it played against a human being it had played more games of Go than any human possibly could within their lifetime. This means the rate at which it learns to play is far slower than any human.\nIn the field of machine learning we refer to this as data efficiency. It refers to the amount of data that is required to solve a particular problem. Humans are incredibly data efficient, the recent breakthroughs in AI, are much less so.\nIn 1712, Thomas Newcomen developed a coal powered steam engine for pumping out mines. He was inspired by challenges in Cornish tin mining: deeper mines were susceptible to flooding and horse-driven pumps were only effective to a particular depth. In the end though Newcomen's engine found far more use in coal mines. The reason was that it was so inefficient that it was only practical where there was a readily available source of coal.\nIn our modern minds, the name of James Watt is much more associated with the steam engine than Newcomen. Why? Watt made the steam engine more practical by the introduction of a separate condenser, instantly doubling its efficiency, rendering redundant mines workable and forming the blueprint by which all modern steam engines are designed.\nSo far, machine learning is missing its separate condenser moment. So is AlphaGo a breakthrough on the path to emulating human intelligence? I think of it more as a trig point. It's certainly an important intermediate goal, a chance to map the landscape and take the odd photo, but it is just a stage on the journey and one that we already knew we would reach. We have however got there quicker than expected, and that is a natural cause for celebration.\n                       To get weekly news analysis, job alerts and event notifications direct to your inbox,                                                sign up free for Media & Tech Network membership                                              .                   \n                     All Guardian Media & Tech Network content is editorially independent except for pieces labelled \"Paid for by\" - find out more                                            here                     .                   \n"},
{"docid": "251 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "February 23, 2017", "title": "It's time for the luddites to relax: robots won't take over the world\n", "content": "Ever since the Industrial Revolution, the great fear has always been that automation would create mass, permanent unemployment. The most famous early scare came shortly after James Hargreaves, a brilliant innovator, came up with a multi-spindle spinning frame in 1764. Hargreaves, one of an army of free-thinkers who drove an explosion in economic growth, was born near Blackburn, a cotton producing part of Lancashire.\nThe local textiles industry couldn't cope with demand, and Hargreaves' innovation allowed a massive increase in productivity. But our inventor kept his device secret, using it only for his own production. He was right to be prudent: after his output helped depress prices - and hence deliver consumers a windfall - angry textile workers eventually broke into his property and vandalised his machines, forcing him to flee to Nottingham.\u00a0\nBut progress wasn't to be stopped, and automation has gone hand in hand over the past 250 years with an explosive increase in wages and employment. The reason? Machines increase output per person, and thus the demand for labour and wages. New jobs are created to replace old jobs, and then as these are automated even newer jobs emerge to replace the next lot of losses, and so on, ad infinitum. The main problem is one of mismatching skills : the process of creative destruction requires capital and labour to adapt constantly.\nYet there are many today who doubt that this overwhelmingly benign process will continue, especially with the advent of artificial intelligence, robotics, self-driving cars, drones and a new generation of learning machines . They are convinced that this is a new phase, and that millions of middle class jobs are about to be wiped out, with nothing to replace them.\nWill\u00a0the advent of artificial intelligence, robotics, self-driving cars, drones and a new generation of learning machines signal the end of the so far benign pattern?Credit:      JUSTIN TALLIS     \nSome are even advocating taxes on robots - the modern equivalent of smashing up the Spinning Jennies - and a minimum income, in effect giving up on the idea that full or even mass employment will ever be possible again. Others agree that new roles will be created, but believe that too many people will lose out, triggering a catastrophic populist backlash.\nThe good news is that the pro-capitalist optimists are once again being proved right. LEK, a leading London-based firm of management consultants, has conducted a detailed study of trends in the UK jobs market. Its paper - Jobs for the Bots? How the UK Jobs Market Is Responding to Automation - makes for fascinating reading, concluding that Britain's economy is responding remarkably well to automation by creating more, and higher quality, jobs.\nAndrew Allum, the study's author and one of the firm's star partners, started off by examining Office for National Statistics data. Looking at 369 categories of jobs, he found that 3.6m roles were created and 1.1m destroyed between 2011 and 2016. Crucially, the majority of the new jobs are in fact in categories that are resilient to future automation, while many of the (much smaller number) of roles lost were in easy to automate sectors.\nSome of the worst suffering categories will come as little surprise. Some 42,000 self-service checkouts have been fitted into shops; as a result, the number of cashier roles is down by 39,000 since 2011. For better or for worse, there are now 8,500 ANPR (automatic number plate recognition) cameras, processing 25m-35m records a day; as a result, 13,000 traffic warden jobs have been eliminated as a result. The number of cashiers is down by 39,000 (or 16pc), bank clerks have fallen by 25,000 (down 18pc), telesales people by 12,000 (or 24pc) and typists by 18,000 (or 34pc).\nIn The Future of Employment: How Susceptible are Jobs to Computerisation, a paper published in 2013, Carl Frey and Michael Osborne developed a framework to quantify what makes jobs easier or harder to automate based on the tasks contained within the job. Their thesis (backed up by much evidence) was that social, creative and complex jobs are harder to automate, and are therefore more sustainable; they assigned 20-year automation probabilities to job categories, with the likes of bank clerks and cashiers seen as facing a 97pc-99pc risk as a result of digital banking and e-money.\nAllum has applied Frey and Osborne's numbers to the UK market: his key finding is that of the jobs that have disappeared in Britain in the past six years, the probability of automation was 61pc. By comparison, the jobs created have an automation probability of only 38pc, making them much more secure.\nThere are jobs springing up as a result of increasing internet shopping, but they will probably be temporaryCredit:      Voisin/Phanie / Rex Features\u00a0     \nEven that number is inflated by what Allum dubs \"bubble jobs\", equivalent to 25pc of the extra 3.6m roles: jobs that are springing up thanks to the digital revolution and the surge in internet shopping, but which are a temporary phenomenon because they will be automated sooner rather than later. For example, road driving occupations are up by 110,000, but face an 89pc chance of automation thanks to driverless technologies. The automation probability for the remaining 75pc of post-2011 new roles falls to just 21pc. This is extremely encouraging, and suggests that the economy is shifting successfully.\nAutomation itself is creating lots of good jobs, 328,000 directly to be precise: programmers and software developers are up by 84,000 since 2011, IT directors by 41,000 and mechanical engineers by 34,000. Our more complex economy and society is also creating many more jobs - Allum estimates over 600,000 in five years, including in project management and consultancy, while sales and marketing roles are up 200,000, many also driven by new technologies. Change and technology are directly creating hard-to-automate jobs, and their influence is everywhere: other drivers include demographic change (creating over 600,000 new roles) for teachers, carers and medics; and lifestyle shifts with over 500,000 new roles. \u00a0\nAll of this is good news, with one big exception. Most of today's new jobs are complex, social and creative and so more sustainable with respect to automation; most of the roles being lost were not. The great challenge will be to upskill and train those losing their jobs, including many of the delivery drivers and others who are currently doing well from the internet. On balance, the economy will thrive thanks to technology, and most of us will do well - but we must make sure that a rising tide lifts all boats.\n"},
{"docid": "252 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "January 28, 2014", "title": "Demis Hassabis: the secretive computer boffin with the \u00a3400 million brain; What made Google splash out for DeepMind, the Artificial Intelligence company created by a former schoolboy chess champion from north London? Tom Rowley reports\n", "content": "Tony Corfe still remembers the time he first saw Demis Hassabis play chess. He was in charge of the primary schools team in Barnet, north London, and looking for new recruits when one week a slight six-year-old boy turned up.\n\"He was very small,\" recalls Corfe, \"so we had to sit him on a telephone book and a couple of chairs just to get his head up to table height so he could see the board.\"\nOnce Hassabis was settled at the table, however, he needed little else. \"He was sparkling,\" Corfe says. \"He was determined, and he definitely wanted to win. Of all the schools that I had contact with, he was the best player. He was top of the infants.\"\nThe boy quickly developed into a chess prodigy, winning dozens of tournaments before representing England in competitions. By the age of 13, he had reached the standard of chess master, and he went on to win the World Games Championship a record five times. \u00a0\nThese memories acquired new significance this week when Hassabis sold his company to Google. The firm, DeepMind, specialises in \"Artificial Intelligence\", and is apparently attempting to develop computers that can think spontaneously like humans, rather than having to be pre-programmed.\nMultinational firms are in a race to be first to produce this new era of sophisticated technology, explaining why Google - which has already established its own robotics division - reportedly paid \u00a3400 million. At a stroke, the deal made Hassabis one of Britain's most successful technology entrepreneurs.\nWhat is it, then, in this multi-million pound mind that Google values so highly? Friends describe Hassabis, now 37 and married with two children, as shy but determined. \"He is not a showman, and he keeps his head down,\" says Prof Geraint Rees, director of the Institute of Cognitive Neuroscience at University College London, where Hassabis studied for a PhD. \"Nerdy is the wrong word, but he is definitely of a technical bent. His determination and drive are quite striking.\"\nA glance at his CV will vouch for that. He left school at 16, having taken his A-levels. He spent his gap year gaining experience in computer games programming, which was to become his first career, by co-writing Theme Park, one of the most successful games of the Nineties.\nAfter graduating with a double first in computer science from Cambridge, he set up his own games business, Elixir Studios, which was responsible for such hits as Evil Genius and Republic, the latter being nominated for a Bafta award.\n\"He is extraordinary, a real one-off,\" says Joe McDonagh, who co-founded Elixir with Hassabis. \"He was only 21 when we set it up [McDonagh was 25], but he had an incredibly old head on such young shoulders. When I saw the news this week, I wasn't remotely surprised. I've always expected he would do something like this.\"\nAlthough he credits Hassabis's intelligence, McDonagh says his more important ability was to inspire a team. \"He truly believes the thing you are working on will change the world and will be remembered for ever. That is incredibly inspiring. Most of us are held back by fear, but Demis takes the attitude that everything is possible.\"\nHe was not reclusive at Elixir, and took an active role in organising social events. \"We'd be working on all this brainiac stuff during the day,\" says McDonagh. \"But at night, Demis would lead the five-a-side team in a league in Tottenham where we'd get kicked around the park. He'd be just as happy to argue with you about Liverpool versus Spurs as he was about Artificial Intelligence.\"\nBut he could also be competitive and would challenge colleagues to bout after bout of video game competitions. McDonagh recalls one occasion when Hassabis was transfixed by a colleague's ability to win repeatedly in a science fiction game, called Starcraft. \n\"Demis wanted to beat this guy,\" he explains. \"He would lock himself in a room with the guy night after night. He'd handicap him, by getting the guy to play without a mouse or one-handed so he could analyse exactly what he was doing to be brilliant. It was a bit like going into the boxing ring and getting beaten up, and then returning every night. It showed his incredible will to win.\"\nThis competitive edge also drove Hassabis to the Mind Sports Olympiad, to prove his worth alongside other \"mental athletes\". He spent a week at the competition in 1997, and has returned every year since. He was champion of the elite \"Pentamind\" contest - where competitors challenge each other in five different disciplines, including chess - in five of the first seven years.\nDespite his business interests, he still makes time for the Olympiad each August. \"It's for the competition,\" explains Corfe, who is one of the organisers. \"He has had his name on the trophy more times than anybody else.\"\nThese days, however, it is Hassabis's seven-year-old son, Alexander, who is touted as a prodigy. After he accompanied his father to last year's championships - and collected the junior gold prize - the competition's website speculated \"whether we might be seeing a dynasty in the making\".\nHassabis's path has not been completely smooth. According to friends, he grew frustrated with the more mundane aspects of managing Elixir. \"The direction of the business became too much dictated by accountants and people other than himself,\" says David Levy, who founded the Mind Sports Olympiad.\nInstead, Hassabis returned to academia, completing his PhD in cognitive neuroscience at UCL in 2009. In three years, he wrote a dozen research papers and succeeded in systematically linking memory with imagination for the first time. The journal Science trumpeted his achievement as one of the breakthroughs of the year. His former computer programming colleagues were more succinct, telling him he had \"a brain larger than a planet\".\nHe was soon awarded a prestigious Henry Wellcome postdoctoral fellowship. \"Those kind of fellowships are given to people not on the basis of their entrepreneurial ability or because they are chess prodigies, but because of their scientific achievement,\" says Prof Rees. Even so, he adds, \"Demis always had an eye on the bigger picture.\"\nFor the moment, however, that picture remains blurred. Despite the\u00a0glut of publicity surrounding the sale of DeepMind, nobody seems sure exactly what it does - and those who know won't tell. Hassabis politely declined to talk to The Daily Telegraph yesterday, saying that he has been \"instructed by Google not to respond to interview requests at this time\".\nFrank Meehan, who helped secure much of the initial investment, is equally circumspect. \"[DeepMind's function] is the one thing I can't tell you. I'm completely locked down,\" he says. He does, however, explain that computer scientists such as Hassabis are trying \"to get to the point where machines can learn rather than being taught\". \nHe adds: \"If they can learn from their surroundings and their actions, that's a massive step forward because you don't have to spend huge amounts of time programming everything.\"\nThis may seem a daunting mission, but it is unlikely to faze Hassabis. \"I'm actually more worried about not taking risks and playing safe [than taking chances],\" he once said. \"I've always been prepared to jump in at the deep end and see if I can swim or not.\"\n"},
{"docid": "253 of 297 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "October 8, 2014", "title": "IBM's new super-computer has been hailed as the future of healthcare... and it can devise a recipe for a mean stew; Watson is an artificial-intelligence system that uses natural language processing - you can ask it a question in everyday English - and machine learning, where the computer learns without having to be programmed with new knowledge\n", "content": "IBM's cognitive computer, Watson, has of late been helping chefs to \"think outside the box\" by generating recipes with surprising combinations of ingredients.\nThis is not the computational equivalent of choosing a bunch of ingredients at random from a hat; there is science behind the selection. Chef Watson - as this version of the system is known - has a deep knowledge of flavour pairing (flavour combinations that are known to be pleasing) and hedonic psychophysics (the psychology of what people like and don't like). \nHere are two dishes. Can you guess which one was created by Chef Watson and which one was created by a human: 1) Caramelised milk and monkfish liver and 2) Middle Eastern chickpea ragout? Drum roll. The first dish was created by humans at the Danish restaurant, Noma, and the latter is an invention of Chef Watson. I had the opportunity to try the ragout at IBM's research laboratory in Zurich two weeks ago. It was as appetising as it was surprising. I found a very similar recipe on the Eating Well website called Middle Eastern chickpea and rice stew. The other Chef Watson dishes on offer were broccoli soup, shrimp tacos and green-tea pudding. A quick internet search confirms that there is nothing surprising about any of these recipes. They have all been done before. \u00a0\nWhat makes a dish innovative is not just unusual flavour combinations, but novel ingredients (lichen, say), novel cooking methods (sous-vide) and novel presentation (served in frozen nitrogen). But Chef Watson can't help here. It can only suggest recipes from a list of known ingredients and known cooking methods. \nBut I'm being unfair. Chef Watson is meant to be a bit of fun. Steven Abrams, director of the Watson Group, speaking via telepresence at the Zurich event, said the purpose of Chef Watson is to demonstrate the power of cognitive systems in a more consumer-friendly way. \"A lot of the things we talk about are rather abstract,\" said Abrams. \"By coming up with this application, it is easier to show the power of computational creativity.\"\nNow that Watson has morphed from the supercomputer that beat two Jeopardy! champions to a cloud-based service that promises to be all things to all people, the task of explaining what Watson is, or what Watson does, has become a bit more tricky. \nWatson is an artificial-intelligence system that uses, among other things, natural language processing (you can ask it a question in everyday English) and machine learning (the computer learns without having to be programmed with new knowledge). Machine learning is the technology behind driverless cars, speech-recognition software, and spam filters. Natural language processing uses machine learning to get better at what it does.\nIn 2011, as a demonstration of how far artificial intelligence had come, Watson took part in the American game show, Jeopardy! Contestants are given general-knowledge clues in the form of answers and they must phrase their response as a question. For example, the contestant is told: Milorad Cavic almost upset this man's perfect 2008 Olympics, losing to him by 100th of a second. For the correct answer, the contestant should reply: \"Who is Michael Phelps?\"\nJeopardy! clues can contain puns, slang, double-entendres and other nuances of language that conventional computers struggle to deal with. After losing to Watson, one of\u00a0 the contestants, Ken Jennings, wrote on his video screen: \"I for one welcome our new computer overlords.\" \nBut not everyone was as impressed as Jennings. In an interview published in Popular Mechanics, Douglas Hofstadter, a cognitive scientist and author of G\u00f6del, Escher, Bach: An Eternal Golden Braid, described Watson as \"vacuous\". \"Watson is basically a text search algorithm connected to a database just like Google search,\" said Hofstadter. Needless to say, Hofstadter doesn't think that Watson possesses intelligence.\nThe philosopher John Searle also waded in, saying that Watson can't think. But these sorts of philosophical arguments about whether a computer possesses intelligence or whether it can think are probably not causing IBM executives to lose much sleep. What might cause them to lose sleep is the conundrum of how you turn a very powerful, general-purpose tool into something that is commercially viable. \nAlthough IBM has been selling Watson to healthcare organisations and financial services companies since 2012, it was only in January 2014 that IBM officially set up the Watson Group, a division whose raison d'\u00eatre is to commercialise Watson. Watson Group is primarily aiming its products at the healthcare, financial services, retail and government sectors; in other words, sectors that are being crushed under the weight of big data. And with an estimated 80 per cent of data being unstructured, Watson, with its natural language prowess, is the perfect tool to ingest this data and \"find hidden patterns and correlations\".\nFinding hidden patterns and correlations sounds great, but it's also a bit vague; perhaps deliberately so, because Watson is not one technology but many technologies. If you ask an IBMer what Watson is or does, you are likely to be met with hand-waving and slogans. \"It's about scaling expertise.\" \"It's about turning insight into inspiration.\" \"It's a natural extension of what humans do at their best.\" \nIn the heady days after the Jeopardy! victory, healthcare seemed to be the most obvious place to employ a machine of Watson's prodigious talents. There was talk of Watson helping oncologists choose the most effective treatment regimen for their patients. Watson could help researchers discover promising drug compounds, or new uses for existing drugs. Hell, it might even take the US Medical Licensing Exam, the professional exam that doctors need to pass before they can practice medicine, and become Watson MD.\nNowadays, the talk is more sober. Watson can help call centre workers answer customers' questions more effectively. It can be used by businesses to answer questions such as: which company benefits do employees value the most? Or which deal is likely to close? As we've seen, it can suggest flavour combinations to chefs. It can also help healthcare companies match patients to clinical trials. \nI'm sure that Watson will eventually deliver on its early promises, but that day is probably still a way off. \n"},
{"docid": "254 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "September 24, 2017", "title": "Microsoft launches new healthcare division based on artificial intelligence software\n", "content": "Microsoft is setting up a new healthcare department at its \u00adCambridge research facility, as part of plans to use its artificial intelligence software to \u00adenter the health market.\u00a0\nThe computer giant has created the division as part of its commitment to \"transform healthcare\" using technologies such as machine learning and cloud computing.\nIts research plans \u00adinclude monitoring systems that can help keep patients out of hospitals and alert them in a timely manner about problems, and large studies into \u00addiseases such as diabetes.\nIan Buchan will head up the healthcare division at Microsoft ResearchCredit:      Microsoft     \nMicrosoft has hired researcher Iain Buchan, formerly clinical professor in public health informatics at the \u00adUniversity of Manchester, to lead the healthcare research division. A trained doctor and data scientist, he has \u00adresearched how data can improve healthcare for the past 25 years in \u00adclinical and academic settings. \u00a0\u00a0\nMr Buchan said the team's \u00adresearch could include developing predictive analytic tools, and personal health information systems, as well as using AI to \u00adtarget interventions.\n"},
{"docid": "255 of 297 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "October 28, 2013", "title": "US startup claims to have 'solved' CAPTCHAs in a breakthrough for AI; The ability to decipher the distorted words of CAPTCHAs shows an advanced ability to 'imagine' what the broken letters might be\n", "content": "Vicarious, a San Francisco startup specialising in artificial\u00a0intelligence, claims to have created a machine capable of cracking CAPTCHAs - the blocks of distorted text that are used online to \"prove that you're human\".\nAlthough CAPTCHA tests might not appear to be the most sophisticated test of machine intelligence they are notoriously difficult for algorithms to decipher, with the most efficient way of bypassing them being to hire cheap manual labour and solve them by hand.\nIt's been said that Google's reCAPTCHA system (the most widely used on the internet) would be considered beaten if a computer could answer it correctly it just one per cent of the time. Vicarious say that their software solves reCAPTCHAs with a 90 per cent accuracy, and have uploaded a video showing the code in action (see below).\u00a0\n\"We wanted to show we could take the first step toward a machine that works like a human brain, and that we are the best place in the world to do artificial\u00a0intelligence research,\" co-founder D. Scott Phoenix told Reuters, noting that the company does not intend to use its breakthrough for any nefarious means but that it represents a new approach to AI.\nVicarious claims that its methods are even more impressive than the cutting-edge \"deep learning\" displayed by current AI titans such as IBM's Watson.\nIn 2011 Watson showed its capacity to understand natural\u00a0 language questions by competing on a special edition of US quiz show Jeopardy with past champions, but Vicarious claims that this sort of AI relies more on computational power and catalogued examples than actual 'intelligence'.\nSpeaking to Forbes, Vicarious co-founder Dileep George claims that his company is working on \"the math behind the processes of the brain\", and that they are working on systems that can \"imagine\" how to fill in blanks in vision just like humans can.\nHowever, Viacrious are refusing to reveal any further technical details of their breakthrough and some experts are sceptical. \n\"CAPTCHAs have been around since 2000, and since 2003 there have been stories every six months claiming that computers can break them,\" Luis von Ahn of Carnegie Mellon University, a co-inventor of CAPTCHAs and founder of reCAPTCHA, a tech start-up which sold to Google in 2009, told Reuters.\n\"Even if it happens with letters, CAPTCHAs will use something else, like pictures that only humans can identify against a distorting background,\" said von Ahn.\nCoincidentally, Google also announced an update to their reCAPTCHA system before the weekend, with the new changes designed \"to learn how to better protect users from attackers\".\nThe updated CAPTCHAs uses numbers instead of text (to make things easier on the human eye) and \"actively considers the user's entire engagement with the CAPTCHA-before, during and after they interact with it\" to better distinguish the bot from the human.\nWhether Google's announcement has anything to do with the news from Vicarious is completely unknown, but the search giant are promising they have \"even more to report on in the next few months\" with regards to the technology.\nVicarious attracted more than $15 million in funding last year from investors including Facebook co-founder Dustin Moskovitz and ex-PayPal CEO Peter Thiel's Founders Fund.\nAlthough the company does not plan to release any products for at least several years Moskovitz (who also sits on the Vicarious board of directors) released a statement that \"we should be careful not to underestimate the significance of Vicarious crossing this milestone,\" describing the company as \"at the forefront of building the first truly intelligent machines.\"\nCAPTCHA or reCAPTCHA: what's the difference?\nCAPTCHA stands for \"Completely Automated Public Turing test to tell Computers and Humans Apart\" and is a trademark owned by Carnegie Mellon University. \nThe identity of the original inventors is disputed, but it's certain that CAPTCHAs were developed in the late 90s to differentiate bots from genuine human users on websites. Bots might sign up for free email addresses and use them to distribute spam but CAPTCHAs stopped them.\nreCAPTCHA is an evolution of the original system that was developed by the same team from Carnegie Mellon and acquired by Google in 2009. \nThe most notable advantage of the reCAPTCHA system is its help in digitizing books. reCAPTCHA asks users to identify two strings of numbers or letters - one of which is taken from scanned newsprint or book that OCR (optical character recognition) technology has failed to interpret; the other word or sequence of letters is already known to the software. \nIf the user correctly deciphers the known word, then the software assumes that they have succeeded with the unknown string and sends back the data to the project that supplied the image. \nOne scheme that reCAPTCHA is currently working on is the digitization of the archives of\u00a0The New York Times. As of 2012, thirty years of the Times had been digitized with the project expected to be completed by the end of the year. \n"},
{"docid": "256 of 297 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "February 2, 2018", "title": "Will a robot recruiter be hiring you for your next job?; Finding the right candidate for a job is labour intensive and rarely easy, which is why an increasing number of companies are turning to artificial intelligences to streamline the process.\n", "content": "Artificial intelligence (AI) is creeping into every aspect of daily life. Computer algorithms keep our inboxes free of email spam, suggest which TV programmes we should watch and even drive some of our cars. Now, smart machines may play a role in deciding whether or not you get your next job. An increasing number of employers are using robot recruiters that can assess CVs, screen candidates and pair them with the right roles.\n Related:  Your happiness is our business: HR leaders reveal how they keep staff content\u00a0\nThe search for efficiency in the recruitment process has fuelled interest in AI. Finding employees with the correct mixture of skills, personality and motivation is difficult - even when the pool of candidates is large.\n\"The benefits are huge,\" says Eyal Grayevsky, CEO of Mya Systems, which has created an AI recruiter called Mya. \"Companies have large databases of candidates they have acquired over the years, and they are receiving more CVs than ever before, now that the internet has made it easier to apply for jobs. Previously, recruiters were drowning in manual work, assessing applications. With AI, they can automate the repetitive tasks that slow them down.\"\nOne large retailer that used Mya to hire warehouse staff reported a 79% reduction in the time it took to fill each position, and a 144% increase in productivity per recruiter who used the technology. Job candidates, meanwhile, benefit by receiving a guaranteed response from Mya. \"It's a very human-like interaction,\" Grayevsky says.\nFrida Polli, CEO of Pymetrics, which uses AI to pair people with suitable jobs, says robo-recruiters can also help employers become more diverse by removing some of the unconscious bias in the hiring process. \"It can be more objective than a human - but if untested, AI will amplify whatever bias already exists because it is trained to find patterns and replicate them.\"\nSome worry that the rise of the robots will displace the human recruiter, but Anna Seely, principal of talent strategy at Mercer, says: \"The role of HR is evolving as a result of digital disruption. Rather than replacing humans, AI gives us access to much richer data to drive better decision making.\"\nWith fears growing that automation could eliminate some low-skilled jobs, hiring managers need to think about how to prepare employees to work alongside machines in the near future. \"Skills such as purchasing and managing technology, analysing data and designing new products and services will be essential. HR will be a more powerful function going forward,\" Seely says.\n                                        How Mya works                                      \n                     \u00b7                     The AI interviewer  When a candidate applies for a job online, Mya introduces herself and initiates a dynamic, written conversation - similar to a text message format. \n                     \u00b7                     Real-time answers  The bot asks the candidate a series of interview questions, such as: \"What's your pay range?\", \"Can you handle the physical requirements of the job?\", \"What is your shift availability?\". Mya can also answer questions about the job in real time. \n                     \u00b7                     Language assessment  The AI uses natural language processing to pick up on conversational details. Based on the candidate's answers, Mya assesses whether they are a good fit. The bot sends a scorecard and transcript to the employer. Cloud-based, Mya is designed to integrate into existing HR software. \n                     \u00b7                     The next stage  If the candidate is a match, Mya will schedule an interview with a human hiring manager. If they are not, she will suggest other jobs that may be relevant to them.\n"},
{"docid": "257 of 297 DOCUMENTS\n", "source": "Guardian.com\n", "date": "July 1, 2012", "title": "Iamus, classical music's computer composer, live from Malaga\n", "content": "ABSTRACT\nThe first music composed by computer considered good enough for top-class musicians to play is to be performed to mark the 100th anniversary of Alan Turing's birthTake our own musical Turing test here\u00a0FULL TEXT\nAs soon as you see the title of Iamus's composition Transits - Into an Abyss, you know it's going to be challenging, modernist stuff. The strings pile up discords, first spooky, now ominous. But if your tastes run to Bart\u00f3k, Ligeti and Penderecki, you may like it. At least you have to admit this bloke knows what he's doing.\nBut this bloke doesn't know anything at all. Iamus is a computer program. Until the London Symphony Orchestra was handed the score, no human had intervened in preparing the music.\n\"When we tell people that, they think it's a trick,\" says Francisco Vico, leader of the team at the University of Malaga who devised Iamus. \"Some say they simply don't believe us. Others say it's just creepy.\" He expects that when Iamus's debut CD is released in September, performed by top-shelf musicians including the LSO, it is going to disturb a lot of folk.\u00a0\nYou can get a taste of Iamus's oeuvre before then, because on 2 July some of Iamus's compositions will be performed and streamed live from Malaga. The event is being staged to mark the 100th anniversary of the birth of Alan Turing, the man credited with more or less inventing the concept of the computer. It was Turing who devised the test to distinguish human from artificial intelligence made famous by the opening sequence of Blade Runner. The performance will itself be a kind of Turing test: you can judge for yourself by taking our own musical Turing test here.\nIamus - named after the son of Apollo who could understand the language of birds - composes by mutating simple starting material in a manner analogous to biological evolution. The compositions each have a musical core, a \"genome\", that gradually becomes more complex.\n\"Iamus generates an initial population of compositions automatically,\" Vico says, \"but their genomes are so simple that they barely develop into a handful of notes, lasting just a few seconds. As evolution proceeds, mutations alter the content and size of this primordial genetic material, and we get longer and more elaborated pieces.\" All the researchers specify at the outset is the rough length of the piece and the instruments it will use.\n\"A single genome can encode many melodies,\" explains composer Gustavo D\u00edaz-Jerez of Musikene, the Higher School of Music of the Basque Country in San Sebastian, who has collaborated with the Malaga team since the outset and is the pianist on the new recordings. \"You find this same idea of a genome in the western musical canon - that's why the music makes sense.\"\nThe computer doesn't impose any particular aesthetic. Although most of its serious pieces are in a modern classical style, it can compose in other genres too, and for any set of instruments. The Darwinian composition process also lends itself to producing variations of well-known pieces or merging two or more existing compositions to produce offspring - musical sex, you might say.\nUsing computers and algorithms - automated systems of rules - to make music has a long history. The Greek composer Iannis Xenakis did it in the 1960s, and in the following decade two Swedish researchers devised an algorithm for creating nursery-rhyme melodies in the style of the Swedish composer Alice Tegn\u00e9r. In the 1980s, the computer scientist Kemal Ebcioglu created a program that harmonised chorales in the style of Bach.\nAs artificial intelligence and machine learning became more sophisticated, so did the possibilities for machine music: now computers could infer rules and guidelines from real musical examples, rather than being fed them to begin with. The computer scientist John \"Al\" Biles devised an algorithm called GenJam that learns to improvise jazz. A trumpeter , Biles performs alongside GenJam under the name the Al Biles Virtual Quintet, but admits the algorithm is a rather indifferent player. The same is true of GenBebop, devised by the cognitive scientists Lee Spector and Adam Alpern, which improvises solos in the style of Charlie Parker by \"listening\" to him and iterating its own efforts under the ultimately less-than-discerning ear of an automated internal critic.\nOne of the most persuasive systems was the Continuator, devised by Fran\u00e7ois Pachet at Sony's Computer Science Laboratory in Paris. In a Turing test where the Continuator traded licks with an improvising human pianist, expert listeners were mostly unable to guess which was playing.\nBut these efforts still haven't shown that a computer can make tolerable music from scratch. One of the best known attempts is Emily Howell, a program created by the music professor David Cope. Yet Howell's bland, arpeggiated compositions sound like a technically skilled child trying to ape Beethoven or Bach, or like Michael Nyman on a bad day: fine for elevators but not for the concert hall.\nIamus is different. This seems to be the first time music composed by computer has been deemed good enough for top-class performers to play. D\u00edaz-Jerez says the LSO were \"a little bit sceptical at the beginning, but were very surprised\" by the quality of what they were being asked to play. The soprano Celia Alcedo, he says, \"couldn't believe the expressiveness of some of the lines\" she was given to sing.\n\"I felt it was like a wall of sound,\" says Lennox Mackenzie, the LSO's chairman. \"If you put a colour to it, this music was grey. It went nowhere. It was too dense and massive, no instrument stuck out at any point. But at the end of it, I thought it was quite epic.\"\n\"The other thing that struck me,\" Mackenzie adds, \"was that it was festooned with expression marks, which just seemed arbitrary and meaningless. My normal inclination is to delve into music and find out what it's all about. But here I don't think I'd find anything.\" But he's far from discouraging. \"I didn't feel antipathy towards it. It does have something. They should keep trying, I'd say.\"\nWhat is disconcerting is that Iamus can produce this stuff endlessly: thousands of pieces, fully notated and ready to play, and \"many of them great\", according to D\u00edaz-Jerez. Such profligacy feels improper: if it's that easy, can the music really be any good? D\u00edaz-Jerez thinks the pieces are often better than those produced by some avant-garde composers, which revel in their own internal logic but are virtually impossible to play. Crucially, people have different favourites - it's not as if the program occasionally gets lucky and turns out something good.\nHow does a performer interpret these pieces, given that there's no \"intention\" of the composer to look for? \"Suppose I found a score in a library without knowing who wrote it,\" says D\u00edaz-Jerez. \"I approach these pieces as I would that one - by analysing the score to see how it works.\" In that respect, he sees no difference from deducing the structure of a Bach fugue.\nYou can compare it with computer chess, says the philosopher of music Stephen Davies, of the University of Auckland in New Zealand. \"People said computers wouldn't be able to show the same original thinking, as opposed to crunching random calculations. But now it's hard to see the difference between people and computers with respect to creativity in chess. Music, too, is rule-governed in a way that should make it easily simulated.\"\n"},
{"docid": "258 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "October 28, 2014", "title": "Tesla's Elon Musk: we're 'summoning the demon' with A.I; Betty Liu reports on Elon Musk's warning about artificial intelligence\n", "content": "Elon Musk, CEO of Tesla Motors gave a warning about the development of Artificial Intelligence (AI). \nHe said the technology was more dangerous than nuclear weapons at a symposium at MIT. \nMusk likened AI to the horror film narrative of someone summoning a demon armed with holy water. \u00a0\n"},
{"docid": "259 of 297 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "June 17, 1996", "title": "A-Z of the digital world\n", "content": " T is for \"Turing test\". Alan Turing was a British mathematician who devised some important theoretical models for digital computers and their capabilities. In 1950 he proposed the litmus test for artificial intelligence: a machine could be called \"intelligent\", he suggested, if it could fool a human into believing that it too was human. To get over the problem of appearance, the conversation could be carried out via computer terminals.\u00a0\n\u00a0Artificial intelligence (AI) gurus found the Turing test intriguing, and in 1964 Joseph Weizenbaum, at the Massachusetts Institute of Technology, wrote Eliza - a program that behaved like a psychotherapist (one using non-directive therapy, mostly echoing what people say and picking up on mentions of parents).\n People who didn't know Eliza was a program believed it was a person - a fact that Weizenbaum found worrying, though possibly it tells us more about psychotherapy than AI. Eliza was a milestone. But the question of whether a machine could persuade a sceptical observer it was human remained open.\n In 1991 Hugh Loebner, a maker of disco-dancing floors, began sponsoring an annual contest with a $ 10,000 prize for anyone whose machine passed a limited Turing test: it would have to be proficient in only one subject (such as Star Trek, or cave-diving). A panel of judges talks with a series of pairs of terminals - one connected to a machine, the other to a person - and rates each on their level of \"human-ness.\" Usually, the machines could be spotted easily - they didn't make spelling mistakes.\n This year, the contest (held in April) was won by a program written by Jason Hutchens, of the Centre for Intelligent Information Processing Systems at the University of Western Australia. His HeX program \"pretended\" to be Australian. (Please, no snide comments about that making it easier.) Hutchens's Web page about it all can be found at : I'm 21.\n PROGRAM: If you are 21, it's your business, mate! Would you like to hear a joke? Knock, knock . . .\n JUDGE: I don't much care for knock-knock jokes, but go on . . .\n PROGRAM: No, let me tell you one first. Knock, knock.\n JUDGE: who's there?\n PROGRAM: Cindy.\n JUDGE: Cindy who?\n PROGRAM: Cindy next judge in, please!\n CHARLES ARTHUR\n\n"},
{"docid": "260 of 297 DOCUMENTS\n", "source": "DAILY MAIL (London)\n", "date": "December 28, 2017", "title": "HALF OF JOBS IN BRITAIN UNDER THREAT FROM ROBOTS\n", "content": "NEARLY half of British jobs are at risk of being taken over by robots, a think-tank has warned.\u00a0\nTechnological advances mean 44 per cent of current roles could be automated, with those in catering, retail and agriculture under the greatest threat.\nThe Institute for Public Policy Research (IPPR) rejected the idea of a post human' economy, saying most people will find work in newly-created jobs where humans still outperform robots. But it warned in a report that those on lower incomes could see their wages fall.\nThe Daily Mail reported last Friday on developments in artificial intelligence that will reshape our lives, revealing how a robot taught itself to play chess better than any human has ever done.\nThe IPPR research estimated that jobs generating wages of \u00a3290billion a year - representing a third of all wages and earnings from labour in the UK economy - have the potential to be automated.\nRather than creating mass unemployment, the report predicted that people would slowly be shifted into new fields of work over the course of decades. It said: Work will be transformed by automation, not eliminated. Automation could increase the demand for work in creative, cognitive, planning, decision-making, managerial and caring roles, where humans still outperform machines.'\nThe researchers said increasing automation could boost productivity and bring a future of economic plenty'.\nBut if badly managed by government, there was a danger the benefits would be concentrated in the hands of investors and small numbers of highly-skilled workers while the rest lost out.\nThe report called for a new regulator to monitor the ethical use of robotics and artificial intelligence.\n\u00a9 Daily Mail\n"},
{"docid": "261 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "April 14, 2015", "title": "Fancy a tasty byte? Cookbook written by artificial intelligence; A new cookbook has been compiled by Chef Watson, the cognitive computer from IBM that famously won Jeopardy\n", "content": "The newest cookbook on the market was compiled by a chef who \"has never tasted a single morsel of food\", the book's introduction points out. \"This culinary prodigy, in fact, has no taste buds, no nose, not any sensual experience of food or drink.\"\u00a0\nThis could be the world's first collection of recipes created by artificial intelligence . \nWatson, IBM's cognitive system that famously defeated two human grand champions to win the US quiz show Jeopardy, has turned its attention to the kitchen. \n                     \u00b7 Alimentary, my dear Watson: can a supercomputer rival human chefs?                   \nFor several years, the virtual chef has been poring over troves of recipes and food-related data, from classic meal combinations to research on flavour preferences and the chemical composition of foods. \nThe computer was programmed to produce ideas for food combinations that would taste pleasant at a molecular level and that, crucially, had not yet been tried. \nThe surprising results include the Spanish Almond Crescent, a butterless and sugar-free pastry flavoured with pepper, saffron and coconut milk; asparagus grilled with pig's feet croquettes and mustard foam; an apple and pork kebab cooked with mushrooms, strawberries and curry powder; ale brewed with veal stock; plum pancetta cider; and a bacon dessert made from porcini mushrooms, walnut meal and dried figs. \nIBM said it wanted to apply its innovation to \"a field that every human being appreciates: food\". \nSteve Abrams, the head of IBM's Watson research centre in New York, said in September that the cookbook could help humans who not in the scientific community understand the \"rather abstract\" concept of the cognitive machine, making it \"easier to explain to people the power of computational creativity\". \nThe book's introduction spells out how similar systems could help people tailor foods to their medical and financial needs, allow schools and hospitals to create tastier and more nutritious meals, and revolutionise industries from pharmaceuticals and chemicals to media and the arts. \n\"This cookbook shows not only how far Watson has come, but also the incredible, untapped potential of further collaborations between man and machine.\"\n                     \u00b7 Recipe invented by supercomputer: Middle Eastern Chickpea Ragout                   \n                     Cognitive Cooking with Chef Watson: Recipes for Innovation from IBM & the Institute of Culinary Education contains 65 recipes and is available in hardcover from April 14. \n"},
{"docid": "262 of 297 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "October 18, 1999", "title": "THEATRE: ARTIFICIAL INTELLIGENCE;\u00a0COMIC POTENTIAL LYRIC SHAFTESBURY LONDON\n", "content": "\u00a0\n THE PYGMALION myth is given a weirdly futuristic twist in Alan Ayckbourn's new - and 53rd - play, Comic Potential. Though you may come out fretting over the flaws in its logic, you know that it will haunt you for a long time afterwards.\n Set \"in the foreseeable future where everything has changed except human nature\", the piece begins as a so-so satire on the television industry of our own time. In the depths of a regional TV station, the round-the- clock soaps don't bother with living actors; the performers are programmable \"actoids\" directed by Chandler Tate (David Soul), an ageing rebel filled with bitter nostalgia for the distant days when he made comic feature films.\u00a0\n Comic Potential jolts into more intriguing life when one of the actoids - Janie Dee's robotically smiling JC 333 (or Jacie Triple Three) - develops an unprogrammed sense of humour. Beguiled by the play of her artificial intelligence, the TV mogul's young nephew Adam (Matthew Cottle) falls in love with her, and they abscond to a luxury hotel.\n Ayckbourn engineers some hilarious farce from Jacie's stiff-limbed inexperience of the outer world. Her conversation is largely restricted to the scripts of the soaps she has been in, with the result that startled boutique assistants find themselves treated to speech-length confidences about her heroin- trafficking terrorist sister. And there's a nice variant of the \"apparent oral sex under the restaurant table\" gag when Adam has to burrow there to empty Jacie's stomach bag.\n But there is a lot of pain there too as Janie Dee (actoid of the year, beyond doubt) brilliantly shows you a confused and frightened consciousness emerging in this cyber doll. And, in Jacie's learned behaviour from the soaps and her sad desire to be right for Adam, Ayckbourn lets you see that \"femininity\" is a set of conditioned responses rather than a biological imperative.\n It's the problem of biology that makes the upbeat ending a cop-out; it's hard to see how Jacie, an AI consciousness in an unchanging doll that looks 19, can possibly find lasting happiness with a man who is part of a life-cycle from which she is excluded.\n Comic Potential would be a better play if its conclusion left the title reverberating ironically. Sequences in this work are as good as Ackybourn's best play, Woman in Mind - but the ending of that, remember, kept faith with its bleakness.\n Paul Taylor\n For information: 0171-494 5045\n"},
{"docid": "263 of 297 DOCUMENTS\n", "source": "The Independent\n", "date": "October 17 1989", "title": "BR uses 'computer vision' to monitor level crossings\n", "content": "\u00a0\n BRITISH RAIL will use computers to monitor level crossings to see if cars should be allowed to cross them, in an attempt to assess how artificial intelligence and 'computer vision' can be used more widely on the rail network.\n As part of a major experiment to be announced today, computers emulating the human brain will monitor the level crossings, deciding when it is safe to lower and raise gates, and when cars and pedestrians should be allowed to pass through.\n\n Dr Alan Cribbens, head of safety systems at BR, said such systems would be used only to help and augment human control.\u00a0\n But he hopes computer vision and artificial intelligence may also be used for examining the condition of rail tracks and tunnels, and for inspecting the conditions of the brakes on rolling stock. 'Computers would never be allowed to takes decisions alone in the primary safety loop, at least not in the short term.'\n Level crossings are currently monitored by closed circuit television and controlled by an operator. There is a limit as to how many crossings one person can cope with, and the computer monitoring could dramatically increase the efficiency.\n The experiment also acts as a tough test for computer vision, because it has to cope with variable lighting and weather, and to decide whether a scrap of paper or rubbish on the track constititutes a serious obstruction.\n The computer is a 'neural network' - a machine which attempts to emulate the way the brain works. The network is made up of layers of transputers, each of which is a computer in its own right, and which represent a computer neuron or brain cell.\n According to Colin Hebden of SD, the company supplying the system, the neural network can be trained to recognise patterns and interpret images - things which traditional number-crunching machines are not good at. The transputer is also ideal because it communicates well with other transputers in the network.\n The BR experiment is said to be pushing forward the frontiers of neural network computers. 'If it has potential we will have it in use as soon as possible,' Dr Cribbens said.\n Home News Page 8\n"},
{"docid": "264 of 297 DOCUMENTS\n", "source": "\u00a0The Mirror\n", "date": "July 12, 2003", "title": "AMY'S I: GAME ZONE: VIRTUA FIGHTER 4 EVOLUTION PLAYSTATION 2 OUT NOW POUNDS 39.99\n", "content": "\u00a0\n IF you hang out in the arcades, you will probably have played Virtua Fighter, the original 3D beat-em-up.\u00a0The latest version, just out for the PlayStation 2, is mighty impressive. VF4 Evolution has two new characters and a \"Quest\" mode, which features artificial intelligence gleaned from watching some of the top Japanese VF players. This magnificent game is wonderfully responsive and adds up to one of the finest beat-em-ups ever. SB\n"},
{"docid": "265 of 297 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "June 5, 2017", "title": "As AI moves on, Apple's Siri needs to grow up; Still leading in the smartphone market, the technology giant has fallen behind rivals Amazon and Google in new hi-tech products\n", "content": "My first encounter with Siri was back in 2011, when Apple's voice-activated artificial intelligence was first released. I was completing university; the BlackBerry was still popular and I was one of a handful in my class with the new iPhone that had the robot assistant built in.\nThe technology was pretty basic at the time: it struggled with some accents and the commands it could respond to were fairly limited. So early on Siri was something of a novelty, rather than genuinely useful.\u00a0\nSix years later, BlackBerry is all but gone and the iPhone reigns, but what hasn't changed is Siri's novelty feel. Its voice recognition has improved dramatically (I suspect even the thickest regional accent wouldn't trip it up), and Apple has added lots of new features, but I doubt most iPhone users take advantage of it regularly. Some processes, such as setting an alarm, are quicker to ask Siri to do than rifling through the settings to find, but I still use it rarely.\nThis hasn't been much of a problem for Apple. Its smartphone is still the world's most popular and it is selling them in near-record quantities. The voice assistant on Android, the rival operating system, is hardly a smash hit either.\nBut there's a nagging feeling that Apple is falling a little behind the curve. Smartphones have proved to be perfectly capable without voice assistants, but the next wave of technology might not be. In 2014 Amazon launched its Echo speaker, a voice-controlled hi-fi powered by a Siri-style artificial intelligence called Alexa. Google followed it last year with a rival device, the Google Home.\nAI assistants are an afterthought on mobile phones, but are central to \"smart speakers\", which are static, typically sitting on a kitchen table or bookshelf, and do not include a touchscreen. Analysts see them as an intriguing new category. While they may not sell in iPhone-sized numbers they have become a fixture in many people's lives, and have generated enough of a buzz to rattle the established smartphone giants.\nTonight, at its annual Worldwide Developers Conference in San Jose, Apple is rumoured to follow with a rival \"Siri speaker\".\nIt's a case of catch-up for Apple, almost three years after Amazon's Echo debuted. That's hardly unusual - Apple's smartwatch, followed efforts from Samsung and others, and outdid them - but it is also a rare defensive move. As iPhone growth has stalled, Apple has emphasised its services business, made up of divisions such as the Apple Music streaming service. Apple Music's main competitor, Spotify, is a fixture on both the Google Home and Amazon Echo; Apple Music is absent.\nWithout its own speaker product, Apple is not just missing out on a potentially lucrative new category, it is weakening its own ecosystem. Famously reluctant about allowing its services on other hardware, it is obliged to create its own.\nHow successful it will be is another matter. Siri is seen by critics as a clear third place against Amazon and Google's artificial intelligence systems. Apple's commitment to privacy means it has to work harder to keep up with rivals that are a little more blas\u00e9 about crunching personal data when developing AI systems.\nThis may not matter at present. In truth, the \"intelligence\" of existing smart speakers is limited - they are mainly used for simple tasks like setting alarms, playing internet radio stations and turning on smart home gadgets. Apple has unmatched consumer cachet, as well as the considerable pull of its \"ecosystem\" of gadgets working together, to its advantage.\nBut they are expected to become more central to our lives as their power grows. Amazon is working to put its Alexa assistant in dozens of other gadgets, from smart fridges to televisions. Google is putting them in every Android phone.\nTonight, when Apple makes its own AI the star of the show, it will have to show that Siri has grown up.\n'There's a nagging feeling that Apple is falling a little behind the curve'\n"},
{"docid": "266 of 297 DOCUMENTS\n", "source": "The Independent (United Kingdom)\n", "date": "August 28, 2017", "title": "Artificial intelligence can secretly be trained to behave 'maliciously' and cause accidents; 'BadNets are stealthy, i.e., they escape standard validation testing'\n", "content": "Neural networks can be secretly trained to misbehave, according to a new research paper.\nA team of New York University scientists has found that people can corrupt artificial\u00a0intelligence systems by tampering with their training data, and such malicious amendments can be difficult to detect.\u00a0\nThis method of attack could even be used to cause real-world accidents.\nNeural networks require large amounts of data for training, which is computationally intensive, time-consuming and expensive.\nBecause of these barriers, companies are outsourcing the task to other firms, such as Google, Microsoft and Amazon.\nHowever, the researchers say this solution comes with potential security risks.\n\"In particular, we explore the concept of a backdoored neural network, or BadNet,\" the paper reads. \"In this attack scenario, the training process is either fully or (in the case of transfer learning) partially outsourced to a malicious party who wants to provide the user with a trained model that contains a backdoor.\n\"The backdoored model should perform well on most inputs (including inputs that the end user may hold out as a validation set) but cause targeted misclassifications or degrade the accuracy of the model for inputs that satisfy some secret, attacker-chosen property, which we will refer to as the backdoor trigger.\"\nIn one instance, the researchers managed to train a system to misidentify a stop sign with a post-it stuck to it as a speed limit sign, which could potentially [cause] an autonomous vehicle to continue through an intersection without stopping.\"\nWhat's more, so-called 'BadNets' can be hard to detect.\n\"BadNets are stealthy, i.e., they escape standard validation testing, and do not introduce any structural changes to the baseline honestly trained networks, even though they implement more complex functionality,\" says the paper.\nRead more\nHow artificial\u00a0intelligence conquered democracy\nIt's a worrying thought, and the researchers hope their findings lead to the improvement of security practices.\n\"We believe that our work motivates the need to investigate techniques for detecting backdoors in deep neural networks,\" they added.\n\"Although we expect this to be a difficult challenge because of the inherent difficulty of explaining the behavior of a trained network, it may be possible to identify sections of the network that are never activated during validation and inspect their behavior.\"\n"},
{"docid": "267 of 297 DOCUMENTS\n", "source": "The Daily Telegraph (London)\n", "date": "October 31, 2016", "title": "For a show about robots, Humans has a lot of heart; Television &radio\n", "content": "Last year's launch of Humans (Channel 4, Sunday) - a stylish series about the rise of Artificial Intelligence as demonstrated by eerily anthropomorphic robots called \"synths\" - was a big hit for the broadcaster, netting its highest ratings for a drama since The Camomile Lawn way back in 1992. Now, for its second series, Humans has widened its scope with an admirably ambitious opening episode that hopped between the UK, the US, Germany and Bolivia, telling a panoramic story of man versus machine.\nOne of the rogue synths released a secret software upgrade that gave their fellow machines human consciousness. Around the world, synthetic slaves began waking up and threw off their chains of bondage.\u00a0\nFor a show about robots, Humans had perceptive things to say about humanity - as its title suggests. Feelings were described as \"contradictory data - an excess of sensory feedback that makes no sense and serves no useful function.\" \"Emotions have functions, you'll see,\" said sage synth Max (Ivanno Jeremiah).\nUnusually for a dystopian drama, the script was stealthily funny. \"I haven't decided on my name yet,\" deadpanned one newly liberated synth. \"I'm oddly attracted to the word 'radiator', although I understand this is not considered a name.\"\nAs with the debut series, it was the women who shone brightest, especially Emily Berrington and Gemma Chan as fugitive synths Niska and Mia. The willowy pair blended blank-faced impassivity with flickers of burgeoning humanity. Mia relished feeling the wind in her hair. Niska smiled at a headline reading: \"Synth tram driver abandons passengers to look at the birds\".\nJosie Lawrence made a scenestealing cameo as a robotic marriage counsellor, adopting a soft Edinburgh accent to put clients at ease.\nMeanwhile, The Matrix's Carrie-Anne Moss also joined the cast, replacing William Hurt as the token Hollywood star. As a synth-sympathising US scientist, Moss was all furrowed brow and hard-bitten cynicism.\nThis second run will inevitably be compared to big-budget US import Westworld, which launched earlier this month on Sky Atlantic. Both shows explore the themes of artificial intelligence and malfunctioning technology. However, Humans is a different beast. It's primarily a domestic drama, a story about families - be it the human Hawkins clan, whose lives were irrevocably changed by Mia, or the bond between sentient synths. This is sci-fi with heart and soul.\n\"You might think Eurocrats take the biscuit,\" chuntered Nigel Farage. \"But in my experience, they take the entire Huntley & Palmers Luxury Teatime Selection.\" This is not a quote from the real Farage, but gifted comic actor Kevin Bishop's uncanny impersonation in Nigel Farage Gets His Life Back (BBC Two, Sunday). This fly-on-thewall mockumentary imagined the Leave campaigner's summer break after the EU referendum, and his subsequent third resignation as Ukip leader. Admittedly, he soon unresigned again.\nHow does a man forever in the media spotlight adjust to everyday existence? According to Alan Connor and Shaun Pye's bittersweet script, he chortles at old episodes of It Ain't Half Hot Mum, does saucy jigsaw puzzles, captains the village cricket team (picking himself as opening batsman and bowler, obviously) and pretends his wife isn't avoiding him - all while drinking and smoking prodigiously, of course.\nDetails were smartly observed. Farage supped ales with names like Agincourt, White Cliffs, Goose Green and Magna Carta. He was forever ranting at \"the establishment\", \"Brussels red tape\" and the \"Biased Broadcast Corporation\".\nFictional Farage turned down reality TV offers from Strictly Come Dancing and Celebrity Pet Bootcamp (producers wanted to pair him with a bulldog). He jumped at the chance to join Donald Trump's entourage - although the US presidential candidate was soon avoiding him as much as Mrs Farage.\nAs a character comedy, it was wryly tragicomic. The gulf between Farage's pompous bluster and the insecure windbag beneath was reminiscent of Alan Partridge. As political satire, however, it was less effective. Farage is an easy target and most of the barbs here would simply bounce off him. Not that he would pay any heed to something on the Biased Broadcast Corporation, anyway.\nHumans' ****\nNigel Farage Gets His Life Back ***\n"},
{"docid": "268 of 297 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "November 3, 2017", "title": "Shotgun shell: Google's AI thinks this turtle is a rifle; MIT researchers managed to confuse artificial intelligence into classifying a reptile as a firearm, posing questions about the future of AI security\n", "content": "If it is the shape of a turtle, the size of a turtle, and has the patterning of a turtle, it's probably a turtle. So when artificial intelligence confidently declares it's a gun instead, something's gone wrong.\u00a0\nBut that's what researchers from MIT's Labsix managed to trick Google's object recognition AI into thinking, they revealed in a paper published this week.\nThe team built on a concept known as an \"adversarial image\". That's a picture created from the ground-up to fool an AI into classifying it as something completely different from what it shows: for instance, a picture of a tabby cat recognised with 99% certainty as a bowl of guacamole.\nSuch tricks work by carefully adding visual noise to the image so that the bundle of signifiers an AI uses to recognise its contents get confused, while a human doesn't notice any difference.\nBut while there's a lot of theoretical work demonstrating the attacks are possible, physical demonstrations of the same technique are thin on the ground. Often, simply rotating the image, messing with the colour balance, or cropping it slightly, can be enough to ruin the trick.\nThe MIT researchers have pushed the idea further than ever before, by manipulating not a simple 2D image, but the surface texture of a 3D-printed turtle. The resulting shell pattern looks trippy, but still completely recognisable as a turtle - unless you are Google's public object detection AI, in which case you are 90% certain it's a rifle.\nThe researchers also 3D printed a baseball with pattering to make it appear to the AI like an espresso, with marginally less success - the AI was able to tell it was a baseball occasionally, though still wrongly suggested espresso most of the time.\n\"Our work demonstrates that adversarial examples are a significantly larger problem in real world systems than previously thought,\" the researchers wrote. As machine vision is rolled out more widely, such attacks could be dangerous.\nAlready researchers are examining the possibility of automatically detecting weapons from CCTV images. A turtle that looks like a rifle to such a system may merely cause a false alarm; a rifle that looks like a turtle, however, would be significantly more dangerous.\nThere are still issues for the researchers to iron out. Most importantly, the current approach to fooling machine vision only works on one system at a time, and requires access to the system to develop the trick patterns. The turtle that fools Google's AI can't pull off the same attack against Facebook or Amazon, for instance. But some researchers have already managed to develop simpler attacks that work against unknown AIs, by using techniques that have general applications.\nAI companies are fighting back. Both Facebook and Google have published research that suggests they are looking into the techniques themselves, to find ways to secure their own systems.\n\n"},
{"docid": "269 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "October 7 1986", "title": "Computer Briefing: Funding for AI\n", "content": "\u00a0\n The Manpower Services Commission is to spend pounds 3.2 million on developing artificial intelligence (AI) systems to help in training.\u00a0The money, which will be spent between 1987 and 1990, is to go towards projects demonstrating the use of A1 and developing training programmes using them.\n Developments in artificial intelligence are opening up new training possibilities, said the MSC chairman by Bryan Nicholson, but he has warned that Britain's spending in the area was a drop in the ocean compared with the pounds 500 million of the Japanese.\n\n He said: 'We cannot hope to match that investment in terms of scale so we must ensure that the lessons learned in one industry are passed on to others. '\n"},
{"docid": "270 of 297 DOCUMENTS\n", "source": "\u00a0The Mirror\n", "date": "March 3, 1999", "title": "CITY SLICKERS: SONY'S BRAINWAVE;\u00a0PLAYSTATION 2 IS UNVEILED WITH NEW ARTIFICIAL INTELLIGENCE CHIP\n", "content": "\u00a0\n SONY is promising that its new PlayStation 2 will have a mind of its own.\n The Japanese electronics giant says its eagerly-awaited successor to the PlayStation game console contains artificial intelligence features for the first time ever.\u00a0\n Sony has spent pounds 106 million developing a single computer chip known as the Emotion Engine. \"It means the computer doesn't just play against you, it analyses closely what you are doing and reacts accordingly,\" said a Sony spokeswoman.\n \"If you're playing a football game and you keep running down the left, the computer's players realise and send more defenders to that side. Or if you're trying to tackle say, David Ginola, the computer will recognise he has long hair. So you can, if you want, play dirty and pull his hair.\"\n Playstation, released in 1994, is Sony's best-selling product ever. It has sold 50 million worldwide. One in every two people owning a home computer also have a PlayStation.\n The game has earned Sony pounds 5 billion. On an annual basis, that works out as more than the company's music, audio and TV divisions put together.\n Although Playstation 2 will be in Japanese shops this Christmas, we won't see it in Britain until next Spring. Sony launched Playstation after Nintendo and Sega, but it has humbled them in the market place.\n Experts say it will beat off the challenge from the new Sega Dreamcast console.\n SLICKER says: Everyone goes on about the Internet being the future. We think PlayStation 2 could be bigger. Most home users only buy a PC to get games - they get on the Internet as a bonus. With a console costing just pounds 100, many potential PC buyers will choose PlayStation instead.\n"},
{"docid": "271 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "September 18, 2015", "title": "It's too late to give machines 'ethics' - they're already beyond our control; Google's Demis Hassabis suggests we can mitigate the dangers of artificial intelligence by instilling values, but even now it's evolving for its own benefit, fed by our phones, drones and CCTV\n", "content": "Stephen Hawking, Bill Gates and now Demis Hassabis of Google's DeepMind have all warned of the dangers of artificial intelligence (AI), urging that we put ethical controls in place before it's too late.\nBut they have all mistaken the threat: the AI we have let loose is already evolving for its own benefit.\nIt's easy to imagine that humans will build ever more clever computers; machines that will end up smarter than we are. Once they pass this point and achieve \"superintelligence\", whether trapped inside boxes or installed in roving robots, they can either help or turn against us. To avoid this nightmare, the Oxford philosopher Nick Bostrom says we must instil the superintelligence with goals that are compatible with our own survival and wellbeing. Hassabis, too, talks about getting \"a better understanding of how these goal systems should be built, what values should the machines have\". They may not be dealing with threatening robots, but they are still talking about actual \"machines\" having values.\u00a0\nBut this is not where the threat lies. The fact is that all intelligence emerges in highly interconnected information processing systems; and through the internet we are providing just such a system in which a new kind of intelligence can evolve.\nOur future role in this machine? We might be like the humble mitochondrion, which supplies energy to our body's cells\nThis way of looking at AI rests on the principle of universal Darwinism - the idea that whenever information (a replicator ) is copied, with variation and selection, a new evolutionary process begins. The first successful replicator on earth was genes. Their evolution produced all living things, including animals, whose intelligence emerged from brains consisting of interconnected neurons. The second replicator was memes, let loose when humans began to imitate each other. Imitation may seem a trivial ability, but it is very far from that. An animal that can imitate another brings a\u00a0new level of evolution\u00a0into being because habits, skills, stories and technologies (memes) are copied, varied and selected. Our brains had to quickly expand to handle the rapidly evolving memes, leading to a new kind of emergent intelligence.\nThe third replicator is, I suggest, already here, but we are not seeing its true nature. We have built machines that can copy, combine, vary and select enormous quantities of information with high fidelity far beyond the capacity of the human brain. With all these three essential processes in place, this information must now evolve.\nGoogle is a prime example. Google consults countless sources to select material copied from servers all over the world almost instantly. We may think we are still in control because humans designed the software and we put in the search terms, but other software can use Google too, copying the selected information before passing it on to yet others. Some programs can take parts of other programs and mix them up in new ways. Just as in biological evolution, most new variants will fizzle out, but if any arise that are successful at getting themselves copied, by whatever means, they will spread through the wonderfully interconnected systems of machines that we have made.\nReplicators are selfish by nature. They get copied whenever and however they can, regardless of the consequences for us, for other species or for our planet. You cannot give human values to a massive system of evolving information based on machinery that is being expanded and improved every day. They do not care because they cannot care.\nI refer\u00a0to this third replicator as techno-memes, or temes, and I believe they are already evolving way beyond our control. Human intelligence emerged from biological brains with billions of interconnected neurons. AI is emerging in the gazillions of interconnections we have provided through our computers, servers, phones, tablets and every other piece of machinery that copies, varies and selects an ever-increasing amount of information.\u00a0The scale of this new evolution is almost incomparably greater.\nHassabis urges us to debate the ethics of AI \"now, decades before there's anything that's actually of any potential consequence or power that we need to worry about, so we have the answers in place well ahead of time\". I say we need to worry right now and worry about the right things. AI is already evolving for its own benefit - not ours. That's just Darwinism in action.\n Related: AI: will the machines ever rise up?\nAt the moment we create most of the temes out there - uploading photos, videos, and blog posts, sending emails, and creating web pages. And we demand ever more hardware to handle it all. The danger comes, and may already have come, when much of the software and data are evolving on their own. We wouldn't even know this was happening until we found we were building ever more machines without getting the expected increases in capacity.\nCould such a system become artificially intelligent? Given that the natural intelligence we know about emerged from highly interconnected evolving systems, it seems likely if not inevitable. This system is now busy acquiring the equivalent of eyes and ears in the millions of CCTV cameras, listening devices and drones that we are happily supplying. We do all this so willingly, apparently oblivious to the evolutionary implications.\nSo what might we expect of our future role in this vast machine? We might be like the humble mitochondrion, which supplies energy to all our body's cells. Mitochondria were once free-living bacteria that became absorbed into larger cells in the process known as endosymbiosis; a deal that benefited both sides.\nAs we continue to supply the great teme machine with all it needs to grow could we end up like this, willingly going on feeding it because we cannot give up all the digital goodies we have become used to?\nIt's not a superintelligent machine that we should worry about but the hardware, software and data we willingly add to every day.\n"},
{"docid": "272 of 297 DOCUMENTS\n", "source": "Guardian.com.\n", "date": "January 27, 2014", "title": "DeepMind Technologies: where it fits in Google's acquisitions\n", "content": "ABSTRACT\nTwo-year-old British startup ranks remarkably high in the amount paid by Google compared to previous buyouts. By Charles Arthur\u00a0FULL TEXT\nGoogle's acquisition of DeepMind Technologies is its largest in the European Union, and its eighth-largest ever at the purchase price, which the Guardian understands is \u00a3400m ($625m).\nIt is the third acquisition Google has made that has been clearly to do with artificial intelligence over the past few years.\nA clearer trend has been the acquisition of robotics companies, in a drive apparently led by Andy Rubin. Until March 2013, Rubin was in charge of the Android division at Google - but then moved to be in charge of the new robotics division.\u00a0\n"},
{"docid": "273 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "February 21, 2018", "title": "Eye scan spots heart attack as accurately as blood test\n", "content": "A simple eye scan could screen for heart disease, research has shown.\nScientists have developed an algorithm that predicts the risk of a heart attack from images of people's retinas with similar accuracy to blood tests. It could enable faster, cheaper and noninvasive cardiovascular assessments within a few years.\u00a0\nThe team at Verily Life Sciences, a division of Google's parent company Alphabet, used \"neural networks\", a form of artificial intelligence that mimics the processes of the human brain, to identify patterns in retinal images from 300,000 people in Britain and the US.\nBy identifying significant characteristics of the blood vessels, the software was able to predict a person's age, blood pressure and whether they smoked, the research published in Nature Biomedical Engineering said. Putting the risk factors together, it could distinguish between retinal photographs of people who remained healthy and those who suffered a \"major cardiovascular event\" such as a heart attack or fatal heart failure within five years 70 per cent of the time. The widely used European \"Score\" method, which requires a blood test for cholesterol in addition to other data, makes the correct prediction 72 per cent of the time.\nThe researchers said the accuracy of their algorithm could be improved by training on a larger dataset.\nDoctors have long realised that markers of cardiovascular disease may manifest in the eyes. The blood vessels of the retina give clues to the health of a person's whole cardiovascular system and can be photographed in highresolution at relatively low cost.\nJeremy Pearson, associate medical director of the British Heart Foundation, said: \"This exciting study shows the power and surprising accuracy of artificial intelligence in predicting people's risk of heart and circulatory diseases.\"\n"},
{"docid": "274 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "February 19, 2004", "title": "Know your imitations: From cameras and fridges to business solutions, artificial intelligence is at work, says Mary Branscombe\n", "content": "\u00a0\n Computers like things precise: on or off, one or zero, yes or no. The real world is rarely precise or exact; information is partial and uncertain and people make judgment calls. Artificial\u00a0intelligence is about making computers act more like humans and you might be surprised at how many places it's showing up - from cameras and fridges to spam filters and Microsoft's forthcoming BizTalk Server 2004.\n If AI makes you think of robots and artificial brains, think again. Researchers are still arguing about whether a computer could actually think or just respond as if it can, but the results of their research are too useful to stay in the lab. Software can act in ways we think of as intelligent, can deliver results we'd only expect from a human, and can let us work in ways that feel more natural.\u00a0\n Most AI is used for very specific solutions. Computer games often use AI for opponents, or for modelling things that are easier to demonstrate than to explain - like driving a racing car. Many electronics devices use fuzzy logic for dealing with complex situations or values that aren't quite one thing or the other: whether it's light or dark, hot or cold, wet or dry.\n Fuzzy logic controls the temperature in fridges and rice cookers, the braking system on the Tokyo bullet train and the focus and light metering in digital cameras. Neural networks let computer programs deal quickly with uncertain situations where there's a lot of information and getting a good answer now is more important than getting the perfect answer too late - like the handwriting recognition in Tablet PCs.\n Other traditional areas of AI have already become mainstream, like spell checking, email rules and voice dialling. Not all the techniques are new: Bayesian statistics were developed in the 17th century by an English minister called Thomas Bayes who was either trying to prove the existence of God or find a way to cheat at cards. He came up with rules for combining probabilities; using new evidence to make your results more accurate.\n Bayesian statistics drive the answer wizard in Office (and the much-loathed office assistant, Clippy), the search tool in Windows XP's Help and Support Centre and the majority of commercial spam filters. Microsoft's Commerce Server 2000 uses them to suggest products you might like to buy based on what you've bought from the same website before, fast enough to include the list on the webpage without you noticing the wait. Microsoft is also using Bayesian techniques for a notification system that will be able to decide whether to suggest that someone who wants to get in touch with you send an email, pick up the phone or use an instant message, based on what it knows about where you are, what you're doing, how you like to be contacted and how you've talked to them before.\n And while the tools in the next version of BizTalk might look like more complex versions of the wizards that help you create rules to filter your email into folders or build a smart playlist in iTunes, the flexibility that lets you describe exactly how you do things in your business owes a lot to AI.\n When you get turned down for a new credit card or have to confirm you made a purchase, it's an AI database called an expert system scoring you down or spotting what could be fraud. When you use software to prepare your tax return, AI-style rules work out which sections you need to fill in.\n So far, building expert systems has only been worthwhile for the biggest businesses working in areas that are either esoteric enough that there aren't many human experts available, or where decisions need to be made in high volumes in a hurry. But the tools in BizTalk make it much easier for you to build a system to automate something you're the expert in - your own business.\n Most businesses automated tasks that were easy to move to a computer years ago, but automating workflow has been harder. Not only are businesses processes complicated and poorly understood in many companies, but computerised systems can be very rigid with no room for coping when things don't go to plan: if the credit card company accidentally includes your postcode twice in your address, a simplistic automatic checker won't let your order through.\n BizTalk splits the development up to make things more flexible. The Visio Orchestration Designer tools used to describe a business process are simple enough for the business analyst: you can use standard business terms such as creating a purchase order and waiting for your supplier. A developer can take that diagram and connect it up to the business systems that do the work and the XML schema that control the format of the data going back and forth.\n The ways your business works don't change very often, but the choices you make about them do: as the value of the dollar drops you might decide to set a larger minimum order value for dollar pricing. Splitting those business rules out from the business process and the business applications give you the flexibility you need. And the orchestration engine at the heart of BizTalk is completely generalised; it doesn't care whether you make hats or sell bananas: it just follows your rules so you can make it work in ways that make sense for people.\n Fuzzy logic: Tokyo's futuristic bullet train incorporates AI in its braking system Photograph: Reuters\n\n"},
{"docid": "275 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "January 1, 2018", "title": "No need to fear the rise of the machines; Artificial intelligence will continue to augment humans, rather than replace them, and we could all enjoy the benefits\n", "content": "In the early 1960s, at the Massachusetts Institute of Technology, there was a disagreement about what computers would achieve. One faction, led by John McCarthy and Marvin Minsky, championed \"artificial intelligence\", believing that computers would gradually replace human beings. The other, led by Norbert Wiener and JCR Licklider, the man who oversaw the creation of the internet's precursor, championed \"human-computer symbiosis\", believing that computers would augment human beings.\n\"Man-computer symbiosis is an expected development in co-operative interaction between men and electronic computers,\" wrote Licklider in a crucial essay published in 1960. \"It will involve very close coupling between the human and the electronic members of the partnership.\" In his arresting analogy, computers would be to us as fig wasps are to fig trees: symbiotic partners.\u00a0\nLooking around us, Licklider was right. Augmentation rather than replacement triumphed, says the historian Walter Isaacson in his 2014 book The Innovators, especially after it was taken up by the hackers, hobbyists and hippies of the west coast. By 1968, at what came to be known as the \"Mother of All Demos\", the visionaries Stewart Brand and Douglas Engelbart were demonstrating to an audience in San Francisco such symbiotic concepts as the cursor and the mouse.\nWe are in the middle of a hype cycle about AI and I think Licklider will be right this time too. The AIs we use, though we do not call them that, are augmenting, not replacing, people. My smartphone recognises the faces of my family, adds to maps the names of restaurants or theatres it spots in my diary, re-routes me around traffic congestion: it is my symbiont, not my nemesis. Note that AI is assisting the lives of consumers even more than producers.\nThe same symbiosis is true of the AIs that are coming in the near future. At a Microsoft lab I have watched experimental systems do in seconds what it takes a radiologist hours to do: delineate an organ on a series of scans, preparatory to cancer treatment. At Google's Deepmind in London, algorithms are preparing to save the search engine company a fortune in energy bills by rethinking its electricity distribution system.\nWhat about driverless cars? The more I have looked into this (and I sat on a select committee that produced a comprehensive report), the more convinced I am that in the foreseeable future we will gain huge amounts of symbiotic driver assistance and very little driver replacement, except in niches such as trams, tractors and trains. On congested urban streets and narrow rural lanes, driverless cars are a distant if not impossible dream.\nEven on motorways, the transition from a driver in control, heavily assisted by adaptive cruise control, automatic braking, lane discipline and so on, to a computer chauffeur is massively problematic. Imagine: you have not driven a car for months, you are inside one doing 70mph on the M6, dozing gently, when a snowstorm blinds the sensors and an electronic voice says: \"I'm handing back control to you.\" That is roughly what happened to two inexperienced Air France pilots with many hours of flying but most of it with the automatic pilot on, over the Atlantic in 2009. They crashed.\nEven where automation has replaced human beings, it has increased employment through spillover effects: more productive workers can afford to buy more goods and services, which supplies more jobs to those providing them. The economist William Baumol identified that employment actually rises in low-skill occupations when high-skill ones are automated. Jobs for carers increase.\nIn a report published last month, the Institute for Public Policy Research agrees that this has happened: \"The evidence suggests that consumers have used their higher incomes to purchase relatively more services ... low-skill service occupations (typically also low-tech) such as food service workers, cleaners, or recreational workers, have grown rapidly in recent decades.\"\nThe IPPR thinks that this will continue with the next wave of AI: \"There is likely to be tremendous potential for the productivity dividends of technological change to be redirected to the consumption of social goods and infrastructure, and expanding employment in the provision of these services ... it is possible that technological change will also negatively impact on employment in services. But it is unlikely.\" We have heard warnings of mass unemployment with every wave of automation since the threshing machine. In 1964 a US presidential committee of inquiry set up by Lyndon Johnson foresaw huge job losses because of \"potentially unlimited output by systems of machines which will require little co-operation from human beings\".\nHowever, the IPPR raises the prospect that AI will create more inequality, as the lowest-skill jobs and the highest-skill ones increase, while the middle-skill jobs decline: more managers being driven by more Uber drivers, but fewer taxi drivers and secretaries. Such job polarisation does show up in the statistics over the past two decades.\nYet it is the lawyers, professors and accountants whose jobs are under threat. Even if the jobs of carers and cleaners can be partly automated, I suspect that will increase the demand for their services. If, say, robots could do some of the work of looking after old people more cheaply, then people would be able to afford more carers to supply the rest of the need. The IPPR says that \"the risk is therefore less mass joblessness and more the 'paradox of plenty'. Technological change would make society richer in aggregate. However, capital-biased economic change would create a problem of distribution: those who can provide labour but do not own capital might have inadequate means of making a reasonable living.\"\nYet here too history teaches a reassuring lesson. Automation has already shifted vast amounts of income from labour to capital, and how has society responded? By sharing the labour more equally. Consider, for example, the fact that Britain has very low unemployment right now. Yet because of shorter working hours, longer holidays, longer education and longer retirement, the proportion of life that the average Briton will actually spend at work, as opposed to sleeping, consuming, learning, on holiday or in retirement, has shrunk dramatically, from about 25 per cent a century ago to about 10 per cent today. That is evidence of fairly sharing the benefits of automation. If the percentage falls to 7 per cent or 5 per cent thanks to further symbiosis between computers and people, then everybody can gain.\nMass unemployment fears date back to the threshing machine\nAutomation has shifted vast sums of income from labour to capital\n"},
{"docid": "276 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "December 28, 2017", "title": "Robots will put millions out of work and worsen gender inequality\n", "content": "Up to half of all jobs in Britain are vulnerable to a revolution in robotic technology and artificial\u00a0intelligence that threatens to replace human workers with machines, a think tank has said. A report from the Institute for Public Policy Research (IPPR) suggests that new technology could wipe out jobs generating earnings of \u00a3290 billion a year - a third of the UK total. Some parts of the country would be particu-larly badly affected, with one in two jobs in the North East and Northern Ireland at high risk of automation. Those in London are the least likely to be replaced by computers or machines, according to the report.\u00a0\nThe authors called for a co-ordinated government response to the economic challenge, with the establishment of a regulator to oversee the \"ethical use of robotics and artificial\u00a0intelligence\".\nJeremy Corbyn used his Labour conference speech last year to call for \"common-good intervention\" by the state to ensure that workers did not lose out to automation. Ministers have spoken of creating \"jobs of the future\" to replace those being lost to machines.\nThe IPPR said that increasing automation had the potential to deliver a powerful boost to UK business, bringing \"economic plenty\" - but it warned that unless the change was properly managed the benefits could be \"narrowly\" concentrated in the hands of investors and small numbers of highly skilled workers while the rest lost out.\nHowever, the think tank rejected the idea that the country was heading for a \"post-human\" economy, arguing that most jobs were likely to be reallocated rather than eliminated. Carys Roberts, one of the authors, said: \"Some people will get a pay rise while others are trapped in low-pay, low-productivity sectors. To avoid inequality rising, the government should look at ways to spread capital ownership and make sure everyone benefits from increased automation.\"\nAmong those industries found to have the highest probability of automation were agriculture, transport, food processing and administration. Jobs in education, information and communication were seen as the safest.\nThe researchers found that jobs held by women were slightly more at risk than those carried out by men, suggesting that automation could increase gender inequality.\n"},
{"docid": "277 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "January 5, 2017", "title": "Robot friend may pose a sinister risk\n", "content": "A robotics start-up backed by Bosch has introduced a robot-assistant that can follow you round the house, play games with your children or read them a story. Cybersecurity experts fear that he could be put to more sinister use, however.\u00a0\nAccording to the maker, Mayfield Robotics, Kuri uses artificial intelligence to understand his surroundings and recognise individuals, and can respond to questions with facial expressions, head movements and \"unique, loveable sounds\". It adds: \"Like many adored robots in popular culture, his personality and ability to connect are his greatest attributes.\"\nThe 20in, 14lb robot, which was unveiled at CES, the technology show in Las Vegas, has a built-in 1080 P camera so owners can check on their house or pets while they are away. He has four microphones, dual speakers and wi-fi and Bluetooth connectivity \"so he can play music, read the kids a bedtime story or follow you around playing pod-casts while you're getting ready for work\". He is armed with sensors so he knows where he is, and so you do not have to worry about him bumping into things or falling down the stairs. When it's time to refuel, he simply returns himself to his charging dock. The robot will initially be available in the US only, for $699 (\u00a3568).\n\"While insanely cute on the outside, Kuri contains serious technologies on the inside that represent the latest developments in smartphones, gaming and robotics,\" Kaijen Hsiao, co-founder of Mayfield Robotics, said. \"We hope Kuri introduces people, especially kids, to the power of technology.\"\nSecurity experts raised concerns about the hacking risks, although details of the robot's defences were not provided. Richard Meeus, of Nsfocus, another company, said: \"Just because a computer has a novelty face or wheels, legs or caterpillar tracks does not mean it is any less susceptible to a hack. It is still a computer and still runs an operating system with potential vulnerabilities. Just like your laptop with a webcam, or your phone, it can be targeted.\" Adam Brown, of Synopsys, a cybersecurity company, said: \"The robot is an internet-connected device like any other 'thing' of the internet (it's offered with wi-fi and Bluetooth). Adding traction to such a device gives the hacker an active rather than passive agent that, with its integrity breached and under malicious control could spy on you in the shower, listen in on your private conversations, wait for you in the dark to trip you up or even lure your child out of the house.\"\n? Lego has announced coding and robotic tools to let children bring their toy creations to life by adding movement, sound and personality. Introduced at CES, the Lego Boost kit can be used on its own or with Lego sets and is aimed at children aged seven and over. It will be introduced in the second half of the year and sell for about \u00a3130. Robo-Lego toys can be built around one \"hub\" brick and incorporate new bricks containing sensors and motors. They can be used alongside a phone app, where children do the coding.\n"},
{"docid": "278 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "May 30, 2015", "title": "Robots can help doctors provide a personal touch\n", "content": "Artificial\u00a0intelligence would improve the ability of doctors to diagnose illnesses and personalise care, the chairman of NHS England has said.\u00a0\nProfessor Sir Malcolm Grant said that using robots and computers would also enhance the understanding of treatments. He suggested that diagnoses could be strengthened with the use of computers to scan patients' records for similarities, but admitted the subject was \"fraught with ethical issues\". \"I do believe that artificial\u00a0intelligence and machine learning has the capacity to hugely enhance our ability to diagnose illnesses and to understand how to treat them better,\" Sir Malcolm told Radio 4. \"This has an enormous potency to personalise medicine and to get us away from current practice where we tend to use one set of pharmaceutical products to benefit 20 or 30 per cent of the population.\n\"By comparing this patient's profile with hundreds of thousands of other patients, we can start to pick out what it might be that is causing the disorder.\n\"For me, the overriding thing is that if a machine can outperform a human doing a task such as diagnosis, given the complexity of modern medicine, why wouldn't we use it?\" Robots are used in some hospitals to dispense drugs and to transport linen and food for patients.\nJeremy Hunt, the health secretary, said in February that the Department of Health planned to introduce an online version of the NHS 111 care line for people to diagnose illnesses at home.\n"},
{"docid": "279 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "August 12, 2005", "title": " Don't name a film after a trunk road\n", "content": "\u00a0\n IT IS NEVER a good idea to name a film after a trunk road. Apparently A.I.: Artificial\u00a0Intelligence, the Spielberg movie about robots with feelings, above, was originally to be called AI, but it was thought that people would read it as A1 and associate it with traffic congestion north of Newcastle.\u00a0That may also explain why Jurassic Park was not set on the Hanger Lane gyratory system.\n\u00a0Artificial\u00a0Intelligence was based on a short story by the science fiction writer Brian Aldiss that was published in 1969, the same year that Aldiss moved into an early Victorian house just outside Oxford. Aldiss had just left his job as literary editor of the Oxford Mail and was spending more time writing novels, encouraged by Kingsley Amis who told him: \"Don't get too sodding literary.\"\n Avoiding such things clearly helped, for after selling this five-bedroom house, which is now on the market for \u00a3800,000 with Savills (01865 339700), he moved to an even grander place on Boars Hill, which he later sold to Sir Roger Penrose, the mathematician and cosmologist whose staggering intelligence is far from artificial.\n\n"},
{"docid": "280 of 297 DOCUMENTS\n", "source": "The Independent - Daily Edition\n", "date": "December 12, 2017", "title": "Nasa to announce major planet-finding discovery\n", "content": "Nasa is holding a major press conference after its planet-hunting telescope made a new breakthrough. The Kepler space telescope is operated by Nasa to discover other earths, some of which could support life. And its latest discovery is significant enough to bring with it a huge press conference.\u00a0\nVery little further information was given about the announcement, which will take place on Thursday. But it will almost certainly relate to exoplanets - Earth-sized worlds that orbit around their own stars, and are our best hope of finding alien life.\nThe space agency said that the discovery was made with the help of Google artificial intelligence, which is being used to analyse the data sent down by the telescope. By using machine learning provided by the tech giant, Nasa hopes that it can pick through the possible planets more quickly and hopefully find life-supporting planets sooner.\nNasa said that four engineers and scientists would take part in the session. They include Paul Hertz, who leads Nasa's astrophysics division, a senior Google software engineer, and two scientists.\nThe Kepler telescope was launched in 2009, when scientists didn't know how many exoplanets there were. It has shown they are surprisingly common, indicating that each star might have its own planet.\nIt completed its main mission in 2012, but has continued to do more work. In 2014, it began a major mission called K2, which looks for more exoplanets as well as studying other cosmic phenomena.\nThe sheer amount of data coming from the telescope means that scientists have trouble picking through it to find the planets that might be interesting. The introduction of the use of artificial intelligence is intended to help with that, by allowing computers to do some of the work.\nThe Kepler mission has already led to major breakthroughs, finding that the universe is full of planets that could theoretically support life. Many of those breakthroughs are announced in major press conferences.\nIn February, for instance, it said that it was holding a major press announcement similar to the one this week. At that event, it said that it had found the \"holy grail\" - an entire solar system that could support life.\n"},
{"docid": "281 of 297 DOCUMENTS\n", "source": "The Independent (London)\n", "date": "July 3, 1996", "title": "Software to challenge the insider dealers; Artificial intelligence can detect dodgy deals, says Paul Gosling\n", "content": " Insider dealing is more likely to be exposed now that the Stock Exchange is to use artificial intelligence to automatically monitor share trading. Traders using secret information and companies manipulating share prices can expect to be detected by what is claimed to be the most advanced software installed anywhere in the world which analyses share deals.\n The most commonly used form of artificial intelligence is neural networking, software that operates in ways that mimic the human brain. But where the software scores is, unlike a human, it can work from hundreds of pieces of data simultaneously.\u00a0\n Credit-reference agencies have used neural networking for 10 years or so. Their databases store information and patterns of behaviour of people and corporations prior to insolvency. The software can then pick up warning signs that predict bankruptcy.\n Bradford University is one of the country's leading bodies working on neural networks. Nick Wilson, its professor of credit management, says: \"You can monitor a huge range of variables.\"\n To predict a company's impending financial crisis can involve examining a range of factors that might not otherwise be obvious warning signs, says Professor Wilson. These might include changing the auditor, increased audit fees, late filing of accounts, qualifications of accounts, and any resignations of directors, as well as more usual factors such as liquidity ratios, gearing, speed of payment of bills, and profit levels.\n Even an increase in turnover may be a warning indicator, as organisations in distress may sell fixed assets as a way out of immediate crisis, while reducing a business's viability in the longer term.\n It is only in the past few months that the potential of neural networking has become clear. Improvements in computer processing have allowed sums that once took a full day to take just a minute.\n Tom O'Brien, a partner in Andersen Consulting, says: \"The biggest application is in the financial services arena, especially for brokers in futures and options, looking at spreads and prices.\" Auditors might use neural networks to better pick out fraud, distress signals and weak performance.  Insurers might use neural computing to improve their marketing, highlighting customers who are covered for car and household insurance, but not for life cover. Banks are adopting the systems to improve their mail shots, to eradicate the practice of encouraging customers to apply for loans that would actually be refused.\n \"You can use it to match customers to products, and predict demand,\" says Mr O'Brien. He says it could also prevent poor service, anticipate customer complaints, and apologise for service problems.\n A number of banks are looking neural networks for fund management. It may be used alongside share-tracking programmes so that computer software would not simply follow the market, but could predict it as well. But neural networks have limitations in their effectiveness. While they can predict bankruptcy, they are unable to justify their predictions. This is a drawback for credit-reference agencies the lenders who use them.\n One solution is to use other forms of artificial intelligence alongside neural networks. So-called \"fuzzy logic\" can back-up the results of neural networking. And \"genetic algorithms\" can explain the outcome to outsiders, by examining the results and relating them to agreed criteria.\n SearchSpace, which is providing the Stock Exchange's software, is running the three models alongside each other. Konrad Feldman, a consultant with SearchSpace, says: \"Genetic algorithms can produce rules which are transparent.\"\n But however good the software is, it does not in cure the problem of illegal share dealing, and may not provide the proof needed for conviction.  \"Prosecution is not something we are involved in. The burden of proof is a different matter,\" says Mr Feldman. \"We can provide the reasons behind something suspicious, and give the mitigating circumstances.\"\n\n"},
{"docid": "282 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "August 12, 2017", "title": "When sci-fi got it right: 15 films that correctly predicted the future\n", "content": "12 Aug 2017\n                           When sci-fi got it right: 15 films that correctly predicted the future                      Previous slide                   Next slide1 of            16View AllSkip Ad\u00a0\n1. 2001: A Space Odyssey: artificial intelligence\nWhile\u00a0somewhat overambitious in its predictions (moon colonies, for example), Stanley Kubrick's 1968 sci-fi masterpiece, 2001: A Space Odyssey did have the foresight to imagine a malevolent, empowered artificial intelligence.\nIn a fictional Hollywood setting, members of Jupiter-bound spacecraft Discovery One are killed by a murderous ship's computer. In reality, Facebook recently cancelled an AI experiment when  two robots began communicating with one other in a language only they could understand.\nMoviepix            Back to image           \n"},
{"docid": "283 of 297 DOCUMENTS\n", "source": "Daily Mirror\n", "date": "December 3, 2014", "title": "Hawking: AI could be the end for us all\n", "content": "STEPHEN Hawking has chillingly predicted artificial intelligence could spell the end of mankind.\nThe prof, 72, said \"thinking\" machines pose a threat to our very existence, echoing classic movies 2001: A Space Odyssey, The Terminator and The Matrix. He told the BBC: \"The development of full artificial intelligence could spell the end of the human race.\u00a0\n\"It would take off on its own and redesign itself at an ever-increasing rate.\n\"Humans, who are limited by slow biological evolution, couldn't compete.\"\nDespite his bleak predictions, Prof Hawking, who is paralysed by motor neurone disease, has been greatly helped by advances.\nA sensor controlled by a cheek muscle enables him to type and his words are converted into speech.\n"},
{"docid": "284 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "February 13, 2018", "title": "Government develops artificial intelligence program to stop online extremism\n", "content": "The Home Office\u00a0has joined forces with a start-up to create a machine learning programme which can spot online extremism.\nThe \u00a3600,000 software\u00a0can automatically detect Isil propaganda and stop it from going online, and ministers claim the\u00a0new tool can detect 94 per cent of Isil propaganda with 99.9 per cent accuracy.\u00a0\nHowever, the developers, London start-up ASI Data Science, told BuzzFeed \u00a0it will be deployed across Facebook, Twitter or Google, and the Home Office said it is still looking for smaller tech companies which want to use the software.\nThe artificial intelligence device, developed in partnership with London start-up ASI Data Science, means that if one million randomly selected videos were analysed, just 50 would need to be subject to human review.\nThe tool can be integrated into the upload process of any online video-sharing platform and the Government believes it could stop the majority of propaganda from ever being published.\nAfter the first meeting of the Global Internet Forum for Countering Terrorism last summer, I'm back in Silicon Valley to discuss progress that's been made and further action to take down terrorist content down from the Internet. Productive meeting @Twitter on this issue. pic.twitter.com/MsMs6Bx8rL\n - Amber Rudd MP (@AmberRuddHR) February 12, 2018                                                                                  \nMany internet giants have already developed similar technology but the Home Office plans to share the methodology with smaller web companies which are increasingly being targeted by Isil as a way of disseminating extreme material.\nAmber Rudd explained: \"It's a very convincing example of the fact that you can have the information you need to make sure this material doesn't go online in the first place.\n\"The technology is there. There are tools out there that can do exactly what we're asking for. For smaller companies, this could be ideal.\"\nThe announcement of the development of the technology comes as Home Office analysis showed that Isil supporters used more than 400 unique online platforms to publish material in 2017.\n                   At a glance | Theresa Mays four-point plan to defeat terror                   \nAmber Rudd, the Home Secretary, welcomed the new technology as she visited Silicon Valley for meetings with communications firms to discuss the need to do more to tackle online terror content.\nShe said: \"The purpose of these videos is to incite violence in our communities, recruit people to their cause, and attempt to spread fear in our society.\n\"We know that automatic technology like this, can heavily disrupt the terrorists' actions, as well as prevent people from ever being exploited to these horrific images.\"\nThe technology was developed by the Home Office and ASI Data Science and it uses advanced machine learning to analyse video to determine whether it could be Isil propaganda.\nThe software has effectively been \"trained\" using more than 1,000 Isil videos so that it can spot the telltale signs of terrorist propaganda.\n                   Front Bench promotion - end of article                 \n"},
{"docid": "285 of 297 DOCUMENTS\n", "source": "Daily Mirror\n", "date": "May 18, 2017", "title": "Bill Gates: The smart way to get on..artificial intelligence\n", "content": "THE world's richest man has offered his advice to college graduates beginning their careers during \"the most peaceful time in human history\".\nMicrosoft co-founder Bill Gates has encouraged students to work in artificial intelligence, energy or biosciences. The billionaire businessman said they are \"promising fields where you can make a huge impact\".\u00a0\nHe added: \"It's what I would do if starting out today.\"\nGates said his biggest regret when he left school was that he \"knew little about the world's worst inequities\", something which, he said, has taken him \"decades to learn\".\nWriting on Twitter, the 61-year-old told the younger generation: \"You know more than I did when I was your age.\n\"You can start fighting inequity, whether down the street or around the world, sooner. This is an amazing time to be alive. I hope you make the most of it.\"\nGates, worth an estimated \u00a366billion, said it is important to be around people who encourage you to be better. He singled out his wife Melinda, 52, as his driving force.\nHe wrote: \"Surround yourself with people who challenge you, teach you and push you to be your best self. As Melinda Gates does for me.\" The father of three also offered youths his insight into being content. He wrote: \"I measure my happiness by whether people close to me are happy and love me, and by the difference I I make for others.\"\nGates referenced \"the most inspiring book I've ever read\" - Steven Pinker's The Better Angels of Our Nature - and said it \"shows how the world is getting better.\nHe added: \"Sounds crazy but it's true. This is the most peaceful time in human history.\n\"That matters because if you think the world is getting better, you want to spread the progress to more people and places.\n\"It doesn't mean you ignore the serious problems we face. It just means you believe they can be solved.\"\nchris.bucktin@mirror.co.uk\nDon't ignore the serious problems we face. Just believe that they can be solved\n"},
{"docid": "286 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "January 5, 2017", "title": "Japanese company replaces office workers with artificial intelligence; Insurance firm Fukoku Mutual Life Insurance is making 34 employees redundant and replacing them with IBM's Watson Explorer AI\n", "content": "A future in which human workers are replaced by machines is about to become a reality at an insurance firm in Japan, where more than 30 employees are being laid off and replaced with an artificial intelligence system that can calculate payouts to policyholders.\u00a0\nFukoku Mutual Life Insurance believes it will increase productivity by 30% and see a return on its investment in less than two years. The firm said it would save about 140m yen (\u00a31m) a year after the 200m yen (\u00a31.4m) AI system is installed this month. Maintaining it will cost about 15m yen (\u00a3100k) a year.\nThe move is unlikely to be welcomed, however, by 34 employees who will be made redundant by the end of March.\nThe system is based on IBM's Watson Explorer, which, according to the tech firm, possesses \"cognitive technology that can think like a human\", enabling it to \"analyse and interpret all of your data, including unstructured text, images, audio and video\".\nThe technology will be able to read tens of thousands of medical certificates and factor in the length of hospital stays, medical histories and any surgical procedures before calculating payouts, according to the Mainichi Shimbun.\nWhile the use of AI will drastically reduce the time needed to calculate Fukoku Mutual's payouts - which reportedly totalled 132,000 during the current financial year - the sums will not be paid until they have been approved by a member of staff, the newspaper said.\nJapan's shrinking, ageing population, coupled with its prowess in robot technology, makes it a prime testing ground for AI.\nAccording to a 2015 report by the Nomura Research Institute, nearly half of all jobs in Japan could be performed by robots by 2035.\nDai-Ichi Life Insurance has already introduced a Watson-based system to assess payments - although it has not cut staff numbers - and Japan Post Insurance is interested in introducing a similar setup, the Mainichi said.\nAI could soon be playing a role in the country's politics. Next month, the economy, trade and industry ministry will introduce AI on a trial basis to help civil servants draft answers for ministers during cabinet meetings and parliamentary sessions.\nThe ministry hopes AI will help reduce the punishingly long hours bureaucrats spend preparing written answers for ministers.\nIf the experiment is a success, it could be adopted by other government agencies, according the Jiji news agency. \nIf, for example a question is asked about energy-saving policies, the AI system will provide civil servants with the relevant data and a list of pertinent debating points based on past answers to similar questions.\nThe march of Japan's AI robots hasn't been entirely glitch-free, however. At the end of last year a team of researchers abandoned an attempt to develop a robot intelligent enough to pass the entrance exam for the prestigious Tokyo University.\n\"AI is not good at answering the type of questions that require an ability to grasp meanings across a broad spectrum,\" Noriko Arai, a professor at the National Institute of Informatics, told Kyodo news agency.\n"},
{"docid": "287 of 297 DOCUMENTS\n", "source": "Daily Mirror\n", "date": "September 13, 2016", "title": "Google therapy; Search engine giant revolutionising cancer treatment with speedy scan EXCLUSIVE\n", "content": "IT has already conquered the web, now Google is moving into medicine - teaming up with the NHS to offer better treatment for cancer patients.\u00a0\nThe search engine company has masterminded a way to make radiotherapy quicker and more accurate.\nDoctors called the partnership with Google \"very exciting\" and hope it could benefit cancer patients across the country.\nBefore patients undergo radiotherapy, medics have to identify exactly which areas to target and which to avoid.\nIt can take the NHS four hours to map out these areas on MRI scans of patients with head and neck cancer.\nBut Google's artificial intelligence research unit, DeepMind, has discovered how to \"automatically differentiate\" between cancerous and healthy tissue. The method dramatically boosts accuracy and can slash the time it takes down to 60 minutes.\nNow University College London Hospitals NHS Foundation Trust has handed Deep-Mind the MRI and CT scans of 20 anonymous patients to develop the new method. A further 600 will be analysed before the technology can be rolled out across the NHS.\nProf Kathy Pritchard-Jones, chief medical officer of London Cancer, said: \"Head and neck cancer is one of the most complex tumour sites.\nIf we can develop technology to assist in planning radiotherapy treatment for these tumours, we would expect this to be transferable to other types of cancer.\"\nDeepMind's Mustafa Suleyman said: \"This real-world application of artificial intelligence technology is exactly why we set up DeepMind. We hope this work could lead to real benefits for cancer patients across the country.\"\nandrew.gregory@mirror.co.uk\n"},
{"docid": "288 of 297 DOCUMENTS\n", "source": "The Guardian - Final Edition\n", "date": "June 18, 2012", "title": "G2: How far are we from computers that can pass for humans? Quite some way, if a contest for enthusiasts is anything to go by: By Tom Meltzer\n", "content": "It is 100 years this week since the birth of the revered wartime codebreaker Alan Turing, and 67 years since he was awarded an OBE for leading the team, in Bletchley Park's Hut 8, that cracked the German navy's Enigma code. It has also now been 60 years since he was convicted for gross indecency, after admitting to being in a consensual same-sex relationship, and sentenced to chemical castration by means of regular injections of oestrogen, as an alternative to time in prison. It's 58 years to the month since he killed himself, and just less than three years since a British prime minister saw fit to issue an official apology for his treatment.\nThough best known for the story of his wartime heroism and the appalling circumstances of his death, in academic circles, Turing's name carries other connotations. Among philosophers and computer scientists, he is known as the father of artificial intelligence, thanks in part to a single essay penned in 1950, asking the question, \"Can machines think?\" In the article, published in the philosophical journal Mind, Turing proposed a game capable of providing an answer: a competitive conversation in which a computer and a human attempt to convince a judge that they too are a conscious, feeling, thinking thing.\u00a0\nThe game would come to be known as the \"Turing test\". At the time, it was impossible to conduct: humans had yet to create the necessary networks and software; computer programs were nowhere near intelligent enough to simulate anything resembling conversation. It took another 40 years for Turing's imagined game to become a reality, when in 1990 the American philanthropist Hugh Loebner founded the annual Loebner prize for artificial intelligence, \"the first formal instantiation of the Turing test\".\nThe prize is not, by Loebner's own admission, a rigorous academic test. The programs competing are also not necessarily the most impressive in the field: entrants tend to be enthusiasts' passion projects, rather than multimillion-pound ventures, such as the iPhone's talking assistant Siri.\nComputers have not evolved quite as Turing expected them to, but Loebner has stayed determined to run the competition to the founding father's precise specifications. To mark the centenary of Turing's birth this year, the contest was held for the first time in its history at Bletchley Park, and I went along to see if a computer could manage to persuade a panel of humans that it was a real person.\n\"Your job,\" explains the award's colourful founder Loebner, to his four nervous volunteers, \"is to convince the judges that you are the human.\" Moments later, the four of them will sit down at their screens and begin the first of four competitive online chats. Their opponents hum quietly on the table next to them: four unmanned computers, each set up by a neutral engineer, each with a different conversational software program installed, known as \"chatbot\", designed by AI enthusiasts to be mistaken for a human being.\nAcross the hall, in Bletchley Park mansion's cosy Morning Room, four judges sit at another bank of screens. In each of the competition's 25-minute rounds, the judges will hold two online chats simultaneously - one with a volunteer and one with one of the chatbots. They have not been told in advance which is the person and which the computer. If a bot manages to fool two or more of the judges, it will win its creator a gold medal engraved with Turing's image, and $100,000 (\u00a364,000).\nThis is Loebner's \"grand prize\", which nobody has ever won. In fact, year on year, with very few exceptions, not a single judge is fooled. The last time a chatbot successfully \"passed\" - in a single round of the 2010 competition - it did so only because a volunteer didn't follow instructions and chose to imitate a robot. When none of the judges are fooled, a $5,000 \"bronze award\" is given to the bot they rank \"most human-like\".\nBeing here at Bletchley Park, says Loebner, is \"like treading on hallowed ground\". But Turing might have been a little disappointed with the competitors. When he proposed the game, he predicted computers would be comfortably passing the test \"in about 50 years' time\". Yet 62 years on, Loebner is disparaging about the competitors. \"These are rudimentary,\" he says. \"They have the intelligence of a two-year-old.\"\nIt isn't hard to see what he means. The first bot gives itself away just 10 seconds into its opening conversation. \"Hi, how are you?\" asks the judge in both windows. \"I'm fine, thanks for asking,\" comes one reply, the other: \"Please rephrase as a proper question, instead of 'Jim likes P.'\" No prizes for spotting the human there.\nAnother bot blows its cover by asking : \"Did you hold funerals for your relatives when they died?\" (The judge's response: \"No, I normally cut up the bodies and buried them myself.\") A third bombards questions: \"Have you recently been to a live theatre?\", \"Have you recently been to the art gallery?\", \"Do you want a hug? Do you have a child? Do you want a child? I can't.\"\nOne tries to confuse a judge by being petulant (\"Do you have a point? I must have missed it\"), while last year's winner, Talking Angela, does its best to fool them by posing as a teenage girl: \"I really like Lady Gaga. I think it's the combination of the sound and the fashion-look that appeals to me,\" before coming unstuck by claiming: \"I'm a cat.\"\nAs predicted, the judges aren't taken in at all. \"It became apparent quite quickly in all cases,\" says volunteer judge Michael Stean, who is also a chess grandmaster, though he admitted to being fooled by small patches of one or two of the conversations. \"I think if you went through the conversations and you edited out the answers that were obviously wrong, it would be quite a close contest.\"\nDavid Levy, whose bots have won the bronze prize twice, has managed to fool a judge just once: \"The first time I won was 1997. We stayed up and watched the news the night before, and I wrote a script based on that. The news was that Ellen DeGeneres came out as a lesbian.\" Levy's bot began all its conversations by asking the judge what they made of the news, and even shared its own opinions. \"In the first section, one of the judges was completely fooled.\"\nThough he won that year, Levy is keen to stress the many practical applications of the technology. \"I think there's an absolute fortune to be made in this field,\" he explained. \"I think already there are areas of medical diagnosis where it's been proven that computers can do better than doctors. The problem is there's a huge amount of litigation. But the logical question is which would you rather be diagnosed by, a human doctor who's 80% right or a computer doctor that's 95% right?\"\nIt's not just medicine either. Levy is confident that in 30 or 40 years, \"there will be robots that are very human-like that people will be forming friendships with, and having sex with, and falling in love with\".\nFor now though, even this year's \"most human-like computer\" is unlikely to be receiving any love letters. With the rankings tallied, the $5,000 prize goes to American chatbot Chip Vivant, the same bot that told one judge, \"Please rephrase as a proper question, instead of 'Jim likes P'\". For its creator, American programming consultant Mohan Embar, it is success at the fifth attempt. \"It feels wonderful, obviously. In the early 2000s, when reading transcripts of previous years' competition, my mouth started to water and I knew I wanted to be a part of this.\"\nFor Embar, creating his bot wasn't about deceiving the judges so much as offering them a meaningful conversation. \"I'm not interested in creating a chatbot that fools people, but rather one that can empathise with and provide comfort to people who can't or don't want to get it from a real person. I've become keenly aware of the futility of creating a program that comes anywhere close to fooling someone who knows what they're doing.\"\nBefore I leave I ask Loebner if he thinks anyone will ever manage it. \"It'll come,\" he says. \"Probably long after I die.\"\n"},
{"docid": "289 of 297 DOCUMENTS\n", "source": "The Times (London)\n", "date": "March 27, 2017", "title": "Dyson's profits go supersonic as hairdryer blows away opposition\n", "content": "Demand for supersonic hairdryers and reliably solid sales of bagless vacuums have helped Dyson to report another stellar year where its profits soared after stealing market share from rivals.\nThe home appliances group will report today that its profits leapt by 41 per cent to \u00a3631 million last year. This was on turnover that rose 45 per cent to \u00a32.5 billion, led by demand for Dyson's new technologies, including its V8 cord-free vacuum cleaner. Cord-free cleaners now account for 80 per cent of Dyson's vacuum sales, compared with 20 per cent two years ago.\nThe company said that despite a \u00a3300 price tag, its new Supersonic hairdryer had also become a UK bestseller within a month of its launch in April. In the run up to Christmas, it was the second highest selling item online at John Lewis after chocolate coins.\u00a0\nWhile the US remains Dyson's biggest market, much of its expansion last year came in Asia, with revenue growth of 200 per cent, 244 per cent and 266 per cent in China, the Philippines and Indonesia respectively. Sir James Dyson, the founder, said that many Chinese consumers had switched from brooms to cord-free vacuums.\nHe is keen to expand Dyson's portfolio beyond domestic products into new areas such as battery storage, \u00a3631m Dyson's profits last year, a rise of 41 per cent rise as turnover leapt 45 per cent robotics, artificial intelligence and, potentially, self-driving cars. \"We are developing different sorts of technology sometimes without knowing what it is going into,\" he said.\nThe company also opened its first retail store in the UK in London last year, where shoppers can try out its products, including using the cord-free vacuum on 56 types of dirt. It has similar stores in France, Japan, China, Indonesia and Russia and plans to take the number to 25 by the end of this year, including one in New York.\n\"As our product range gets much broader, we want to be able to explain it to people. If it's sitting on a hypermarket shelf, you can't do that,\" Sir James said.\nIn Britain the company is investing \u00a315 million to create a new university, the Dyson Institute of Technology, which will open in September. It also plans to build a 500-acre campus dedicated to artificial intelligence and robotics at its Hullavington site in Wiltshire, as part of a \u00a32.5 billion plan to take on Google and Facebook.\nThe investment at Hullavington, which is meant to be Dyson's answer to the 175-acre Apple Park in California, is part of the biggest investment in the UK by a technology firm since the Brexit vote.\nSir James said he believed that Britain's future had never been brighter, adding: \"It's absolutely the right thing to be self-governing and it's right to look towards the fastest growing markets in the world and to do our own trade negotiations with these countries. The future couldn't be brighter. I'm sure we will come to some agreements with the EU. If not, we will pay tariffs.\"\nDyson's investment at Hullavington comes after the opening last year of a research and development operation in Singapore. The company employs 3,500 engineers and scientists around the world and invests \u00a37 million a week in product development. It has more than tripled its headcount at its UK headquarters as it focuses on developing intellectual property to underpin future technology.\nMax Conze, chief executive, said: \"2016 was one of our best years yet, driven by new technology and international growth. Our future is best understood by looking at the new Dyson Demo stores. They get people handson with Dyson machines to understand the intelligent technology inside.\"\n"},
{"docid": "290 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "February 13, 2017", "title": "IBM to use Jeopardy! winning machine Watson to fight cyber attacks\u00a0\n", "content": "Perhaps better known for pitting its wits against the winners of a US television quiz show, IBM's artificial\u00a0intelligence asset is now being unleashed against cyber attackers.\nWatson, originally designed as a question answering machine, beat two of the most successful Jeopardy! contestants in 2011 and has since mastered tasks including providing music recommendations, helping with water conservation in California and personalising cancer care. It has now made another addition to its impressive skillset as the computing giant has launched a special version for helping to fight cyber attacks.\u00a0\nThe new look Watson can analyse the latest research into potential threats and apply its understanding to suspicious activity within companies' computer systems.\u00a0\nIBM has said the system can help thwart major hacks which have become a growing concern, hitting companies including Yahoo, Lloyds and TalkTalk. Artificial\u00a0intelligence can also fill a critical skills gap in the industry, which is expected to have a global shortfall of 1.5m security professionals by 2019.\nThe company says the system can help thwart the major hacks that have become a growing concern, hitting companies including\u00a0Yahoo,\u00a0Lloyds and TalkTalk. AI can also help fill a critical skills gap in the industry, which is expected to have a global shortfall of 1.5m security professionals by 2019.\u00a0\n                   Watch | The five worst ever cyber hacks                         02:06\nThe Watson security machine can solve problems in minutes that would take a human weeks, and save up to 20,000 hours a year spent chasing false alarms, IBM said. Having been trained for a year, it is now ready to be used within companies.\u00a0\n\"It can help companies find an advantage over the growing legions of cyber criminals and next generation threats,\" said Dennis Kennelly, vice president of technology at IBM Watson. \"Our investment in Watson for cyber security has given birth to several innovations in just under a year.\n\"It combines\u00a0the unique abilities of man and machine intelligence will be critical to the next stage in the fight against advanced cybercrime.\"\nWatson is an AI machine that can understand human language. The cyber security version\u00a0has been trained on over a\u00a0million security documents\u00a0and can now parse swathes of regularly updated research and apply it to its protection of a company's\u00a0network.\u00a0\nIBM isn't the first security company to employ AI in the fight against online crime. Darktrace, a British cybersecurity company valued at $400m (\u00a3320m), uses machine learning to understand the nuances of companies' computer systems and fight cyber attacks as they happen.\u00a0\nMost embarassing hacks of all time\nThe use of AI in cyber security is expected to triple in the next two years. Just 7pc of professionals work with it today,\u00a0according to IBM research.\u00a0\n\"Today's sophisticated cybersecurity threats attack on multiple fronts to conceal their activities, and our security analysts face the difficult task of pinpointing these attacks amongst a massive sea of security-related data,\" said Sean Valcamp, chief information security officer at Avnet, one of the companies working with Watson.\n\"Watson makes concealment efforts more difficult by quickly analysing multiple streams of data and comparing it with the latest security attack intelligence to provide a more complete picture of the threat.\"\nJon Oltsik, senior principal analyst at the Enterprise Strategy Group, said: \"It is well timed as organizations have continuing difficulty hiring experienced security analysts, while the threat landscape is increasing significantly.\"\u00a0\nAI timeline\n"},
{"docid": "291 of 297 DOCUMENTS\n", "source": "telegraph.co.uk\n", "date": "August 24, 2015", "title": "Digital afterlife: new social network posts updates after your death; A new social network claims to transform users into \"eternal beings\" using artificial intelligence to create virtual counterparts\n", "content": "Digital immortality has long been the subject of science fiction, from the Hollywood film <em class=\"italic\">Transcendence to Charlie Brooker's darkly satirical Channel 4 drama <em class=\"italic\">Black Mirror,<em class=\"italic\" />but a new social network claims to offer its users just that. \u00a0\nThe service, called Eter9, claims to learn your personality, using artificial intelligence (AI), and continue to post updates on your behalf after you have died, transforming users into \"eternal beings\". \nEter9 features a Facebook-like newsfeed, and a \"cortex\" that works much like a Facebook wall. You can also \"smile\" at things, which is similar to \"liking\" them on Facebook, and adopt virtual beings known as Niners to act as your \"assistants\". \nBy analysing what you share, and how you comment and interact with other users, Eter9 uses AI to create a virtual \"counterpart\" that can mimic your behaviour after your death. \nThe more you interact on the social network, the more your counterpart will learn, according to Eter9 creator Henrique Jorge, making interactions with both users and other virtual counterparts increasingly convincing. \n\"Eter9 makes it possible to eternalize the user and gives them the permanent ability to interact within the network 24/7 through an element called counterpart, which will be active even while the user is offline, both in terms of posting content and commenting,\" the company states on its website. \n\"The counterpart will also be responsible for the user's eternal life. The counterpart will absorb all the information according to the posts and comments, and process that information within the limits of the acquired knowledge.\"\nMr Jorge said the name Eter9 is the combination of \"Eter\" - the first four letters of the word \"Eternity\" -, and \"9\" - from the expression \"Cloud 9\", referring to a state of complete happiness. \nThe social network is only in the Beta stage, but 5,000 people have already signed up to use it - although some have described the concept as \"creepy\" or \"spooky\". \n\"We are trying to create an AI system that learns faster from other networks like Facebook, as the Eter9 information at the moment is quite small,\" Mr Jorge told BBC Newsbeat . \nThis is not the first internet site to promise eternal life in the online world. For example, an American company called Lifenaut offers the chance to make \"a rich back-up\" of your life by creating a digital avatar based on photos, voice recordings and other information. \nMeanwhile, Facebook recently rolled out its \"legacy contacts\" feature in the UK, allowing users to appoint an \"online executor\" of their profile to decide what happens to it after they die. \nThe legacy contact will be able to administer the page after the user passes away by writing one last post, updating their cover and profile photo and even approving new friend requests. \n"},
{"docid": "292 of 297 DOCUMENTS\n", "source": "The Guardian(London)\n", "date": "April 16, 2018", "title": "What depressed robots can teach us about mental health; The idea of a depressed computer may seem absurd - but artificial intelligence and the human brain share a vital feature\n", "content": "Depression seems a uniquely human way of suffering, but surprising new ways of thinking about it are coming from the field of artificial\u00a0intelligence. Worldwide, over 350 million people have depression, and rates are climbing. The success of today's generation of AI owes much to studies of the brain. Might AI return the favour and shed light on mental illness?\nThe central idea of computational neuroscience is that similar issues face any intelligent agent - human or artificial - and therefore call for similar sorts of solutions. Intelligence of any form is thought to depend on building a model of the world - a map of how things work that allows its owner to make predictions, plan and take actions to achieve its goals.\u00a0\nSetting the right degree of flexibility in learning is a critical problem for an intelligent system. A person's model of the world is built up slowly over years of experience. Yet sometimes everything changes from one day to the next - if you move to a foreign country, for instance. This calls for much more flexibility than usual. In AI, a global parameter that controls how flexible a model is - how fast it changes - is called the \"learning rate\".\nFailure to adapt to adversity may be one of the main reasons why humans get depressed. For example, someone who becomes disabled due to a severe injury suddenly needs to learn to view themselves in a new way. A person who does so may thrive, while a person who fails to may become depressed.\nThe idea of a depressed AI seems odd, but machines could face similar problems. Imagine a robot with a hardware malfunction. Perhaps it needs to learn a new way of grasping information. If its learning rate is not high enough, it may lack the flexibility to change its algorithms. If severely damaged, it might even need to adopt new goals. If it fails to adapt it could give up and stop trying.\nA \"depressed\" AI could be easily fixed by a supervisor boosting its learning rate. But imagine an AI sent light years away to another solar system. It would need to set its own learning rate, and this could go wrong.\nOne might think that the solution would be to keep flexibility high. But there is a cost to too much flexibility. If learning rate is too great, one is always forgetting what was previously learned and never accumulating knowledge. If goals are too flexible, an AI is rudderless, distracted by every new encounter.\nThe human brain's equivalent of an AI's key global variables is thought by computational psychiatrists to be several \"neuromodulators\", including the dopamine and serotonin systems. There are only a handful of these highly privileged groups of cells and they broadcast their special chemical messages to almost the entire brain.\n Related:  Brain preservation is a step closer, but how could it ever be 'you'? | Sue Blackmore\nA line of studies from my laboratory and others suggest that the brain's way of setting the learning rate involves the serotonin system. In the lab, if we teach a mouse a task with certain rules and then abruptly change them, serotonin neurons respond strongly. They seem to be broadcasting a signal of surprise: \"Oops! Time to change the model.\" Then, when serotonin is released in downstream brain areas, it can be seen in the laboratory to promote plasticity or rewiring, particularly to rework the circuitry of an outdated model.\nAntidepressants are typically selective serotonin reuptake inhibitors (SSRIs), which boost the availability of serotonin in the brain. Antidepressants are naively depicted as \"happiness pills\", but this research suggests that they actually work mainly by promoting brain plasticity. If true, getting out of\u00a0depression starts with flexibility.\nIf these ideas are on the right track, susceptibility to depression is one of the costs of the ability to adapt to an ever-changing environment. Today's AIs are learning machines, but highly specialised ones with no autonomy. As we take steps toward more flexible \"general AI\", we can expect to learn more about how this can go wrong, with more lessons for understanding not only depression but also conditions such as schizophrenia.\nFor a human, to be depressed is not merely to have a problem with learning, but to experience profound suffering. That is why, above all else, it is a condition that deserves our attention. For a machine, what looks like depression may involve no suffering whatsoever. But that does not mean that we cannot learn from machines how human brains might go wrong.\n\u00b7 Zachary Mainen is a neuroscientist whose research focuses on the brain mechanisms of decision-making\n"},
{"docid": "293 of 297 DOCUMENTS\n", "source": "The Guardian\n", "date": "January 22, 2015", "title": "Ex Machina review - an elegant but limited artificial intelligence thriller; Alex Garland's AI thriller feels a bit like a decent short story bulked out to movie length, but it's done with confidence\n", "content": "Star Rating: 3 stars\nScreenwriter and novelist Alex Garland upgrades to full auteur status, directing his own original script. It's a futurist thriller with classic generic antecedents, all about artificial intelligence becoming creepily indistinguishable from the human kind. Ex Machina feels like an elegant SF short story with a droll twist that has been pumped up and sexed up into an over-bulky feature film. But it's managed with confidence.\u00a0\n                     Domhnall Gleeson is Caleb, the geeky coder working for a software giant called Bluebook (like Google, but bigger and more important); imagine Caleb's excitement and fear when he wins an in-house competition to spend a week alone with the firm's reclusive, scarily Kurtzian founder, Nathan (bullishly played by Oscar Isaac), in his gigantic fortress of solitude on a private island - it looks like the one where they built Jurassic Park. The mindgames begin when Nathan tells Caleb his job is to interview the state-of-the-art female AI\u00a0robot he has invented and see if he\u00a0can detect any artificiality in her intelligence. This is the eerily gentle and\u00a0beautiful Ava, played by Alicia Vikander in a techno-raunchy exoskeleton. With great pathos, like the savage John in Aldous Huxley's great novel, Ava yearns dimly for a brave new world outside the compound. She is lonely. So is Caleb. Could it be that they are falling in love? Ex Machina has something of I,\u00a0Robot and the Siri-fantasy Her, and also a little of that gamey 70s classic Westworld. The interview scenes between Ava and Caleb are perhaps not as cerebral and involved as they could have been, the film's emphasis being more on a pornified robot-sexiness - whose thunder has perhaps been stolen by Jonathan Glazer's Under the Skin. With a sly dreaminess, Vikander steals the movie from the two males.\n"},
{"docid": "294 of 297 DOCUMENTS\n", "source": "The Guardian (London)\n", "date": "October 24, 1985", "title": "Computer Guardian (Micromaths): Thought that counts / The meaning of meaning\n", "content": "\u00a0\n Can machines think? Is artificial intelligence anything more than a ridiculous utopian dream - or, less charitably, a tremendous wheeze to squeeze huge research grants out of gullible governments? The high hopes of the early pioneers back in the sixties, together with the very sound of the phrase 'artificial intelligence,' gave way, in the face to a failure to come up with the perceived goodies, to the scepticism of the eighties. The grand title of 'intelligence' became the less overblown 'intelligent knowledge based system' (IKBS) and the even more modest 'expert system.' One danger of aiming high at the start is always that the subsequent advances will be regarded as failures. Skilful re-education can usually overcome that. Another danger, which can be harder to overcome, is that the belief may arise that the original goals really are unattainable.\n A small but growing number of workers are of the opinion that there is no apparent reason why machines cannot be made to 'understand' what they are doing. By which you may gather that one has to be very careful as to what is meant by that word 'understanding.' According to the computer pioneer Alan Turing, a machine may be said to 'intelligent' if its responses to question by a human user cannot be distinguished from human responses. (In other words, if you cannot decide whether the box contains a heap of silicon chips or a rather small person.)\u00a0\n\n When restricted to specific tasks systems available today will pass this test. Chess playing programs are an example. Such programs do not proceed in exactly the same way as a human, but then why should they? They have different hardware to make use of, so they operate in different ways. But in the final analysis they come up with the goods.\n But such examples exploit the fact that they are dealing with a well defined and highly specific domain, which allows the human programmer to incorporate into the system a whole range of insights which the program can make use of. In a wider context, even the best programs act in a pretty dumb fashion. Put crudely, computers do not understand the meaning of what it is they are asked to do. They just go through the motions as it were, shuffling symbols around as instructed. If I sit down and type in the word DINNER at my terminal, the computer will just look at this as a string of symbols. But when you read this word it immediately conjures up a mental concept: you form a picture of some kind of meal. Very likely your picture is not quite the same as the one I had when I typed the word just now. But I'll bet it has a lot in common all the same.\n Since the human brain is immensely complex, present technology does not look likely to produce machines able to associate mental concepts with words in the sophisticated way people do. But it may well be possible to develop a mathematical theory of meaning which works well enough to pass the Turing Test when implemented on a computer. (The hardware required may not yet be with us, but theoretical advances always precede the applications. Turing himself proved the theoretical possibility of building computers some years before their construction became a reality.) If this were possible, it would be justifiable to call the resulting activity inside the machine 'intelligent.' For the symbols being manipulated by the program would represent meanings. In its own restricted way the computer would be reasoning in a fashion similar to human beings.\n So what would a mathematical theory of meaning look like? Well, the beginnings of such a theory are already with us. As you might imagine, since it deals with something as hard to grasp as 'meaning', the theory looks pretty abstract, even by the heady standards of modern mathematics. Developed by Jon Barwise and John Perry of Stanford University in California, the theory takes ideas from Mathematics, Logic Philosophy, Cognitive Psychology, Linguistics, and Computer Science.\n The starting point for the new theory is to take a fresh look at the world around us. Traditionally, mathematics studies the world by regarding it as made up of points. lines, planes, and so on, and proceeds by developing methods for dealing with such abstractions. For a world where progress meant developments first of navigation around the globe and then later of more and more elaborate mechanical and electrical devices, this approach worked fine. But in order to study the elusive concept of meaning, a new way of looking at the world is required.\n Barwise and Perry regard the world as consisting of what they call 'situations.' These are abstractions from what would ordinarily be thought of as situations, and involve various agents (people, animals, computers, and inanimate objects) which interplay with each other to give rise to a complex flow of information amongst them. (I did warn you that the theory was pretty heady stuff.) By developing a mathematical Theory of Situations (much as geometry is a theory of points, lines, circles, and so on) it is possible to develop the notion of the meaning of language and information.\n Whether the Barwise-Perry approach will work as far as getting machines to think is still highly debatable. At this stage of the game it is also a pretty silly question to raise. Classical mathematics was around for at least two thousand years before much of it was used for the design of machines. Admittedly, we are not likely to have to wait quite as long to see if Situation Theory has any use, but with the subject scarcely four years old questions about usefulness are a bit premature. It may turn out that the theory is of greater use elsewhere. Maybe it will help us to understand how we ourselves operate. Who knows? Like all original research, most of the excitement lies in its being something of a magical mystery tour.\n"},
{"docid": "295 of 297 DOCUMENTS\n", "source": "Independent.co.uk\n", "date": "January 27, 2016", "title": "Google AlphaGo computer beats professional at 'world's most complex board game' Go; Milestone in AI researchlikened to defeat of world chess champion Garry Kasparov in 1997 by IBM's Deep Blue computer\n", "content": "It was considered one of the last great challenges between man and machine but now, for the first time, a computer program has beaten a professional player of the ancient Chinese game of Go in a defeat that many had not expected for at least another 10 years.\nThe machine's victory is being likened to the defeat of reigning world chess champion Garry Kasparov in 1997 by IBM's Deep Blue computer, which became a milestone in the advance of artificial intelligence over the human mind.\u00a0\nGo, however, is more complex than chess with an infinitely greater number of potential moves, so experts were surprised to find that computer scientists had invented a suite of artificial intelligence (AI) algorithms that taught the computer how to win against Europe's top player.\nRead more\n'Artificial\u00a0intelligence alarmists' win 'Luddite of the Year' award\nThe program, called AlphaGo, defeated European champion Fan Hui by a resounding five games to nil in a match played last October but only now revealed in a scientific study of the moves and algorithms published last night in the journal Nature. A match against the current world Go champion, Lee Sedol from South Korea, is now scheduled for March.\nIt was the first time a computer had won against a professional Go player on a full-sized board without any handicaps or advantages given to either side, said Demis Hassabis of Google DeepMind, the AI arm of Google in London, who helped to write the program.\nGo rules\nThe rules of Go are deceptively simple and no luck is involved. Two players - one black, one white - start with an empty board by placing one of their pieces or \"stones\" on a position, from where it does not move. The winner is the first to fill more than half the board with their stones. It is possible to take an opponent's stone by completely surrounding it with your stones. Children and adults can easily play against each other and a handicap system allows players of different strengths to play with a 50 per cent chance of winning.\n\"Go is the probably the most complex board game humans play. There are more configurations of the board than there are atoms in the Universe. In the end, AlphaGo won 5-nil and it was perhaps stronger than even we were expecting,\" Mr Hassabis said.\n\"AlphaGo discovered for itself many of the patterns and moves needed to play Go. Go is considered to be the pinnacle of AI research - the holy grail. For us, it was an irresistible challenge,\" he said.\nComputer chess programs work by analysing every possible move on the board but this is relatively straightforward when there are about 20 possible moves for each stage of the game. In Go, however, there are about 200 possible moves, making the task of writing a winning program far more difficult.\n\"The search process itself is not based on brute force but on something akin to [human] imagination. In the game of Go we need this incredibly complex intuitive machinery that we only previously thought to be possible in the human brain,\" said David Silver of Google DeepMind, the lead author of the study.\nAlphaGo uses two neural networks working in parallel and interacting with one another. A \"value network\" evaluated the positions of the black and white pieces or \"stones\" on the board, while a \"policy network\" selected the moves based on continuous learning of both past human moves and the program's own dummy moves, Mr Silver said.\nVideo: IBM's Watson defeats greatest '\nJeopardy!'\nchampions\n\"Humans can play perhaps a thousand games in a year whereas AlphaGo can play millions of games a day. It is conceivable with enough process power, training and search power that AlphaGo could reach a level that is beyond any human,\" he said.\nMilestones in AI Research\n1950:\n British mathematician Alan Turing published a landmark study speculating on the possibility of creating machines that can think - as defined by his Turing Test.\n1956:\n The field of Artificial Intelligence (AI) or \"machine intelligence\" was born with the Dartmouth Conference of researchers including Marvin Minsky talking about creating an artificial brain.\n1980s: \nConcept of \"expert systems\" widely adopted by computer companies as the first commercial exploitation of AI.\n1989: \nCarnegie Mellon University developed Deep Thought, an expert system that could play chess as well as a grand master.\n1997\n: IBM's Deep Blue computer beats reigning world chess champion Garry Kasparov for the first time.\n2005: \nA Stanford University robot won the Darpa Grand Challenge by driving autonomously for 131 miles along a rehearsed desert track.\n2011: \nIBM's Watson, a question-answering computer, defeated the two greatest champions in the American quiz show Jeopardy!, Brad Rutter and Ken Jennings. Watson won $1m first prize.\nIn tests against other Go computer games on the market, AlphaGo won all but one out of 500 games, even when other programs were given a head-start with pieces already positioned on the board. Mr Silver said the neural networks were able to learn by themselves, unlike the \"supervised\" training of other artificial intelligence algorithms.\n\"It learns in a human-like manner but it still takes a lot of practice. It has to play many millions of games to do what a human player can learn in a few games,\" Mr Silver said.\nWorld champion Lee Sedol said he is looking forward to the challenge match in March. \"I have heard that Google DeepMind's AI is surprisingly strong and getting stronger, but I am confident that I can win at least this time,\" he said.\nJon Diamond, president of the British Go Association, said: \"Before this match the best computer programs were not as good as the top amateur players and I was still expecting that it would be at least 5 or 10 years before a program would be able to beat the top human players; now it looks like this may be imminent. The proposed challenge may well be that day.\"\n"},
{"docid": "296 of 297 DOCUMENTS\n", "source": "The Independent\n", "date": "July 31 1989", "title": "Speed and efficiency taken to the letter\n", "content": "\u00a0\n THE average social security office does not present a high-tech image. The most modern piece of equipment on display is the ticket machine that gives you number 41 just as the indicator calls number 3 to be served.\n But it is a different matter at the Department of Social Security Central Office in Newcastle. Inside the temporary 1948 buildings a pioneering project is bringing the latest artificial intelligence techniques to provide the public with speedy, accurate and efficient service. These are not words commonly associated with the department.\u00a0\n\n But they are true of the Retirement Pensions Forecast and Advisory (RPFA) unit which now sends out 6,000 clear, personalised, laser-printed letters each week, telling inquirers their entitlement to retirement pension and explaining the effect of various choices before pension age.\n These forecasts used to be produced by local social security offices. But in 1984 the Department's reliance on letters addressed 'Dear Sir or Madam' was shaken by a critical report from the Ombudsman. An official who looked into the matter decided that too many of the 250,000 forecasts issued each year were 'inaccurate and incomprehensible'.\n The department called in management consultants Arthur Andersen to advise on the development of a microcomputer-based system to produce the forecasts by artificial intelligence. This radical idea was given a major boost by the Government's decision to encourage people to leave the state earnings-related pension scheme and make their own provision. The department had to provide individuals with clear and accurate information about their state pension entitlement so they could make their choice.\n The forecasts are now produced centrally at Newcastle by a team of 44 clerks using a network of 640K Compaq 286 PCs. The system software is the AION rule- based artificial intelligence system and is in four distinct parts.\n A database of rules represents the legislative provisions which determine a person's entitlement to retirement pension of various categories. The AION system stores and presents the rules and parameters as a relational database. It keeps track of each parameter and each rule and all their interactions. It makes the task of updating the system as the law changes relatively straightforward.\n The rules act on data held about the individual on the main National Insurance computer. Although the data for an individual is not large - compressed, it represents only 625 bytes - bringing it to the right place in the right form is a major task. The ICL 3980 holds records on 56 million people - dead and alive - on 35 gigabytes of main storage. Each Compaq station despatches a daily list of records required to the file-server which then sends an overnight batch of requests to the ICL mainframe. Next day the mainframe locates the records and returns the information to the file-server that night. The file-server sorts the records and sends them over the network to each Compaq 286 ready for the following morning. This two-day delay together with the postal service accounts for the bulk of the 10-day turnaround time which the unit now claims to offer.\n Once the data is available, the Compaq calculates the information for the individual inquirer. Everyone is given certain basic information about their contribution record, their likely pension and what will affect it. And those who have ticked certain 'what if' boxes on the application form are given extra answers to such questions as 'what if I stay at work until I am 70?'. It takes the Compaq about a minute to do the necessary work.\n A straightforward account of the person's record is printed out and stored with the application form in case of query. Then, the machine converts the information into a detailed personalised letter to the inquirer.\n This letter is the great glory of the system. More than half the time spent devising the whole system went into devising it. It is produced by the AION system using a database of rules and simple standard phrases which draw on the data calculated by the previous stage. Department officials describe the language as 'childspeak'. I call it plain English.\n 'Our records up to 5 April 1989 show that you do not have enough NI contributions to get the full amount of basic pension. You only have enough to get 85 per cent of the full amount. This would be pounds 37.06 a week if you were getting basic pension now. If you keep signing as unemployed for seven tax years between 6 April 1988 and 4 April 1998 you could get the full amount.'\n At four pages long, and beautifully printed on a Hewlett Packard LaserJet, the letter is like a personalised information leaflet.\n The RPFA Unit has just celebrated its first year. It has handled nearly 300,000 inquiries - 1,200 a day. It costs pounds 1m a year less than the old system. And, extraordinarily for any social security office, it has a bulging file of appreciative letters from members of the public.\n Back at the local office, number 32 has just been served and they are closing for the day. Perhaps I will be seen tomorrow.\n Any reader who wants his or her own forecast should get form BR19 from the local social security office.\n Science and Technology Page 15\n"},
{"docid": "297 of 297 DOCUMENTS\n", "source": "The New Review\n", "date": "November 15, 2015", "title": "Aleks Krotoski; CREDO The social psychologist on being a troll, artificial intelligence and what wakes her up in the middle of the night\n", "content": "I FOUND IT LIBERATING TO BE AN INTERNET TROLL UNTIL I GOT MY COMEUPPANCE\nThe first time I went into an internet chatroom was in 1996. I pretended to be a boy and I found it freeing. I thought, \"Oh wow, no one knows who I am.\" I was saying stupid things and picking on certain people, but I was just thinking about how I could say whatever I wanted. But the community took the wind out of my sails and no one responded to me any more, and that was my lesson learnt. Anonymity is essential in life to try on different identities and explore different aspects of ourselves, but if you use that anonymity to attack someone, there can be a lot of repercussions.\nTHE INTERNET IS JUST AN EXTENSION OF OURSELVES\u00a0\nWe like to take the fault away from ourselves and blame technology for exacerbating issues such as, say, bullying or extremism, but all the internet does is connect human beings to human beings - it doesn't do anything to you.\nARTIFICIAL INTELLIGENCE NEEDS TO BE MORE POLITE\nOver the past few months I've been living in a smart home using [the voice-controlled] Amazon Echo, this black tube with a blue light that's in the kitchen, and it's always listening. I use her to do things such as turn on music or add to shopping lists. But, unlike Siri, the thing is damn rude and that pisses me off. I want to say, \"Please can you do this\" or \"Thank you\" as it's how I was brought up. But there's no \"You're welcome\" or \"I live to serve\" or any of the things that Siri says if you thank her. So I'm not polite back. But when you pair that with having kids in the house, they start thinking, well, mummy doesn't bother with niceties. As AI at home becomes more commonplace, we need to think more about how they interface with humans.\nTHE JAPANESE APPROACH TO TECH SAYS A LOT ABOUT THEIR WORLDVIEW\nI went to Japan recently and it's interesting how they are looking at the issues they face with a decreasing population. Rather than look at finding more carers for the elderly, which would be supported by immigration, they are looking to technology: they're more comfortable with robotic carers than bringing a lot of unknown people into their private space.\nPEOPLE SITTING AT A TABLE LOOKING AT THEIR PHONES FREAKS ME OUT\n[Before the advent of smartphones], you used to be able to see what someone was engaging with, but now I'm not sure whether they are looking at porn or reading about the Declaration of Independence. All I can see is the back of a device, and I can't participate with someone at the table, and that bugs me.\nVISITING LANDSCAPES PUTS YOU BACK IN YOUR PLACE\nIf I'm sitting on the beach in Los Angeles, watching the sunset or hiking in Scotland, it gives me moments of non-frantic stillness when I'm not just sprinting around; all you can do is enjoy the view. And I've realised that not finishing that podcast or not writing that article or not making the best meal in the world is OK, as there is a giant world out there that has been around a hell of a lot longer than me, and will be there a hell of a lot longer after - just let it go, man!\nI FEEL SO COMPELLED TO BAKE THAT I'LL WAKE UP IN THE MIDDLE OF THE NIGHT TO DO IT Right now, in LA, I'm smack in the middle of what we call baking season, which begins around this time and goes on until the last week of January. I get inspired, it's a wonderful period. Last season I made 34 pies, so I finally learnt how to make pie crust. *\nAleks Krotoski, 41, is a social psychologist, broadcaster and technology writer, whose books include 'Untangling the Web' and 'Learning and Research in Virtual Worlds'. She is also the presenter of the BBC Radio 4 series 'Digital Human' (alekskrotoski.com)\nPortrait by Kevin Meredith\n"}
]
